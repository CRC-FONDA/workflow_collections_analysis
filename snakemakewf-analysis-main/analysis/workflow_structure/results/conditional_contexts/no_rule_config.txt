repo=epigen/unsupervised_analysis, file=workflow/Snakefile
context_key: ['if config["umap"]["connectivity"]==1']
    (26, 'if config["umap"]["connectivity"]==1:')
    (27, "    umap_content.append(\\'connectivity\\')")
    (28, "    densmap_content.append(\\'connectivity\\')")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=epigen/unsupervised_analysis, file=workflow/Snakefile
context_key: ['if config["umap"]["diagnostics"]==1']
    (29, 'if config["umap"]["diagnostics"]==1:')
    (30, "    umap_content.append(\\'diagnostics\\')")
    (31, "    densmap_content.append(\\'diagnostics\\')")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Ovewh/Climaso, file=workflow/Snakefile
context_key: ['try', "if config.get(\\'lookup_file_endings_NorESM\\', None)"]
    (56, "    if config.get(\\'lookup_file_endings_NorESM\\', None):")
    (57, "        with open(config[\\'lookup_file_endings_NorESM\\'], \\'r\\') as f:")
    (58, '            LOOK_FNAMES_NORESM = yaml.safe_load(f)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=akcorut/kGWASflow, file=workflow/rules/count_kmers.smk
context_key: ['if config["settings"]["trimming"]["activate"]', 'rule generate_input_lists', 'input']
    (60, 'if config["settings"]["trimming"]["activate"]:')
    (61, '    rule generate_input_lists:')
    (62, '        input:')
    (63, '            r1 = expand(rules.cutadapt_pe.output.fastq1, zip,')
    (64, '                        sample=sample_names,')
    (65, '                        library=library_names),')
    (66, '            r2 = expand(rules.cutadapt_pe.output.fastq2, zip,')
    (67, '                        sample=sample_names,')
    (68, '                        library=library_names),')
    (69, '            qc= "results/qc/multiqc.html"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=akcorut/kGWASflow, file=workflow/rules/count_kmers.smk
context_key: ['if config["settings"]["trimming"]["activate"]', 'rule generate_input_lists', 'output']
    (70, '        output:')
    (71, '            "results/trimmed/{sample}/input_files.txt"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=akcorut/kGWASflow, file=workflow/rules/count_kmers.smk
context_key: ['if config["settings"]["trimming"]["activate"]', 'rule generate_input_lists', 'params']
    (72, '        params:')
    (73, '            prefix = get_input_path_for_generate_input_lists()')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=akcorut/kGWASflow, file=workflow/rules/count_kmers.smk
context_key: ['if config["settings"]["trimming"]["activate"]', 'rule generate_input_lists', 'log']
    (74, '        log:')
    (75, '            "logs/generate_input_lists/{sample}/{sample}_generate_input_lists.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=akcorut/kGWASflow, file=workflow/rules/count_kmers.smk
context_key: ['if config["settings"]["trimming"]["activate"]', 'rule generate_input_lists', 'message']
    (76, '        message:')
    (77, '            "Generating input list files..."')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=akcorut/kGWASflow, file=workflow/rules/count_kmers.smk
context_key: ['if config["settings"]["trimming"]["activate"]', 'rule generate_input_lists', 'script']
    (78, '        script:')
    (79, '            "../scripts/generate_input_lists.py"')
    (80, '')
    (81, '# =================================================================================================')
    (82, '#     KMC with canonization')
    (83, '# =================================================================================================')
    (84, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=akcorut/kGWASflow, file=workflow/rules/align_kmers.smk
context_key: ['if config["settings"]["align_kmers"]["use_bowtie"]', 'rule align_kmers', 'input']
    (4, 'if config["settings"]["align_kmers"]["use_bowtie"]:')
    (5, '    rule align_kmers:')
    (6, '        input:')
    (7, '            kmers_list = "results/fetch_kmers/{phenos_filt}_kmers_list.fa",')
    (8, '            index = rules.bowtie_build.output')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=akcorut/kGWASflow, file=workflow/rules/align_kmers.smk
context_key: ['if config["settings"]["align_kmers"]["use_bowtie"]', 'rule align_kmers', 'output']
    (9, '        output:')
    (10, '            "results/align_kmers/{phenos_filt}/{phenos_filt}_kmers_alignment.sam"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=akcorut/kGWASflow, file=workflow/rules/align_kmers.smk
context_key: ['if config["settings"]["align_kmers"]["use_bowtie"]', 'rule align_kmers', 'params']
    (11, '        params:')
    (12, '            index = "resources/ref/genome/bowtie_index/genome",')
    (13, '            extra = config["params"]["bowtie"]["extra"]')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=akcorut/kGWASflow, file=workflow/rules/align_kmers.smk
context_key: ['if config["settings"]["align_kmers"]["use_bowtie"]', 'rule align_kmers', 'conda']
    (14, '        conda:')
    (15, '            "../envs/align_kmers.yaml"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=akcorut/kGWASflow, file=workflow/rules/align_kmers.smk
context_key: ['if config["settings"]["align_kmers"]["use_bowtie"]', 'rule align_kmers', 'threads']
    (16, '        threads:')
    (17, '            config["params"]["bowtie"]["threads"]')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=akcorut/kGWASflow, file=workflow/rules/align_kmers.smk
context_key: ['if config["settings"]["align_kmers"]["use_bowtie"]', 'rule align_kmers', 'log']
    (18, '        log:')
    (19, '            "logs/align_kmers/{phenos_filt}_kmers_align.bowtie.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=akcorut/kGWASflow, file=workflow/rules/align_kmers.smk
context_key: ['if config["settings"]["align_kmers"]["use_bowtie"]', 'rule align_kmers', 'message']
    (20, '        message:')
    (21, '            "Aligning signficant k-mers to the reference genome..."')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=akcorut/kGWASflow, file=workflow/rules/align_kmers.smk
context_key: ['if config["settings"]["align_kmers"]["use_bowtie"]', 'rule align_kmers', 'shell']
    (22, '        shell:')
    (23, '            """')
    (24, '            bowtie -p {threads} -a --best --strata {params.extra} \\\\')
    (25, '            -x {params.index} -f {input.kmers_list} --sam {output} 2> {log}')
    (26, '            """')
    (27, '')
    (28, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=akcorut/kGWASflow, file=workflow/rules/align_kmers.smk
context_key: ['if config["settings"]["align_kmers"]["use_bowtie2"]', 'rule align_kmers', 'input']
    (29, 'if config["settings"]["align_kmers"]["use_bowtie2"]:')
    (30, '    rule align_kmers:')
    (31, '        input:')
    (32, '            kmers_list = "results/fetch_kmers/{phenos_filt}_kmers_list.fa",')
    (33, '            index = rules.bowtie2_build.output')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=akcorut/kGWASflow, file=workflow/rules/align_kmers.smk
context_key: ['if config["settings"]["align_kmers"]["use_bowtie2"]', 'rule align_kmers', 'output']
    (34, '        output:')
    (35, '            "results/align_kmers/{phenos_filt}/{phenos_filt}_kmers_alignment.sam"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=akcorut/kGWASflow, file=workflow/rules/align_kmers.smk
context_key: ['if config["settings"]["align_kmers"]["use_bowtie2"]', 'rule align_kmers', 'params']
    (36, '        params:')
    (37, '            index = "resources/ref/genome/bowtie2_index/genome",')
    (38, '            extra = config["params"]["bowtie2"]["extra"]')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=akcorut/kGWASflow, file=workflow/rules/align_kmers.smk
context_key: ['if config["settings"]["align_kmers"]["use_bowtie2"]', 'rule align_kmers', 'conda']
    (39, '        conda:')
    (40, '            "../envs/align_kmers.yaml"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=akcorut/kGWASflow, file=workflow/rules/align_kmers.smk
context_key: ['if config["settings"]["align_kmers"]["use_bowtie2"]', 'rule align_kmers', 'threads']
    (41, '        threads:')
    (42, '            config["params"]["bowtie2"]["threads"]')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=akcorut/kGWASflow, file=workflow/rules/align_kmers.smk
context_key: ['if config["settings"]["align_kmers"]["use_bowtie2"]', 'rule align_kmers', 'log']
    (43, '        log:')
    (44, '            "logs/align_kmers/{phenos_filt}_kmers_align.bowtie2.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=akcorut/kGWASflow, file=workflow/rules/align_kmers.smk
context_key: ['if config["settings"]["align_kmers"]["use_bowtie2"]', 'rule align_kmers', 'message']
    (45, '        message:')
    (46, '            "Aligning signficant k-mers to the reference genome..."')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=akcorut/kGWASflow, file=workflow/rules/align_kmers.smk
context_key: ['if config["settings"]["align_kmers"]["use_bowtie2"]', 'rule align_kmers', 'shell']
    (47, '        shell:')
    (48, '            """')
    (49, '            bowtie2 -p {threads} {params.extra} \\\\')
    (50, '            -x {params.index} -f {input.kmers_list} -S {output} 2> {log}')
    (51, '            """')
    (52, '')
    (53, '# =======================================================================================================')
    (54, '#     Convert SAM outputs to BAM format')
    (55, '# =======================================================================================================')
    (56, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=akcorut/kGWASflow, file=workflow/rules/fetch_reads.smk
context_key: ['if config["settings"]["trimming"]["activate"]', 'rule fetch_source_reads', 'input']
    (62, 'if config["settings"]["trimming"]["activate"]:')
    (63, '    rule fetch_source_reads:')
    (64, '        input:')
    (65, '            kmers_tab = "results/filter_kmers/{phenos_filt}_kmers_table.txt",')
    (66, '            kmers_list = "results/fetch_kmers/{phenos_filt}_kmers_list.fa",')
    (67, '            fetch_reads = "scripts/external/fetch_reads_with_kmers/fetch_reads",')
    (68, '            filter_kmers = "results/filter_kmers/filter_kmers.done",')
    (69, '            r1 = expand(rules.cutadapt_pe.output.fastq1, zip,')
    (70, '                            sample=sample_names,')
    (71, '                            library=library_names),')
    (72, '            r2 = expand(rules.cutadapt_pe.output.fastq2, zip,')
    (73, '                            sample=sample_names,')
    (74, '                            library=library_names),')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=akcorut/kGWASflow, file=workflow/rules/fetch_reads.smk
context_key: ['if config["settings"]["trimming"]["activate"]', 'rule fetch_source_reads', 'output']
    (75, '        output:')
    (76, '            dir = directory("results/fetch_reads_with_kmers/{phenos_filt}"),')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=akcorut/kGWASflow, file=workflow/rules/fetch_reads.smk
context_key: ['if config["settings"]["trimming"]["activate"]', 'rule fetch_source_reads', 'params']
    (77, '        params:')
    (78, '            kmers_list_prefix = lambda w, input: os.path.dirname(input.kmers_list),')
    (79, '            out_prefix = lambda w, output: os.path.dirname(output[0]),')
    (80, '            samples= sample_names,')
    (81, '            library= library_names,')
    (82, '            pheno = "{phenos_filt}",')
    (83, '            kmer_len = config["params"]["kmc"]["kmer_len"]')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=akcorut/kGWASflow, file=workflow/rules/fetch_reads.smk
context_key: ['if config["settings"]["trimming"]["activate"]', 'rule fetch_source_reads', 'log']
    (84, '        log:')
    (85, '            "logs/fetch_reads_with_kmers/{phenos_filt}/fetch_source_reads_of_kmers.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=akcorut/kGWASflow, file=workflow/rules/fetch_reads.smk
context_key: ['if config["settings"]["trimming"]["activate"]', 'rule fetch_source_reads', 'threads']
    (86, '        threads: ')
    (87, '            config["params"]["fetch_reads"]["threads"]')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=akcorut/kGWASflow, file=workflow/rules/fetch_reads.smk
context_key: ['if config["settings"]["trimming"]["activate"]', 'rule fetch_source_reads', 'message']
    (88, '        message:')
    (89, '            "Fetching reads that contain significant k-mers find in {input.kmers_list}..."    ')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=akcorut/kGWASflow, file=workflow/rules/fetch_reads.smk
context_key: ['if config["settings"]["trimming"]["activate"]', 'rule fetch_source_reads', 'script']
    (90, '        script:')
    (91, '            "../scripts/fetch_source_reads.py"')
    (92, '')
    (93, '')
    (94, '# =========================================================================================================')
    (95, '#     Aggregate fetch_source_reads outputs')
    (96, '# =========================================================================================================')
    (97, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/mosaicatcher-pipeline, file=workflow/rules/plots.smk
context_key: ['if config["ashleys_pipeline"] is False', 'rule plot_mosaic_counts', 'input']
    (9, 'if config["ashleys_pipeline"] is False:')
    (10, '')
    (11, '    rule plot_mosaic_counts:')
    (12, '        input:')
    (13, '            counts="{folder}/{sample}/counts/{sample}.txt.raw.gz",')
    (14, '            info="{folder}/{sample}/counts/{sample}.info_raw",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/mosaicatcher-pipeline, file=workflow/rules/plots.smk
context_key: ['if config["ashleys_pipeline"] is False', 'rule plot_mosaic_counts', 'output']
    (15, '        output:')
    (16, '            "{folder}/{sample}/plots/counts/CountComplete.classic.pdf",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/mosaicatcher-pipeline, file=workflow/rules/plots.smk
context_key: ['if config["ashleys_pipeline"] is False', 'rule plot_mosaic_counts', 'log']
    (17, '        log:')
    (18, '            "{folder}/log/plot_mosaic_counts/{sample}.log",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/mosaicatcher-pipeline, file=workflow/rules/plots.smk
context_key: ['if config["ashleys_pipeline"] is False', 'rule plot_mosaic_counts', 'conda']
    (19, '        conda:')
    (20, '            "../envs/rtools.yaml"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/mosaicatcher-pipeline, file=workflow/rules/plots.smk
context_key: ['if config["ashleys_pipeline"] is False', 'rule plot_mosaic_counts', 'resources']
    (21, '        resources:')
    (22, '            mem_mb=get_mem_mb,')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/mosaicatcher-pipeline, file=workflow/rules/plots.smk
context_key: ['if config["ashleys_pipeline"] is False', 'rule plot_mosaic_counts', 'shell']
    (23, '        shell:')
    (24, '            """')
    (25, '            LC_CTYPE=C Rscript workflow/scripts/plotting/qc.R {input.counts} {input.info} {output} > {log} 2>&1')
    (26, '            """')
    (27, '')
    (28, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/mosaicatcher-pipeline, file=workflow/rules/common.smk
context_key: ['if config["genecore"] is False']
    (21, 'if config["genecore"] is False:')
    (22, '    l_samples = os.listdir(config["data_location"])')
    (23, '    assert (')
    (24, '        "fastq" not in l_samples')
    (25, '    ), "fastq folder found in the {} data_location specified: please specify a parent folder".format(')
    (26, '        config["data_location"]')
    (27, '    )')
    (28, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/mosaicatcher-pipeline, file=workflow/rules/common.smk
context_key: ['if config["ashleys_pipeline"] is True']
    (45, 'if config["ashleys_pipeline"] is True:')
    (46, '    assert (')
    (47, '        config["ashleys_pipeline"] != config["input_old_behavior"]')
    (48, '    ), "ashleys_pipeline and input_old_behavior parameters cannot both be set to True"')
    (49, '')
    (50, '')
    (51, '# Configure if handle_input needs to be based on bam or fastq')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/mosaicatcher-pipeline, file=workflow/Snakefile
context_key: ['if config["ashleys_pipeline"] is True', 'snakefile']
    (19, 'if config["ashleys_pipeline"] is True:')
    (20, '')
    (21, '    module ashleys_qc:')
    (22, '        snakefile:')
    (23, '            github(')
    (24, '                "friendsofstrandseq/ashleys-qc-pipeline",')
    (25, '                path="workflow/Snakefile",')
    (26, '                tag="1.3.2"')
    (27, '                # branch="main",')
    (28, '                # branch="dev",')
    (29, '            )')
    (30, '        config:')
    (31, '            config')
    (32, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/mosaicatcher-pipeline, file=workflow/Snakefile
context_key: ['if config["ashleys_pipeline"] is True']
    (33, '    use rule * from ashleys_qc as ashleys_*')
    (34, '')
    (35, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/mosaicatcher-pipeline, file=workflow/Snakefile
context_key: ['if config["ashleys_pipeline"] is True', 'rule all', 'input']
    (81, 'if config["ashleys_pipeline"] is True:')
    (82, '')
    (83, '    rule all:')
    (84, '        input:')
    (85, '            rules.ashleys_all.input,')
    (86, '            get_final_output(),')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/mosaicatcher-pipeline, file=workflow/Snakefile
context_key: ['if config["ashleys_pipeline"] is True', 'rule all', 'default_target']
    (87, '        default_target: True')
    (88, '')
    (89, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/mosaicatcher-pipeline, file=workflow/Snakefile
context_key: ['else', 'if config["dl_external_files"] is False and config["dl_bam_example"] is False', 'rule all', 'input']
    (91, '    if config["dl_external_files"] is False and config["dl_bam_example"] is False:')
    (92, '')
    (93, '        rule all:')
    (94, '            input:')
    (95, '                get_final_output(),')
    (96, '')
    (97, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/mosaicatcher-pipeline, file=workflow/Snakefile
context_key: ['else', 'else', 'if config["dl_bam_example"] is True and config["dl_external_files"] is False', 'rule all', 'input']
    (100, '        if config["dl_bam_example"] is True and config["dl_external_files"] is False:')
    (101, '')
    (102, '            rule all:')
    (103, '                input:')
    (104, '                    rules.dl_example_data.output,')
    (105, '')
    (106, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/mosaicatcher-pipeline, file=workflow/Snakefile
context_key: ['else', 'else', 'if config["reference"] == "hg19"', 'rule all', 'input']
    (112, '            if config["reference"] == "hg19":')
    (113, '')
    (114, '                rule all:')
    (115, '                    input:')
    (116, '                        rules.download_hg19_reference.output,')
    (117, '')
    (118, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/mosaicatcher-pipeline, file=workflow/Snakefile
context_key: ['else', 'else', 'if config["reference"] == "hg19"', 'elif config["reference"] == "hg38"', 'rule all', 'input']
    (119, '            elif config["reference"] == "hg38":')
    (120, '')
    (121, '                rule all:')
    (122, '                    input:')
    (123, '                        rules.download_hg38_reference.output,')
    (124, '')
    (125, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/mosaicatcher-pipeline, file=workflow/Snakefile
context_key: ['else', 'else', 'if config["reference"] == "hg19"', 'elif config["reference"] == "T2T"', 'rule all', 'input']
    (126, '            elif config["reference"] == "T2T":')
    (127, '')
    (128, '                rule all:')
    (129, '                    input:')
    (130, '                        [')
    (131, '                            rules.download_T2T_reference.output,')
    (132, '                            rules.install_T2T_BSgenome_tarball.output,')
    (133, '                        ],')
    (134, '')
    (135, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/mosaicatcher-pipeline, file=workflow/Snakefile
context_key: ['if config["email"]', 'onsuccess']
    (136, 'if config["email"]:')
    (137, '')
    (138, '    onsuccess:')
    (139, '        onsuccess_fct(log)')
    (140, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/mosaicatcher-pipeline, file=workflow/Snakefile
context_key: ['if config["email"]', 'onerror']
    (141, '    onerror:')
    (142, '        onerror_fct(log)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=epigen/scrnaseq_processing_seurat, file=workflow/Snakefile
context_key: ['if config["split_by"] is not None']
    (27, 'if config["split_by"] is not None:')
    (28, '    for split in config["split_by"]:')
    (29, '        data_splits.extend(["{}_{}".format(split, value) for value in config["split_by"][split]])')
    (30, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=epigen/scrnaseq_processing_seurat, file=workflow/Snakefile
context_key: ['if config["stop_after"]=="CORRECTED"']
    (33, 'if config["stop_after"]=="CORRECTED":')
    (34, '    plot_steps = ["NORMALIZED","CORRECTED"]')
    (35, '    metadata_plot_steps = all_steps[:all_steps.index(config["stop_after"])]')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=epigen/scrnaseq_processing_seurat, file=workflow/Snakefile
context_key: ['elif config["stop_after"]=="NORMALIZED"']
    (36, 'elif config["stop_after"]=="NORMALIZED":')
    (37, '    plot_steps = ["NORMALIZED"]')
    (38, '    metadata_plot_steps = all_steps[:all_steps.index(config["stop_after"])+1]')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=solida-core/musta, file=workflow/rules/common.smk
context_key: ['if config.get("run").get("call")', 'if "tumor_bam" in samples_master[sample]']
    (19, '        if config.get("run").get("call"):')
    (20, '            if "tumor_bam" in samples_master[sample]:')
    (21, '                samples.append(sample)')
    (22, '            else:')
    (23, '                pass')
    (24, '        elif config.get("run").get("annotate"):')
    (25, '            if "vcf" in samples_master[sample]:')
    (26, '                samples.append(sample)')
    (27, '            else:')
    (28, '                pass')
    (29, '        elif config.get("run").get("analysis"):')
    (30, '            if "maf" in samples_master[sample]:')
    (31, '                samples.append(sample)')
    (32, '            else:')
    (33, '                pass')
    (34, '        else:')
    (35, '            if "tumor_bam" in samples_master[sample]:')
    (36, '                samples.append(sample)')
    (37, '            else:')
    (38, '                pass')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=solida-core/musta, file=workflow/Snakefile
context_key: ['if config.get("run").get("all")', 'rule all', 'input']
    (20, 'if config.get("run").get("all"):')
    (21, '')
    (22, '    rule all:')
    (23, '        input:')
    (24, '            expand(')
    (25, '                resolve_results_filepath(')
    (26, '                    config.get("paths").get("results_dir"),')
    (27, '                    "results/{sample}_somatic_filtered_selected.vcf.gz",')
    (28, '                ),')
    (29, '                sample=list(samples_master.keys()),')
    (30, '            ),')
    (31, '            expand(')
    (32, '                resolve_results_filepath(')
    (33, '                    config.get("paths").get("results_dir"),')
    (34, '                    "results/annotation/funcotator/{sample}_funcotated.maf",')
    (35, '                ),')
    (36, '                sample=list(samples_master.keys()),')
    (37, '            ),')
    (38, '            resolve_single_filepath(')
    (39, '                config.get("paths").get("results_dir"),')
    (40, '                "results/analysis/signatures/plots/cosmic_signatures.png",')
    (41, '            ),')
    (42, '            resolve_single_filepath(')
    (43, '                config.get("paths").get("results_dir"),')
    (44, '                "results/analysis/driver/plots/somatic_interactions.png",')
    (45, '            ),')
    (46, '            resolve_single_filepath(')
    (47, '                config.get("paths").get("results_dir"),')
    (48, '                "results/analysis/base/plots/top10_VAF.png",')
    (49, '            ),')
    (50, '            resolve_single_filepath(')
    (51, '                config.get("paths").get("results_dir"),')
    (52, '                "results/analysis/pathways/plots/oncogenic_pathways.png",')
    (53, '            ),')
    (54, '            resolve_single_filepath(')
    (55, '                config.get("paths").get("results_dir"),')
    (56, '                "results/analysis/heterogeneity/tables/successful.tsv",')
    (57, '            ),')
    (58, '')
    (59, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=solida-core/musta, file=workflow/Snakefile
context_key: ['if config.get("run").get("call")', 'rule call', 'input']
    (60, 'if config.get("run").get("call"):')
    (61, '')
    (62, '    rule call:')
    (63, '        input:')
    (64, '            expand(')
    (65, '                resolve_results_filepath(')
    (66, '                    config.get("paths").get("results_dir"),')
    (67, '                    "results/{sample}_somatic_filtered_selected.vcf.gz",')
    (68, '                ),')
    (69, '                sample=list(samples_master.keys()),')
    (70, '            ),')
    (71, '')
    (72, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=solida-core/musta, file=workflow/Snakefile
context_key: ['if config.get("run").get("annotate")', 'rule annotate', 'input']
    (73, 'if config.get("run").get("annotate"):')
    (74, '')
    (75, '    rule annotate:')
    (76, '        input:')
    (77, '            expand(')
    (78, '                resolve_results_filepath(')
    (79, '                    config.get("paths").get("results_dir"),')
    (80, '                    "results/annotation/funcotator/{sample}_funcotated.maf",')
    (81, '                ),')
    (82, '                sample=list(samples_master.keys()),')
    (83, '            ),')
    (84, '')
    (85, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=solida-core/musta, file=workflow/Snakefile
context_key: ['if config.get("run").get("analysis")', 'rule analysis', 'input']
    (86, 'if config.get("run").get("analysis"):')
    (87, '')
    (88, '    rule analysis:')
    (89, '        input:')
    (90, '            resolve_single_filepath(')
    (91, '                config.get("paths").get("results_dir"),')
    (92, '                "results/analysis/signatures/plots/cosmic_signatures.png",')
    (93, '            ),')
    (94, '            resolve_single_filepath(')
    (95, '                config.get("paths").get("results_dir"),')
    (96, '                "results/analysis/driver/plots/somatic_interactions.png",')
    (97, '            ),')
    (98, '            resolve_single_filepath(')
    (99, '                config.get("paths").get("results_dir"),')
    (100, '                "results/analysis/base/plots/top10_VAF.png",')
    (101, '            ),')
    (102, '            resolve_single_filepath(')
    (103, '                config.get("paths").get("results_dir"),')
    (104, '                "results/analysis/pathways/plots/oncogenic_pathways.png",')
    (105, '            ),')
    (106, '            resolve_single_filepath(')
    (107, '                config.get("paths").get("results_dir"),')
    (108, '                "results/analysis/heterogeneity/tables/successful.tsv",')
    (109, '            ),')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SilkeAllmannLab/pacbio_snakemake, file=workflow/Snakefile
context_key: ['if config["genome"]["map_to_genome"] == True', 'rule all', 'message']
    (63, '        message:')
    (64, '            "PacBio IsoSeq Snakemake pipeline successfully run (with genome alignment \\\'on\\\')."')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SilkeAllmannLab/pacbio_snakemake, file=workflow/Snakefile
context_key: ['elif config["genome"]["map_to_genome"] == False', 'rule all', 'input']
    (65, 'elif config["genome"]["map_to_genome"] == False:')
    (66, '    rule all:')
    (67, '        input:')
    (68, '            TRANSCRIPTS')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SilkeAllmannLab/pacbio_snakemake, file=workflow/Snakefile
context_key: ['elif config["genome"]["map_to_genome"] == False', 'rule all', 'message']
    (69, '        message:')
    (70, '            "PacBio IsoSeq Snakemake pipeline successfully run (genome alignment \\\'off\\\')."')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SilkeAllmannLab/pacbio_snakemake, file=workflow/Snakefile
context_key: ['if config["genome"]["map_to_genome"] == False', 'rule export_transcripts_to_fasta', 'input']
    (170, 'if config["genome"]["map_to_genome"] == False:')
    (171, '    rule export_transcripts_to_fasta:')
    (172, '        input: ')
    (173, '            transcripts_bam = config["working_dir"] + "04_transcripts/{sample}.transcripts.bam" ')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SilkeAllmannLab/pacbio_snakemake, file=workflow/Snakefile
context_key: ['if config["genome"]["map_to_genome"] == False', 'rule export_transcripts_to_fasta', 'output']
    (174, '        output:')
    (175, '            transcripts_fasta = config["result_dir"] + "{sample}.transcripts.fasta"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SilkeAllmannLab/pacbio_snakemake, file=workflow/Snakefile
context_key: ['if config["genome"]["map_to_genome"] == False', 'rule export_transcripts_to_fasta', 'message']
    (176, '        message:')
    (177, '            "Exporting {wildcards.sample} transcripts in the {output} file"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SilkeAllmannLab/pacbio_snakemake, file=workflow/Snakefile
context_key: ['if config["genome"]["map_to_genome"] == False', 'rule export_transcripts_to_fasta', 'conda']
    (178, '        conda:')
    (179, '            "envs/samtools.yaml"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SilkeAllmannLab/pacbio_snakemake, file=workflow/Snakefile
context_key: ['if config["genome"]["map_to_genome"] == False', 'rule export_transcripts_to_fasta', 'shell']
    (180, '        shell:')
    (181, '            "samtools fasta -o {output} {input}"  ')
    (182, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SilkeAllmannLab/pacbio_snakemake, file=workflow/Snakefile
context_key: ['if config["genome"]["map_to_genome"] == True', 'rule generate_genome_index', 'input']
    (183, 'if config["genome"]["map_to_genome"] == True:')
    (184, '    rule generate_genome_index:')
    (185, '        input:')
    (186, '            config["genome"]["genome_fasta_ref"]')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SilkeAllmannLab/pacbio_snakemake, file=workflow/Snakefile
context_key: ['if config["genome"]["map_to_genome"] == True', 'rule generate_genome_index', 'output']
    (187, '        output: ')
    (188, '            config["working_dir"] + "05_minimap/genome.mmi"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SilkeAllmannLab/pacbio_snakemake, file=workflow/Snakefile
context_key: ['if config["genome"]["map_to_genome"] == True', 'rule generate_genome_index', 'conda']
    (189, '        conda:')
    (190, '            "envs/pbmm2.yaml"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SilkeAllmannLab/pacbio_snakemake, file=workflow/Snakefile
context_key: ['if config["genome"]["map_to_genome"] == True', 'rule generate_genome_index', 'threads']
    (191, '        threads: 30')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SilkeAllmannLab/pacbio_snakemake, file=workflow/Snakefile
context_key: ['if config["genome"]["map_to_genome"] == True', 'rule generate_genome_index', 'message']
    (192, '        message:')
    (193, '            "Generate genome index using {input} FASTA file"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SilkeAllmannLab/pacbio_snakemake, file=workflow/Snakefile
context_key: ['if config["genome"]["map_to_genome"] == True', 'rule generate_genome_index', 'shell']
    (194, '        shell:')
    (195, '            "pbmm2 index "')
    (196, '            "--num-threads {threads} "')
    (197, '            "--preset ISOSEQ "')
    (198, '            "{input} "')
    (199, '            "{output}"')
    (200, '    ')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SilkeAllmannLab/pacbio_snakemake, file=workflow/Snakefile
context_key: ['if config["genome"]["map_to_genome"] == True', 'rule align_reads_to_genome', 'input']
    (201, '    rule align_reads_to_genome:')
    (202, '        input:')
    (203, '            genome_index = config["working_dir"] + "05_minimap/genome.mmi",')
    (204, '            transcripts = config["working_dir"] + "04_transcripts/{sample}.transcripts.bam" ')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SilkeAllmannLab/pacbio_snakemake, file=workflow/Snakefile
context_key: ['if config["genome"]["map_to_genome"] == True', 'rule align_reads_to_genome', 'output']
    (205, '        output:')
    (206, '            aln = config["working_dir"] + "05_minimap/{sample}.aligned.sorted.bam"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SilkeAllmannLab/pacbio_snakemake, file=workflow/Snakefile
context_key: ['if config["genome"]["map_to_genome"] == True', 'rule align_reads_to_genome', 'message']
    (207, '        message:')
    (208, '            "Align {wildcards.sample} transcripts to genome reference"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SilkeAllmannLab/pacbio_snakemake, file=workflow/Snakefile
context_key: ['if config["genome"]["map_to_genome"] == True', 'rule align_reads_to_genome', 'threads']
    (209, '        threads: 30')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SilkeAllmannLab/pacbio_snakemake, file=workflow/Snakefile
context_key: ['if config["genome"]["map_to_genome"] == True', 'rule align_reads_to_genome', 'conda']
    (210, '        conda:')
    (211, '            "envs/pbmm2.yaml"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SilkeAllmannLab/pacbio_snakemake, file=workflow/Snakefile
context_key: ['if config["genome"]["map_to_genome"] == True', 'rule align_reads_to_genome', 'shell']
    (212, '        shell:')
    (213, '            "pbmm2 align "')
    (214, '            "--preset ISOSEQ " ')
    (215, '            "--sort "')
    (216, '            "--num-threads {threads} "')
    (217, '            "{input.genome_index} "')
    (218, '            "{input.transcripts} "')
    (219, '            "{output}"')
    (220, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SilkeAllmannLab/pacbio_snakemake, file=workflow/Snakefile
context_key: ['if config["genome"]["map_to_genome"] == True', 'rule collapse_isoforms', 'input']
    (221, '    rule collapse_isoforms:')
    (222, '        input:')
    (223, '            aln = config["working_dir"] + "05_minimap/{sample}.aligned.sorted.bam",')
    (224, '            css = config["working_dir"] + "01_css/{sample}.css.bam"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SilkeAllmannLab/pacbio_snakemake, file=workflow/Snakefile
context_key: ['if config["genome"]["map_to_genome"] == True', 'rule collapse_isoforms', 'output']
    (225, '        output:')
    (226, '            gff = config["working_dir"] + "06_gff/{sample}.collapsed.gff",')
    (227, '            fasta = config["result_dir"] + "{sample}.collapsed.fasta"  ')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SilkeAllmannLab/pacbio_snakemake, file=workflow/Snakefile
context_key: ['if config["genome"]["map_to_genome"] == True', 'rule collapse_isoforms', 'message']
    (228, '        message:')
    (229, '            "Collapse mRNA isoforms of {wildcards.sample} and outputs a GFF and FASTA file"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SilkeAllmannLab/pacbio_snakemake, file=workflow/Snakefile
context_key: ['if config["genome"]["map_to_genome"] == True', 'rule collapse_isoforms', 'conda']
    (230, '        conda:')
    (231, '            "envs/isoseq3.yaml"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SilkeAllmannLab/pacbio_snakemake, file=workflow/Snakefile
context_key: ['if config["genome"]["map_to_genome"] == True', 'rule collapse_isoforms', 'params']
    (232, '        params:')
    (233, '            min_aln_coverage = config["isoseq3"]["collapse"]["min_aln_coverage"],')
    (234, '            min_aln_identity = config["isoseq3"]["collapse"]["min_aln_identity"],')
    (235, '            max_fuzzy_junction = config["isoseq3"]["collapse"]["max_fuzzy_junction"],')
    (236, '            temp_fasta = config["working_dir"] + "06_gff/{sample}.collapsed.fasta"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SilkeAllmannLab/pacbio_snakemake, file=workflow/Snakefile
context_key: ['if config["genome"]["map_to_genome"] == True', 'rule collapse_isoforms', 'shell']
    (237, '        shell:')
    (238, '            "isoseq3 collapse "')
    (239, '            "--min-aln-coverage {params.min_aln_coverage} "')
    (240, '            "--min-aln-identity {params.min_aln_identity} "')
    (241, '            "--max-fuzzy-junction {params.max_fuzzy_junction} "')
    (242, '            "{input.aln} "')
    (243, '            "{input.css} "')
    (244, '            "{output.gff};"')
    (245, '            "mv {params.temp_fasta} {output.fasta} "')
    (246, '    ')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SilkeAllmannLab/pacbio_snakemake, file=workflow/Snakefile
context_key: ['if config["genome"]["map_to_genome"] == True', 'rule convert_gff_to_gff', 'input']
    (247, '    rule convert_gff_to_gff:')
    (248, '        input:')
    (249, '            gff = config["working_dir"] + "06_gff/{sample}.collapsed.gff",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SilkeAllmannLab/pacbio_snakemake, file=workflow/Snakefile
context_key: ['if config["genome"]["map_to_genome"] == True', 'rule convert_gff_to_gff', 'output']
    (250, '        output:')
    (251, '            gtf = config["result_dir"] + "{sample}.collapsed.gtf"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SilkeAllmannLab/pacbio_snakemake, file=workflow/Snakefile
context_key: ['if config["genome"]["map_to_genome"] == True', 'rule convert_gff_to_gff', 'message']
    (252, '        message:')
    (253, '            "Convert {wildcards.sample} GFF annotation to GTF"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SilkeAllmannLab/pacbio_snakemake, file=workflow/Snakefile
context_key: ['if config["genome"]["map_to_genome"] == True', 'rule convert_gff_to_gff', 'conda']
    (254, '        conda:')
    (255, '            "envs/cufflinks.yaml"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SilkeAllmannLab/pacbio_snakemake, file=workflow/Snakefile
context_key: ['if config["genome"]["map_to_genome"] == True', 'rule convert_gff_to_gff', 'shell']
    (256, '        shell:')
    (257, '            "gffread {input} -T -o {output}"')
    (258, '')
    (259, '        ')
    (260, '             ')
    (261, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule mergeBams', 'input']
    (12, 'if config["GC_analysis"] is True:')
    (13, '')
    (14, '    ruleorder: mergeBams > mergeSortBams > mergeBams_plate_row > mergeSortBams_plate_row > index_merged_bam > index_merged_bam_plate_row > alfred_merged > alfred_plate_row > alfred_sc > alfred_table > alfred_table_merged > alfred_table_plate_row')
    (15, '')
    (16, '    rule mergeBams:')
    (17, '        input:')
    (18, '            lambda wc: expand(')
    (19, '                "{folder}/{sample}/bam/{bam}.sort.mdup.bam",')
    (20, '                folder=config["data_location"],')
    (21, '                sample=wc.sample,')
    (22, '                bam=cell_per_sample[wc.sample],')
    (23, '            ),')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule mergeBams', 'output']
    (24, '        output:')
    (25, '            temp("{folder}/{sample}/merged_bam/merged.raw.bam"),')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule mergeBams', 'log']
    (26, '        log:')
    (27, '            "{folder}/log/merged_bam/{sample}.log",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule mergeBams', 'resources']
    (28, '        resources:')
    (29, '            mem_mb=get_mem_mb_heavy,')
    (30, '            time="01:00:00",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule mergeBams', 'threads']
    (31, '        threads: 32')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule mergeBams', 'conda']
    (32, '        conda:')
    (33, '            "../envs/ashleys_base.yaml"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule mergeBams', 'shell']
    (34, '        shell:')
    (35, '            "samtools merge -@ {threads} {output} {input} 2>&1 > {log}"')
    (36, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule mergeSortBams', 'input']
    (37, '    rule mergeSortBams:')
    (38, '        input:')
    (39, '            "{folder}/{sample}/merged_bam/merged.raw.bam",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule mergeSortBams', 'output']
    (40, '        output:')
    (41, '            temp("{folder}/{sample}/merged_bam/merged.bam"),')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule mergeSortBams', 'log']
    (42, '        log:')
    (43, '            "{folder}/log/merged_bam/{sample}.mergeSortBams.log",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule mergeSortBams', 'resources']
    (44, '        resources:')
    (45, '            mem_mb=get_mem_mb_heavy,')
    (46, '            time="01:00:00",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule mergeSortBams', 'threads']
    (47, '        threads: 32')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule mergeSortBams', 'conda']
    (48, '        conda:')
    (49, '            "../envs/ashleys_base.yaml"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule mergeSortBams', 'shell']
    (50, '        shell:')
    (51, '            "samtools sort -@ {threads} -o {output} {input} 2>&1 > {log}"')
    (52, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule index_merged_bam', 'input']
    (53, '    rule index_merged_bam:')
    (54, '        input:')
    (55, '            "{folder}/{sample}/merged_bam/merged.bam",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule index_merged_bam', 'output']
    (56, '        output:')
    (57, '            temp("{folder}/{sample}/merged_bam/merged.bam.bai"),')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule index_merged_bam', 'log']
    (58, '        log:')
    (59, '            "{folder}/log/{sample}/merged_bam/index_merged_bam.log",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule index_merged_bam', 'conda']
    (60, '        conda:')
    (61, '            "../envs/ashleys_base.yaml"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule index_merged_bam', 'resources']
    (62, '        resources:')
    (63, '            mem_mb=get_mem_mb,')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule index_merged_bam', 'shell']
    (64, '        shell:')
    (65, '            "samtools index {input} > {log} 2>&1"')
    (66, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule mergeBams_plate_row', 'input']
    (67, '    rule mergeBams_plate_row:')
    (68, '        input:')
    (69, '            # "{folder}/{sample}/all/{bam}.sort.mdup.bam",')
    (70, '            lambda wc: expand(')
    (71, '                "{folder}/{sample}/bam/{bam}.sort.mdup.bam",')
    (72, '                folder=config["data_location"],')
    (73, '                sample=wc.sample,')
    (74, '                bam=d[wc.sample][wc.row],')
    (75, '            ),')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule mergeBams_plate_row', 'output']
    (76, '        output:')
    (77, '            temp("{folder}/{sample}/merged_bam/PLATE_ROW/{row}.platerow.raw.bam"),')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule mergeBams_plate_row', 'log']
    (78, '        log:')
    (79, '            "{folder}/log/merged_bam/{sample}.{row}.log",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule mergeBams_plate_row', 'resources']
    (80, '        resources:')
    (81, '            mem_mb=get_mem_mb_heavy,')
    (82, '            time="01:00:00",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule mergeBams_plate_row', 'threads']
    (83, '        threads: 32')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule mergeBams_plate_row', 'conda']
    (84, '        conda:')
    (85, '            "../envs/ashleys_base.yaml"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule mergeBams_plate_row', 'shell']
    (86, '        shell:')
    (87, '            "samtools merge -@ {threads} {output} {input} 2>&1 > {log}"')
    (88, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule mergeSortBams_plate_row', 'input']
    (89, '    rule mergeSortBams_plate_row:')
    (90, '        input:')
    (91, '            "{folder}/{sample}/merged_bam/PLATE_ROW/{row}.platerow.raw.bam",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule mergeSortBams_plate_row', 'output']
    (92, '        output:')
    (93, '            temp("{folder}/{sample}/merged_bam/PLATE_ROW/{row}.platerow.bam"),')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule mergeSortBams_plate_row', 'log']
    (94, '        log:')
    (95, '            "{folder}/log/merged_bam/{sample}.{row}.mergeSortBams.log",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule mergeSortBams_plate_row', 'resources']
    (96, '        resources:')
    (97, '            mem_mb=get_mem_mb_heavy,')
    (98, '            time="01:00:00",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule mergeSortBams_plate_row', 'threads']
    (99, '        threads: 32')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule mergeSortBams_plate_row', 'conda']
    (100, '        conda:')
    (101, '            "../envs/ashleys_base.yaml"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule mergeSortBams_plate_row', 'shell']
    (102, '        shell:')
    (103, '            "samtools sort -@ {threads} -o {output} {input} 2>&1 > {log}"')
    (104, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule index_merged_bam_plate_row', 'input']
    (105, '    rule index_merged_bam_plate_row:')
    (106, '        input:')
    (107, '            "{folder}/{sample}/merged_bam/PLATE_ROW/{row}.platerow.bam",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule index_merged_bam_plate_row', 'output']
    (108, '        output:')
    (109, '            temp("{folder}/{sample}/merged_bam/PLATE_ROW/{row}.platerow.bam.bai"),')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule index_merged_bam_plate_row', 'log']
    (110, '        log:')
    (111, '            "{folder}/log/merged_bam/{sample}/{row}.log",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule index_merged_bam_plate_row', 'conda']
    (112, '        conda:')
    (113, '            "../envs/ashleys_base.yaml"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule index_merged_bam_plate_row', 'resources']
    (114, '        resources:')
    (115, '            mem_mb=get_mem_mb,')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule index_merged_bam_plate_row', 'shell']
    (116, '        shell:')
    (117, '            "samtools index {input} > {log} 2>&1"')
    (118, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule alfred_merged', 'input']
    (119, '    rule alfred_merged:')
    (120, '        input:')
    (121, '            merged_bam="{folder}/{sample}/merged_bam/merged.bam",')
    (122, '            merged_bam_bai="{folder}/{sample}/merged_bam/merged.bam.bai",')
    (123, '            fasta=config["references_data"][config["reference"]]["reference_fasta"],')
    (124, '            fasta_index="{fasta}.fai".format(')
    (125, '                fasta=config["references_data"][config["reference"]]["reference_fasta"]')
    (126, '            ),')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule alfred_merged', 'output']
    (127, '        output:')
    (128, '            alfred_json="{folder}/{sample}/alfred/MERGE/merged_bam.merge.json.gz",')
    (129, '            alfred_tsv="{folder}/{sample}/alfred/MERGE/merged_bam.merge.tsv.gz",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule alfred_merged', 'log']
    (130, '        log:')
    (131, '            "{folder}/{sample}/log/alfred/{sample}.log",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule alfred_merged', 'resources']
    (132, '        resources:')
    (133, '            mem_mb=get_mem_mb,')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule alfred_merged', 'conda']
    (134, '        conda:')
    (135, '            "../envs/ashleys_base.yaml"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule alfred_merged', 'shell']
    (136, '        shell:')
    (137, '            """')
    (138, '            alfred qc -r {input.fasta} -j {output.alfred_json} -o {output.alfred_tsv} {input.merged_bam}')
    (139, '            """')
    (140, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule alfred_sc', 'input']
    (141, '    rule alfred_sc:')
    (142, '        input:')
    (143, '            bam="{folder}/{sample}/bam/{bam}.sort.mdup.bam",')
    (144, '            bam_bai="{folder}/{sample}/bam/{bam}.sort.mdup.bam.bai",')
    (145, '            fasta=config["references_data"][config["reference"]]["reference_fasta"],')
    (146, '            fasta_index="{fasta}.fai".format(')
    (147, '                fasta=config["references_data"][config["reference"]]["reference_fasta"]')
    (148, '            ),')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule alfred_sc', 'output']
    (149, '        output:')
    (150, '            alfred_json="{folder}/{sample}/alfred/{bam}.json.gz",')
    (151, '            alfred_tsv="{folder}/{sample}/alfred/{bam}.tsv.gz",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule alfred_sc', 'log']
    (152, '        log:')
    (153, '            "{folder}/{sample}/log/alfred/{bam}.log",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule alfred_sc', 'resources']
    (154, '        resources:')
    (155, '            mem_mb=get_mem_mb,')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule alfred_sc', 'conda']
    (156, '        conda:')
    (157, '            "../envs/ashleys_base.yaml"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule alfred_sc', 'shell']
    (158, '        shell:')
    (159, '            """')
    (160, '            alfred qc -r {input.fasta} -j {output.alfred_json} -o {output.alfred_tsv} {input.bam}')
    (161, '            """')
    (162, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule alfred_plate_row', 'input']
    (163, '    rule alfred_plate_row:')
    (164, '        input:')
    (165, '            bam="{folder}/{sample}/merged_bam/PLATE_ROW/{row}.platerow.bam",')
    (166, '            bam_bai="{folder}/{sample}/merged_bam/PLATE_ROW/{row}.platerow.bam.bai",')
    (167, '            fasta=config["references_data"][config["reference"]]["reference_fasta"],')
    (168, '            fasta_index="{fasta}.fai".format(')
    (169, '                fasta=config["references_data"][config["reference"]]["reference_fasta"]')
    (170, '            ),')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule alfred_plate_row', 'output']
    (171, '        output:')
    (172, '            alfred_json="{folder}/{sample}/alfred/PLATE_ROW/{row}.row.json.gz",')
    (173, '            alfred_tsv="{folder}/{sample}/alfred/PLATE_ROW/{row}.row.tsv.gz",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule alfred_plate_row', 'log']
    (174, '        log:')
    (175, '            "{folder}/{sample}/log/alfred/{row}.log",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule alfred_plate_row', 'resources']
    (176, '        resources:')
    (177, '            mem_mb=get_mem_mb,')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule alfred_plate_row', 'conda']
    (178, '        conda:')
    (179, '            "../envs/ashleys_base.yaml"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule alfred_plate_row', 'shell']
    (180, '        shell:')
    (181, '            """')
    (182, '            alfred qc -r {input.fasta} -j {output.alfred_json} -o {output.alfred_tsv} {input.bam}')
    (183, '            """')
    (184, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule alfred_table', 'input']
    (185, '    rule alfred_table:')
    (186, '        input:')
    (187, '            bam="{folder}/{sample}/alfred/{bam}.tsv.gz",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule alfred_table', 'output']
    (188, '        output:')
    (189, '            "{folder}/{sample}/alfred/{bam}.table",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule alfred_table', 'log']
    (190, '        log:')
    (191, '            "{folder}/{sample}/log/alfred_table/{bam}.log",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule alfred_table', 'resources']
    (192, '        resources:')
    (193, '            mem_mb=get_mem_mb,')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule alfred_table', 'conda']
    (194, '        conda:')
    (195, '            "../envs/ashleys_base.yaml"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule alfred_table', 'shell']
    (196, '        shell:')
    (197, '            """')
    (198, '            zcat {input} | grep "^GC" > {output}')
    (199, '            """')
    (200, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule alfred_table_plate_row', 'input']
    (201, '    rule alfred_table_plate_row:')
    (202, '        input:')
    (203, '            bam="{folder}/{sample}/alfred/PLATE_ROW/{row}.row.tsv.gz",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule alfred_table_plate_row', 'output']
    (204, '        output:')
    (205, '            "{folder}/{sample}/alfred/PLATE_ROW/{row}.row.table",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule alfred_table_plate_row', 'log']
    (206, '        log:')
    (207, '            "{folder}/{sample}/log/alfred_table/PLATE_ROW/{row}.log",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule alfred_table_plate_row', 'resources']
    (208, '        resources:')
    (209, '            mem_mb=get_mem_mb,')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule alfred_table_plate_row', 'conda']
    (210, '        conda:')
    (211, '            "../envs/ashleys_base.yaml"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule alfred_table_plate_row', 'shell']
    (212, '        shell:')
    (213, '            """')
    (214, '            zcat {input} | grep "^GC" > {output}')
    (215, '            """')
    (216, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule alfred_table_merged', 'input']
    (217, '    rule alfred_table_merged:')
    (218, '        input:')
    (219, '            bam="{folder}/{sample}/alfred/MERGE/merged_bam.merge.tsv.gz",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule alfred_table_merged', 'output']
    (220, '        output:')
    (221, '            "{folder}/{sample}/alfred/MERGE/merged_bam.merge.table",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule alfred_table_merged', 'log']
    (222, '        log:')
    (223, '            "{folder}/{sample}/log/alfred_table/merged_bam.log",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule alfred_table_merged', 'resources']
    (224, '        resources:')
    (225, '            mem_mb=get_mem_mb,')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule alfred_table_merged', 'conda']
    (226, '        conda:')
    (227, '            "../envs/ashleys_base.yaml"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule alfred_table_merged', 'shell']
    (228, '        shell:')
    (229, '            """')
    (230, '            zcat {input} | grep "^GC" > {output}')
    (231, '            """')
    (232, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule alfred_plot', 'input']
    (233, '    rule alfred_plot:')
    (234, '        input:')
    (235, '            table="{folder}/{sample}/alfred/{bam}.table",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule alfred_plot', 'output']
    (236, '        output:')
    (237, '            gcdist_plot=report(')
    (238, '                "{folder}/{sample}/plots/alfred/{bam}_gc_dist.png",')
    (239, '                category="GC analysis",')
    (240, '                labels={')
    (241, '                    "Sample": "{sample}",')
    (242, '                    "Cell(s)": "{bam}",')
    (243, '                    "Type": "GC distribution",')
    (244, '                },')
    (245, '            ),')
    (246, '            gcdevi_plot=report(')
    (247, '                "{folder}/{sample}/plots/alfred/{bam}_gc_devi.png",')
    (248, '                category="GC analysis",')
    (249, '                labels={')
    (250, '                    "Sample": "{sample}",')
    (251, '                    "Cell(s)": "{bam}",')
    (252, '                    "Type": "GC deviation",')
    (253, '                },')
    (254, '            ),')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule alfred_plot', 'log']
    (255, '        log:')
    (256, '            "{folder}/{sample}/log/alfred_plot/{bam}.log",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule alfred_plot', 'resources']
    (257, '        resources:')
    (258, '            mem_mb=get_mem_mb,')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule alfred_plot', 'conda']
    (259, '        conda:')
    (260, '            "../envs/ashleys_rtools.yaml"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule alfred_plot', 'script']
    (261, '        script:')
    (262, '            "../scripts/GC/gc.R"')
    (263, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule alfred_plot_merge', 'input']
    (264, '    rule alfred_plot_merge:')
    (265, '        input:')
    (266, '            table="{folder}/{sample}/alfred/MERGE/merged_bam.merge.table",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule alfred_plot_merge', 'output']
    (267, '        output:')
    (268, '            gcdist_plot=report(')
    (269, '                "{folder}/{sample}/plots/alfred/MERGE/merged_bam_gc_dist.merge.png",')
    (270, '                category="GC analysis",')
    (271, '                labels={"Sample": "{sample}", "Type": "GC distribution"},')
    (272, '            ),')
    (273, '            gcdevi_plot=report(')
    (274, '                "{folder}/{sample}/plots/alfred/MERGE/merged_bam_gc_devi.merge.png",')
    (275, '                category="GC analysis",')
    (276, '                labels={"Sample": "{sample}", "Type": "GC deviation"},')
    (277, '            ),')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule alfred_plot_merge', 'log']
    (278, '        log:')
    (279, '            "{folder}/{sample}/log/alfred_plot/merge_bam.log",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule alfred_plot_merge', 'resources']
    (280, '        resources:')
    (281, '            mem_mb=get_mem_mb,')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule alfred_plot_merge', 'conda']
    (282, '        conda:')
    (283, '            "../envs/ashleys_rtools.yaml"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule alfred_plot_merge', 'script']
    (284, '        script:')
    (285, '            "../scripts/GC/gc.R"')
    (286, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule alfred_plot_plate_row', 'input']
    (287, '    rule alfred_plot_plate_row:')
    (288, '        input:')
    (289, '            table="{folder}/{sample}/alfred/PLATE_ROW/{row}.row.table",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule alfred_plot_plate_row', 'output']
    (290, '        output:')
    (291, '            gcdist_plot=report(')
    (292, '                "{folder}/{sample}/plots/alfred/PLATE_ROW/{row}_gc_dist.row.png",')
    (293, '                category="GC analysis",')
    (294, '                labels={')
    (295, '                    "Sample": "{sample}",')
    (296, '                    "Cell(s)": "{row}",')
    (297, '                    "Type": "GC distribution",')
    (298, '                },')
    (299, '            ),')
    (300, '            gcdevi_plot=report(')
    (301, '                "{folder}/{sample}/plots/alfred/PLATE_ROW/{row}_gc_devi.row.png",')
    (302, '                category="GC analysis",')
    (303, '                labels={')
    (304, '                    "Sample": "{sample}",')
    (305, '                    "Cell(s)": "{row}",')
    (306, '                    "Type": "GC deviation",')
    (307, '                },')
    (308, '            ),')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule alfred_plot_plate_row', 'log']
    (309, '        log:')
    (310, '            "{folder}/{sample}/log/alfred_plot/{row}.log",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule alfred_plot_plate_row', 'resources']
    (311, '        resources:')
    (312, '            mem_mb=get_mem_mb,')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule alfred_plot_plate_row', 'conda']
    (313, '        conda:')
    (314, '            "../envs/ashleys_rtools.yaml"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule alfred_plot_plate_row', 'script']
    (315, '        script:')
    (316, '            "../scripts/GC/gc.R"')
    (317, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule VST_correction', 'input']
    (318, '    rule VST_correction:')
    (319, '        input:')
    (320, '            counts="{folder}/{sample}/counts/{sample}.txt.raw.gz",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule VST_correction', 'output']
    (321, '        output:')
    (322, '            counts_vst="{folder}/{sample}/counts/GC_correction/{sample}.txt.VST.gz",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule VST_correction', 'log']
    (323, '        log:')
    (324, '            "{folder}/{sample}/log/VST_correction/{sample}.log",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule VST_correction', 'resources']
    (325, '        resources:')
    (326, '            mem_mb=get_mem_mb,')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule VST_correction', 'conda']
    (327, '        conda:')
    (328, '            "../envs/ashleys_rtools.yaml"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule VST_correction', 'script']
    (329, '        script:')
    (330, '            "../scripts/GC/variance_stabilizing_transformation.R"')
    (331, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule GC_correction', 'input']
    (332, '    rule GC_correction:')
    (333, '        input:')
    (334, '            counts_vst="{folder}/{sample}/counts/GC_correction/{sample}.txt.VST.gz",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule GC_correction', 'output']
    (335, '        output:')
    (336, '            counts_vst_gc="{folder}/{sample}/counts/GC_correction/{sample}.txt.VST.GC.gz",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule GC_correction', 'log']
    (337, '        log:')
    (338, '            "{folder}/{sample}/log/GC_correction/{sample}.log",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule GC_correction', 'params']
    (339, '        params:')
    (340, '            gc_matrix="workflow/data/GC/GC_matrix_200000.txt",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule GC_correction', 'resources']
    (341, '        resources:')
    (342, '            mem_mb=get_mem_mb,')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule GC_correction', 'conda']
    (343, '        conda:')
    (344, '            "../envs/ashleys_rtools.yaml"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule GC_correction', 'script']
    (345, '        script:')
    (346, '            "../scripts/GC/GC_correction.R"')
    (347, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule counts_scaling', 'input']
    (348, '    rule counts_scaling:')
    (349, '        input:')
    (350, '            counts_vst_gc="{folder}/{sample}/counts/GC_correction/{sample}.txt.VST.GC.gz",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule counts_scaling', 'output']
    (351, '        output:')
    (352, '            counts_vst_gc_scaled="{folder}/{sample}/counts/GC_correction/{sample}.txt.VST.GC.scaled.gz",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule counts_scaling', 'log']
    (353, '        log:')
    (354, '            "{folder}/{sample}/log/counts_scaling/{sample}.log",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule counts_scaling', 'resources']
    (355, '        resources:')
    (356, '            mem_mb=get_mem_mb,')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule counts_scaling', 'conda']
    (357, '        conda:')
    (358, '            "../envs/ashleys_rtools.yaml"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule counts_scaling', 'script']
    (359, '        script:')
    (360, '            "../scripts/GC/counts_scaling.R"')
    (361, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule plot_mosaic_gc_norm_counts', 'input']
    (362, '    rule plot_mosaic_gc_norm_counts:')
    (363, '        input:')
    (364, '            counts="{folder}/{sample}/counts/GC_correction/{sample}.txt.VST.GC.scaled.gz",')
    (365, '            info="{folder}/{sample}/counts/{sample}.info_raw",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule plot_mosaic_gc_norm_counts', 'output']
    (366, '        output:')
    (367, '            "{folder}/{sample}/plots/counts/CountComplete.GC_corrected.pdf",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule plot_mosaic_gc_norm_counts', 'log']
    (368, '        log:')
    (369, '            "{folder}/{sample}/log/plot_mosaic_counts/{sample}.log",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule plot_mosaic_gc_norm_counts', 'conda']
    (370, '        conda:')
    (371, '            "../envs/ashleys_rtools.yaml"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule plot_mosaic_gc_norm_counts', 'resources']
    (372, '        resources:')
    (373, '            mem_mb=get_mem_mb,')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/gc.smk
context_key: ['if config["GC_analysis"] is True', 'rule plot_mosaic_gc_norm_counts', 'shell']
    (374, '        shell:')
    (375, '            """')
    (376, '            LC_CTYPE=C Rscript workflow/scripts/plotting/qc.R {input.counts} {input.info} {output} > {log} 2>&1')
    (377, '            """')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/common.smk
context_key: ['if config["genecore"] is False']
    (325, '    if config["genecore"] is False:')
    (326, '        # FASTQC outputs')
    (327, '        final_list.extend(')
    (328, '            (')
    (329, '                [')
    (330, '                    sub_e')
    (331, '                    for e in [')
    (332, '                        expand(')
    (333, '                            "{path}/{sample}/fastqc/{cell}_{pair}_fastqc.html",')
    (334, '                            path=config["data_location"],')
    (335, '                            sample=sample,')
    (336, '                            cell=cell_per_sample[sample],')
    (337, '                            pair=[1, 2],')
    (338, '                        )')
    (339, '                        for sample in samples')
    (340, '                    ]')
    (341, '                    for sub_e in e')
    (342, '                ]')
    (343, '            )')
    (344, '        )')
    (345, '')
    (346, '    final_list.extend(')
    (347, '        expand(')
    (348, '            "{path}/{sample}/cell_selection/labels.tsv",')
    (349, '            path=config["data_location"],')
    (350, '            sample=samples,')
    (351, '        )')
    (352, '    )')
    (353, '')
    (354, '    if config["GC_analysis"] is True:')
    (355, '')
    (356, '        # ALFRED for each single cell')
    (357, '        final_list.extend(')
    (358, '            (')
    (359, '                [')
    (360, '                    sub_e')
    (361, '                    for e in [')
    (362, '                        expand(')
    (363, '                            "{path}/{sample}/plots/alfred/{bam}_gc_{alfred_plot}.png",')
    (364, '                            path=config["data_location"],')
    (365, '                            sample=sample,')
    (366, '                            bam=cell_per_sample[sample],')
    (367, '                            alfred_plot=config["alfred_plots"],')
    (368, '                        )')
    (369, '                        for sample in samples')
    (370, '                    ]')
    (371, '                    for sub_e in e')
    (372, '                ]')
    (373, '            )')
    (374, '        )')
    (375, '')
    (376, '        # ALFRED for the complete plate')
    (377, '        final_list.extend(')
    (378, '            (')
    (379, '                [')
    (380, '                    sub_e')
    (381, '                    for e in [')
    (382, '                        expand(')
    (383, '                            "{path}/{sample}/plots/alfred/MERGE/merged_bam_gc_{alfred_plot}.merge.png",')
    (384, '                            path=config["data_location"],')
    (385, '                            sample=sample,')
    (386, '                            alfred_plot=config["alfred_plots"],')
    (387, '                        )')
    (388, '                        for sample in samples')
    (389, '                    ]')
    (390, '                    for sub_e in e')
    (391, '                ]')
    (392, '            )')
    (393, '        )')
    (394, '')
    (395, '        # ALFRED for each row/column')
    (396, '        if d:')
    (397, '            final_list.extend(')
    (398, '                (')
    (399, '                    [')
    (400, '                        sub_e')
    (401, '                        for e in [')
    (402, '                            expand(')
    (403, '                                "{path}/{sample}/plots/alfred/PLATE_ROW/{row}_gc_{alfred_plot}.row.png",')
    (404, '                                path=config["data_location"],')
    (405, '                                sample=sample,')
    (406, '                                row=list(string.ascii_uppercase)[: orientation[0]],')
    (407, '                                alfred_plot=config["alfred_plots"],')
    (408, '                            )')
    (409, '                            for sample in samples')
    (410, '                            if len(cell_per_sample[sample]) == 96')
    (411, '                        ]')
    (412, '                        for sub_e in e')
    (413, '                    ]')
    (414, '                )')
    (415, '            )')
    (416, '')
    (417, '    # if config["genecore"] is True and config["genecore_date_folder"]:')
    (418, '    #     final_list.extend(genecore_list)')
    (419, '')
    (420, '    # QC count plots (classic only or classic + corrected based on config GC_analysis option)')
    (421, '    final_list.extend(')
    (422, '        expand(')
    (423, '            "{output_folder}/{sample}/plots/counts/CountComplete.{plottype_counts}.pdf",')
    (424, '            output_folder=config["data_location"],')
    (425, '            sample=samples,')
    (426, '            plottype_counts=plottype_counts,')
    (427, '        ),')
    (428, '    )')
    (429, '')
    (430, '    return final_list')
    (431, '')
    (432, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/rules.smk
context_key: ['if config["genecore"] is True and config["genecore_date_folder"]', 'rule genecore_symlink', 'input']
    (11, 'if config["genecore"] is True and config["genecore_date_folder"]:')
    (12, '')
    (13, '    rule genecore_symlink:')
    (14, '        input:')
    (15, '            lambda wc: df_config_files.loc[')
    (16, '                (df_config_files["Sample"] == wc.sample)')
    (17, '                & (df_config_files["File"] == "{}.{}".format(wc.cell, wc.pair))')
    (18, '            ]["Genecore_path"]')
    (19, '            .unique()')
    (20, '            .tolist(),')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/rules.smk
context_key: ['if config["genecore"] is True and config["genecore_date_folder"]', 'rule genecore_symlink', 'output']
    (21, '        output:')
    (22, '            "{folder}/{sample}/fastq/{cell}.{pair}.fastq.gz",')
    (23, '# wildcard_constraints:')
    (24, '#     cell="^((?!mdup).)*$"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/rules.smk
context_key: ['if config["genecore"] is True and config["genecore_date_folder"]', 'rule genecore_symlink', 'shell']
    (25, '        shell:')
    (26, '            "ln -s {input} {output}"')
    (27, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/rules.smk
context_key: ['if config["genecore"] is True and config["genecore_date_folder"]', 'ruleorder']
    (28, '    ruleorder: genecore_symlink > fastqc > bwa_strandseq_to_reference_alignment')
    (29, '')
    (30, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/rules.smk
context_key: ['if config["mosaicatcher_pipeline"] is False']
    (79, 'if config["mosaicatcher_pipeline"] is False:')
    (80, '')
    (81, '    ruleorder: bwa_strandseq_to_reference_alignment > samtools_sort_bam > mark_duplicates > samtools_index')
    (82, '')
    (83, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/rules.smk
context_key: ['if config["mosaicatcher_pipeline"] is False', 'rule samtools_index', 'input']
    (156, 'if config["mosaicatcher_pipeline"] is False:')
    (157, '')
    (158, '    rule samtools_index:')
    (159, '        input:')
    (160, '            "{folder}/{sample}/bam/{cell}.sort.mdup.bam",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/rules.smk
context_key: ['if config["mosaicatcher_pipeline"] is False', 'rule samtools_index', 'output']
    (161, '        output:')
    (162, '            "{folder}/{sample}/bam/{cell}.sort.mdup.bam.bai",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/rules.smk
context_key: ['if config["mosaicatcher_pipeline"] is False', 'rule samtools_index', 'log']
    (163, '        log:')
    (164, '            "{folder}/{sample}/log/samtools_index/{cell}.log",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/rules.smk
context_key: ['if config["mosaicatcher_pipeline"] is False', 'rule samtools_index', 'conda']
    (165, '        conda:')
    (166, '            "../envs/ashleys_base.yaml"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/rules.smk
context_key: ['if config["mosaicatcher_pipeline"] is False', 'rule samtools_index', 'shell']
    (167, '        shell:')
    (168, '            "samtools index {input} 2>&1 > {log}"')
    (169, '')
    (170, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/rules.smk
context_key: ['if config["hand_selection"] is False', 'rule generate_features', 'input']
    (171, 'if config["hand_selection"] is False:')
    (172, '')
    (173, '    rule generate_features:')
    (174, '        input:')
    (175, '            bam=lambda wc: expand(')
    (176, '                "{folder}/{sample}/bam/{cell}.sort.mdup.bam",')
    (177, '                folder=config["data_location"],')
    (178, '                sample=wc.sample,')
    (179, '                cell=cell_per_sample[str(wc.sample)],')
    (180, '            ),')
    (181, '            bai=lambda wc: expand(')
    (182, '                "{folder}/{sample}/bam/{cell}.sort.mdup.bam.bai",')
    (183, '                folder=config["data_location"],')
    (184, '                sample=wc.sample,')
    (185, '                cell=cell_per_sample[str(wc.sample)],')
    (186, '            ),')
    (187, '            plot=expand(')
    (188, '                "{{folder}}/{{sample}}/plots/counts/CountComplete.{plottype}.pdf",')
    (189, '                plottype=plottype_counts,')
    (190, '            ),')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/rules.smk
context_key: ['if config["hand_selection"] is False', 'rule generate_features', 'output']
    (191, '        output:')
    (192, '            "{folder}/{sample}/predictions/ashleys_features.tsv",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/rules.smk
context_key: ['if config["hand_selection"] is False', 'rule generate_features', 'log']
    (193, '        log:')
    (194, '            "{folder}/log/ashleys/{sample}/features.log",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/rules.smk
context_key: ['if config["hand_selection"] is False', 'rule generate_features', 'conda']
    (195, '        conda:')
    (196, '            "../envs/ashleys_base.yaml"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/rules.smk
context_key: ['if config["hand_selection"] is False', 'rule generate_features', 'threads']
    (197, '        threads: 64')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/rules.smk
context_key: ['if config["hand_selection"] is False', 'rule generate_features', 'params']
    (198, '        params:')
    (199, '            windows="5000000 2000000 1000000 800000 600000 400000 200000",')
    (200, '            extension=".sort.mdup.bam",')
    (201, '            folder=lambda wildcards, input: "{}bam".format(input.bam[0].split("bam")[0]),')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/rules.smk
context_key: ['if config["hand_selection"] is False', 'rule generate_features', 'resources']
    (202, '        resources:')
    (203, '            mem_mb=get_mem_mb_heavy,')
    (204, '            time="10:00:00",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/rules.smk
context_key: ['if config["hand_selection"] is False', 'rule generate_features', 'shell']
    (205, '        shell:')
    (206, '            "ashleys -j {threads} features -f {params.folder} -w {params.windows} -o {output} --recursive_collect -e {params.extension}"')
    (207, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/rules.smk
context_key: ['if config["hand_selection"] is False', 'rule predict', 'input']
    (208, '    rule predict:')
    (209, '        input:')
    (210, '            folder="{folder}/{sample}/predictions/ashleys_features.tsv",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/rules.smk
context_key: ['if config["hand_selection"] is False', 'rule predict', 'output']
    (211, '        output:')
    (212, '            "{folder}/{sample}/cell_selection/labels_raw.tsv",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/rules.smk
context_key: ['if config["hand_selection"] is False', 'rule predict', 'log']
    (213, '        log:')
    (214, '            "{folder}/log/ashleys/{sample}/prediction_ashleys.log",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/rules.smk
context_key: ['if config["hand_selection"] is False', 'rule predict', 'conda']
    (215, '        conda:')
    (216, '            "../envs/ashleys_base.yaml"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/rules.smk
context_key: ['if config["hand_selection"] is False', 'rule predict', 'params']
    (217, '        params:')
    (218, '            model_default="./workflow/ashleys_models/svc_default.pkl",')
    (219, '            model_stringent="./workflow/ashleys_models/svc_stringent.pkl",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/rules.smk
context_key: ['if config["hand_selection"] is False', 'rule predict', 'resources']
    (220, '        resources:')
    (221, '            mem_mb=get_mem_mb,')
    (222, '            time="10:00:00",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/rules.smk
context_key: ['if config["hand_selection"] is False', 'rule predict', 'shell']
    (223, '        shell:')
    (224, '            "ashleys predict -p {input.folder} -o {output} -m {params.model_default}"')
    (225, '')
    (226, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/rules.smk
context_key: ['elif config["hand_selection"] is True', 'localrules']
    (227, 'elif config["hand_selection"] is True:')
    (228, '')
    (229, '    localrules:')
    (230, '        notebook_hand_selection,')
    (231, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/rules.smk
context_key: ['elif config["hand_selection"] is True', 'rule notebook_hand_selection', 'input']
    (232, '    rule notebook_hand_selection:')
    (233, '        input:')
    (234, '            pdf_raw=expand(')
    (235, '                "{{folder}}/{{sample}}/plots/counts/CountComplete.{plottype}.pdf",')
    (236, '                plottype=plottype_counts,')
    (237, '            ),')
    (238, '            info="{folder}/{sample}/counts/{sample}.info_raw",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/rules.smk
context_key: ['elif config["hand_selection"] is True', 'rule notebook_hand_selection', 'output']
    (239, '        output:')
    (240, '            folder="{folder}/{sample}/cell_selection/labels_raw.tsv",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/rules.smk
context_key: ['elif config["hand_selection"] is True', 'rule notebook_hand_selection', 'log']
    (241, '        log:')
    (242, '            "{folder}/log/hand_selection/{sample}/prediction_probabilities.log",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/rules.smk
context_key: ['elif config["hand_selection"] is True', 'rule notebook_hand_selection', 'params']
    (243, '        params:')
    (244, '            cell_per_sample=cell_per_sample,')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/rules.smk
context_key: ['elif config["hand_selection"] is True', 'rule notebook_hand_selection', 'conda']
    (245, '        conda:')
    (246, '            "../envs/ashleys_notebook.yaml"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/rules.smk
context_key: ['elif config["hand_selection"] is True', 'rule notebook_hand_selection', 'container']
    (247, '        container:')
    (248, '            None')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/rules.smk
context_key: ['elif config["hand_selection"] is True', 'rule notebook_hand_selection', 'notebook']
    (249, '        notebook:')
    (250, '            "../notebooks/hand_selection.py.ipynb"')
    (251, '')
    (252, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/rules.smk
context_key: ['if config["use_light_data"] is False', 'rule cp_predictions', 'input']
    (253, 'if config["use_light_data"] is False:')
    (254, '')
    (255, '    rule cp_predictions:')
    (256, '        input:')
    (257, '            folder="{folder}/{sample}/cell_selection/labels_raw.tsv",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/rules.smk
context_key: ['if config["use_light_data"] is False', 'rule cp_predictions', 'output']
    (258, '        output:')
    (259, '            folder="{folder}/{sample}/cell_selection/labels.tsv",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/rules.smk
context_key: ['if config["use_light_data"] is False', 'rule cp_predictions', 'log']
    (260, '        log:')
    (261, '            "{folder}/log/cp_predictions/{sample}.log",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/rules.smk
context_key: ['if config["use_light_data"] is False', 'rule cp_predictions', 'conda']
    (262, '        conda:')
    (263, '            "../envs/ashleys_base.yaml"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/rules.smk
context_key: ['if config["use_light_data"] is False', 'rule cp_predictions', 'shell']
    (264, '        shell:')
    (265, '            "cp {input.folder} {output.folder} > {log} 2>&1"')
    (266, '')
    (267, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/rules.smk
context_key: ['elif config["use_light_data"] is True', 'rule dev_all_cells_correct', 'input']
    (268, 'elif config["use_light_data"] is True:')
    (269, '')
    (270, '    rule dev_all_cells_correct:')
    (271, '        input:')
    (272, '            folder="{folder}/{sample}/cell_selection/labels_raw.tsv",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/rules.smk
context_key: ['elif config["use_light_data"] is True', 'rule dev_all_cells_correct', 'output']
    (273, '        output:')
    (274, '            folder="{folder}/{sample}/cell_selection/labels.tsv",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/rules.smk
context_key: ['elif config["use_light_data"] is True', 'rule dev_all_cells_correct', 'log']
    (275, '        log:')
    (276, '            "{folder}/log/dev_all_cells_correct/{sample}.log",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/rules.smk
context_key: ['elif config["use_light_data"] is True', 'rule dev_all_cells_correct', 'conda']
    (277, '        conda:')
    (278, '            "../envs/ashleys_base.yaml"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/rules.smk
context_key: ['elif config["use_light_data"] is True', 'rule dev_all_cells_correct', 'script']
    (279, '        script:')
    (280, '            "../scripts/utils/dev_all_cells_correct.py"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/Snakefile
context_key: ['if config["mosaicatcher_pipeline"] is False']
    (8, 'if config["mosaicatcher_pipeline"] is False:')
    (9, '')
    (10, '    docker_container = "docker://weber8thomas/ashleys-qc-pipeline:{version}".format(')
    (11, '        version=str(config["version"])')
    (12, '    )')
    (13, '')
    (14, '    containerized: docker_container')
    (15, '')
    (16, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/Snakefile
context_key: ['if config["mosaicatcher_pipeline"] is False']
    (32, 'if config["mosaicatcher_pipeline"] is False:')
    (33, '')
    (34, '    include: "rules/examples.smk"')
    (35, '')
    (36, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/Snakefile
context_key: ['if config["dl_external_files"] is True', 'if config["mosaicatcher_pipeline"] is False', 'if config["reference"] in ["hg19", "hg38", "T2T"]', 'if config["reference"] == "hg19"', 'rule all', 'input']
    (37, 'if config["dl_external_files"] is True:')
    (38, '')
    (39, '    if config["mosaicatcher_pipeline"] is False:')
    (40, '')
    (41, '        if config["reference"] in ["hg19", "hg38", "T2T"]:')
    (42, '')
    (43, '            if config["reference"] == "hg19":')
    (44, '')
    (45, '                rule all:')
    (46, '                    input:')
    (47, '                        rules.download_hg19_reference.output,')
    (48, '')
    (49, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/Snakefile
context_key: ['if config["dl_external_files"] is True', 'if config["mosaicatcher_pipeline"] is False', 'if config["reference"] in ["hg19", "hg38", "T2T"]', 'elif config["reference"] == "hg38"', 'rule all', 'input']
    (50, '            elif config["reference"] == "hg38":')
    (51, '')
    (52, '                rule all:')
    (53, '                    input:')
    (54, '                        rules.download_hg38_reference.output,')
    (55, '')
    (56, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/Snakefile
context_key: ['if config["dl_external_files"] is True', 'if config["mosaicatcher_pipeline"] is False', 'if config["reference"] in ["hg19", "hg38", "T2T"]', 'elif config["reference"] == "T2T"', 'rule all', 'input']
    (57, '            elif config["reference"] == "T2T":')
    (58, '')
    (59, '                rule all:')
    (60, '                    input:')
    (61, '                        rules.download_T2T_reference.output,')
    (62, '')
    (63, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/Snakefile
context_key: ['if config["dl_external_files"] is True', 'if config["mosaicatcher_pipeline"] is False', 'else']
    (64, '        else:')
    (65, '            sys.exit(')
    (66, '                "You provide a wrong/not supported reference assembly: {}. Supported assemblies : hg19, hg38, T2T".format(')
    (67, '                    config["reference"]')
    (68, '                )')
    (69, '            )')
    (70, '')
    (71, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=fischer-hub/metagenomics, file=Snakefile
context_key: ['if config["help"] != "dummy value"']
    (8, 'if config["help"] != "dummy value" :')
    (9, '    print(f"{HELPMSG}")')
    (10, '    exit()')
    (11, '')
    (12, '# read in samplesheet')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=sanjaynagi/probe, file=workflow/rules/common.smk
context_key: ["if config[\\'PopulationStructure\\'][\\'Relatedness\\'][\\'activate\\']"]
    (115, "    if config[\\'PopulationStructure\\'][\\'Relatedness\\'][\\'activate\\']:")
    (116, '        selected_input.extend(')
    (117, '            expand(')
    (118, '                "results/relatedness/ngsRelate.{dataset}",')
    (119, "            dataset=config[\\'dataset\\'],")
    (120, '            )')
    (121, '        )')
    (122, '')
    (123, "    if config[\\'PopulationStructure\\'][\\'PCA\\'][\\'activate\\']:")
    (124, '        selected_input.extend(')
    (125, '            expand(')
    (126, '                [')
    (127, '                "results/PCA/{cohort}.{contig}.html",')
    (128, '                ],')
    (129, "                contig=config[\\'contigs\\'], ")
    (130, "                cohort=PCAcohorts[\\'cohortNoSpaceText\\'],")
    (131, '            )')
    (132, '        )')
    (133, '')
    (134, "    if config[\\'Selection\\'][\\'VariantsOfInterest\\'][\\'activate\\']:")
    (135, '        selected_input.extend(')
    (136, '            expand(')
    (137, '                [')
    (138, '                    "results/variantsOfInterest/VOI.{dataset}.frequencies.tsv",')
    (139, '                     "results/variantsOfInterest/VOI.{dataset}.heatmap.png"')
    (140, '                ],    ')
    (141, "                dataset=config[\\'dataset\\'],")
    (142, '            )')
    (143, '        )')
    (144, '')
    (145, '')
    (146, "    for stat in [\\'H12\\', \\'G12\\',\\'G123\\']:")
    (147, "        if config[\\'Selection\\'][stat][\\'activate\\']:")
    (148, '            selected_input.extend(')
    (149, '                expand(')
    (150, '                [')
    (151, '                    "results/selection/{stat}/{stat}_{cohort}.{contig}.png"')
    (152, '                ],    ')
    (153, "                    contig=config[\\'contigs\\'], ")
    (154, "                    cohort=cohorts[\\'cohortNoSpaceText\\'],")
    (155, '                    stat=stat')
    (156, '                )')
    (157, '            )')
    (158, '')
    (159, "    if config[\\'Selection\\'][\\'PBS\\'][\\'activate\\']:")
    (160, '        selected_input.extend(')
    (161, '            expand(')
    (162, '            [')
    (163, '                "results/selection/PBS/PBS_{cohort}.{contig}.png"')
    (164, '            ],    ')
    (165, "                contig=config[\\'contigs\\'], ")
    (166, "                cohort=PBScohorts[\\'cohortNoSpaceText\\'],")
    (167, '                stat=stat')
    (168, '            )')
    (169, '        )')
    (170, '')
    (171, '')
    (172, "    if config[\\'PopulationStructure\\'][\\'f2_variants\\'][\\'activate\\']:")
    (173, '        selected_input.extend(')
    (174, '            expand(')
    (175, '            [')
    (176, '                "results/f2HapLengths_{contig}.tsv",')
    (177, '            ],    ')
    (178, "                contig=config[\\'contigs\\'], ")
    (179, '            )')
    (180, '        )')
    (181, '')
    (182, '    return(selected_input)')
    (183, '')
    (184, '')
    (185, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=sanjaynagi/probe, file=workflow/Snakefile
context_key: ["if config[\\'Selection\\'][\\'PBS\\'][\\'activate\\']"]
    (29, "if config[\\'Selection\\'][\\'PBS\\'][\\'activate\\']:")
    (30, "    PBScohorts = getCohorts(metadata, columns=config[\\'metadataCohortColumns\\'], comparatorColumn=config[\\'Selection\\'][\\'PBS\\'][\\'metadataComparatorColumn\\'], minPopSize=15)")
    (31, '    PBScohorts = PBScohorts.dropna()')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=jbloomlab/SARS-CoV-2-RBD_DMS_Omicron, file=Snakefile
context_key: ["if config[\\'seqdata_source\\'] == \\'HutchServer\\'", 'rule get_ccs', 'input']
    (320, "if config[\\'seqdata_source\\'] == \\'HutchServer\\':")
    (321, '')
    (322, '    rule get_ccs:')
    (323, '        """Symbolically link CCS files."""')
    (324, '        input:')
    (325, '            ccs_fastq=lambda wildcards: (pacbio_runs')
    (326, "                                        .set_index(\\'pacbioRun\\')")
    (327, "                                        .at[wildcards.pacbioRun, \\'ccs\\']")
    (328, '                                        )')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=jbloomlab/SARS-CoV-2-RBD_DMS_Omicron, file=Snakefile
context_key: ["if config[\\'seqdata_source\\'] == \\'HutchServer\\'", 'rule get_ccs', 'output']
    (329, '        output:')
    (330, '            ccs_fastq=os.path.join(config[\\\'ccs_dir\\\'], "{pacbioRun}_ccs.fastq.gz")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=jbloomlab/SARS-CoV-2-RBD_DMS_Omicron, file=Snakefile
context_key: ["if config[\\'seqdata_source\\'] == \\'HutchServer\\'", 'rule get_ccs', 'run']
    (331, '        run:')
    (332, '            os.symlink(input.ccs_fastq, output.ccs_fastq)')
    (333, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=jbloomlab/SARS-CoV-2-RBD_DMS_Omicron, file=Snakefile
context_key: ["elif config[\\'seqdata_source\\'] == \\'SRA\\'"]
    (334, "elif config[\\'seqdata_source\\'] == \\'SRA\\':")
    (335, "    raise RuntimeError(\\'getting sequence data from SRA not yet implemented\\')")
    (336, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=jmenglund/FEGA-encryption-workflow, file=Snakefile
context_key: ['if config["privateKeyFile"] is not None']
    (16, 'if config["privateKeyFile"] is not None:')
    (17, '    PRIVATE_KEY_COMMMAND = " --sk " + config["privateKeyFile"]')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NBISweden/nbis-meta, file=workflow/rules/annotation.smk
context_key: ['if config["runOnUppMax"]', 'rule emapper_annotate_hits_uppmax', 'input']
    (291, 'if config["runOnUppMax"]:')
    (292, '    rule emapper_annotate_hits_uppmax:')
    (293, '        """Copy EGGNOG db into memory before running annotations"""')
    (294, '        input:')
    (295, '            results+"/annotation/{assembly}/{assembly}.emapper.seed_orthologs",')
    (296, '            "resources/eggnog-mapper/eggnog.db",')
    (297, '            "resources/eggnog-mapper/eggnog_proteins.dmnd"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NBISweden/nbis-meta, file=workflow/rules/annotation.smk
context_key: ['if config["runOnUppMax"]', 'rule emapper_annotate_hits_uppmax', 'output']
    (298, '        output:')
    (299, '            results+"/annotation/{assembly}/{assembly}.emapper.annotations"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NBISweden/nbis-meta, file=workflow/rules/annotation.smk
context_key: ['if config["runOnUppMax"]', 'rule emapper_annotate_hits_uppmax', 'params']
    (300, '        params:')
    (301, '            resource_dir=lambda wildcards, input: os.path.dirname(input[1]),')
    (302, '            tmpdir=temppath+"/{assembly}-eggnog",')
    (303, '            out=results+"/annotation/{assembly}/{assembly}",')
    (304, '            flags="--no_file_comments"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NBISweden/nbis-meta, file=workflow/rules/annotation.smk
context_key: ['if config["runOnUppMax"]', 'rule emapper_annotate_hits_uppmax', 'log']
    (305, '        log:')
    (306, '            results+"/annotation/{assembly}/{assembly}.emapper.annotations.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NBISweden/nbis-meta, file=workflow/rules/annotation.smk
context_key: ['if config["runOnUppMax"]', 'rule emapper_annotate_hits_uppmax', 'conda']
    (307, '        conda:')
    (308, '            "../envs/annotation.yml"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NBISweden/nbis-meta, file=workflow/rules/annotation.smk
context_key: ['if config["runOnUppMax"]', 'rule emapper_annotate_hits_uppmax', 'message']
    (309, '        message: "Annotating hits table for {wildcards.assembly}"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NBISweden/nbis-meta, file=workflow/rules/annotation.smk
context_key: ['if config["runOnUppMax"]', 'rule emapper_annotate_hits_uppmax', 'threads']
    (310, '        threads: 10')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NBISweden/nbis-meta, file=workflow/rules/annotation.smk
context_key: ['if config["runOnUppMax"]', 'rule emapper_annotate_hits_uppmax', 'resources']
    (311, '        resources:')
    (312, '            runtime=lambda wildcards, attempt: attempt**2*60')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NBISweden/nbis-meta, file=workflow/rules/annotation.smk
context_key: ['if config["runOnUppMax"]', 'rule emapper_annotate_hits_uppmax', 'shell']
    (313, '        shell:')
    (314, '            """')
    (315, '            if [ -z ${{SLURM_JOB_ID+x}} ]; then SLURM_JOB_ID="emapper_annotate_hits_uppmax"; fi')
    (316, '            #Copy eggnog.db')
    (317, '            mkdir -p /dev/shm/$SLURM_JOB_ID')
    (318, '            cp {params.resource_dir}/eggnog.db {params.resource_dir}/eggnog_proteins.dmnd /dev/shm/$SLURM_JOB_ID')
    (319, '')
    (320, '            emapper.py {params.flags} --cpu {threads} -o {params.out} \\\\')
    (321, '                --annotate_hits_table {input[0]} --usemem \\\\')
    (322, '                --data_dir /dev/shm/$SLURM_JOB_ID >{log} 2>&1')
    (323, '            rm -rf /dev/shm/$SLURM_JOB_ID')
    (324, '            """')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NBISweden/nbis-meta, file=workflow/rules/binning.smk
context_key: ['if config["checkm"]["taxonomy_wf"]', 'rule checkm_taxonomy_wf', 'input']
    (293, 'if config["checkm"]["taxonomy_wf"]:')
    (294, '    rule checkm_taxonomy_wf:')
    (295, '        input:')
    (296, '            db="resources/checkm/.dmanifest",')
    (297, '            tsv=results+"/binning/{binner}/{assembly}/{l}/summary_stats.tsv"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NBISweden/nbis-meta, file=workflow/rules/binning.smk
context_key: ['if config["checkm"]["taxonomy_wf"]', 'rule checkm_taxonomy_wf', 'output']
    (298, '        output:')
    (299, '            tsv=results+"/binning/{binner}/{assembly}/{l}/checkm/genome_stats.tsv",')
    (300, '            ms=results+"/binning/{binner}/{assembly}/{l}/checkm/lineage.ms"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NBISweden/nbis-meta, file=workflow/rules/binning.smk
context_key: ['if config["checkm"]["taxonomy_wf"]', 'rule checkm_taxonomy_wf', 'log']
    (301, '        log:')
    (302, '            results+"/binning/{binner}/{assembly}/{l}/checkm/checkm.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NBISweden/nbis-meta, file=workflow/rules/binning.smk
context_key: ['if config["checkm"]["taxonomy_wf"]', 'rule checkm_taxonomy_wf', 'conda']
    (303, '        conda:')
    (304, '            "../envs/checkm.yml"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NBISweden/nbis-meta, file=workflow/rules/binning.smk
context_key: ['if config["checkm"]["taxonomy_wf"]', 'rule checkm_taxonomy_wf', 'threads']
    (305, '        threads: 10')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NBISweden/nbis-meta, file=workflow/rules/binning.smk
context_key: ['if config["checkm"]["taxonomy_wf"]', 'rule checkm_taxonomy_wf', 'resources']
    (306, '        resources:')
    (307, '            runtime=lambda wildcards, attempt: attempt**2*60')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NBISweden/nbis-meta, file=workflow/rules/binning.smk
context_key: ['if config["checkm"]["taxonomy_wf"]', 'rule checkm_taxonomy_wf', 'params']
    (308, '        params:')
    (309, "            suff=\\'fa\\',")
    (310, '            indir=lambda wildcards, input: os.path.dirname(input.tsv),')
    (311, '            outdir=lambda wildcards, output: os.path.dirname(output.tsv),')
    (312, '            rank=config["checkm"]["rank"],')
    (313, '            taxon=config["checkm"]["taxon"]')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NBISweden/nbis-meta, file=workflow/rules/binning.smk
context_key: ['if config["checkm"]["taxonomy_wf"]', 'rule checkm_taxonomy_wf', 'shell']
    (314, '        shell:')
    (315, '            """')
    (316, "            lines=$(wc -l {input.tsv} | cut -f1 -d \\' \\')")
    (317, '            if [ $lines == 1 ] ; then')
    (318, '                echo "NO BINS FOUND" > {output.tsv}')
    (319, '                touch {output.ms}')
    (320, '            else')
    (321, '                checkm taxonomy_wf -t {threads} -x {params.suff} -q \\\\')
    (322, '                    --tab_table -f {output.tsv} \\\\')
    (323, '                    {params.rank} {params.taxon} {params.indir} {params.outdir} \\\\')
    (324, '                    > {log} 2>&1')
    (325, '                ln -s {params.taxon}.ms {output.ms}')
    (326, '            fi')
    (327, '            """')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NBISweden/nbis-meta, file=workflow/rules/assembly.smk
context_key: ['if config["assembly"]["metaspades"]', 'localrules']
    (16, 'if config["assembly"]["metaspades"]:')
    (17, '    localrules:')
    (18, '        generate_metaspades_input')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NBISweden/nbis-meta, file=workflow/rules/assembly.smk
context_key: ['if config["assembly"]["metaspades"]', 'rule generate_metaspades_input', 'input']
    (19, '    rule generate_metaspades_input:')
    (20, '        """Generate input files for use with Metaspades"""')
    (21, '        input:')
    (22, '            lambda wildcards: get_all_assembly_files(assemblies[wildcards.assembly])')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NBISweden/nbis-meta, file=workflow/rules/assembly.smk
context_key: ['if config["assembly"]["metaspades"]', 'rule generate_metaspades_input', 'output']
    (23, '        output:')
    (24, '            R1=temp(results+"/assembly/{assembly}/R1.fq"),')
    (25, '            R2=temp(results+"/assembly/{assembly}/R2.fq"),')
    (26, '            se=touch(temp(results+"/assembly/{assembly}/se.fq")),')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NBISweden/nbis-meta, file=workflow/rules/assembly.smk
context_key: ['if config["assembly"]["metaspades"]', 'rule generate_metaspades_input', 'params']
    (27, '        params:')
    (28, '            assembly = lambda wildcards: assemblies[wildcards.assembly],')
    (29, '            assembler = "metaspades"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NBISweden/nbis-meta, file=workflow/rules/assembly.smk
context_key: ['if config["assembly"]["metaspades"]', 'rule generate_metaspades_input', 'script']
    (30, '        script:')
    (31, '            "../scripts/assembly_utils.py"')
    (32, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NBISweden/nbis-meta, file=workflow/rules/assembly.smk
context_key: ['if config["assembly"]["metaspades"]', 'rule metaspades', 'input']
    (33, '    rule metaspades:')
    (34, '        input:')
    (35, '            R1=results+"/assembly/{assembly}/R1.fq",')
    (36, '            R2=results+"/assembly/{assembly}/R2.fq",')
    (37, '            se=results+"/assembly/{assembly}/se.fq",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NBISweden/nbis-meta, file=workflow/rules/assembly.smk
context_key: ['if config["assembly"]["metaspades"]', 'rule metaspades', 'output']
    (38, '        output:')
    (39, '            results+"/assembly/{assembly}/final_contigs.fa",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NBISweden/nbis-meta, file=workflow/rules/assembly.smk
context_key: ['if config["assembly"]["metaspades"]', 'rule metaspades', 'log']
    (40, '        log:')
    (41, '            results+"/assembly/{assembly}/spades.log",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NBISweden/nbis-meta, file=workflow/rules/assembly.smk
context_key: ['if config["assembly"]["metaspades"]', 'rule metaspades', 'params']
    (42, '        params:')
    (43, '            intermediate_contigs=results+"/intermediate/assembly/{assembly}/intermediate_contigs",')
    (44, '            corrected=results+"/intermediate/assembly/{assembly}/corrected",')
    (45, '            additional_settings=config["metaspades"]["extra_settings"],')
    (46, '            tmp=temppath+"/{assembly}.metaspades",')
    (47, '            output_dir=lambda wildcards, output: os.path.dirname(output[0])')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NBISweden/nbis-meta, file=workflow/rules/assembly.smk
context_key: ['if config["assembly"]["metaspades"]', 'rule metaspades', 'threads']
    (48, '        threads: config["metaspades"]["threads"]')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NBISweden/nbis-meta, file=workflow/rules/assembly.smk
context_key: ['if config["assembly"]["metaspades"]', 'rule metaspades', 'resources']
    (49, '        resources:')
    (50, '            runtime=lambda wildcards, attempt: attempt**2*60*4')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NBISweden/nbis-meta, file=workflow/rules/assembly.smk
context_key: ['if config["assembly"]["metaspades"]', 'rule metaspades', 'conda']
    (51, '        conda:')
    (52, '            "../envs/metaspades.yml"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NBISweden/nbis-meta, file=workflow/rules/assembly.smk
context_key: ['if config["assembly"]["metaspades"]', 'rule metaspades', 'shell']
    (53, '        shell:')
    (54, '            """')
    (55, '            # Create directories')
    (56, '            mkdir -p {params.tmp}')
    (57, '            # Clean output dir')
    (58, '            #rm -rf {params.output_dir}/*')
    (59, '            # Clean temp dir')
    (60, '            rm -rf {params.tmp}/*')
    (61, '            # Only use single-end if present')
    (62, '            if [ -s {input.se} ]; then')
    (63, '                single="-s {input.se}"')
    (64, '            else')
    (65, '                single=""')
    (66, '            fi')
    (67, '            metaspades.py \\\\')
    (68, '                -t {threads} -1 {input.R1} -2 {input.R2} $single \\\\')
    (69, '                -o {params.tmp} > {log} 2>&1')
    (70, '')
    (71, '            # If set to keep intermediate contigs, move to intermediate folder before deleting')
    (72, '            if [ "{config[metaspades][keep_intermediate]}" == "True" ]; then')
    (73, '                mkdir -p {params.intermediate_contigs}')
    (74, '                cp -r {params.tmp}/K* {params.intermediate_contigs}')
    (75, '            fi')
    (76, '            if [ "{config[metaspades][keep_corrected]}" == "True" ]; then')
    (77, '                mkdir -p {params.corrected}')
    (78, '                cp -r {params.tmp}/corrected {params.corrected}')
    (79, '            fi')
    (80, '')
    (81, '            # Clear intermediate contigs')
    (82, '            rm -rf {params.tmp}/K*')
    (83, '            # Clear corrected reads dir')
    (84, '            rm -rf {params.tmp}/corrected')
    (85, '            # Sync tmp output to outdir before removing')
    (86, '            cp -r {params.tmp}/* {params.output_dir}')
    (87, '            rm -rf {params.tmp}')
    (88, '            mv {params.output_dir}/scaffolds.fasta {params.output_dir}/final_contigs.fa')
    (89, '            """')
    (90, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NBISweden/nbis-meta, file=workflow/Snakefile
context_key: ['if config["run_preprocessing"] or config["preprocessing"]["fastqc"]']
    (22, '    if config["run_preprocessing"] or config["preprocessing"]["fastqc"]:')
    (23, '        wanted_input.append(results+"/report/samples_report.html")')
    (24, '')
    (25, '    if config["run_assembly"]:')
    (26, '        # add assembly stats')
    (27, '        wanted_input.append(results+"/report/assembly/assembly_stats.pdf")')
    (28, '        # get annotation input')
    (29, '        wanted_input += annotation_input(config, assemblies)')
    (30, '        # get binning input')
    (31, '        wanted_input += binning_input(config)')
    (32, '')
    (33, '    wanted_input += classify_input(config)')
    (34, '')
    (35, '    return wanted_input')
    (36, '')
    (37, '##### master target rule #####')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=healthyPlant/PhytoPipe, file=Snakefile
context_key: ['if config["strand1"] != \\\'\\\'', "if seq_type == \\'pe\\'", 'if len(SAMPLES) == 0', 'if (seq_type == "se")', 'elif (seq_type == "pe")']
    (102, 'if config["strand1"] != \\\'\\\':')
    (103, '\\tSAMPLES = [re.sub(r"(.*)_%s.*" % config["strand1"], "\\\\\\\\1", x) for x in SAMPLES]')
    (104, '')
    (105, "if seq_type == \\'pe\\':")
    (106, '\\tSAMPLES = [re.sub(r"(.*)_%s.*" % config["strand2"], "\\\\\\\\1", x) for x in SAMPLES]')
    (107, 'SAMPLES = list(set(SAMPLES))  #remove duplicated from a list using set')
    (108, '')
    (109, 'print("Samples: %s"  % ", ".join(SAMPLES))')
    (110, 'config["samples"] = SAMPLES  #save sample names in a global viriable')
    (111, '#print("config samples: ", config[\\\'samples\\\'])')
    (112, 'STRANDS = [config["strand1"], config["strand2"]]')
    (113, 'strand2 = config["strand2"]')
    (114, 'if len(SAMPLES) == 0:')
    (115, '\\tsys.exit("No sample files found. Exit!")')
    (116, '')
    (117, '# load rules ')
    (118, 'include: os.path.join(snakefiles_dir, "cleanReads.smk")')
    (119, 'include: os.path.join(snakefiles_dir, "classifyReads.smk")')
    (120, 'include: os.path.join(snakefiles_dir, "assemble.smk")')
    (121, 'include: os.path.join(snakefiles_dir, "annotate.smk")')
    (122, 'include: os.path.join(snakefiles_dir, "mappingReads.smk")')
    (123, 'include: os.path.join(snakefiles_dir, "makeReport.smk")')
    (124, '')
    (125, '# Single-end')
    (126, 'if (seq_type == "se"):')
    (127, '    #QC raw reads')
    (128, '\\trawFastQC = expand(qcDir + "/raw_fastqc/{sample}_fastqc.zip", sample=SAMPLES)')
    (129, '\\t#check host ribosomal RNA')
    (130, '\\trRNACheck = expand(trimDir + "/{sample}.filtRNA.fastq.gz", sample=SAMPLES)')
    (131, '\\t#remove duplicate reads')
    (132, '\\trmDup = expand(trimDir + "/{sample}.rmdup.fastq.gz", sample=SAMPLES) #run clumpify to remove duplicate reads')
    (133, '\\t#remove PhiX174 contaminant')
    (134, '\\trmCtm = expand(trimDir + "/{sample}.rmdup_ctm.fastq.gz", sample=SAMPLES) #run clumpify to remove duplicate reads')
    (135, '\\t#Trim reads')
    (136, '\\ttrim = expand(trimDir + "/{sample}.trimmed.fastq.gz", sample=SAMPLES), #run trimmomatic ')
    (137, '\\t#QC trimmed reads')
    (138, '\\ttrimmedFastQC = expand(qcDir + "/trimmed_fastqc/{sample}.trimmed_fastqc.zip",sample=SAMPLES), #run fastqc for trimmed reads')
    (139, '\\t#extract pathogen reads')
    (140, '\\textractPathRead = expand(cleanDir + "/{sample}.pathogen.fastq.gz", sample=SAMPLES),')
    (141, '')
    (142, '# Paired-ends')
    (143, 'elif (seq_type == "pe"):')
    (144, '    #QC raw reads')
    (145, '    rawFastQC = expand(qcDir + "/raw_fastqc/{sample}_{strand}_fastqc.zip", sample=SAMPLES, strand=STRANDS)')
    (146, '    #check host ribosomal RNA')
    (147, '    rRNACheck = expand(trimDir + "/{sample}_" + strand2 + ".filtRNA.fastq.gz", sample=SAMPLES)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=ESR-NZ/human_genomics_pipeline, file=workflow/Snakefile
context_key: ['if config[\\\'DATA\\\'] == "Cohort" or config[\\\'DATA\\\'] == \\\'cohort\\\'', 'rule all', 'input']
    (160, 'if config[\\\'DATA\\\'] == "Cohort" or config[\\\'DATA\\\'] == \\\'cohort\\\':')
    (161, '    rule all:')
    (162, '        input:')
    (163, '            "../results/qc/multiqc_report.html",')
    (164, '            expand("../results/mapped/{sample}_recalibrated.bam", sample = SAMPLES),')
    (165, '            expand("../results/called/{family}_raw_snps_indels.vcf", family = FAMILIES)')
    (166, '')
    (167, '##### Load rules #####')
    (168, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=ESR-NZ/human_genomics_pipeline, file=workflow/Snakefile
context_key: ['if config[\\\'TRIM\\\'] == "No" or config[\\\'TRIM\\\'] == "no"']
    (173, 'if config[\\\'TRIM\\\'] == "No" or config[\\\'TRIM\\\'] == "no":')
    (174, '    include: "rules/multiqc.smk"')
    (175, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=ESR-NZ/human_genomics_pipeline, file=workflow/Snakefile
context_key: ['if config[\\\'TRIM\\\'] == "Yes" or config[\\\'TRIM\\\'] == "yes"']
    (176, 'if config[\\\'TRIM\\\'] == "Yes" or config[\\\'TRIM\\\'] == "yes":')
    (177, '    include: "rules/trim_galore_pe.smk"')
    (178, '    include: "rules/multiqc_trim.smk"')
    (179, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=ESR-NZ/human_genomics_pipeline, file=workflow/Snakefile
context_key: ['if config[\\\'GPU_ACCELERATED\\\'] == "No" or config[\\\'GPU_ACCELERATED\\\'] == "no"']
    (180, 'if config[\\\'GPU_ACCELERATED\\\'] == "No" or config[\\\'GPU_ACCELERATED\\\'] == "no":')
    (181, '    include: "rules/bwa_mem.smk"')
    (182, '    include: "rules/gatk_MarkDuplicates.smk"')
    (183, '    include: "rules/gatk_BaseRecalibrator.smk"')
    (184, '    include: "rules/gatk_ApplyBQSR.smk"')
    (185, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=ESR-NZ/human_genomics_pipeline, file=workflow/Snakefile
context_key: ['if config[\\\'GPU_ACCELERATED\\\'] == "Yes" or config[\\\'GPU_ACCELERATED\\\'] == "yes"']
    (194, 'if config[\\\'GPU_ACCELERATED\\\'] == "Yes" or config[\\\'GPU_ACCELERATED\\\'] == "yes":')
    (195, '    include: "rules/pbrun_germline.smk"')
    (196, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AstrobioMike/genome-assembly-summary, file=Snakefile
context_key: ['if config["is_euk"]', 'rule run_eukcc', 'conda']
    (40, 'if config["is_euk"]:')
    (41, '')
    (42, '    rule run_eukcc:')
    (43, '        conda:')
    (44, '            "envs/eukcc.yaml"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AstrobioMike/genome-assembly-summary, file=Snakefile
context_key: ['if config["is_euk"]', 'rule run_eukcc', 'input']
    (45, '        input:')
    (46, '            genome = config["genomes_dir"] + "/{genome_ID}" + config["assembly_extension"],')
    (47, '            eukcc_db_trigger = config["DIR_HOLDING_eukcc_DIR"] + "/" + config["eukcc_db_dir"] + "/" + config["eukcc_TRIGGER_FILE"]')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AstrobioMike/genome-assembly-summary, file=Snakefile
context_key: ['if config["is_euk"]', 'rule run_eukcc', 'params']
    (48, '        params:')
    (49, '            output_dir = "{genome_ID}-eukcc-out",')
    (50, '            eukcc_db_dir = config["DIR_HOLDING_eukcc_DIR"] + "/" + config["eukcc_db_dir"]')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AstrobioMike/genome-assembly-summary, file=Snakefile
context_key: ['if config["is_euk"]', 'rule run_eukcc', 'resources']
    (51, '        resources:')
    (52, '            cpus = config["threads"]')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AstrobioMike/genome-assembly-summary, file=Snakefile
context_key: ['if config["is_euk"]', 'rule run_eukcc', 'log']
    (53, '        log:')
    (54, '            config["logs_dir"] + "{genome_ID}-eukcc.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AstrobioMike/genome-assembly-summary, file=Snakefile
context_key: ['if config["is_euk"]', 'rule run_eukcc', 'output']
    (55, '        output:')
    (56, '            est_tab = "{genome_ID}-eukcc-estimates.tsv",')
    (57, '            AA_seqs = "{genome_ID}-prots.faa"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AstrobioMike/genome-assembly-summary, file=Snakefile
context_key: ['if config["is_euk"]', 'rule run_eukcc', 'shell']
    (58, '        shell:')
    (59, '            """')
    (60, '            eukcc single --db {params.eukcc_db_dir} --threads {resources.cpus} --out {params.output_dir} --keep {input.genome} > {log} 2>&1')
    (61, '')
    (62, '            # getting comp./redund. estimates')
    (63, '            paste <( echo "{wildcards.genome_ID}" ) <( tail -n +2 {params.output_dir}/eukcc.csv | head -n 1 | cut -f 2,3 ) > {output.est_tab}')
    (64, '')
    (65, '            # getting protein seqs to pass to CAT formatted in a way it likes so they can be tracked back to the contigs')
    (66, "            sed \\'s/metaeuk_//\\' {params.output_dir}/workdir/metaeuk/*_metaeuk_cleaned.faa > {output.AA_seqs}")
    (67, '')
    (68, '            rm -rf {params.output_dir}')
    (69, '            """')
    (70, '')
    (71, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AstrobioMike/genome-assembly-summary, file=Snakefile
context_key: ['if config["is_euk"]', 'rule combine_eukcc_estimates', 'input']
    (72, '    rule combine_eukcc_estimates:')
    (73, '        input:')
    (74, '            expand("{genome_ID}-eukcc-estimates.tsv", genome_ID = genome_IDs)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AstrobioMike/genome-assembly-summary, file=Snakefile
context_key: ['if config["is_euk"]', 'rule combine_eukcc_estimates', 'output']
    (75, '        output:')
    (76, '            "combined-eukcc-estimates.tsv"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AstrobioMike/genome-assembly-summary, file=Snakefile
context_key: ['if config["is_euk"]', 'rule combine_eukcc_estimates', 'shell']
    (77, '        shell:')
    (78, '            """')
    (79, '            printf "Assembly\\\\\\\\tEst. Comp.\\\\\\\\tEst. Redund.\\\\\\')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=pangeo-data/WeatherBench, file=Snakefile
context_key: ["if config[\\'tmpdir\\'] == \\'None\\'"]
    (7, "if config[\\'tmpdir\\'] == \\'None\\':")
    (8, "    config[\\'tmpdir\\'] = config[\\'datadir\\']")
    (9, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=yztxwd/snakemake-pipeline-general, file=rules/bowtie2.smk
context_key: ['if config["skiptrim"]']
    (5, '    if config["skiptrim"]:')
    (6, '        return ["data/" + samples.loc[(wildcards.sample, wildcards.rep, wildcards.unit), "fq1"],')
    (7, '                "data/" + samples.loc[(wildcards.sample, wildcards.rep, wildcards.unit), "fq2"]]')
    (8, '    else:')
    (9, '        return [f"output/trimmed/{{sample}}-{{rep}}-{{unit}}.{trimmer}.1.fq.gz",')
    (10, '                f"output/trimmed/{{sample}}-{{rep}}-{{unit}}.{trimmer}.2.fq.gz"]')
    (11, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=hans-vg/snakemake_rnaseq_hisat2_workflow, file=rules/align.smk
context_key: ['if config["trimming"]["skip"]']
    (1, '    if config["trimming"]["skip"]:')
    (2, '        # no trimming, use raw reads')
    (3, '        return units.loc[(wildcards.sample, wildcards.unit), ["fq1", "fq2"]].dropna()')
    (4, '    else:')
    (5, '        # yes trimming, use trimmed data')
    (6, '        if not is_single_end(**wildcards):')
    (7, '            # paired-end sample')
    (8, '            #print(expand("trimmed/{sample}-{unit}.{group}.fastq.gz", group=[1, 2], **wildcards))')
    (9, '            return expand("trimmed/{sample}-{unit}.{group}.fastq.gz", group=[1, 2], **wildcards)')
    (10, '        # single end sample')
    (11, '        #print("trimmed/{sample}-{unit}.fastq.gz".format(**wildcards))')
    (12, '        return "trimmed/{sample}-{unit}.fastq.gz".format(**wildcards)')
    (13, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SherineAwad/gatkVariantCalling, file=Snakefile
context_key: ["if config[\\'PAIRED\\']", 'rule trim', 'input']
    (106, "if config[\\'PAIRED\\']:")
    (107, '    rule trim:')
    (108, '       input:')
    (109, '           r1 = "{sample}.r_1.fq.gz",')
    (110, '           r2 = "{sample}.r_2.fq.gz"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SherineAwad/gatkVariantCalling, file=Snakefile
context_key: ["if config[\\'PAIRED\\']", 'rule trim', 'output']
    (111, '       output:')
    (112, '           "galore/{sample}.r_1_val_1.fq.gz",')
    (113, '           "galore/{sample}.r_2_val_2.fq.gz"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SherineAwad/gatkVariantCalling, file=Snakefile
context_key: ["if config[\\'PAIRED\\']", 'rule trim', 'conda']
    (114, "       conda: \\'env/env-trim.yaml\\'")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SherineAwad/gatkVariantCalling, file=Snakefile
context_key: ["if config[\\'PAIRED\\']", 'rule trim', 'shell']
    (115, '       shell:')
    (116, '           """')
    (117, '           mkdir -p galore')
    (118, '           mkdir -p fastqc')
    (119, '           trim_galore --gzip --retain_unpaired --trim1 --fastqc --fastqc_args "--outdir fastqc" -o galore --paired {input.r1} {input.r2}')
    (120, '           """')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SherineAwad/gatkVariantCalling, file=Snakefile
context_key: ["if config[\\'PAIRED\\']", 'rule tosam', 'input']
    (121, '    rule tosam:')
    (122, '       input:')
    (123, '          expand("{genome}.fasta.fai", genome = config[\\\'GENOME\\\']),')
    (124, '          expand("{genome}.rev.1.bt2", genome = config[\\\'GENOME\\\']),')
    (125, '          expand("{genome}.rev.2.bt2", genome = config[\\\'GENOME\\\']),')
    (126, '          expand("{genome}.1.bt2", genome = config[\\\'GENOME\\\']),')
    (127, '          expand("{genome}.2.bt2", genome = config[\\\'GENOME\\\']),')
    (128, '          expand("{genome}.3.bt2", genome = config[\\\'GENOME\\\']),')
    (129, '          expand("{genome}.4.bt2", genome = config[\\\'GENOME\\\']),')
    (130, '          r1 = "galore/{sample}.r_1_val_1.fq.gz",')
    (131, '          r2 = "galore/{sample}.r_2_val_2.fq.gz"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SherineAwad/gatkVariantCalling, file=Snakefile
context_key: ["if config[\\'PAIRED\\']", 'rule tosam', 'params']
    (132, '       params:')
    (133, "          genome = config[\\'GENOME\\']")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SherineAwad/gatkVariantCalling, file=Snakefile
context_key: ["if config[\\'PAIRED\\']", 'rule tosam', 'benchmark']
    (134, '       benchmark: "logs/{sample}.bowtie2.benchmark"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SherineAwad/gatkVariantCalling, file=Snakefile
context_key: ["if config[\\'PAIRED\\']", 'rule tosam', 'conda']
    (135, "       conda: \\'env/env-align.yaml\\'")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SherineAwad/gatkVariantCalling, file=Snakefile
context_key: ["if config[\\'PAIRED\\']", 'rule tosam', 'output']
    (136, '       output:')
    (137, '          "{sample}.sam"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SherineAwad/gatkVariantCalling, file=Snakefile
context_key: ["if config[\\'PAIRED\\']", 'rule tosam', 'shell']
    (138, '       shell:')
    (139, '          "bowtie2 -x {params.genome} -1 {input.r1} -2 {input.r2} -S {output}"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SherineAwad/StructureVariations, file=Snakefile
context_key: ["if config[\\'PAIRED\\']", 'rule trim', 'input']
    (25, "if config[\\'PAIRED\\']:")
    (26, '    rule trim:')
    (27, '       input:')
    (28, '           r1 = "{sample}.r_1.fq.gz",')
    (29, '           r2 = "{sample}.r_2.fq.gz"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SherineAwad/StructureVariations, file=Snakefile
context_key: ["if config[\\'PAIRED\\']", 'rule trim', 'output']
    (30, '       output:')
    (31, '           "galore/{sample}.r_1_val_1.fq.gz",')
    (32, '           "galore/{sample}.r_2_val_2.fq.gz"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SherineAwad/StructureVariations, file=Snakefile
context_key: ["if config[\\'PAIRED\\']", 'rule trim', 'conda']
    (33, "       conda: \\'env/env-trim.yaml\\'")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SherineAwad/StructureVariations, file=Snakefile
context_key: ["if config[\\'PAIRED\\']", 'rule trim', 'shell']
    (34, '       shell:')
    (35, '           """')
    (36, '           mkdir -p galore')
    (37, '           mkdir -p fastqc')
    (38, '           trim_galore --gzip --retain_unpaired --trim1 --fastqc --fastqc_args "--outdir fastqc" -o galore --paired {input.r1} {input.r2}')
    (39, '           """')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SherineAwad/StructureVariations, file=Snakefile
context_key: ["if config[\\'PAIRED\\']", 'rule tosam', 'input']
    (40, '    rule tosam:')
    (41, '        input:')
    (42, "            genome = config[\\'GENOME\\'],")
    (43, '            r1 = "galore/{sample}.r_1_val_1.fq.gz",')
    (44, '            r2 = "galore/{sample}.r_2_val_2.fq.gz"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SherineAwad/StructureVariations, file=Snakefile
context_key: ["if config[\\'PAIRED\\']", 'rule tosam', 'output']
    (45, '        output:')
    (46, "            \\'{sample}.sam\\'")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SherineAwad/StructureVariations, file=Snakefile
context_key: ["if config[\\'PAIRED\\']", 'rule tosam', 'conda']
    (47, "        conda: \\'env/env-align.yaml\\'")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SherineAwad/StructureVariations, file=Snakefile
context_key: ["if config[\\'PAIRED\\']", 'rule tosam', 'shell']
    (48, '        shell:')
    (49, '            "bwa mem {input.genome} {input.r1} {input.r2} > {output}"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=usnistgov/giab-asm-benchmarking, file=workflow/Snakefile
context_key: ['if config["reference"] == "GRCh38"']
    (65, 'if config["reference"] == "GRCh38":')
    (66, '    ref_id = config["ref38"]["id"]')
    (67, '    ref_url = config["ref38"]["url"]')
    (68, '    strat_url = config["strat38"]["url"]')
    (69, '    strat_tsv = config["strat38"]["tsv"]')
    (70, '    strat_id = config["strat38"]["id"]')
    (71, '    par_ref = config["par38"]')
    (72, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=usnistgov/giab-asm-benchmarking, file=workflow/Snakefile
context_key: ['elif config["reference"] == "GRCh37"']
    (73, 'elif config["reference"] == "GRCh37":')
    (74, '    ref_id = config["ref37"]["id"]')
    (75, '    ref_url = config["ref37"]["url"]')
    (76, '    strat_url = config["strat37"]["url"]')
    (77, '    strat_tsv = config["strat37"]["tsv"]')
    (78, '    strat_id = config["strat37"]["id"]')
    (79, '    par_ref = config["par37"]')
    (80, '')
    (81, '## Define basename for benchmark files')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=usnistgov/giab-asm-benchmarking, file=workflow/Snakefile
context_key: ['if config["gender"] == "male"', 'rule dipcall_makefile_male', 'output']
    (165, '        output: "results/dipcall/{prefix}.mak"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=usnistgov/giab-asm-benchmarking, file=workflow/Snakefile
context_key: ['if config["gender"] == "male"', 'rule dipcall_makefile_male', 'params']
    (166, '        params:')
    (167, '            prefix= "results/dipcall/{prefix}",')
    (168, '            dock=config["docker_container"]')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=usnistgov/giab-asm-benchmarking, file=workflow/Snakefile
context_key: ['if config["gender"] == "male"', 'rule dipcall_makefile_male', 'shell']
    (169, '        shell: """')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=usnistgov/giab-asm-benchmarking, file=workflow/Snakefile
context_key: ['if config["gender"] == "male"', 'rule dipcall_makefile_male']
    (170, '        H1=$(basename {input.h1})')
    (171, '        H2=$(basename {input.h2})')
    (172, '        WD=$(pwd)')
    (173, '        ASMDIR1=$WD/$(dirname {input.h1})')
    (174, '        ASMDIR2=$WD/$(dirname {input.h2})')
    (175, '        docker run -it \\\\')
    (176, '            -v $(pwd):/data \\\\')
    (177, '            -v $ASMDIR1:/assem1 \\\\')
    (178, '            -v $ASMDIR2:/assem2 \\\\')
    (179, '            {params.dock} /data/src/dipcall.kit/run-dipcall \\\\')
    (180, '                    -x /data/{input.par} \\\\')
    (181, '                    /data/{params.prefix} \\\\')
    (182, '                    /data/{input.ref} \\\\')
    (183, '                    /assem1/$H1 \\\\')
    (184, '                    /assem2/$H2 \\\\')
    (185, '                    > {output}')
    (186, '        """')
    (187, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=usnistgov/giab-asm-benchmarking, file=workflow/Snakefile
context_key: ['elif config["gender"] == "female"', 'rule dipcall_makefile_female', 'input']
    (188, 'elif config["gender"] == "female" :')
    (189, '    rule dipcall_makefile_female:')
    (190, '        input:')
    (191, '            h1=get_hap1,')
    (192, '            h2=get_hap2,')
    (193, '            #ref="resources/references/" + ref_id + ".fa"')
    (194, '            ref= rules.get_ref.output,')
    (195, '            ref_idx= rules.index_ref.output')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=usnistgov/giab-asm-benchmarking, file=workflow/Snakefile
context_key: ['elif config["gender"] == "female"', 'rule dipcall_makefile_female', 'output']
    (196, '        output: "results/dipcall/{prefix}.mak"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=usnistgov/giab-asm-benchmarking, file=workflow/Snakefile
context_key: ['elif config["gender"] == "female"', 'rule dipcall_makefile_female', 'params']
    (197, '        params:')
    (198, '            prefix= "results/dipcall/{prefix}",')
    (199, '            dock=config["docker_container"]')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=usnistgov/giab-asm-benchmarking, file=workflow/Snakefile
context_key: ['elif config["gender"] == "female"', 'rule dipcall_makefile_female', 'log']
    (200, '        log: "results/dipcall/{prefix}_dipcall_makefile.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=usnistgov/giab-asm-benchmarking, file=workflow/Snakefile
context_key: ['elif config["gender"] == "female"', 'rule dipcall_makefile_female', 'shell']
    (201, '        shell: """')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=usnistgov/giab-asm-benchmarking, file=workflow/Snakefile
context_key: ['elif config["gender"] == "female"', 'rule dipcall_makefile_female']
    (202, '        H1=$(basename {input.h1})')
    (203, '        H2=$(basename {input.h2})')
    (204, '        WD=$(pwd)')
    (205, '        ASMDIR1=$WD/$(dirname {input.h1})')
    (206, '        ASMDIR2=$WD/$(dirname {input.h2})')
    (207, '        docker run -it \\\\')
    (208, '            -v $(pwd):/data \\\\')
    (209, '            -v $ASMDIR1:/assem1 \\\\')
    (210, '            -v $ASMDIR2:/assem2 \\\\')
    (211, '            {params.dock} /data/src/dipcall.kit/run-dipcall \\\\')
    (212, '                    /data/{params.prefix} \\\\')
    (213, '                    /data/{input.ref} \\\\')
    (214, '                    /assem1/$H1 \\\\')
    (215, '                    /assem2/$H2 \\\\')
    (216, '                    > {output}')
    (217, '        """')
    (218, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SherineAwad/SomaticMutations, file=Snakefile
context_key: ["if config[\\'PAIRED\\']", 'rule trim', 'input']
    (42, "if config[\\'PAIRED\\']:")
    (43, '    rule trim:')
    (44, '       input:')
    (45, '           r1 = "{sample}.r_1.fq.gz",')
    (46, '           r2 = "{sample}.r_2.fq.gz"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SherineAwad/SomaticMutations, file=Snakefile
context_key: ["if config[\\'PAIRED\\']", 'rule trim', 'output']
    (47, '       output:')
    (48, '           "galore/{sample}.r_1_val_1.fq.gz",')
    (49, '           "galore/{sample}.r_2_val_2.fq.gz"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SherineAwad/SomaticMutations, file=Snakefile
context_key: ["if config[\\'PAIRED\\']", 'rule trim', 'conda']
    (50, "       conda: \\'env/env-trim.yaml\\'")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SherineAwad/SomaticMutations, file=Snakefile
context_key: ["if config[\\'PAIRED\\']", 'rule trim', 'shell']
    (51, '       shell:')
    (52, '           """')
    (53, '           mkdir -p galore')
    (54, '           mkdir -p fastqc')
    (55, '           trim_galore --gzip --retain_unpaired --trim1 --fastqc --fastqc_args "--outdir fastqc" -o galore --paired {input.r1} {input.r2}')
    (56, '           """')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SherineAwad/SomaticMutations, file=Snakefile
context_key: ["if config[\\'PAIRED\\']", 'rule align', 'input']
    (57, '    rule align:')
    (58, '       input:')
    (59, '          r1 = "galore/{sample}.r_1_val_1.fq.gz",')
    (60, '          r2 = "galore/{sample}.r_2_val_2.fq.gz"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SherineAwad/SomaticMutations, file=Snakefile
context_key: ["if config[\\'PAIRED\\']", 'rule align', 'output']
    (61, '       output:')
    (62, '             "{sample}_Aligned.out.sam"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SherineAwad/SomaticMutations, file=Snakefile
context_key: ["if config[\\'PAIRED\\']", 'rule align', 'params']
    (63, '       params:')
    (64, "            threads = config[\\'THREADS\\'],")
    (65, "            gtf = config[\\'GTF\\'],")
    (66, '            prefix = "{sample}_",')
    (67, "            index = config[\\'INDEX\\']")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SherineAwad/SomaticMutations, file=Snakefile
context_key: ["if config[\\'PAIRED\\']", 'rule align', 'conda']
    (68, "       conda: \\'env/env-align.yaml\\'")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SherineAwad/SomaticMutations, file=Snakefile
context_key: ["if config[\\'PAIRED\\']", 'rule align', 'shell']
    (69, '       shell:')
    (70, '            """')
    (71, '            STAR --genomeDir {params.index} --runThreadN {params.threads} --readFilesCommand zcat --readFilesIn {input.r1} {input.r2}  --outFileNamePrefix {params.prefix} --sjdbGTFfile {params.gtf}  --twopassMode Basic')
    (72, '            """')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NCI-CGR/Nanopore_DNA-seq, file=modules/Snakefile_SV_hpv
context_key: ['if config.get("target_bed")', 'if os.path.exists(target)']
    (12, 'if config.get("target_bed"):')
    (13, '    target = config["target_bed"]')
    (14, '    if os.path.exists(target):')
    (15, '        target_bed = target')
    (16, '        print("Using {} as target file".format(target_bed))')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NCI-CGR/Nanopore_DNA-seq, file=modules/Snakefile_SV_hpv
context_key: ['if config.get("target_bed")', 'else']
    (17, '    else:')
    (18, '        print("Target BED {} not found. Continuing without target".format(target))')
    (19, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NCI-CGR/Nanopore_DNA-seq, file=modules/Snakefile_SV
context_key: ['if config.get("target_bed")', 'if os.path.exists(target)']
    (8, 'if config.get("target_bed"):')
    (9, '    target = config["target_bed"]')
    (10, '    if os.path.exists(target):')
    (11, '        target_bed = target')
    (12, '        print("Using {} as target file".format(target_bed))')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NCI-CGR/Nanopore_DNA-seq, file=modules/Snakefile_SV
context_key: ['if config.get("target_bed")', 'else']
    (13, '    else:')
    (14, '        print("Target BED {} not found. Continuing without target".format(target))')
    (15, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=williamjeong2/snakemake_RNA-seq, file=Snakefile
context_key: ['if config["aligner"].upper().find("HISAT2") >= 0', 'if config["organism"].upper().find("HOMO") >= 0 or config["organism"].upper().find("HUMAN") >= 0']
    (124, 'if config["aligner"].upper().find("HISAT2") >= 0:')
    (125, '    if config["organism"].upper().find("HOMO") >= 0 or config["organism"].upper().find("HUMAN") >= 0:')
    (126, '        ref_ver = config["ref"]["hg_release_ver"]')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=williamjeong2/snakemake_RNA-seq, file=Snakefile
context_key: ['if config["aligner"].upper().find("HISAT2") >= 0', 'elif config["organism"].upper().find("MUS") >= 0 or config["organism"].upper().find("MOUSE") >= 0']
    (127, '    elif config["organism"].upper().find("MUS") >= 0 or config["organism"].upper().find("MOUSE") >= 0:')
    (128, '        ref_ver = config["ref"]["mm_release_ver"]')
    (129, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=williamjeong2/snakemake_RNA-seq, file=Snakefile
context_key: ['if config["aligner"].upper().find("HISAT2") >= 0', 'if config["need_indexed"].upper().find("NEED") >= 0', 'rule hisat_index', 'output']
    (130, '    if config["need_indexed"].upper().find("NEED") >= 0:')
    (131, '        rule hisat_index:')
    (132, '            output:')
    (133, '                [WORKING_DIR + "genome/genome." + str(i) + ".ht2" for i in range(1,9)],')
    (134, '                WORKING_DIR + "genome/genome.gtf"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=williamjeong2/snakemake_RNA-seq, file=Snakefile
context_key: ['if config["aligner"].upper().find("HISAT2") >= 0', 'if config["need_indexed"].upper().find("NEED") >= 0', 'rule hisat_index', 'message']
    (135, '            message:')
    (136, '                "indexing genome"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=williamjeong2/snakemake_RNA-seq, file=Snakefile
context_key: ['if config["aligner"].upper().find("HISAT2") >= 0', 'if config["need_indexed"].upper().find("NEED") >= 0', 'rule hisat_index', 'params']
    (137, '            params:')
    (138, '                WORKING_DIR + "genome/",')
    (139, '                ref_ver')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=williamjeong2/snakemake_RNA-seq, file=Snakefile
context_key: ['if config["aligner"].upper().find("HISAT2") >= 0', 'if config["need_indexed"].upper().find("NEED") >= 0', 'rule hisat_index', 'threads']
    (140, '            threads: THREADS')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=williamjeong2/snakemake_RNA-seq, file=Snakefile
context_key: ['if config["aligner"].upper().find("HISAT2") >= 0', 'if config["need_indexed"].upper().find("NEED") >= 0', 'rule hisat_index', 'run', 'if config["organism"].upper().find("HOMO") >= 0 or config["organism"].upper().find("HUMAN") >= 0']
    (141, '            run:')
    (142, '                if config["organism"].upper().find("HOMO") >= 0 or config["organism"].upper().find("HUMAN") >= 0:')
    (143, '                    shell("cp scripts/make_grch38_tran.sh {params[0]} && sh temp/genome/make_grch38_tran.sh {params[1]} {threads}")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=williamjeong2/snakemake_RNA-seq, file=Snakefile
context_key: ['if config["aligner"].upper().find("HISAT2") >= 0', 'if config["need_indexed"].upper().find("NEED") >= 0', 'rule hisat_index', 'run', 'elif config["organism"].upper().find("MUS") >= 0 or config["organism"].upper().find("MOUSE") >= 0']
    (144, '                elif config["organism"].upper().find("MUS") >= 0 or config["organism"].upper().find("MOUSE") >= 0:')
    (145, '                    shell("cp scripts/make_grcm38_tran.sh {params[0]} && sh temp/genome/make_grcm38_tran.sh {params[1]} {threads}")')
    (146, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=williamjeong2/snakemake_RNA-seq, file=Snakefile
context_key: ['if config["aligner"].upper().find("HISAT2") >= 0', 'rule hisat_mapping', 'input']
    (147, '    rule hisat_mapping:')
    (148, '        input:')
    (149, '            get_trimmed,')
    (150, '            indexFiles = [WORKING_DIR + "genome/genome." + str(i) + ".ht2" for i in range(1,9)]')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=williamjeong2/snakemake_RNA-seq, file=Snakefile
context_key: ['if config["aligner"].upper().find("HISAT2") >= 0', 'rule hisat_mapping', 'output']
    (151, '        output:')
    (152, '            bams = temp(WORKING_DIR + "mapped/{sample}.sorted.bam"),')
    (153, '            log  = RESULT_DIR + "logs/hisat2/{sample}_log.txt"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=williamjeong2/snakemake_RNA-seq, file=Snakefile
context_key: ['if config["aligner"].upper().find("HISAT2") >= 0', 'rule hisat_mapping', 'params']
    (154, '        params:')
    (155, '            indexName = WORKING_DIR + "genome/genome",')
    (156, '            sampleName = "{sample}"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=williamjeong2/snakemake_RNA-seq, file=Snakefile
context_key: ['if config["aligner"].upper().find("HISAT2") >= 0', 'rule hisat_mapping', 'message']
    (157, '        message:')
    (158, '            "mapping reads to genome to bam files."')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=williamjeong2/snakemake_RNA-seq, file=Snakefile
context_key: ['if config["aligner"].upper().find("HISAT2") >= 0', 'rule hisat_mapping', 'threads']
    (159, '        threads: THREADS')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=williamjeong2/snakemake_RNA-seq, file=Snakefile
context_key: ['if config["aligner"].upper().find("HISAT2") >= 0', 'rule hisat_mapping', 'run', 'if sample_is_single_end(params.sampleName)']
    (160, '        run:')
    (161, '            if sample_is_single_end(params.sampleName):')
    (162, '                shell("hisat2 -p {threads} --summary-file {output.log} -q -x {params.indexName} \\\\')
    (163, '                -U {input[0]} | samtools view -@ {threads} -Sb -F 4 | samtools sort -@ {threads} -o {output.bams}; \\\\')
    (164, '                samtools index {output.bams}")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=williamjeong2/snakemake_RNA-seq, file=Snakefile
context_key: ['if config["aligner"].upper().find("HISAT2") >= 0', 'rule hisat_mapping', 'run', 'else']
    (165, '            else:')
    (166, '                shell("hisat2 -p {threads} --summary-file {output.log} -q -x {params.indexName} \\\\')
    (167, '                -1 {input[0]} -2 {input[1]} | samtools view -@ {threads} -Sb -F 4 | samtools sort -@ {threads} -o {output.bams}; \\\\')
    (168, '                samtools index {output.bams}")')
    (169, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=williamjeong2/snakemake_RNA-seq, file=Snakefile
context_key: ['elif config["aligner"].upper().find("STAR") >= 0', 'if config["need_indexed"].upper().find("NEED") >= 0', 'rule star_index', 'input']
    (170, 'elif config["aligner"].upper().find("STAR") >= 0:')
    (171, '    if config["need_indexed"].upper().find("NEED") >= 0:')
    (172, '        rule star_index:')
    (173, '            input:')
    (174, '                fasta = WORKING_DIR + "genome/genome.fa", ')
    (175, '                gtf  = WORKING_DIR + "genome/genome.gtf"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=williamjeong2/snakemake_RNA-seq, file=Snakefile
context_key: ['elif config["aligner"].upper().find("STAR") >= 0', 'if config["need_indexed"].upper().find("NEED") >= 0', 'rule star_index', 'output']
    (176, '            output:')
    (177, "                directory(WORKING_DIR + \\'genome\\')")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=williamjeong2/snakemake_RNA-seq, file=Snakefile
context_key: ['elif config["aligner"].upper().find("STAR") >= 0', 'if config["need_indexed"].upper().find("NEED") >= 0', 'rule star_index', 'message']
    (178, '            message:')
    (179, '                "indexing genome"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=williamjeong2/snakemake_RNA-seq, file=Snakefile
context_key: ['elif config["aligner"].upper().find("STAR") >= 0', 'if config["need_indexed"].upper().find("NEED") >= 0', 'rule star_index', 'threads']
    (180, '            threads: THREADS')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=williamjeong2/snakemake_RNA-seq, file=Snakefile
context_key: ['elif config["aligner"].upper().find("STAR") >= 0', 'if config["need_indexed"].upper().find("NEED") >= 0', 'rule star_index', 'shell']
    (181, '            shell:"""')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=williamjeong2/snakemake_RNA-seq, file=Snakefile
context_key: ['elif config["aligner"].upper().find("STAR") >= 0', 'if config["need_indexed"].upper().find("NEED") >= 0', 'rule star_index']
    (182, '            STAR --runThreadN {threads} \\\\')
    (183, '            --runMode genomeGenerate \\\\')
    (184, '            --genomeDir {output} \\\\')
    (185, '            --genomeFastaFiles {input.fasta} \\\\')
    (186, '            --sjdbGTFfile {input.gtf} \\\\')
    (187, '            --sjdbOverhang 100')
    (188, '            """')
    (189, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=williamjeong2/snakemake_RNA-seq, file=Snakefile
context_key: ['elif config["aligner"].upper().find("STAR") >= 0', 'rule star_mapping', 'input']
    (190, '    rule star_mapping:')
    (191, '        input:')
    (192, '            get_trimmed')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=williamjeong2/snakemake_RNA-seq, file=Snakefile
context_key: ['elif config["aligner"].upper().find("STAR") >= 0', 'rule star_mapping', 'output']
    (193, '        output:')
    (194, '            bams = temp(WORKING_DIR + "mapped/{sample}.sorted.bam"),')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=williamjeong2/snakemake_RNA-seq, file=Snakefile
context_key: ['elif config["aligner"].upper().find("STAR") >= 0', 'rule star_mapping', 'log']
    (195, '        log:')
    (196, '            RESULT_DIR + "logs/star/{sample}.log.txt"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=williamjeong2/snakemake_RNA-seq, file=Snakefile
context_key: ['elif config["aligner"].upper().find("STAR") >= 0', 'rule star_mapping', 'params']
    (197, '        params:')
    (198, "            gtf = WORKING_DIR + \\'genome/genome.gtf\\',")
    (199, "            index = WORKING_DIR + \\'genome\\',")
    (200, '            prefix = WORKING_DIR + "mapped/{sample}.",')
    (201, '            outdir = WORKING_DIR + "mapped",')
    (202, '            sampleName = "{sample}"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=williamjeong2/snakemake_RNA-seq, file=Snakefile
context_key: ['elif config["aligner"].upper().find("STAR") >= 0', 'rule star_mapping', 'message']
    (203, '        message:')
    (204, '            "mapping reads to genome to bam files."')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=williamjeong2/snakemake_RNA-seq, file=Snakefile
context_key: ['elif config["aligner"].upper().find("STAR") >= 0', 'rule star_mapping', 'threads']
    (205, '        threads: THREADS')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=williamjeong2/snakemake_RNA-seq, file=Snakefile
context_key: ['elif config["aligner"].upper().find("STAR") >= 0', 'rule star_mapping', 'run', 'if sample_is_single_end(params.sampleName)']
    (206, '        run:')
    (207, '            if sample_is_single_end(params.sampleName):')
    (208, '                shell("STAR --runThreadN {threads} --genomeDir {params.index} --outSAMunmapped None --outSAMtype BAM Unsorted \\\\')
    (209, '                --outStd BAM_Unsorted --sjdbGTFfile {params.gtf} --readFilesIn {input[0]} --readFilesCommand zcat \\\\')
    (210, '                --outFileNamePrefix {params.prefix} | samtools sort -@ {threads} -O bam -o {output.bams} 2> {log}")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=williamjeong2/snakemake_RNA-seq, file=Snakefile
context_key: ['elif config["aligner"].upper().find("STAR") >= 0', 'rule star_mapping', 'run', 'else']
    (211, '            else:')
    (212, '                shell("STAR --runThreadN {threads} --genomeDir {params.index} --outSAMunmapped None --outSAMtype BAM Unsorted \\\\')
    (213, '                --outStd BAM_Unsorted --sjdbGTFfile {params.gtf} --readFilesIn {input[0]} {input[1]} --readFilesCommand zcat \\\\')
    (214, '                --outFileNamePrefix {params.prefix} | samtools sort -@ {threads} -O bam -o {output.bams} 2> {log}")')
    (215, '')
    (216, '#########################################')
    (217, '# Get table containing the RPKM or FPKM')
    (218, '#########################################')
    (219, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=williamjeong2/snakemake_RNA-seq, file=Snakefile_toCount
context_key: ['if config["aligner"].upper().find("HISAT2") >= 0', 'if config["organism"].upper().find("HOMO") >= 0 or config["organism"].upper().find("HUMAN") >= 0']
    (163, 'if config["aligner"].upper().find("HISAT2") >= 0:')
    (164, '    if config["organism"].upper().find("HOMO") >= 0 or config["organism"].upper().find("HUMAN") >= 0:')
    (165, '        ref_ver = config["ref"]["hg_release_ver"]')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=williamjeong2/snakemake_RNA-seq, file=Snakefile_toCount
context_key: ['if config["aligner"].upper().find("HISAT2") >= 0', 'elif config["organism"].upper().find("MUS") >= 0 or config["organism"].upper().find("MOUSE") >= 0']
    (166, '    elif config["organism"].upper().find("MUS") >= 0 or config["organism"].upper().find("MOUSE") >= 0:')
    (167, '        ref_ver = config["ref"]["mm_release_ver"]')
    (168, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=williamjeong2/snakemake_RNA-seq, file=Snakefile_toCount
context_key: ['if config["aligner"].upper().find("HISAT2") >= 0', 'if config["need_indexed"].upper().find("NEED") >= 0', 'rule hisat_index', 'output']
    (169, '    if config["need_indexed"].upper().find("NEED") >= 0:')
    (170, '        rule hisat_index:')
    (171, '            output:')
    (172, '                [WORKING_DIR + "genome/genome." + str(i) + ".ht2" for i in range(1,9)],')
    (173, '                WORKING_DIR + "genome/genome.gtf"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=williamjeong2/snakemake_RNA-seq, file=Snakefile_toCount
context_key: ['if config["aligner"].upper().find("HISAT2") >= 0', 'if config["need_indexed"].upper().find("NEED") >= 0', 'rule hisat_index', 'message']
    (174, '            message:')
    (175, '                "indexing genome"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=williamjeong2/snakemake_RNA-seq, file=Snakefile_toCount
context_key: ['if config["aligner"].upper().find("HISAT2") >= 0', 'if config["need_indexed"].upper().find("NEED") >= 0', 'rule hisat_index', 'params']
    (176, '            params:')
    (177, '                WORKING_DIR + "genome/",')
    (178, '                ref_ver')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=williamjeong2/snakemake_RNA-seq, file=Snakefile_toCount
context_key: ['if config["aligner"].upper().find("HISAT2") >= 0', 'if config["need_indexed"].upper().find("NEED") >= 0', 'rule hisat_index', 'threads']
    (179, '            threads: THREADS')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=williamjeong2/snakemake_RNA-seq, file=Snakefile_toCount
context_key: ['if config["aligner"].upper().find("HISAT2") >= 0', 'if config["need_indexed"].upper().find("NEED") >= 0', 'rule hisat_index', 'run', 'if config["organism"].upper().find("HOMO") >= 0 or config["organism"].upper().find("HUMAN") >= 0']
    (180, '            run:')
    (181, '                if config["organism"].upper().find("HOMO") >= 0 or config["organism"].upper().find("HUMAN") >= 0:')
    (182, '                    shell("cp scripts/make_grch38_tran.sh {params[0]} && sh temp/genome/make_grch38_tran.sh {params[1]} {threads}")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=williamjeong2/snakemake_RNA-seq, file=Snakefile_toCount
context_key: ['if config["aligner"].upper().find("HISAT2") >= 0', 'if config["need_indexed"].upper().find("NEED") >= 0', 'rule hisat_index', 'run', 'elif config["organism"].upper().find("MUS") >= 0 or config["organism"].upper().find("MOUSE") >= 0']
    (183, '                elif config["organism"].upper().find("MUS") >= 0 or config["organism"].upper().find("MOUSE") >= 0:')
    (184, '                    shell("cp scripts/make_grcm38_tran.sh {params[0]} && sh temp/genome/make_grcm38_tran.sh {params[1]} {threads}")')
    (185, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=williamjeong2/snakemake_RNA-seq, file=Snakefile_toCount
context_key: ['if config["aligner"].upper().find("HISAT2") >= 0', 'rule hisat_mapping', 'input']
    (186, '    rule hisat_mapping:')
    (187, '        input:')
    (188, '            get_trimmed,')
    (189, '            indexFiles = [WORKING_DIR + "genome/genome." + str(i) + ".ht2" for i in range(1,9)]')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=williamjeong2/snakemake_RNA-seq, file=Snakefile_toCount
context_key: ['if config["aligner"].upper().find("HISAT2") >= 0', 'rule hisat_mapping', 'output']
    (190, '        output:')
    (191, '            bams = temp(WORKING_DIR + "mapped/{sample}.sorted.bam"),')
    (192, '            log  = RESULT_DIR + "logs/hisat2/{sample}_log.txt"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=williamjeong2/snakemake_RNA-seq, file=Snakefile_toCount
context_key: ['if config["aligner"].upper().find("HISAT2") >= 0', 'rule hisat_mapping', 'params']
    (193, '        params:')
    (194, '            indexName = WORKING_DIR + "genome/genome",')
    (195, '            sampleName = "{sample}"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=williamjeong2/snakemake_RNA-seq, file=Snakefile_toCount
context_key: ['if config["aligner"].upper().find("HISAT2") >= 0', 'rule hisat_mapping', 'message']
    (196, '        message:')
    (197, '            "mapping reads to genome to bam files."')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=williamjeong2/snakemake_RNA-seq, file=Snakefile_toCount
context_key: ['if config["aligner"].upper().find("HISAT2") >= 0', 'rule hisat_mapping', 'threads']
    (198, '        threads: THREADS')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=williamjeong2/snakemake_RNA-seq, file=Snakefile_toCount
context_key: ['if config["aligner"].upper().find("HISAT2") >= 0', 'rule hisat_mapping', 'run', 'if sample_is_single_end(params.sampleName)']
    (199, '        run:')
    (200, '            if sample_is_single_end(params.sampleName):')
    (201, '                shell("hisat2 -p {threads} --summary-file {output.log} -q -x {params.indexName} \\\\')
    (202, '                -U {input[0]} | samtools view -@ {threads} -Sb -F 4 | samtools sort -@ {threads} -o {output.bams}; \\\\')
    (203, '                samtools index {output.bams}")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=williamjeong2/snakemake_RNA-seq, file=Snakefile_toCount
context_key: ['if config["aligner"].upper().find("HISAT2") >= 0', 'rule hisat_mapping', 'run', 'else']
    (204, '            else:')
    (205, '                shell("hisat2 -p {threads} --summary-file {output.log} -q -x {params.indexName} \\\\')
    (206, '                -1 {input[0]} -2 {input[1]} | samtools view -@ {threads} -Sb -F 4 | samtools sort -@ {threads} -o {output.bams}; \\\\')
    (207, '                samtools index {output.bams}")')
    (208, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=williamjeong2/snakemake_RNA-seq, file=Snakefile_toCount
context_key: ['elif config["aligner"].upper().find("STAR") >= 0', 'if config["need_indexed"].upper().find("NEED") >= 0', 'rule star_index', 'input']
    (209, 'elif config["aligner"].upper().find("STAR") >= 0:')
    (210, '    if config["need_indexed"].upper().find("NEED") >= 0:')
    (211, '        rule star_index:')
    (212, '            input:')
    (213, '                fasta = WORKING_DIR + "genome/genome.fa", ')
    (214, '                gtf  = WORKING_DIR + "genome/genome.gtf"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=williamjeong2/snakemake_RNA-seq, file=Snakefile_toCount
context_key: ['elif config["aligner"].upper().find("STAR") >= 0', 'if config["need_indexed"].upper().find("NEED") >= 0', 'rule star_index', 'output']
    (215, '            output:')
    (216, "                directory(WORKING_DIR + \\'genome\\')")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=williamjeong2/snakemake_RNA-seq, file=Snakefile_toCount
context_key: ['elif config["aligner"].upper().find("STAR") >= 0', 'if config["need_indexed"].upper().find("NEED") >= 0', 'rule star_index', 'message']
    (217, '            message:')
    (218, '                "indexing genome"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=williamjeong2/snakemake_RNA-seq, file=Snakefile_toCount
context_key: ['elif config["aligner"].upper().find("STAR") >= 0', 'if config["need_indexed"].upper().find("NEED") >= 0', 'rule star_index', 'threads']
    (219, '            threads: THREADS')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=williamjeong2/snakemake_RNA-seq, file=Snakefile_toCount
context_key: ['elif config["aligner"].upper().find("STAR") >= 0', 'if config["need_indexed"].upper().find("NEED") >= 0', 'rule star_index', 'shell']
    (220, '            shell:"""')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=williamjeong2/snakemake_RNA-seq, file=Snakefile_toCount
context_key: ['elif config["aligner"].upper().find("STAR") >= 0', 'if config["need_indexed"].upper().find("NEED") >= 0', 'rule star_index']
    (221, '            STAR --runThreadN {threads} \\\\')
    (222, '            --runMode genomeGenerate \\\\')
    (223, '            --genomeDir {output} \\\\')
    (224, '            --genomeFastaFiles {input.fasta} \\\\')
    (225, '            --sjdbGTFfile {input.gtf} \\\\')
    (226, '            --sjdbOverhang 100')
    (227, '            """')
    (228, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=williamjeong2/snakemake_RNA-seq, file=Snakefile_toCount
context_key: ['elif config["aligner"].upper().find("STAR") >= 0', 'rule star_mapping', 'input']
    (229, '    rule star_mapping:')
    (230, '        input:')
    (231, '            get_trimmed')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=williamjeong2/snakemake_RNA-seq, file=Snakefile_toCount
context_key: ['elif config["aligner"].upper().find("STAR") >= 0', 'rule star_mapping', 'output']
    (232, '        output:')
    (233, '            bams = temp(WORKING_DIR + "mapped/{sample}.sorted.bam"),')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=williamjeong2/snakemake_RNA-seq, file=Snakefile_toCount
context_key: ['elif config["aligner"].upper().find("STAR") >= 0', 'rule star_mapping', 'log']
    (234, '        log:')
    (235, '            RESULT_DIR + "logs/star/{sample}.log.txt"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=williamjeong2/snakemake_RNA-seq, file=Snakefile_toCount
context_key: ['elif config["aligner"].upper().find("STAR") >= 0', 'rule star_mapping', 'params']
    (236, '        params:')
    (237, "            gtf = WORKING_DIR + \\'genome/genome.gtf\\',")
    (238, "            index = WORKING_DIR + \\'genome\\',")
    (239, '            prefix = WORKING_DIR + "mapped/{sample}.",')
    (240, '            outdir = WORKING_DIR + "mapped",')
    (241, '            sampleName = "{sample}"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=williamjeong2/snakemake_RNA-seq, file=Snakefile_toCount
context_key: ['elif config["aligner"].upper().find("STAR") >= 0', 'rule star_mapping', 'message']
    (242, '        message:')
    (243, '            "mapping reads to genome to bam files."')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=williamjeong2/snakemake_RNA-seq, file=Snakefile_toCount
context_key: ['elif config["aligner"].upper().find("STAR") >= 0', 'rule star_mapping', 'threads']
    (244, '        threads: THREADS')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=williamjeong2/snakemake_RNA-seq, file=Snakefile_toCount
context_key: ['elif config["aligner"].upper().find("STAR") >= 0', 'rule star_mapping', 'run', 'if sample_is_single_end(params.sampleName)']
    (245, '        run:')
    (246, '            if sample_is_single_end(params.sampleName):')
    (247, '                shell("STAR --runThreadN {threads} --genomeDir {params.index} --outSAMunmapped None --outSAMtype BAM Unsorted \\\\')
    (248, '                --outStd BAM_Unsorted --sjdbGTFfile {params.gtf} --readFilesIn {input[0]} --readFilesCommand zcat \\\\')
    (249, '                --outFileNamePrefix {params.prefix} | samtools sort -@ {threads} -O bam -o {output.bams} 2> {log}")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=williamjeong2/snakemake_RNA-seq, file=Snakefile_toCount
context_key: ['elif config["aligner"].upper().find("STAR") >= 0', 'rule star_mapping', 'run', 'else']
    (250, '            else:')
    (251, '                shell("STAR --runThreadN {threads} --genomeDir {params.index} --outSAMunmapped None --outSAMtype BAM Unsorted \\\\')
    (252, '                --outStd BAM_Unsorted --sjdbGTFfile {params.gtf} --readFilesIn {input[0]} {input[1]} --readFilesCommand zcat \\\\')
    (253, '                --outFileNamePrefix {params.prefix} | samtools sort -@ {threads} -O bam -o {output.bams} 2> {log}")')
    (254, '')
    (255, '#########################################')
    (256, '# Get table containing the RPKM or FPKM')
    (257, '#########################################')
    (258, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=olabiyi/snakemake-workflow-qiime2, file=Snakefile.16S
context_key: ["if config[\\'RENAME_FILES\\']", 'rule Rename_files', 'output']
    (103, "if config[\\'RENAME_FILES\\']:")
    (104, '')
    (105, '    rule Rename_files:')
    (106, '        input: log_dirs=rules.Make_logs_directories.output')
    (107, '        output:')
    (108, '            expand(["01.raw_data/{sample}/{sample}_R1.fastq.gz",')
    (109, '                    "01.raw_data/{sample}/{sample}_R2.fastq.gz"], sample=config[\\\'samples\\\'])')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=olabiyi/snakemake-workflow-qiime2, file=Snakefile.16S
context_key: ["if config[\\'RENAME_FILES\\']", 'rule Rename_files', 'log']
    (110, '        log: "logs/Rename_files/Rename_files.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=olabiyi/snakemake-workflow-qiime2, file=Snakefile.16S
context_key: ["if config[\\'RENAME_FILES\\']", 'rule Rename_files', 'threads']
    (111, '        threads: 5')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=olabiyi/snakemake-workflow-qiime2, file=Snakefile.16S
context_key: ["if config[\\'RENAME_FILES\\']", 'rule Rename_files', 'run']
    (112, '        run:')
    (113, '            for old,new in zip(metadata.Old_name,metadata.New_name):')
    (114, '                shell("[ -f {new} ] || mv {old} {new}".format(old=old, new=new))')
    (115, '')
    (116, '')
    (117, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=olabiyi/snakemake-workflow-qiime2, file=Snakefile.16S
context_key: ['if config[\\\'amplicon\\\'] == "16S"']
    (730, 'if config[\\\'amplicon\\\'] == "16S":')
    (731, '    taxa2filter = "Unassigned,Chloroplast,Mitochondria,Eukaryota"')
    (732, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=olabiyi/snakemake-workflow-qiime2, file=Snakefile.16S
context_key: ['elif config[\\\'amplicon\\\'] == "18S"']
    (733, 'elif config[\\\'amplicon\\\'] == "18S":')
    (734, '    taxa2filter = "Bacteria,Fungi,Chytridiomycota,Basidiomycota,Metazoa,Rotifera,"')
    (735, '    "Gastrotricha,Nematozoa,Embryophyta,Spermatophyta,Asterales,"')
    (736, '    "Brassicales,Caryophyllales,Cupressales,Fabales,Malpighiales,"')
    (737, '    "Pinales,Rosales,Solanales,Arecales,Asparagales,Poales,"')
    (738, '    "Capsicum,Jatropha,Bryophyta,Tracheophyta"')
    (739, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=olabiyi/snakemake-workflow-qiime2, file=Snakefile.16S
context_key: ['elif config[\\\'amplicon\\\'] == "ITS"']
    (740, 'elif config[\\\'amplicon\\\'] == "ITS":')
    (741, '    taxa2filter = "Unassigned,Chloroplast,Mitochondria"')
    (742, '')
    (743, '')
    (744, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=olabiyi/snakemake-workflow-qiime2, file=Snakefile.ITS
context_key: ["if config[\\'RENAME_FILES\\']", 'rule Rename_files', 'output']
    (103, "if config[\\'RENAME_FILES\\']:")
    (104, '')
    (105, '    rule Rename_files:')
    (106, '        input: log_dirs=rules.Make_logs_directories.output')
    (107, '        output:')
    (108, '            expand(["01.raw_data/{sample}/{sample}_R1.fastq.gz",')
    (109, '                    "01.raw_data/{sample}/{sample}_R2.fastq.gz"], sample=config[\\\'samples\\\'])')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=olabiyi/snakemake-workflow-qiime2, file=Snakefile.ITS
context_key: ["if config[\\'RENAME_FILES\\']", 'rule Rename_files', 'log']
    (110, '        log: "logs/Rename_files/Rename_files.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=olabiyi/snakemake-workflow-qiime2, file=Snakefile.ITS
context_key: ["if config[\\'RENAME_FILES\\']", 'rule Rename_files', 'threads']
    (111, '        threads: 5')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=olabiyi/snakemake-workflow-qiime2, file=Snakefile.ITS
context_key: ["if config[\\'RENAME_FILES\\']", 'rule Rename_files', 'run']
    (112, '        run:')
    (113, '            for old,new in zip(metadata.Old_name,metadata.New_name):')
    (114, '                shell("[ -f {new} ] || mv {old} {new}".format(old=old, new=new))')
    (115, '')
    (116, '')
    (117, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=olabiyi/snakemake-workflow-qiime2, file=Snakefile.ITS
context_key: ['if config[\\\'amplicon\\\'] == "16S"']
    (730, 'if config[\\\'amplicon\\\'] == "16S":')
    (731, '    taxa2filter = "Unassigned,Chloroplast,Mitochondria,Eukaryota"')
    (732, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=olabiyi/snakemake-workflow-qiime2, file=Snakefile.ITS
context_key: ['elif config[\\\'amplicon\\\'] == "18S"']
    (733, 'elif config[\\\'amplicon\\\'] == "18S":')
    (734, '    taxa2filter = "Bacteria,Fungi,Chytridiomycota,Basidiomycota,Metazoa,Rotifera,"')
    (735, '    "Gastrotricha,Nematozoa,Embryophyta,Spermatophyta,Asterales,"')
    (736, '    "Brassicales,Caryophyllales,Cupressales,Fabales,Malpighiales,"')
    (737, '    "Pinales,Rosales,Solanales,Arecales,Asparagales,Poales,"')
    (738, '    "Capsicum,Jatropha,Bryophyta,Tracheophyta"')
    (739, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=olabiyi/snakemake-workflow-qiime2, file=Snakefile.ITS
context_key: ['elif config[\\\'amplicon\\\'] == "ITS"']
    (740, 'elif config[\\\'amplicon\\\'] == "ITS":')
    (741, '    taxa2filter = "Fungi"')
    (742, '')
    (743, '')
    (744, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=olabiyi/snakemake-workflow-qiime2, file=Snakefile
context_key: ["if config[\\'RENAME_FILES\\']", 'if mode == "pair" or mode == "merge"', 'rule Rename_files', 'output']
    (111, "if config[\\'RENAME_FILES\\']:")
    (112, '    # Remaning paired-end files')
    (113, '    if mode == "pair" or mode == "merge":')
    (114, '')
    (115, '        rule Rename_files:')
    (116, '            input: log_dirs=rules.Make_logs_directories.output')
    (117, '            output:')
    (118, '                expand(["01.raw_data/{sample}/{sample}_R1.fastq.gz",')
    (119, '                        "01.raw_data/{sample}/{sample}_R2.fastq.gz"], sample=config[\\\'samples\\\'])')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=olabiyi/snakemake-workflow-qiime2, file=Snakefile
context_key: ["if config[\\'RENAME_FILES\\']", 'if mode == "pair" or mode == "merge"', 'rule Rename_files', 'log']
    (120, '            log: "logs/Rename_files/Rename_files.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=olabiyi/snakemake-workflow-qiime2, file=Snakefile
context_key: ["if config[\\'RENAME_FILES\\']", 'if mode == "pair" or mode == "merge"', 'rule Rename_files', 'threads']
    (121, '            threads: 5')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=olabiyi/snakemake-workflow-qiime2, file=Snakefile
context_key: ["if config[\\'RENAME_FILES\\']", 'if mode == "pair" or mode == "merge"', 'rule Rename_files', 'run']
    (122, '            run:')
    (123, '                for old,new in zip(metadata.Old_name,metadata.New_name):')
    (124, '                    shell("[ -f {new} ] || mv {old} {new}".format(old=old, new=new))')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=olabiyi/snakemake-workflow-qiime2, file=Snakefile
context_key: ["if config[\\'RENAME_FILES\\']", 'else', 'rule Rename_files', 'output']
    (125, '    else:')
    (126, '    # Renaming single-end files')
    (127, '        rule Rename_files:')
    (128, '            output:')
    (129, '                expand("01.raw_data/{sample}.fastq.gz",sample=config[\\\'samples\\\'])')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=olabiyi/snakemake-workflow-qiime2, file=Snakefile
context_key: ["if config[\\'RENAME_FILES\\']", 'else', 'rule Rename_files', 'log']
    (130, '            log: "logs/Rename_files/Rename_files.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=olabiyi/snakemake-workflow-qiime2, file=Snakefile
context_key: ["if config[\\'RENAME_FILES\\']", 'else', 'rule Rename_files', 'threads']
    (131, '            threads: 5')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=olabiyi/snakemake-workflow-qiime2, file=Snakefile
context_key: ["if config[\\'RENAME_FILES\\']", 'else', 'rule Rename_files', 'run']
    (132, '            run:')
    (133, '                for old,new in zip(metadata.Old_name,metadata.New_name):')
    (134, '                    shell("mv {old} {new}".format(old=old, new=new))')
    (135, '')
    (136, '')
    (137, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=olabiyi/snakemake-workflow-qiime2, file=Snakefile
context_key: ['if config[\\\'amplicon\\\'] == "16S"']
    (860, 'if config[\\\'amplicon\\\'] == "16S":')
    (861, '    taxa2filter = "Unassigned,Chloroplast,Mitochondria,Eukaryota"')
    (862, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=olabiyi/snakemake-workflow-qiime2, file=Snakefile
context_key: ['elif config[\\\'amplicon\\\'] == "18S"']
    (863, 'elif config[\\\'amplicon\\\'] == "18S":')
    (864, '    taxa2filter = "Bacteria,Fungi,Chytridiomycota,Basidiomycota,Metazoa,Rotifera,"')
    (865, '    "Gastrotricha,Nematozoa,Embryophyta,Spermatophyta,Asterales,"')
    (866, '    "Brassicales,Caryophyllales,Cupressales,Fabales,Malpighiales,"')
    (867, '    "Pinales,Rosales,Solanales,Arecales,Asparagales,Poales,"')
    (868, '    "Capsicum,Jatropha,Bryophyta,Tracheophyta"')
    (869, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=olabiyi/snakemake-workflow-qiime2, file=Snakefile
context_key: ['elif config[\\\'amplicon\\\'] == "ITS"']
    (870, 'elif config[\\\'amplicon\\\'] == "ITS":')
    (871, '    taxa2filter = "Fungi"')
    (872, '')
    (873, '')
    (874, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=olabiyi/snakemake-workflow-qiime2, file=Snakefile
context_key: ['if config[\\\'amplicon\\\'] == "16S"', 'rule Function_annotation', 'output']
    (1370, '        output:')
    (1371, '            ec="15.Function_annotation/picrust2_out_pipeline/EC_metagenome_out/pred_metagenome_unstrat.tsv.gz",')
    (1372, '            ko="15.Function_annotation/picrust2_out_pipeline/KO_metagenome_out/pred_metagenome_unstrat.tsv.gz",')
    (1373, '            pathway="15.Function_annotation/picrust2_out_pipeline/pathways_out/path_abun_unstrat.tsv.gz",')
    (1374, '            #contrib="15.Function_annotation/picrust2_out_pipeline/KO_metagenome_out/pred_metagenome_contrib.tsv.gz"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=olabiyi/snakemake-workflow-qiime2, file=Snakefile
context_key: ['if config[\\\'amplicon\\\'] == "16S"', 'rule Function_annotation', 'log']
    (1375, '        log: "logs/Function_annotation/Function_annotation.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=olabiyi/snakemake-workflow-qiime2, file=Snakefile
context_key: ['if config[\\\'amplicon\\\'] == "16S"', 'rule Function_annotation', 'threads']
    (1376, '        threads: 10')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=olabiyi/snakemake-workflow-qiime2, file=Snakefile
context_key: ['if config[\\\'amplicon\\\'] == "16S"', 'rule Function_annotation', 'params']
    (1377, '        params:')
    (1378, '            conda_activate=config[\\\'conda\\\'][\\\'picrust2\\\']["env"],')
    (1379, '            out_dir=lambda w, output: output.ec.split(\\\'/\\\')[0] + "/" + output.ec.split(\\\'/\\\')[1],')
    (1380, "            threads=config[\\'parameters\\'][\\'picrust\\'][\\'threads\\']")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=olabiyi/snakemake-workflow-qiime2, file=Snakefile
context_key: ['if config[\\\'amplicon\\\'] == "16S"', 'rule Function_annotation', 'shell']
    (1381, '        shell:')
    (1382, '            """')
    (1383, '            set +u')
    (1384, '            {params.conda_activate}')
    (1385, '            set -u')
    (1386, '        ')
    (1387, '            # Remove the temporary output directory if it already exists')
    (1388, '            [ -d picrust2_out_pipeline/ ] && rm -rf picrust2_out_pipeline/')
    (1389, '        ')
    (1390, '            # ---- Run picrust2 pipeline for function annotation -------- #')
    (1391, '            picrust2_pipeline.py \\\\')
    (1392, '                -s {input.rep_seqs} \\\\')
    (1393, '                -i {input.feature_table} \\\\')
    (1394, '                -o picrust2_out_pipeline/ \\\\')
    (1395, '                -p {params.threads} && \\\\')
    (1396, '                mv picrust2_out_pipeline/* {params.out_dir}/ && \\\\')
    (1397, '                rmdir picrust2_out_pipeline/')
    (1398, '            """')
    (1399, '')
    (1400, '    # Add description to PICRUST2 function annotation tables')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=olabiyi/snakemake-workflow-qiime2, file=Snakefile
context_key: ['if config[\\\'amplicon\\\'] == "16S"', 'rule Add_description', 'input']
    (1401, '    rule Add_description:')
    (1402, '        input:')
    (1403, '            ec=rules.Function_annotation.output.ec,')
    (1404, '            ko=rules.Function_annotation.output.ko,')
    (1405, '            pathway=rules.Function_annotation.output.pathway,')
    (1406, '            #contrib=rules.Function_annotation.output.contrib')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=olabiyi/snakemake-workflow-qiime2, file=Snakefile
context_key: ['if config[\\\'amplicon\\\'] == "16S"', 'rule Add_description', 'output']
    (1407, '        output:')
    (1408, '            ec="15.Function_annotation/picrust2_out_pipeline/EC_metagenome_out/pred_metagenome_unstrat_descrip.tsv",')
    (1409, '            ko="15.Function_annotation/picrust2_out_pipeline/KO_metagenome_out/pred_metagenome_unstrat_descrip.tsv",')
    (1410, '            pathway="15.Function_annotation/picrust2_out_pipeline/pathways_out/path_abun_unstrat_descrip.tsv",')
    (1411, '            #ec_contrib="15.Function_annotation/picrust2_out_pipeline/EC_metagenome_out/pred_metagenome_contrib.tsv",')
    (1412, '            #ko_contrib="15.Function_annotation/picrust2_out_pipeline/KO_metagenome_out/pred_metagenome_contrib.tsv",')
    (1413, '            #pathway_contrib="15.Function_annotation/picrust2_out_pipeline/pathways_out/path_abun_contrib.tsv"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=olabiyi/snakemake-workflow-qiime2, file=Snakefile
context_key: ['if config[\\\'amplicon\\\'] == "16S"', 'rule Add_description', 'log']
    (1414, '        log: "logs/Add_description/Add_description.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=olabiyi/snakemake-workflow-qiime2, file=Snakefile
context_key: ['if config[\\\'amplicon\\\'] == "16S"', 'rule Add_description', 'threads']
    (1415, '        threads: 10')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=olabiyi/snakemake-workflow-qiime2, file=Snakefile
context_key: ['if config[\\\'amplicon\\\'] == "16S"', 'rule Add_description', 'params']
    (1416, '        params:')
    (1417, '            conda_activate=config[\\\'conda\\\'][\\\'picrust2\\\']["env"],')
    (1418, '            threads=10,')
    (1419, '            outdir="15.Function_annotation/picrust2_out_pipeline/"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=olabiyi/snakemake-workflow-qiime2, file=Snakefile
context_key: ['if config[\\\'amplicon\\\'] == "16S"', 'rule Add_description', 'shell']
    (1420, '        shell:')
    (1421, '            """')
    (1422, '            set +u')
    (1423, '            {params.conda_activate}')
    (1424, '            set -u')
    (1425, '')
    (1426, '            # ----- Annotate your enzymes, KOs and pathways by adding a description column ------#')
    (1427, '            # EC')
    (1428, '            add_descriptions.py -i {input.ec} -m EC -o {output.ec}')
    (1429, '')
    (1430, '            # Metacyc Pathway')
    (1431, '            add_descriptions.py -i {input.pathway} -m METACYC -o {output.pathway}')
    (1432, '')
    (1433, '            # KO')
    (1434, '            add_descriptions.py -i {input.ko} -m KO -o {output.ko} ')
    (1435, ' ')
    (1436, '            # Unizip the metagenome contribution files - these files describe the micribes contribution the function profiles')
    (1437, '            #find {params.outdir} -type f -name "*contrib.tsv.gz" -exec gunzip {{}} \\\\;')
    (1438, '            """')
    (1439, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=jiarong/xander-assembly-pipeline, file=Snakefile
context_key: ["if config[\\'WORKDIR\\']"]
    (13, "if config[\\'WORKDIR\\']:")
    (14, "    workdir: config[\\'WORKDIR\\']")
    (15, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=sheucke/rna-seq-star-deseq2, file=rules/align.smk
context_key: ['if config["trimming"]["skip"]']
    (1, '    if config["trimming"]["skip"]:')
    (2, '        # no trimming, use raw reads')
    (3, '        return units.loc[(wildcards.sample, wildcards.unit), ["fq1", "fq2"]].dropna()')
    (4, '    else:')
    (5, '        # yes trimming, use trimmed data')
    (6, '        if not is_single_end(**wildcards):')
    (7, '            # paired-end sample')
    (8, '            return expand("trimmed/{sample}-{unit}.{group}.fastq.gz",')
    (9, '                          group=[1, 2], **wildcards)')
    (10, '        # single end sample')
    (11, '        return "trimmed/{sample}-{unit}.fastq.gz".format(**wildcards)')
    (12, '            ')
    (13, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=crazyhottommy/pyflow-RNAseq, file=Snakefile
context_key: ['if config["from_fastq"]', 'if not config["from_fastq"]', 'rule all', 'rule STAR_fq', 'rule HTSeq_fq', 'rule featureCount_fq', 'rule sortBam_fq', 'rule indexBam_fq', 'rule make_bigwig_fq', 'rule HTseq_bam', 'rule featureCount_bam', 'rule make_bigwig_bam']
    (18, 'if config["from_fastq"]:')
    (19, '\\tALL_BAM = expand("01bam_fq/{sample}Aligned.out.bam", sample = SAMPLES)')
    (20, '\\tALL_SORTED_BAM = expand("02sortBam_fq/{sample}.sorted.bam", sample = SAMPLES)')
    (21, '\\tALL_BAM_INDEX = expand("02sortBam_fq/{sample}.sorted.bam.bai", sample = SAMPLES)')
    (22, '\\tTARGETS.extend(ALL_BAM)')
    (23, '\\tTARGETS.extend(ALL_SORTED_BAM)')
    (24, '\\tTARGETS.extend(ALL_BAM_INDEX)')
    (25, '\\t')
    (26, '\\tif config["htseq"]:')
    (27, '\\t\\tALL_CNT = expand("03htseq_fq/{sample}_htseq.cnt", sample = SAMPLES)')
    (28, '\\t\\tTARGETS.extend(ALL_CNT)')
    (29, '')
    (30, '\\tif config["featureCount"]:')
    (31, '\\t\\tALL_featureCount = expand("04featureCount_fq/{sample}_featureCount.txt", sample = SAMPLES)')
    (32, '\\t\\tTARGETS.extend(ALL_featureCount)')
    (33, '')
    (34, '\\tALL_BIGWIG = expand("05bigwig_fq/{sample}.bw", sample = SAMPLES)')
    (35, '\\tTARGETS.extend(ALL_BIGWIG)')
    (36, '')
    (37, '')
    (38, '## construct the target if the inputs are bams')
    (39, '')
    (40, 'if not config["from_fastq"]:')
    (41, '\\tif config["htseq"]:')
    (42, '\\t\\tALL_CNT = expand("01htseq_bam/{sample}_htseq.cnt", sample = SAMPLES)')
    (43, '\\t\\tTARGETS.extend(ALL_CNT)')
    (44, '')
    (45, '\\tif config["featureCount"]:')
    (46, '\\t\\tALL_featureCount = expand("02featureCount_bam/{sample}_featureCount.txt", sample = SAMPLES)')
    (47, '\\t\\tTARGETS.extend(ALL_featureCount)')
    (48, '')
    (49, '\\tALL_BIGWIG = expand("03bigwig_bam/{sample}.bw", sample = SAMPLES)')
    (50, '\\tTARGETS.extend(ALL_BIGWIG)')
    (51, '')
    (52, 'localrules: all')
    (53, '# localrules will let the rule run locally rather than submitting to cluster')
    (54, '# computing nodes, this is for very small jobs')
    (55, '')
    (56, 'rule all:')
    (57, '\\tinput: TARGETS')
    (58, '')
    (59, 'rule STAR_fq:')
    (60, '\\tinput: ')
    (61, "\\t\\tr1 = lambda wildcards: FILES[wildcards.sample][\\'R1\\'],")
    (62, "\\t\\tr2 = lambda wildcards: FILES[wildcards.sample][\\'R2\\']")
    (63, '\\toutput: "01bam_fq/{sample}Aligned.out.bam"')
    (64, '\\tlog: "00log/{sample}_STAR_align.log"')
    (65, '\\tparams: ')
    (66, '\\t\\tjobname = "{sample}",')
    (67, '\\t\\toutprefix = "01bam_fq/{sample}"')
    (68, '\\tthreads: 5')
    (69, '\\tmessage: "aligning {input} using STAR: {threads} threads"')
    (70, '\\tshell:')
    (71, '\\t\\t"""')
    (72, '\\t\\tSTAR --runMode alignReads \\\\')
    (73, '\\t\\t--runThreadN 5 \\\\')
    (74, '\\t\\t--genomeDir {STARINDEX} \\\\')
    (75, '\\t\\t--genomeLoad NoSharedMemory \\\\')
    (76, '\\t\\t--readFilesIn {input.r1} {input.r2} \\\\')
    (77, '\\t\\t--readFilesCommand zcat \\\\')
    (78, '\\t\\t--twopassMode Basic \\\\')
    (79, '\\t\\t--runRNGseed 777 \\\\')
    (80, '\\t\\t--outFilterType Normal \\\\')
    (81, '\\t\\t--outFilterMultimapNmax 20 \\\\')
    (82, '\\t\\t--outFilterMismatchNmax 10 \\\\')
    (83, '\\t\\t--outFilterMultimapScoreRange 1 \\\\')
    (84, '\\t\\t--outFilterMatchNminOverLread 0.33 \\\\')
    (85, '\\t\\t--outFilterScoreMinOverLread 0.33 \\\\')
    (86, '\\t\\t--outReadsUnmapped None \\\\')
    (87, '\\t\\t--alignIntronMin 20 \\\\')
    (88, '\\t\\t--alignIntronMax 500000 \\\\')
    (89, '\\t\\t--alignMatesGapMax 1000000 \\\\')
    (90, '\\t\\t--alignSJoverhangMin 8 \\\\')
    (91, '\\t\\t--alignSJstitchMismatchNmax 5 -1 5 5 \\\\')
    (92, '\\t\\t--sjdbScore 2 \\\\')
    (93, '\\t\\t--alignSJDBoverhangMin 1 \\\\')
    (94, '\\t\\t--sjdbOverhang 100 \\\\')
    (95, '\\t\\t--chimSegmentMin 20 \\\\')
    (96, '\\t\\t--chimJunctionOverhangMin 20 \\\\')
    (97, '\\t\\t--chimSegmentReadGapMax 3 \\\\')
    (98, '\\t\\t--quantMode GeneCounts \\\\')
    (99, '\\t\\t--outMultimapperOrder Random \\\\')
    (100, '\\t\\t--outSAMstrandField intronMotif \\\\')
    (101, '\\t\\t--outSAMattributes All \\\\')
    (102, '\\t\\t--outSAMunmapped Within KeepPairs \\\\')
    (103, '\\t\\t--outSAMtype BAM Unsorted \\\\')
    (104, '\\t\\t--limitBAMsortRAM 30000000000 \\\\')
    (105, '\\t\\t--outSAMmode Full \\\\')
    (106, '\\t\\t--outSAMheaderHD @HD VN:1.4 \\\\')
    (107, '\\t\\t--outFileNamePrefix {params.outprefix} 2> {log}')
    (108, '\\t\\t"""')
    (109, '')
    (110, 'rule HTSeq_fq:')
    (111, '\\tinput: "01bam_fq/{sample}Aligned.out.bam"')
    (112, '\\toutput: "03htseq_fq/{sample}_htseq.cnt"')
    (113, '\\tlog: "00log/{sample}_htseq_count.log"')
    (114, '\\tparams: ')
    (115, '\\t\\tjobname = "{sample}"')
    (116, '\\tthreads: 1')
    (117, '\\tmessage: "htseq-count {input} : {threads} threads"')
    (118, '\\tshell:')
    (119, '\\t\\t"""')
    (120, '\\t\\tsource activate root')
    (121, '\\t\\thtseq-count -m intersection-nonempty --stranded=no --idattr gene_id -r name -f bam {input} {MYGTF} > {output} 2> {log}')
    (122, '')
    (123, '\\t\\t"""')
    (124, '')
    (125, 'rule featureCount_fq:')
    (126, '\\tinput: "01bam_fq/{sample}Aligned.out.bam"')
    (127, '\\toutput: "04featureCount_fq/{sample}_featureCount.txt"')
    (128, '\\tlog: "00log/{sample}_featureCount.log"')
    (129, '\\tparams:')
    (130, '\\t\\tjobname = "{sample}"')
    (131, '\\tthreads: 5')
    (132, '\\tmessage: "feature-count {input} : {threads} threads"')
    (133, '\\tshell:')
    (134, '\\t\\t"""')
    (135, '\\t\\t# -p for paried-end, counting fragments rather reads')
    (136, '\\t\\tfeatureCounts -T 5 -p -t exon -g gene_id -a {MYGTF} -o {output} {input} 2> {log}')
    (137, '')
    (138, '\\t\\t"""')
    (139, 'rule sortBam_fq:')
    (140, '\\tinput: "01bam_fq/{sample}Aligned.out.bam"')
    (141, '\\toutput: "02sortBam_fq/{sample}.sorted.bam"')
    (142, '\\tlog: "00log/{sample}_sortbam.log"')
    (143, '\\tparams:')
    (144, '\\t\\tjobname = "{sample}"')
    (145, '\\tthreads: 5')
    (146, '\\tmessage: "sorting {input} : {threads} threads"')
    (147, '\\tshell:')
    (148, '\\t\\t"""')
    (149, '\\t\\tsamtools sort -m 2G -@ 5 -T {output}.tmp -o {output} {input} 2> {log}')
    (150, '')
    (151, '\\t\\t"""')
    (152, '')
    (153, 'rule indexBam_fq:')
    (154, '\\tinput: "02sortBam_fq/{sample}.sorted.bam"')
    (155, '\\toutput: "02sortBam_fq/{sample}.sorted.bam.bai"')
    (156, '\\tlog: "00log/{sample}_index_bam.log"')
    (157, '\\tparams: ')
    (158, '\\t\\tjobname = "{sample}"')
    (159, '\\tthreads: 1')
    (160, '\\tmessage: "indexing {input} : {threads} threads"')
    (161, '\\tshell:')
    (162, '\\t\\t"""')
    (163, '\\t\\tsamtools index {input}')
    (164, '\\t\\t"""')
    (165, '\\t')
    (166, '')
    (167, 'rule make_bigwig_fq:')
    (168, '\\tinput: "02sortBam_fq/{sample}.sorted.bam", "02sortBam_fq/{sample}.sorted.bam.bai"')
    (169, '\\toutput: "05bigwig_fq/{sample}.bw"')
    (170, '\\tlog: "00log/{sample}_bigwig.log"')
    (171, '\\tparams:')
    (172, '\\t\\tjobname = "{sample}"')
    (173, '\\tthreads: 5')
    (174, '\\tmessage: "making bigwig {input} : {threads} threads"')
    (175, '\\tshell:')
    (176, '\\t\\t"""')
    (177, '\\t\\tsource activate root')
    (178, '\\t\\tbamCoverage -b {input[0]} --skipNonCoveredRegions --normalizeUsingRPKM --binSize 20 --smoothLength 100 -p 5  -o {output} 2> {log}')
    (179, '')
    (180, '\\t\\t"""')
    (181, '')
    (182, 'rule HTseq_bam:')
    (183, '\\tinput: lambda wildcards: FILES[wildcards.sample]')
    (184, '\\toutput: "01htseq_bam/{sample}_htseq.cnt"')
    (185, '\\tlog: "00log/{sample}_htseq_count.log"')
    (186, '\\tparams: ')
    (187, '\\t\\tjobname = "{sample}"')
    (188, '\\tthreads: 1')
    (189, '\\tmessage: "htseq-count {input} : {threads} threads"')
    (190, '\\tshell:')
    (191, '\\t\\t"""')
    (192, '\\t\\tsource activate root')
    (193, '\\t\\thtseq-count -m intersection-nonempty --stranded=no --idattr gene_id -r name -f bam {input} {MYGTF} > {output} 2> {log}')
    (194, '')
    (195, '\\t\\t"""')
    (196, 'rule featureCount_bam:')
    (197, '\\tinput: lambda wildcards: FILES[wildcards.sample]')
    (198, '\\toutput: "02featureCount_bam/{sample}_featureCount.txt"')
    (199, '\\tlog: "00log/{sample}_featureCount.log"')
    (200, '\\tparams: ')
    (201, '\\t\\tjobname = "{sample}"')
    (202, '\\tthreads: 5')
    (203, '\\tmessage: "feature-count {input} : {threads} threads"')
    (204, '\\tshell:')
    (205, '\\t\\t"""')
    (206, '\\t\\t# -p for paried-end, counting fragments rather reads')
    (207, '\\t\\tfeatureCounts -T 5 -p -t exon -g gene_id -a {MYGTF} -o {output} {input} 2> {log}')
    (208, '')
    (209, '\\t\\t"""')
    (210, '\\t')
    (211, 'rule make_bigwig_bam:')
    (212, '\\tinput: lambda wildcards: FILES[wildcards.sample]')
    (213, '\\toutput: "03bigwig_bam/{sample}.bw"')
    (214, '\\tlog: "00log/{sample}_bigwig.log"')
    (215, '\\tparams:')
    (216, '\\t\\tjobname = "{sample}"')
    (217, '\\tthreads: 5')
    (218, '\\tmessage: "making bigwig {input} : {threads} threads"')
    (219, '\\tshell:')
    (220, '\\t\\t"""')
    (221, '\\t\\tsource activate root')
    (222, '\\t\\tbamCoverage -b {input} --skipNonCoveredRegions --normalizeUsingRPKM --binSize 20 --smoothLength 100 -p 5  -o {output} 2> {log}')
    (223, '')
    (224, '\\t\\t"""\'')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['elif config["demultiplexing"]["demultiplex"] == "T" and config["LIBRARY_LAYOUT"] != "SE" and len(config["input_files"])>2', 'rule init_structure', 'input']
    (71, 'elif config["demultiplexing"]["demultiplex"] == "T" and config["LIBRARY_LAYOUT"] != "SE" and len(config["input_files"])>2:')
    (72, '    rule init_structure:')
    (73, '        input:')
    (74, '            file_list = config["input_files"]')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['elif config["demultiplexing"]["demultiplex"] == "T" and config["LIBRARY_LAYOUT"] != "SE" and len(config["input_files"])>2', 'rule init_structure', 'output']
    (75, '        output:')
    (76, '            r1="{PROJECT}/samples/{sample}/rawdata/fw.fastq"  if config["gzip_input"] == "F" else "{PROJECT}/samples/{sample}/rawdata/fw.fastq.gz",')
    (77, '            r2="{PROJECT}/samples/{sample}/rawdata/rv.fastq"  if config["gzip_input"] == "F" else "{PROJECT}/samples/{sample}/rawdata/rv.fastq.gz",')
    (78, '            metadata="{PROJECT}/metadata/sampleList_mergedBarcodes_{sample}.txt"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['elif config["demultiplexing"]["demultiplex"] == "T" and config["LIBRARY_LAYOUT"] != "SE" and len(config["input_files"])>2', 'rule init_structure', 'script']
    (79, '        script:')
    (80, '            "Scripts/init_sample.py"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['elif config["demultiplexing"]["demultiplex"] == "T" and config["LIBRARY_LAYOUT"] == "SE" and len(config["input_files"])>2', 'rule init_structure', 'input']
    (81, 'elif config["demultiplexing"]["demultiplex"] == "T" and config["LIBRARY_LAYOUT"] == "SE" and len(config["input_files"])>2:')
    (82, '    rule init_structure:')
    (83, '        input:')
    (84, '            file_list = config["input_files"]')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['elif config["demultiplexing"]["demultiplex"] == "T" and config["LIBRARY_LAYOUT"] == "SE" and len(config["input_files"])>2', 'rule init_structure', 'output']
    (85, '        output:')
    (86, '            r1="{PROJECT}/samples/{sample}/rawdata/fw.fastq"  if config["gzip_input"] == "F" else "{PROJECT}/samples/{sample}/rawdata/fw.fastq.gz",')
    (87, '            metadata="{PROJECT}/metadata/sampleList_mergedBarcodes_{sample}.txt"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['elif config["demultiplexing"]["demultiplex"] == "T" and config["LIBRARY_LAYOUT"] == "SE" and len(config["input_files"])>2', 'rule init_structure', 'script']
    (88, '        script:')
    (89, '            "Scripts/init_sample_SE.py"')
    (90, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['elif config["LIBRARY_LAYOUT"] == "SE" and len(config["input_files"])>2', 'rule init_structure', 'input']
    (91, 'elif config["LIBRARY_LAYOUT"] == "SE" and len(config["input_files"])>2:')
    (92, '    rule init_structure:')
    (93, '        input:')
    (94, '            file_list = config["input_files"]')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['elif config["LIBRARY_LAYOUT"] == "SE" and len(config["input_files"])>2', 'rule init_structure', 'output']
    (95, '        output:')
    (96, '            r1="{PROJECT}/samples/{sample}/rawdata/fw.fastq"  if config["gzip_input"] == "F" else "{PROJECT}/samples/{sample}/rawdata/fw.fastq.gz"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['elif config["LIBRARY_LAYOUT"] == "SE" and len(config["input_files"])>2', 'rule init_structure', 'script']
    (97, '        script:')
    (98, '            "Scripts/init_sample_SE.py"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["LIBRARY_LAYOUT"] != "SE"', 'rule fast_qc', 'input']
    (109, 'if config["LIBRARY_LAYOUT"] != "SE":')
    (110, '    rule fast_qc:')
    (111, '        """')
    (112, '        Runs QC on raw reads')
    (113, '        """')
    (114, '        input:')
    (115, '            r1="{PROJECT}/samples/{sample}/rawdata/fw.fastq" if config["gzip_input"] == "F" else "{PROJECT}/samples/{sample}/rawdata/fw.fastq.gz",')
    (116, '            r2="{PROJECT}/samples/{sample}/rawdata/rv.fastq" if config["gzip_input"] == "F" else "{PROJECT}/samples/{sample}/rawdata/rv.fastq.gz"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["LIBRARY_LAYOUT"] != "SE"', 'rule fast_qc', 'output']
    (117, '        output:')
    (118, '            o1="{PROJECT}/samples/{sample}/qc/fw_fastqc.html",')
    (119, '            o2="{PROJECT}/samples/{sample}/qc/rv_fastqc.html",')
    (120, '            s1="{PROJECT}/samples/{sample}/qc/fw_fastqc/summary.txt",')
    (121, '            s2="{PROJECT}/samples/{sample}/qc/rv_fastqc/summary.txt"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["LIBRARY_LAYOUT"] != "SE"', 'rule fast_qc', 'benchmark']
    (122, '        benchmark:')
    (123, '            "{PROJECT}/samples/{sample}/qc/fq.benchmark"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["LIBRARY_LAYOUT"] != "SE"', 'rule fast_qc', 'shell']
    (124, '        shell:')
    (125, '            "{config[fastQC][command]} {input.r1} {input.r2} --extract {config[fastQC][extra_params]} -t 10 -o {wildcards.PROJECT}/samples/{wildcards.sample}/qc/"')
    (126, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["LIBRARY_LAYOUT"] != "SE"', 'rule validateQC', 'input']
    (127, '    rule validateQC:')
    (128, '        """')
    (129, '        Interpret FastQC output and stops on interactive mode, if too many')
    (130, '        errors.')
    (131, '        """')
    (132, '        input:')
    (133, '            "{PROJECT}/samples/{sample}/qc/fw_fastqc/summary.txt",')
    (134, '            "{PROJECT}/samples/{sample}/qc/rv_fastqc/summary.txt",')
    (135, '            "{PROJECT}/samples/{sample}/qc/fw_fastqc.html",')
    (136, '            "{PROJECT}/samples/{sample}/qc/rv_fastqc.html",')
    (137, '            "{PROJECT}/samples/{sample}/rawdata/fw.fastq" if config["gzip_input"] == "F" else "{PROJECT}/samples/{sample}/rawdata/fw.fastq.gz",')
    (138, '            "{PROJECT}/samples/{sample}/rawdata/rv.fastq" if config["gzip_input"] == "F" else "{PROJECT}/samples/{sample}/rawdata/rv.fastq.gz"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["LIBRARY_LAYOUT"] != "SE"', 'rule validateQC', 'output']
    (139, '        output:')
    (140, '            "{PROJECT}/samples/{sample}/qc/fq_fw_internal_validation.txt",')
    (141, '            "{PROJECT}/samples/{sample}/qc/fq_rv_internal_validation.txt"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["LIBRARY_LAYOUT"] != "SE"', 'rule validateQC', 'script']
    (142, '        script:')
    (143, '            "Scripts/validateQC.py"')
    (144, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["LIBRARY_LAYOUT"] != "SE"', 'rule pear', 'input']
    (145, '    rule pear:')
    (146, '        """')
    (147, '        Paire/extend paired-end data')
    (148, '        """')
    (149, '        input:')
    (150, '            r1="{PROJECT}/samples/{sample}/rawdata/fw.fastq" if config["gzip_input"] == "F" else "{PROJECT}/samples/{sample}/rawdata/fw.fastq.gz",')
    (151, '            r2="{PROJECT}/samples/{sample}/rawdata/rv.fastq" if config["gzip_input"] == "F" else "{PROJECT}/samples/{sample}/rawdata/rv.fastq.gz",')
    (152, '            tmp1="{PROJECT}/samples/{sample}/qc/fq_fw_internal_validation.txt",')
    (153, '            tmp2="{PROJECT}/samples/{sample}/qc/fq_rv_internal_validation.txt"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["LIBRARY_LAYOUT"] != "SE"', 'rule pear', 'output']
    (154, '        output:')
    (155, '            "{PROJECT}/runs/{run}/{sample}_data/peared/seqs.assembled.fastq",# if config["UNPAIRED_DATA_PIPELINE"] != "T" else')
    (156, '            "{PROJECT}/runs/{run}/{sample}_data/peared/seqs.unassembled.forward.fastq",')
    (157, '            "{PROJECT}/runs/{run}/{sample}_data/peared/pear.log",')
    (158, '            "{PROJECT}/runs/{run}/{sample}_data/peared/seqs.unassembled.reverse.fastq" ')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["LIBRARY_LAYOUT"] != "SE"', 'rule pear', 'benchmark']
    (159, '        benchmark:')
    (160, '            "{PROJECT}/runs/{run}/{sample}_data/peared/pear.benchmark"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["LIBRARY_LAYOUT"] != "SE"', 'rule pear', 'params']
    (161, '        params:')
    (162, '            "{PROJECT}/runs/{run}/{sample}_data/peared/seqs"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["LIBRARY_LAYOUT"] != "SE"', 'rule pear', 'shell']
    (163, '        shell:')
    (164, '            "{config[pear][command]} -f {input.r1} -r {input.r2} -o {params[0]} "')
    (165, '            "-t {config[pear][t]} -v {config[pear][v]} -j {config[pear][j]} -p {config[pear][p]} {config[pear][extra_params]} > "')
    (166, '            "{output[2]}"')
    (167, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["LIBRARY_LAYOUT"] != "SE"', 'if config["UNPAIRED_DATA_PIPELINE"] == "T" or config["demultiplexing"]["add_unpair"] == "T"', 'rule identify_unpaired_fw', 'input']
    (168, '    if config["UNPAIRED_DATA_PIPELINE"] == "T" or config["demultiplexing"]["add_unpair"] == "T":')
    (169, '        rule identify_unpaired_fw:')
    (170, '            """')
    (171, '            Identify reads that they were not paired.')
    (172, '            """')
    (173, '            input:')
    (174, '                fw="{PROJECT}/runs/{run}/{sample}_data/peared/seqs.unassembled.forward.fastq"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["LIBRARY_LAYOUT"] != "SE"', 'if config["UNPAIRED_DATA_PIPELINE"] == "T" or config["demultiplexing"]["add_unpair"] == "T"', 'rule identify_unpaired_fw', 'output']
    (175, '            output:')
    (176, '                fwo=temp("{PROJECT}/runs/{run}/{sample}_data/peared/seqs.unassembled.forward.out")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["LIBRARY_LAYOUT"] != "SE"', 'if config["UNPAIRED_DATA_PIPELINE"] == "T" or config["demultiplexing"]["add_unpair"] == "T"', 'rule identify_unpaired_fw', 'shell']
    (177, '            shell:')
    (178, '                "cat {input.fw} | awk \\\'{{if((NR-1)%4==0){{header=$1}}else if((NR-2)%4==0){{seq=$0}}else if(NR%4==0){{print header\\\\"\\\\\\\\t\\\\"seq\\\\"\\\\\\\\t\\\\"$0}}}}\\\' > {output.fwo}"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["LIBRARY_LAYOUT"] != "SE"', 'if config["UNPAIRED_DATA_PIPELINE"] == "T" or config["demultiplexing"]["add_unpair"] == "T"', 'rule identify_unpaired_rv', 'input']
    (179, '        rule identify_unpaired_rv:')
    (180, '            """')
    (181, '            Is like the rule above, but this RC the sequence and reverse the quality values!!')
    (182, '            """')
    (183, '            input:')
    (184, '                rv="{PROJECT}/runs/{run}/{sample}_data/peared/seqs.unassembled.reverse.fastq"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["LIBRARY_LAYOUT"] != "SE"', 'if config["UNPAIRED_DATA_PIPELINE"] == "T" or config["demultiplexing"]["add_unpair"] == "T"', 'rule identify_unpaired_rv', 'output']
    (185, '            output:')
    (186, '                rvo=temp("{PROJECT}/runs/{run}/{sample}_data/peared/seqs.unassembled.reverse.out")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["LIBRARY_LAYOUT"] != "SE"', 'if config["UNPAIRED_DATA_PIPELINE"] == "T" or config["demultiplexing"]["add_unpair"] == "T"', 'rule identify_unpaired_rv', 'shell']
    (187, '            shell:')
    (188, '                "cat {input.rv} | awk \\\'{{if((NR-1)%4==0){{header=$1}}else if((NR-2)%4==0){{seq=$0}}else if(NR%4==0){{print header\\\\"\\\\\\\\t\\\\"seq\\\\"\\\\\\\\t\\\\"$0}}}}\\\' > {output.rvo}"')
    (189, '             #"cat {input.rv} | awk \\\'BEGIN{{a[\\\\"T\\\\"]=\\\\"A\\\\";a[\\\\"A\\\\"]=\\\\"T\\\\";a[\\\\"C\\\\"]=\\\\"G\\\\";a[\\\\"G\\\\"]=\\\\"C\\\\";a[\\\\"N\\\\"]=\\\\"N\\\\"}}"')
    (190, '             #"{{if((NR-1)%4==0){{header=$1}}else if((NR-2)%4==0){{seq=$0}}else if(NR%4==0){{rc=\\\\"\\\\";rq=\\\\"\\\\";for(i=length(seq);i>0;i--){{k=substr(seq,i,1);rc=rc a[k];rq=rq substr($0,i,1)}} "')
    (191, '             #"printf \\\\"%s\\\\\\\\t%s\\\\\\\\t%s\\\\\\')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'rule bc_mapping_validation', 'input']
    (283, 'if config["demultiplexing"]["demultiplex"] == "T":')
    (284, '')
    (285, '    rule bc_mapping_validation:')
    (286, '        """')
    (287, '        Check if the mapping file is ok. Header line needs to start with #')
    (288, '        """')
    (289, '        input:')
    (290, '            mapp="{PROJECT}/metadata/sampleList_mergedBarcodes_{sample}.txt"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'rule bc_mapping_validation', 'output']
    (291, '        output:')
    (292, '            "{PROJECT}/metadata/bc_validation/{sample}/sampleList_mergedBarcodes_{sample}.log" # antes .log pero creo carpeta .log??')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'rule bc_mapping_validation', 'benchmark']
    (293, '        benchmark:')
    (294, '            "{PROJECT}/metadata/bc_validation/{sample}/validation.benchmark"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'rule bc_mapping_validation', 'params']
    (295, '        params:')
    (296, '            "{PROJECT}/metadata/bc_validation/{sample}/"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'rule bc_mapping_validation', 'shell']
    (297, '        shell:')
    (298, '            "{config[qiime][path]}validate_mapping_file.py -o {params} -m {input.mapp}"')
    (299, '#validate bc validation log file stop WF in failure')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'rule validateBCV', 'input']
    (300, '    rule validateBCV:')
    (301, '        input:')
    (302, '            "{PROJECT}/metadata/bc_validation/{sample}/sampleList_mergedBarcodes_{sample}.log",')
    (303, '            "{PROJECT}/metadata/sampleList_mergedBarcodes_{sample}.txt"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'rule validateBCV', 'output']
    (304, '        output:')
    (305, '            "{PROJECT}/metadata/bc_validation/{sample}/validation.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'rule validateBCV', 'params']
    (306, '        params:')
    (307, '            "{PROJECT}/metadata/bc_validation/{sample}/"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'rule validateBCV', 'script']
    (308, '        script:')
    (309, '            "Scripts/validateBCV.py"')
    (310, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'if config["demultiplexing"]["add_unpair"] == "T" and  config["LIBRARY_LAYOUT"] != "SE"', 'rule concat_assembly', 'input']
    (311, '    if config["demultiplexing"]["add_unpair"] == "T" and  config["LIBRARY_LAYOUT"] != "SE":')
    (312, '        rule concat_assembly:')
    (313, '            input: ')
    (314, '                pair="{PROJECT}/runs/{run}/{sample}_data/peared/seqs.assembled.fastq",')
    (315, '                unpair="{PROJECT}/runs/{run}/{sample}_data/peared/seqs.assembled.UNPAIRED.fastq"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'if config["demultiplexing"]["add_unpair"] == "T" and  config["LIBRARY_LAYOUT"] != "SE"', 'rule concat_assembly', 'output']
    (316, '            output:')
    (317, '                temp("{PROJECT}/runs/{run}/{sample}_data/peared/seqs.assembled.PAIRED_UNPAIRED.fastq")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'if config["demultiplexing"]["add_unpair"] == "T" and  config["LIBRARY_LAYOUT"] != "SE"', 'rule concat_assembly', 'shell']
    (318, '            shell:')
    (319, '                "cat {input.pair} {input.unpair} > {output}" ')
    (320, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'if  config["LIBRARY_LAYOUT"] != "SE"', 'rule extract_barcodes', 'input']
    (321, '    if  config["LIBRARY_LAYOUT"] != "SE":')
    (322, '        rule extract_barcodes:')
    (323, '            """')
    (324, '            Extracts the barcodes from the fastq reads. This rules applies to the not Single END mode.')
    (325, '            For choosing the correct "assembly" it uses the peared/seqs.assembled.PAIRED_UNPAIRED.fastq (Paired + Unpaired) if the WF is')
    (326, '            different to the UNPAIRED WF and if the add_unpair option is set to T.')
    (327, '            It selects only the paired sequences if the workflow is different to the unpaired WF and ther option add_unpair is set to F.')
    (328, '            Finally, it uses only the unpaired sequences if the Workflow is the UNPAIRED no matter what the user choose for the add_unpair option.')
    (329, '            """')
    (330, '            input:')
    (331, '                tmp2="{PROJECT}/runs/{run}/{sample}_data/peared/pear.log.validation",')
    (332, '                assembly="{PROJECT}/runs/{run}/{sample}_data/peared/seqs.assembled.PAIRED_UNPAIRED.fastq" if config["UNPAIRED_DATA_PIPELINE"] != "T" and config["demultiplexing"]["add_unpair"] == "T"     ')
    (333, '                else "{PROJECT}/runs/{run}/{sample}_data/peared/seqs.assembled.fastq" if config["UNPAIRED_DATA_PIPELINE"] != "T" else')
    (334, '                "{PROJECT}/runs/{run}/{sample}_data/peared/seqs.assembled.UNPAIRED.fastq",')
    (335, '                tmpinput="{PROJECT}/runs/{run}/{sample}_data/peared/qc/fq_fw_internal_validation.txt",')
    (336, '                tmp3="{PROJECT}/metadata/bc_validation/{sample}/validation.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'if  config["LIBRARY_LAYOUT"] != "SE"', 'rule extract_barcodes', 'output']
    (337, '            output:')
    (338, '                "{PROJECT}/runs/{run}/{sample}_data/barcodes/barcodes.fastq",')
    (339, '                "{PROJECT}/runs/{run}/{sample}_data/barcodes/reads.fastq"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'if  config["LIBRARY_LAYOUT"] != "SE"', 'rule extract_barcodes', 'params']
    (340, '            params:')
    (341, '                "{PROJECT}/runs/{run}/{sample}_data/barcodes/"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'if  config["LIBRARY_LAYOUT"] != "SE"', 'rule extract_barcodes', 'benchmark']
    (342, '            benchmark:')
    (343, '                "{PROJECT}/runs/{run}/{sample}_data/barcodes/barcodes.benchmark"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'if  config["LIBRARY_LAYOUT"] != "SE"', 'rule extract_barcodes', 'shell']
    (344, '            shell:')
    (345, '                "{config[qiime][path]}extract_barcodes.py -f {input.assembly} -c {config[ext_bc][c]} "')
    (346, '                "{config[ext_bc][bc_length]} {config[ext_bc][extra_params]} -o {params}"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'else']
    (347, '    else: #The workflow is SE')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'rule extract_barcodes', 'input']
    (348, '        rule extract_barcodes:')
    (349, '            input:')
    (350, '                assembly="{PROJECT}/samples/{sample}/rawdata/fw.fastq" if config["gzip_input"] == "F" else "{PROJECT}/samples/{sample}/rawdata/fw.fastq.gz",')
    (351, '                tmp="{PROJECT}/samples/{sample}/qc/fq_fw_internal_validation.txt",')
    (352, '                tmp3="{PROJECT}/metadata/bc_validation/{sample}/validation.log"')
    (353, '            output:')
    (354, '                "{PROJECT}/runs/{run}/{sample}_data/barcodes/barcodes.fastq",')
    (355, '                "{PROJECT}/runs/{run}/{sample}_data/barcodes/reads.fastq"')
    (356, '            params:')
    (357, '                "{PROJECT}/runs/{run}/{sample}_data/barcodes/"')
    (358, '            benchmark:')
    (359, '                "{PROJECT}/runs/{run}/{sample}_data/barcodes/barcodes.benchmark"')
    (360, '            shell:')
    (361, '                "{config[qiime][path]}extract_barcodes.py -f {input.assembly} -c {config[ext_bc][c]} "')
    (362, '                "{config[ext_bc][bc_length]} {config[ext_bc][extra_params]} -o {params}"')
    (363, '')
    (364, '#If allow mismatch correct bar code')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'if config["bc_mismatch"]', 'rule correct_barcodes', 'input']
    (365, '    if config["bc_mismatch"]:')
    (366, '        rule correct_barcodes:')
    (367, '            input:')
    (368, '                bc="{PROJECT}/runs/{run}/{sample}_data/barcodes/barcodes.fastq",')
    (369, '                mapp="{PROJECT}/metadata/sampleList_mergedBarcodes_{sample}.txt"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'if config["bc_mismatch"]', 'rule correct_barcodes', 'output']
    (370, '            output:')
    (371, '                "{PROJECT}/runs/{run}/{sample}_data/barcodes/barcodes.fastq_corrected"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'if config["bc_mismatch"]', 'rule correct_barcodes', 'benchmark']
    (372, '            benchmark:')
    (373, '                "{PROJECT}/runs/{run}/{sample}_data/barcodes/barcodes_corrected.benchmark"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'if config["bc_mismatch"]', 'rule correct_barcodes', 'shell']
    (374, '            shell:')
    (375, '                "java -cp Scripts/BarcodeCorrector/build/classes/ barcodecorrector.BarcodeCorrector -f {input.bc} -b  {input.mapp} -m  "  + str(config["bc_mismatch"])')
    (376, '                #"{config[Rscript][command]} Scripts/errorCorrectBarcodes.R $PWD {input.mapp} {input.bc} "  + str(config["bc_mismatch"])')
    (377, '#split libraries - demultiplex')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'rule split_libraries', 'input']
    (378, '    rule split_libraries:')
    (379, '        input:')
    (380, '            rFile="{PROJECT}/runs/{run}/{sample}_data/barcodes/reads.fastq",')
    (381, '            mapFile="{PROJECT}/metadata/sampleList_mergedBarcodes_{sample}.txt",')
    (382, '            bcFile="{PROJECT}/runs/{run}/{sample}_data/barcodes/barcodes.fastq_corrected" if config["bc_mismatch"] else "{PROJECT}/runs/{run}/{sample}_data/barcodes/barcodes.fastq",')
    (383, '            #tmp3="{PROJECT}/metadata/bc_validation/{sample}/validation.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'rule split_libraries', 'output']
    (384, '        output:')
    (385, '            seqs=temp("{PROJECT}/runs/{run}/{sample}_data/splitLibs/seqs.fna"),')
    (386, '            spliLog="{PROJECT}/runs/{run}/{sample}_data/splitLibs/split_library_log.txt",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'rule split_libraries', 'params']
    (387, '        params:')
    (388, '            outDir="{PROJECT}/runs/{run}/{sample}_data/splitLibs",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'rule split_libraries', 'benchmark']
    (389, '        benchmark:')
    (390, '            "{PROJECT}/runs/{run}/{sample}_data/splitLibs/splitLibs.benchmark"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'rule split_libraries', 'shell']
    (391, '        shell:')
    (392, '            "{config[qiime][path]}split_libraries_fastq.py -m {input.mapFile} -i {input.rFile} "')
    (393, '            "-o {params.outDir} -b {input.bcFile} -q {config[split][q]} -r {config[split][r]} "')
    (394, '            "--retain_unassigned_reads --barcode_type {config[split][barcode_type]} {config[split][extra_params]}"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'if config["LIBRARY_LAYOUT"] != "SE"', 'rule get_unassigned', 'input']
    (395, '    if config["LIBRARY_LAYOUT"] != "SE":')
    (396, '        rule get_unassigned:')
    (397, '            input:')
    (398, '                split="{PROJECT}/runs/{run}/{sample}_data/splitLibs/seqs.fna",')
    (399, '                assembly="{PROJECT}/runs/{run}/{sample}_data/peared/seqs.assembled.PAIRED_UNPAIRED.fastq" if config["UNPAIRED_DATA_PIPELINE"] != "T" and config["demultiplexing"]["add_unpair"] == "T"     ')
    (400, '                else "{PROJECT}/runs/{run}/{sample}_data/peared/seqs.assembled.fastq" if config["UNPAIRED_DATA_PIPELINE"] != "T" ')
    (401, '                else "{PROJECT}/runs/{run}/{sample}_data/peared/seqs.assembled.UNPAIRED.fastq" ')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'if config["LIBRARY_LAYOUT"] != "SE"', 'rule get_unassigned', 'output']
    (402, '            output:')
    (403, '                temp("{PROJECT}/runs/{run}/{sample}_data/splitLibs/unassigned.fastq")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'if config["LIBRARY_LAYOUT"] != "SE"', 'rule get_unassigned', 'shell']
    (404, '            shell:')
    (405, '                "cat {input.split} | grep \\\\"^>Unassigned\\\\" |  sed \\\'s/>Unassigned_[0-9]* /@/g\\\' | "')
    (406, '                "sed \\\'s/ .*//\\\' | grep -F -w -A3  -f - {input.assembly} |  sed \\\'/^--$/d\\\' > {output}"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'else', 'rule uncompress_singleEND', 'input']
    (407, '    else:')
    (408, '        rule uncompress_singleEND:')
    (409, '            input:')
    (410, '                "{PROJECT}/samples/{sample}/rawdata/fw.fastq.gz"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'else', 'rule uncompress_singleEND', 'output']
    (411, '            output:')
    (412, '                temp("{PROJECT}/samples/{sample}/rawdata/fw.tmp.fastq")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'else', 'rule uncompress_singleEND', 'shell']
    (413, '            shell:')
    (414, '                "gzip -cd {input} > {output}"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'else', 'rule get_unassigned', 'input']
    (415, '        rule get_unassigned:')
    (416, '            input:')
    (417, '                split="{PROJECT}/runs/{run}/{sample}_data/splitLibs/seqs.fna",')
    (418, '                assembly="{PROJECT}/samples/{sample}/rawdata/fw.fastq" if config["gzip_input"] == "F" else "{PROJECT}/samples/{sample}/rawdata/fw.tmp.fastq"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'else', 'rule get_unassigned', 'output']
    (419, '            output:')
    (420, '                temp("{PROJECT}/runs/{run}/{sample}_data/splitLibs/unassigned.fastq")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'else', 'rule get_unassigned', 'shell']
    (421, '            shell:')
    (422, '                "cat {input.split} | grep \\\\"^>Unassigned\\\\" |  sed \\\'s/>Unassigned_[0-9]* /@/g\\\' | "')
    (423, '                "sed \\\'s/ .*//\\\' | grep -F -w -A3  -f - {input.assembly} |  sed \\\'/^--$/d\\\' > {output}"')
    (424, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'rule rc_unassigned', 'input']
    (425, '    rule rc_unassigned:')
    (426, '        input:')
    (427, '            "{PROJECT}/runs/{run}/{sample}_data/splitLibs/unassigned.fastq"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'rule rc_unassigned', 'output']
    (428, '        output:')
    (429, '            temp("{PROJECT}/runs/{run}/{sample}_data/splitLibs/unassigned.reversed.fastq")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'rule rc_unassigned', 'shell']
    (430, '        shell:')
    (431, '            "vsearch --fastx_revcomp {input} --fastqout {output}"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'rule extract_barcodes_unassigned', 'input']
    (432, '    rule extract_barcodes_unassigned:')
    (433, '        input:')
    (434, '            assembly="{PROJECT}/runs/{run}/{sample}_data/splitLibs/unassigned.reversed.fastq"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'rule extract_barcodes_unassigned', 'output']
    (435, '        output:')
    (436, '            "{PROJECT}/runs/{run}/{sample}_data/barcodes_unassigned/barcodes.fastq",')
    (437, '            "{PROJECT}/runs/{run}/{sample}_data/barcodes_unassigned/reads.fastq"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'rule extract_barcodes_unassigned', 'params']
    (438, '        params:')
    (439, '            "{PROJECT}/runs/{run}/{sample}_data/barcodes_unassigned/"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'rule extract_barcodes_unassigned', 'benchmark']
    (440, '        benchmark:')
    (441, '            "{PROJECT}/runs/{run}/{sample}_data/barcodes_unassigned/barcodes.benchmark"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'rule extract_barcodes_unassigned', 'shell']
    (442, '        shell:')
    (443, '            "{config[qiime][path]}extract_barcodes.py -f {input.assembly} -c {config[ext_bc][c]} "')
    (444, '            "{config[ext_bc][bc_length]} {config[ext_bc][extra_params]} -o {params}"')
    (445, '#If allow mismatch correct bar code')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'if config["bc_mismatch"]', 'rule correct_barcodes_unassigned', 'input']
    (446, '    if config["bc_mismatch"]:')
    (447, '        rule correct_barcodes_unassigned:')
    (448, '            input:')
    (449, '                bc="{PROJECT}/runs/{run}/{sample}_data/barcodes_unassigned/barcodes.fastq",')
    (450, '                mapp="{PROJECT}/metadata/sampleList_mergedBarcodes_{sample}.txt"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'if config["bc_mismatch"]', 'rule correct_barcodes_unassigned', 'output']
    (451, '            output:')
    (452, '                "{PROJECT}/runs/{run}/{sample}_data/barcodes_unassigned/barcodes.fastq_corrected"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'if config["bc_mismatch"]', 'rule correct_barcodes_unassigned', 'benchmark']
    (453, '            benchmark:')
    (454, '                "{PROJECT}/runs/{run}/{sample}_data/barcodes_unassigned/barcodes_corrected.benchmark"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'if config["bc_mismatch"]', 'rule correct_barcodes_unassigned', 'shell']
    (455, '            shell:')
    (456, '                "java -cp Scripts/BarcodeCorrector/build/classes/ barcodecorrector.BarcodeCorrector -f {input.bc} -b  {input.mapp} -m  "  + str(config["bc_mismatch"])')
    (457, '                #"{config[Rscript][command]} Scripts/errorCorrectBarcodes.R $PWD {input.mapp} {input.bc} "  + str(config["bc_mismatch"])')
    (458, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'rule split_libraries_rc', 'input']
    (459, '    rule split_libraries_rc:')
    (460, '        """')
    (461, '        This rule will call a script in order to execute the librarie splitting for the')
    (462, '        RC sequences. It still need the seqs.fna file bz this file contains the exact')
    (463, '        number of sequences assigned during the first split, then the script takes that')
    (464, '        number and start to assign reads for the new splitting starting at the previous')
    (465, '        number...')
    (466, '        """')
    (467, '')
    (468, '        input:')
    (469, '            spplited="{PROJECT}/runs/{run}/{sample}_data/splitLibs/seqs.fna",')
    (470, '            rFile="{PROJECT}/runs/{run}/{sample}_data/barcodes_unassigned/reads.fastq",')
    (471, '            mapFile="{PROJECT}/metadata/sampleList_mergedBarcodes_{sample}.txt",')
    (472, '            bcFile="{PROJECT}/runs/{run}/{sample}_data/barcodes_unassigned/barcodes.fastq_corrected" if config["bc_mismatch"]')
    (473, '            else "{PROJECT}/runs/{run}/{sample}_data/barcodes_unassigned/barcodes.fastq"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'rule split_libraries_rc', 'output']
    (474, '        output:')
    (475, '            seqsRC=temp("{PROJECT}/runs/{run}/{sample}_data/splitLibsRC/seqs.fna"), #marc as tmp')
    (476, '            spliLog="{PROJECT}/runs/{run}/{sample}_data/splitLibsRC/split_library_log.txt"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'rule split_libraries_rc', 'params']
    (477, '        params:')
    (478, '            outDirRC="{PROJECT}/runs/{run}/{sample}_data/splitLibsRC"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'rule split_libraries_rc', 'benchmark']
    (479, '        benchmark:')
    (480, '            "{PROJECT}/runs/{run}/{sample}_data/splitLibsRC/splitLibs.benchmark"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'rule split_libraries_rc', 'script']
    (481, '        script:')
    (482, '            "Scripts/splitRC.py"')
    (483, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'rule remove_unassigned_fw', 'input']
    (484, '    rule remove_unassigned_fw:')
    (485, '        input:')
    (486, '            "{PROJECT}/runs/{run}/{sample}_data/splitLibs/seqs.fna"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'rule remove_unassigned_fw', 'output']
    (487, '        output:')
    (488, '            "{PROJECT}/runs/{run}/{sample}_data/splitLibs/seqs.no_unassigneds.fna"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'rule remove_unassigned_fw', 'shell']
    (489, '        shell:')
    (490, '            "cat {input} | grep -P -A1 \\\'(?!>Unass)^>\\\' | sed \\\'/^--$/d\\\' > {output}"')
    (491, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'rule remove_unassigned_rv', 'input']
    (492, '    rule remove_unassigned_rv:')
    (493, '        input:')
    (494, '            splitRC="{PROJECT}/runs/{run}/{sample}_data/splitLibsRC/seqs.fna"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'rule remove_unassigned_rv', 'output']
    (495, '        output:')
    (496, '            "{PROJECT}/runs/{run}/{sample}_data/splitLibsRC/seqs.no_unassigneds.fna"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'rule remove_unassigned_rv', 'shell']
    (497, '        shell:')
    (498, '            "cat {input} | grep -P -A1 \\\'(?!>Unass)^>\\\' | sed \\\'/^--$/d\\\' > {output}"')
    (499, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'rule create_unassigned_file', 'input']
    (500, '    rule create_unassigned_file:')
    (501, '        input:')
    (502, '            splitRC="{PROJECT}/runs/{run}/{sample}_data/splitLibsRC/seqs.fna"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'rule create_unassigned_file', 'output']
    (503, '        output:')
    (504, '            "{PROJECT}/runs/{run}/{sample}_data/seqs.unassigned.fna"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'rule create_unassigned_file', 'shell']
    (505, '        shell:')
    (506, '            "cat {input} | grep -A1 --no-group-separator \\\\"^>Unassigned\\\\"  > {output}"')
    (507, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'if config["UNPAIRED_DATA_PIPELINE"] != "T" and config["demultiplexing"]["add_unpair"] == "T" and config["LIBRARY_LAYOUT"] != "SE"', 'rule find_unassembled_fw_ids', 'input']
    (508, '    if config["UNPAIRED_DATA_PIPELINE"] != "T" and config["demultiplexing"]["add_unpair"] == "T" and config["LIBRARY_LAYOUT"] != "SE":')
    (509, '        rule find_unassembled_fw_ids:')
    (510, '             """')
    (511, '             This rule creates a file with all the new ids assigned to unassembled reads.')
    (512, '             The file seqs.unassembled.forward.out is equivalent to the seqs.unassembled.reverse.out in this context')
    (513, '             since we only need the fadstq ids which should be exactly the same in both files')
    (514, '             """')
    (515, '             input:')
    (516, '                 fasta="{PROJECT}/runs/{run}/{sample}_data/splitLibs/seqs.no_unassigneds.fna",')
    (517, '                 mapa="{PROJECT}/runs/{run}/{sample}_data/peared/seqs.unassembled.forward.out"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'if config["UNPAIRED_DATA_PIPELINE"] != "T" and config["demultiplexing"]["add_unpair"] == "T" and config["LIBRARY_LAYOUT"] != "SE"', 'rule find_unassembled_fw_ids', 'output']
    (518, '             output:')
    (519, '                 temp("{PROJECT}/runs/{run}/{sample}_data/splitLibs/seqs.unassembled_ids.txt")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'if config["UNPAIRED_DATA_PIPELINE"] != "T" and config["demultiplexing"]["add_unpair"] == "T" and config["LIBRARY_LAYOUT"] != "SE"', 'rule find_unassembled_fw_ids', 'shell']
    (520, '             shell: ')
    (521, '                 "cat {input.mapa} | cut -f1 | sed \\\'s/@//\\\' | grep -F -w -f - {input.fasta} | cut -f1 -d\\\\" \\\\" | sed \\\'s/>//\\\' > {output} || true" ')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'if config["UNPAIRED_DATA_PIPELINE"] != "T" and config["demultiplexing"]["add_unpair"] == "T" and config["LIBRARY_LAYOUT"] != "SE"', 'rule find_unassembled_rv_ids', 'input']
    (522, '        rule find_unassembled_rv_ids:')
    (523, '             """')
    (524, '             Similar rule as find_unassembled_fw_ids. Here we can ')
    (525, '             use either the reverse or forward, they should be the same')
    (526, '             """')
    (527, '             input:')
    (528, '                 fasta="{PROJECT}/runs/{run}/{sample}_data/splitLibsRC/seqs.no_unassigneds.fna",')
    (529, '                 mapa="{PROJECT}/runs/{run}/{sample}_data/peared/seqs.unassembled.reverse.out"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'if config["UNPAIRED_DATA_PIPELINE"] != "T" and config["demultiplexing"]["add_unpair"] == "T" and config["LIBRARY_LAYOUT"] != "SE"', 'rule find_unassembled_rv_ids', 'output']
    (530, '             output:')
    (531, '                 temp("{PROJECT}/runs/{run}/{sample}_data/splitLibsRC/seqs.unassembled_ids.txt")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'if config["UNPAIRED_DATA_PIPELINE"] != "T" and config["demultiplexing"]["add_unpair"] == "T" and config["LIBRARY_LAYOUT"] != "SE"', 'rule find_unassembled_rv_ids', 'shell']
    (532, '             shell: ')
    (533, '                 "cat {input.mapa} | cut -f1 | sed \\\'s/@//\\\' | grep -F -w -f - {input.fasta} | cut -f1 -d\\\\" \\\\" | sed \\\'s/>//\\\' > {output} || true"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'if config["UNPAIRED_DATA_PIPELINE"] != "T" and config["demultiplexing"]["add_unpair"] == "T" and config["LIBRARY_LAYOUT"] != "SE"', 'rule remove_unassembled_fw', 'input']
    (534, '        rule remove_unassembled_fw:')
    (535, '             input:')
    (536, '                 fasta="{PROJECT}/runs/{run}/{sample}_data/splitLibs/seqs.no_unassigneds.fna",')
    (537, '                 ids="{PROJECT}/runs/{run}/{sample}_data/splitLibs/seqs.unassembled_ids.txt"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'if config["UNPAIRED_DATA_PIPELINE"] != "T" and config["demultiplexing"]["add_unpair"] == "T" and config["LIBRARY_LAYOUT"] != "SE"', 'rule remove_unassembled_fw', 'output']
    (538, '             output:')
    (539, '                 "{PROJECT}/runs/{run}/{sample}_data/splitLibs/seqs.assigned.fna"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'if config["UNPAIRED_DATA_PIPELINE"] != "T" and config["demultiplexing"]["add_unpair"] == "T" and config["LIBRARY_LAYOUT"] != "SE"', 'rule remove_unassembled_fw', 'shell']
    (540, '             shell: ')
    (541, '                 "{config[qiime][path]}filter_fasta.py -f {input.fasta} -s {input.ids} -n -o {output}"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'if config["UNPAIRED_DATA_PIPELINE"] != "T" and config["demultiplexing"]["add_unpair"] == "T" and config["LIBRARY_LAYOUT"] != "SE"', 'rule remove_unassembled_rv', 'input']
    (542, '        rule remove_unassembled_rv:')
    (543, '             input:')
    (544, '                 fasta="{PROJECT}/runs/{run}/{sample}_data/splitLibsRC/seqs.no_unassigneds.fna",')
    (545, '                 ids="{PROJECT}/runs/{run}/{sample}_data/splitLibsRC/seqs.unassembled_ids.txt"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'if config["UNPAIRED_DATA_PIPELINE"] != "T" and config["demultiplexing"]["add_unpair"] == "T" and config["LIBRARY_LAYOUT"] != "SE"', 'rule remove_unassembled_rv', 'output']
    (546, '             output:')
    (547, '                 "{PROJECT}/runs/{run}/{sample}_data/splitLibsRC/seqs.assigned.fna"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'if config["UNPAIRED_DATA_PIPELINE"] != "T" and config["demultiplexing"]["add_unpair"] == "T" and config["LIBRARY_LAYOUT"] != "SE"', 'rule remove_unassembled_rv', 'shell']
    (548, '             shell: ')
    (549, '                 "{config[qiime][path]}filter_fasta.py -f {input.fasta} -s {input.ids} -n -o {output}"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'else', 'rule rename_assembled_fw', 'input']
    (550, '    else:')
    (551, '         rule rename_assembled_fw:')
    (552, '             input:')
    (553, '                 "{PROJECT}/runs/{run}/{sample}_data/splitLibs/seqs.no_unassigneds.fna"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'else', 'rule rename_assembled_fw', 'output']
    (554, '             output:')
    (555, '                 "{PROJECT}/runs/{run}/{sample}_data/splitLibs/seqs.assigned.fna"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'else', 'rule rename_assembled_fw', 'shell']
    (556, '             shell: ')
    (557, '                 "mv {input} {output}"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'else', 'rule rename_assembled_rv', 'input']
    (558, '         rule rename_assembled_rv:')
    (559, '             input:')
    (560, '                 "{PROJECT}/runs/{run}/{sample}_data/splitLibsRC/seqs.no_unassigneds.fna"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'else', 'rule rename_assembled_rv', 'output']
    (561, '             output:')
    (562, '                 "{PROJECT}/runs/{run}/{sample}_data/splitLibsRC/seqs.assigned.fna"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'else', 'rule rename_assembled_rv', 'shell']
    (563, '             shell: ')
    (564, '                 "mv {input} {output}"')
    (565, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'rule validateDemultiplex', 'input']
    (566, '    rule validateDemultiplex:')
    (567, '        input:')
    (568, '            split="{PROJECT}/runs/{run}/{sample}_data/splitLibs/seqs.assigned.fna", ')
    (569, '            splitRC="{PROJECT}/runs/{run}/{sample}_data/splitLibsRC/seqs.assigned.fna", ')
    (570, '            logSplit="{PROJECT}/runs/{run}/{sample}_data/splitLibs/split_library_log.txt",')
    (571, '            logSplitRC="{PROJECT}/runs/{run}/{sample}_data/splitLibsRC/split_library_log.txt",')
    (572, '            allreads="{PROJECT}/runs/{run}/{sample}_data/barcodes/reads.fastq",')
    (573, '            unassigned="{PROJECT}/runs/{run}/{sample}_data/seqs.unassigned.fna"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'rule validateDemultiplex', 'output']
    (574, '        output:')
    (575, '            "{PROJECT}/runs/{run}/{sample}_data/splitLibs/split_library_log.txt.validation"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'rule validateDemultiplex', 'params']
    (576, '        params:')
    (577, '            "{PROJECT}/runs/{run}/{sample}_data/splitLibs",')
    (578, '            "{PROJECT}/runs/{run}/{sample}_data/splitLibsRC"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'rule validateDemultiplex', 'script']
    (579, '        script:')
    (580, '            "Scripts/validateSplitNew.py"')
    (581, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'rule combine_accepted_reads', 'input']
    (582, '    rule combine_accepted_reads:')
    (583, '        input:')
    (584, '            seqs="{PROJECT}/runs/{run}/{sample}_data/splitLibs/seqs.assigned.fna", #marc as tmp')
    (585, '            seqsRC="{PROJECT}/runs/{run}/{sample}_data/splitLibsRC/seqs.assigned.fna", #marc as')
    (586, '            tmpFlow="{PROJECT}/runs/{run}/{sample}_data/splitLibs/split_library_log.txt.validation"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'rule combine_accepted_reads', 'output']
    (587, '        output:')
    (588, '            "{PROJECT}/runs/{run}/{sample}_data/seqs_fw_rev_accepted.fna"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'rule combine_accepted_reads', 'benchmark']
    (589, '        benchmark:')
    (590, '            "{PROJECT}/runs/{run}/{sample}_data/combine_seqs_fw_rev.benchmark"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'rule combine_accepted_reads', 'shell']
    (591, '        shell:')
    (592, '            "cat {input.seqs} {input.seqsRC}  > {output}"')
    (593, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'if (config["demultiplexing"]["create_fastq_files"] == "T" or config["ANALYSIS_TYPE"] == "ASV") and config["LIBRARY_LAYOUT"] != "SE"', 'rule write_dmx_files_fw', 'input']
    (594, '    if (config["demultiplexing"]["create_fastq_files"] == "T" or config["ANALYSIS_TYPE"] == "ASV") and config["LIBRARY_LAYOUT"] != "SE":')
    (595, '        rule write_dmx_files_fw:')
    (596, '            input:')
    (597, '                dmx= "{PROJECT}/runs/{run}/{sample}_data/splitLibs/seqs.no_unassigneds.fna" if config["UNPAIRED_DATA_PIPELINE"] != "T" and config["demultiplexing"]["add_unpair"] == "T"')
    (598, '                else "{PROJECT}/runs/{run}/{sample}_data/splitLibs/seqs.assigned.fna",')
    (599, '                r1="{PROJECT}/samples/{sample}/rawdata/fw.fastq" if config["gzip_input"] == "F" else "{PROJECT}/samples/{sample}/rawdata/fw.fastq.gz",')
    (600, '                r2="{PROJECT}/samples/{sample}/rawdata/rv.fastq" if config["gzip_input"] == "F" else "{PROJECT}/samples/{sample}/rawdata/rv.fastq.gz"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'if (config["demultiplexing"]["create_fastq_files"] == "T" or config["ANALYSIS_TYPE"] == "ASV") and config["LIBRARY_LAYOUT"] != "SE"', 'rule write_dmx_files_fw', 'params']
    (601, '            params:')
    (602, '                outdir="{PROJECT}/runs/{run}/{sample}_data/demultiplexed/"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'if (config["demultiplexing"]["create_fastq_files"] == "T" or config["ANALYSIS_TYPE"] == "ASV") and config["LIBRARY_LAYOUT"] != "SE"', 'rule write_dmx_files_fw', 'output']
    (603, '            output:')
    (604, '                "{PROJECT}/runs/{run}/{sample}_data/demultiplexed/summary_fw.txt"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'if (config["demultiplexing"]["create_fastq_files"] == "T" or config["ANALYSIS_TYPE"] == "ASV") and config["LIBRARY_LAYOUT"] != "SE"', 'rule write_dmx_files_fw', 'benchmark']
    (605, '            benchmark:')
    (606, '                "{PROJECT}/runs/{run}/{sample}_data/demultiplexed/demultiplex_fq.benchmark"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'if (config["demultiplexing"]["create_fastq_files"] == "T" or config["ANALYSIS_TYPE"] == "ASV") and config["LIBRARY_LAYOUT"] != "SE"', 'rule write_dmx_files_fw', 'shell']
    (607, '            shell:')
    (608, '                "{config[java][command]}  -cp Scripts DemultiplexQiime --over-write --fasta -a fw -b {config[demultiplexing][remove_bc]}  -d {input.dmx} -o {params.outdir} "')
    (609, '                "-r1 {input.r1} -r2 {input.r2} {config[demultiplexing][dmx_params]}"')
    (610, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'if (config["demultiplexing"]["create_fastq_files"] == "T" or config["ANALYSIS_TYPE"] == "ASV") and config["LIBRARY_LAYOUT"] != "SE"', 'rule write_dmx_files_rv', 'input']
    (611, '        rule write_dmx_files_rv:')
    (612, '            """ ')
    (613, "            We supply the input \\'overw\\' because it force to run first the write_dmx_files_fw which is the ")
    (614, '            one with the --over-write flag, so if the rule is re run, the generated files do not duplicate')
    (615, '            entries.')
    (616, '            """')
    (617, '            input:')
    (618, '                dmx="{PROJECT}/runs/{run}/{sample}_data/splitLibsRC/seqs.no_unassigneds.fna" if config["UNPAIRED_DATA_PIPELINE"] != "T" and config["demultiplexing"]["add_unpair"] == "T"')
    (619, '                else "{PROJECT}/runs/{run}/{sample}_data/splitLibsRC/seqs.assigned.fna",')
    (620, '                overw="{PROJECT}/runs/{run}/{sample}_data/demultiplexed/summary_fw.txt",')
    (621, '                r2="{PROJECT}/samples/{sample}/rawdata/fw.fastq" if config["gzip_input"] == "F" else "{PROJECT}/samples/{sample}/rawdata/fw.fastq.gz",')
    (622, '                r1="{PROJECT}/samples/{sample}/rawdata/rv.fastq" if config["gzip_input"] == "F" else "{PROJECT}/samples/{sample}/rawdata/rv.fastq.gz"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'if (config["demultiplexing"]["create_fastq_files"] == "T" or config["ANALYSIS_TYPE"] == "ASV") and config["LIBRARY_LAYOUT"] != "SE"', 'rule write_dmx_files_rv', 'params']
    (623, '            params:')
    (624, '                outdir="{PROJECT}/runs/{run}/{sample}_data/demultiplexed/"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'if (config["demultiplexing"]["create_fastq_files"] == "T" or config["ANALYSIS_TYPE"] == "ASV") and config["LIBRARY_LAYOUT"] != "SE"', 'rule write_dmx_files_rv', 'output']
    (625, '            output:')
    (626, '                "{PROJECT}/runs/{run}/{sample}_data/demultiplexed/summary_rv.txt"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'if (config["demultiplexing"]["create_fastq_files"] == "T" or config["ANALYSIS_TYPE"] == "ASV") and config["LIBRARY_LAYOUT"] != "SE"', 'rule write_dmx_files_rv', 'benchmark']
    (627, '            benchmark:')
    (628, '                "{PROJECT}/runs/{run}/{sample}_data/demultiplexed/demultiplex_fq.benchmark"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'if (config["demultiplexing"]["create_fastq_files"] == "T" or config["ANALYSIS_TYPE"] == "ASV") and config["LIBRARY_LAYOUT"] != "SE"', 'rule write_dmx_files_rv', 'shell']
    (629, '            shell:')
    (630, '                "{config[java][command]}  -cp Scripts DemultiplexQiime  --fasta -a rv -b {config[demultiplexing][remove_bc]}  -d {input.dmx} -o {params.outdir} "')
    (631, '                "-r1 {input.r1} -r2 {input.r2} {config[demultiplexing][dmx_params]}"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'if (config["demultiplexing"]["create_fastq_files"] == "T" or config["ANALYSIS_TYPE"] == "ASV") and config["LIBRARY_LAYOUT"] != "SE"', 'if config["demultiplexing"]["primers"]["remove"].lower() == "cfg"', 'rule remove_primers_dmx_files', 'input']
    (632, '        if config["demultiplexing"]["primers"]["remove"].lower() == "cfg":')
    (633, '            rule remove_primers_dmx_files:')
    (634, '                input:')
    (635, '                    fw="{PROJECT}/runs/{run}/{sample}_data/demultiplexed/summary_fw.txt",')
    (636, '                    rv="{PROJECT}/runs/{run}/{sample}_data/demultiplexed/summary_rv.txt"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'if (config["demultiplexing"]["create_fastq_files"] == "T" or config["ANALYSIS_TYPE"] == "ASV") and config["LIBRARY_LAYOUT"] != "SE"', 'if config["demultiplexing"]["primers"]["remove"].lower() == "cfg"', 'rule remove_primers_dmx_files', 'params']
    (637, '                params:')
    (638, '                    "{PROJECT}/runs/{run}/{sample}_data/demultiplexed",')
    (639, '                    config["demultiplexing"]["primers"]["extra_params"],')
    (640, '                    "fastq.gz",')
    (641, '                    "PE",')
    (642, '                    "{PROJECT}/runs/{run}/report_files/cutadapt.{sample}.fastq_summary.tsv"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'if (config["demultiplexing"]["create_fastq_files"] == "T" or config["ANALYSIS_TYPE"] == "ASV") and config["LIBRARY_LAYOUT"] != "SE"', 'if config["demultiplexing"]["primers"]["remove"].lower() == "cfg"', 'rule remove_primers_dmx_files', 'benchmark']
    (643, '                benchmark:')
    (644, '                    "{PROJECT}/runs/{run}/{sample}_data/demultiplexed/remove_primers_fq.benchmark" ')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'if (config["demultiplexing"]["create_fastq_files"] == "T" or config["ANALYSIS_TYPE"] == "ASV") and config["LIBRARY_LAYOUT"] != "SE"', 'if config["demultiplexing"]["primers"]["remove"].lower() == "cfg"', 'rule remove_primers_dmx_files', 'output']
    (645, '                output:')
    (646, '                    "{PROJECT}/runs/{run}/{sample}_data/demultiplexed/summary.txt"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'if (config["demultiplexing"]["create_fastq_files"] == "T" or config["ANALYSIS_TYPE"] == "ASV") and config["LIBRARY_LAYOUT"] != "SE"', 'if config["demultiplexing"]["primers"]["remove"].lower() == "cfg"', 'rule remove_primers_dmx_files', 'script']
    (647, '                script:')
    (648, '                    "Scripts/removePrimersDemultiplex_cfg.py"')
    (649, '                #shell:')
    (650, '                    #"Scripts/removePrimersDemultiplex.sh {params} fastq.gz {config[demultiplexing][primers][fw_primer]} {config[demultiplexing][primers][rv_primer]} {config[demultiplexing][primers][min_overlap]} {config[demultiplexing][primers][extra_params]}"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'if (config["demultiplexing"]["create_fastq_files"] == "T" or config["ANALYSIS_TYPE"] == "ASV") and config["LIBRARY_LAYOUT"] != "SE"', 'elif config["demultiplexing"]["primers"]["remove"].lower() == "metadata"', 'rule remove_primers_dmx_files', 'input']
    (651, '        elif config["demultiplexing"]["primers"]["remove"].lower() == "metadata":')
    (652, '            rule remove_primers_dmx_files:')
    (653, '                input:')
    (654, '                    config="{PROJECT}/metadata/sampleList_mergedBarcodes_{sample}.txt" if config["demultiplexing"]["demultiplex"] == "T"')
    (655, '                    else config["metadata"],')
    (656, '                    fw="{PROJECT}/runs/{run}/{sample}_data/demultiplexed/summary_fw.txt",')
    (657, '                    rv="{PROJECT}/runs/{run}/{sample}_data/demultiplexed/summary_rv.txt"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'if (config["demultiplexing"]["create_fastq_files"] == "T" or config["ANALYSIS_TYPE"] == "ASV") and config["LIBRARY_LAYOUT"] != "SE"', 'elif config["demultiplexing"]["primers"]["remove"].lower() == "metadata"', 'rule remove_primers_dmx_files', 'params']
    (658, '                params:')
    (659, '                    "{PROJECT}/runs/{run}/{sample}_data/demultiplexed",')
    (660, '                    config["demultiplexing"]["primers"]["extra_params"],')
    (661, '                    "fastq.gz",')
    (662, '                    "PE",')
    (663, '                    "{PROJECT}/runs/{run}/report_files/cutadapt.{sample}.fastq_summary.tsv"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'if (config["demultiplexing"]["create_fastq_files"] == "T" or config["ANALYSIS_TYPE"] == "ASV") and config["LIBRARY_LAYOUT"] != "SE"', 'elif config["demultiplexing"]["primers"]["remove"].lower() == "metadata"', 'rule remove_primers_dmx_files', 'benchmark']
    (664, '                benchmark:')
    (665, '                    "{PROJECT}/runs/{run}/{sample}_data/demultiplexed/remove_primers_fq.benchmark"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'if (config["demultiplexing"]["create_fastq_files"] == "T" or config["ANALYSIS_TYPE"] == "ASV") and config["LIBRARY_LAYOUT"] != "SE"', 'elif config["demultiplexing"]["primers"]["remove"].lower() == "metadata"', 'rule remove_primers_dmx_files', 'output']
    (666, '                output:')
    (667, '                    "{PROJECT}/runs/{run}/{sample}_data/demultiplexed/summary.txt",')
    (668, '                    #"{PROJECT}/runs/{run}/{sample}_data/demultiplexed/no_primer/cutadapt.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'if (config["demultiplexing"]["create_fastq_files"] == "T" or config["ANALYSIS_TYPE"] == "ASV") and config["LIBRARY_LAYOUT"] != "SE"', 'elif config["demultiplexing"]["primers"]["remove"].lower() == "metadata"', 'rule remove_primers_dmx_files', 'script']
    (669, '                script:')
    (670, '                    "Scripts/removePrimersDemultiplex.py"')
    (671, '           # rule summary_remove_primers_dmx_files:')
    (672, '           #     input:')
    (673, '           #         "{PROJECT}/runs/{run}/{sample}_data/demultiplexed/no_primer/cutadapt.log"')
    (674, '           #     output:')
    (675, '           #         "{PROJECT}/runs/{run}/{sample}_data/demultiplexed/summary.txt"')
    (676, '           #     shell:')
    (677, '           #         "grep \\\\"(passing filters)\\\\" {input} | awk \\\'{{print $5\\\\"\\\\\\\\t\\\\"$6}}\\\' > {output}"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'if (config["demultiplexing"]["create_fastq_files"] == "T" or config["ANALYSIS_TYPE"] == "ASV") and config["LIBRARY_LAYOUT"] != "SE"', 'else', 'rule summary_write_dmx_files', 'input']
    (678, '        else:')
    (679, '            rule summary_write_dmx_files:')
    (680, '                input:')
    (681, '                    fw="{PROJECT}/runs/{run}/{sample}_data/demultiplexed/summary_fw.txt",')
    (682, '                    rv="{PROJECT}/runs/{run}/{sample}_data/demultiplexed/summary_rv.txt"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'if (config["demultiplexing"]["create_fastq_files"] == "T" or config["ANALYSIS_TYPE"] == "ASV") and config["LIBRARY_LAYOUT"] != "SE"', 'else', 'rule summary_write_dmx_files', 'output']
    (683, '                output:')
    (684, '                    "{PROJECT}/runs/{run}/{sample}_data/demultiplexed/summary.txt"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'if (config["demultiplexing"]["create_fastq_files"] == "T" or config["ANALYSIS_TYPE"] == "ASV") and config["LIBRARY_LAYOUT"] != "SE"', 'else', 'rule summary_write_dmx_files', 'shell']
    (685, '                shell:')
    (686, '                    "cat {input.fw} {input.rv} > {output}"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'elif (config["demultiplexing"]["create_fastq_files"] == "T" or config["ANALYSIS_TYPE"] == "ASV") and config["LIBRARY_LAYOUT"] == "SE"', 'rule write_dmx_files_fw_SE', 'input']
    (687, '    elif (config["demultiplexing"]["create_fastq_files"] == "T" or config["ANALYSIS_TYPE"] == "ASV") and config["LIBRARY_LAYOUT"] == "SE":')
    (688, '        rule write_dmx_files_fw_SE:')
    (689, '            input:')
    (690, '                dmx="{PROJECT}/runs/{run}/{sample}_data/splitLibs/seqs.assigned.fna",')
    (691, '                r1="{PROJECT}/samples/{sample}/rawdata/fw.fastq" if config["gzip_input"] == "F" else "{PROJECT}/samples/{sample}/rawdata/fw.fastq.gz",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'elif (config["demultiplexing"]["create_fastq_files"] == "T" or config["ANALYSIS_TYPE"] == "ASV") and config["LIBRARY_LAYOUT"] == "SE"', 'rule write_dmx_files_fw_SE', 'params']
    (692, '            params:')
    (693, '                outdir="{PROJECT}/runs/{run}/{sample}_data/demultiplexed/"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'elif (config["demultiplexing"]["create_fastq_files"] == "T" or config["ANALYSIS_TYPE"] == "ASV") and config["LIBRARY_LAYOUT"] == "SE"', 'rule write_dmx_files_fw_SE', 'output']
    (694, '            output:')
    (695, '                "{PROJECT}/runs/{run}/{sample}_data/demultiplexed/summary_fw.txt"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'elif (config["demultiplexing"]["create_fastq_files"] == "T" or config["ANALYSIS_TYPE"] == "ASV") and config["LIBRARY_LAYOUT"] == "SE"', 'rule write_dmx_files_fw_SE', 'benchmark']
    (696, '            benchmark:')
    (697, '                "{PROJECT}/runs/{run}/{sample}_data/demultiplexed/demultiplex_fq.benchmark"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'elif (config["demultiplexing"]["create_fastq_files"] == "T" or config["ANALYSIS_TYPE"] == "ASV") and config["LIBRARY_LAYOUT"] == "SE"', 'rule write_dmx_files_fw_SE', 'shell']
    (698, '            shell:')
    (699, '                "{config[java][command]}  -cp Scripts DemultiplexQiime --over-write --fasta -a fw -b {config[demultiplexing][remove_bc]}  -d {input.dmx} -o {params.outdir} "')
    (700, '                "-r {input.r1}  {config[demultiplexing][dmx_params]}"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'elif (config["demultiplexing"]["create_fastq_files"] == "T" or config["ANALYSIS_TYPE"] == "ASV") and config["LIBRARY_LAYOUT"] == "SE"', 'if config["demultiplexing"]["primers"]["remove"].lower() == "cfg"', 'rule remove_primers_dmx_files_SE', 'input']
    (701, '        if config["demultiplexing"]["primers"]["remove"].lower() == "cfg":')
    (702, '            rule remove_primers_dmx_files_SE:')
    (703, '                input:')
    (704, '                    fw="{PROJECT}/runs/{run}/{sample}_data/demultiplexed/summary_fw.txt",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'elif (config["demultiplexing"]["create_fastq_files"] == "T" or config["ANALYSIS_TYPE"] == "ASV") and config["LIBRARY_LAYOUT"] == "SE"', 'if config["demultiplexing"]["primers"]["remove"].lower() == "cfg"', 'rule remove_primers_dmx_files_SE', 'params']
    (705, '                params:')
    (706, '                    "{PROJECT}/runs/{run}/{sample}_data/demultiplexed",')
    (707, '                    config["demultiplexing"]["primers"]["extra_params"],')
    (708, '                    "fastq.gz",')
    (709, '                    "SE",')
    (710, '                    "{PROJECT}/runs/{run}/report_files/cutadapt.{sample}.fastq_summary.tsv"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'elif (config["demultiplexing"]["create_fastq_files"] == "T" or config["ANALYSIS_TYPE"] == "ASV") and config["LIBRARY_LAYOUT"] == "SE"', 'if config["demultiplexing"]["primers"]["remove"].lower() == "cfg"', 'rule remove_primers_dmx_files_SE', 'benchmark']
    (711, '                benchmark:')
    (712, '                    "{PROJECT}/runs/{run}/{sample}_data/demultiplexed/remove_primers_fq.benchmark"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'elif (config["demultiplexing"]["create_fastq_files"] == "T" or config["ANALYSIS_TYPE"] == "ASV") and config["LIBRARY_LAYOUT"] == "SE"', 'if config["demultiplexing"]["primers"]["remove"].lower() == "cfg"', 'rule remove_primers_dmx_files_SE', 'output']
    (713, '                output:')
    (714, '                    "{PROJECT}/runs/{run}/{sample}_data/demultiplexed/summary.txt"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'elif (config["demultiplexing"]["create_fastq_files"] == "T" or config["ANALYSIS_TYPE"] == "ASV") and config["LIBRARY_LAYOUT"] == "SE"', 'if config["demultiplexing"]["primers"]["remove"].lower() == "cfg"', 'rule remove_primers_dmx_files_SE', 'script']
    (715, '                script:')
    (716, '                    "Scripts/removePrimersDemultiplex_cfg.py"')
    (717, '                #shell:')
    (718, '                #    "Scripts/removePrimersDemultiplexSE.sh {params} fastq.gz {config[demultiplexing][primers][fw_primer]} {config[demultiplexing][primers][min_overlap]} {config[demultiplexing][primers][extra_params]}"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'elif (config["demultiplexing"]["create_fastq_files"] == "T" or config["ANALYSIS_TYPE"] == "ASV") and config["LIBRARY_LAYOUT"] == "SE"', 'elif config["demultiplexing"]["primers"]["remove"].lower() == "metadata"', 'rule remove_primers_dmx_files_SE', 'input']
    (719, '        elif config["demultiplexing"]["primers"]["remove"].lower() == "metadata":')
    (720, '            rule remove_primers_dmx_files_SE:')
    (721, '                input:')
    (722, '                    fw="{PROJECT}/runs/{run}/{sample}_data/demultiplexed/summary_fw.txt"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'elif (config["demultiplexing"]["create_fastq_files"] == "T" or config["ANALYSIS_TYPE"] == "ASV") and config["LIBRARY_LAYOUT"] == "SE"', 'elif config["demultiplexing"]["primers"]["remove"].lower() == "metadata"', 'rule remove_primers_dmx_files_SE', 'params']
    (723, '                params:')
    (724, '                    "{PROJECT}/runs/{run}/{sample}_data/demultiplexed",')
    (725, '                    config["demultiplexing"]["primers"]["extra_params"],')
    (726, '                    "fastq.gz",')
    (727, '                    "SE",')
    (728, '                    "{PROJECT}/runs/{run}/report_files/cutadapt.{sample}.fastq_summary.tsv"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'elif (config["demultiplexing"]["create_fastq_files"] == "T" or config["ANALYSIS_TYPE"] == "ASV") and config["LIBRARY_LAYOUT"] == "SE"', 'elif config["demultiplexing"]["primers"]["remove"].lower() == "metadata"', 'rule remove_primers_dmx_files_SE', 'benchmark']
    (729, '                benchmark:')
    (730, '                    "{PROJECT}/runs/{run}/{sample}_data/demultiplexed/remove_primers_fq.benchmark"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'elif (config["demultiplexing"]["create_fastq_files"] == "T" or config["ANALYSIS_TYPE"] == "ASV") and config["LIBRARY_LAYOUT"] == "SE"', 'elif config["demultiplexing"]["primers"]["remove"].lower() == "metadata"', 'rule remove_primers_dmx_files_SE', 'output']
    (731, '                output:')
    (732, '                    "{PROJECT}/runs/{run}/{sample}_data/demultiplexed/summary.txt",')
    (733, '                    #"{PROJECT}/runs/{run}/{sample}_data/demultiplexed/no_primer/cutadapt.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'elif (config["demultiplexing"]["create_fastq_files"] == "T" or config["ANALYSIS_TYPE"] == "ASV") and config["LIBRARY_LAYOUT"] == "SE"', 'elif config["demultiplexing"]["primers"]["remove"].lower() == "metadata"', 'rule remove_primers_dmx_files_SE', 'script']
    (734, '                script:')
    (735, '                    "Scripts/removePrimersDemultiplex.py"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'elif (config["demultiplexing"]["create_fastq_files"] == "T" or config["ANALYSIS_TYPE"] == "ASV") and config["LIBRARY_LAYOUT"] == "SE"', 'else', 'rule summary_write_dmx_files', 'input']
    (736, '        else:')
    (737, '            rule summary_write_dmx_files:')
    (738, '                input:')
    (739, '                    fw="{PROJECT}/runs/{run}/{sample}_data/demultiplexed/summary_fw.txt",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'elif (config["demultiplexing"]["create_fastq_files"] == "T" or config["ANALYSIS_TYPE"] == "ASV") and config["LIBRARY_LAYOUT"] == "SE"', 'else', 'rule summary_write_dmx_files', 'output']
    (740, '                output:')
    (741, '                    "{PROJECT}/runs/{run}/{sample}_data/demultiplexed/summary.txt"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'elif (config["demultiplexing"]["create_fastq_files"] == "T" or config["ANALYSIS_TYPE"] == "ASV") and config["LIBRARY_LAYOUT"] == "SE"', 'else', 'rule summary_write_dmx_files', 'shell']
    (742, '                shell:')
    (743, '                    "cat {input.fw} > {output}"')
    (744, '')
    (745, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'else', 'rule skip_dmx_file_creation', 'params']
    (746, '    else:')
    (747, '        rule skip_dmx_file_creation:')
    (748, '            params:')
    (749, '                "{PROJECT}/runs/{run}/{sample}_data/demultiplexed/"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'else', 'rule skip_dmx_file_creation', 'output']
    (750, '            output:')
    (751, '                "{PROJECT}/runs/{run}/{sample}_data/demultiplexed/summary.txt"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T"', 'else', 'rule skip_dmx_file_creation', 'shell']
    (752, '            shell:')
    (753, '                "touch {output}"')
    (754, '')
    (755, '#if demultiplex{}')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['else', 'if config["ANALYSIS_TYPE"] == "ASV" and config["LIBRARY_LAYOUT"] != "SE" and config["UNPAIRED_DATA_PIPELINE"] != "T"', 'rule skip_dmx_file_creation', 'input']
    (776, '    if config["ANALYSIS_TYPE"] == "ASV" and config["LIBRARY_LAYOUT"] != "SE" and config["UNPAIRED_DATA_PIPELINE"] != "T":')
    (777, '        rule skip_dmx_file_creation:')
    (778, '            input:')
    (779, '                r1="{PROJECT}/samples/{sample}/rawdata/fw.fastq" if config["gzip_input"] == "F" else "{PROJECT}/samples/{sample}/rawdata/fw.fastq.gz",')
    (780, '                r2="{PROJECT}/samples/{sample}/rawdata/rv.fastq" if config["gzip_input"] == "F" else "{PROJECT}/samples/{sample}/rawdata/rv.fastq.gz"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['else', 'if config["ANALYSIS_TYPE"] == "ASV" and config["LIBRARY_LAYOUT"] != "SE" and config["UNPAIRED_DATA_PIPELINE"] != "T"', 'rule skip_dmx_file_creation', 'params']
    (781, '            params:')
    (782, '                "{PROJECT}/runs/{run}/{sample}_data/demultiplexed/"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['else', 'if config["ANALYSIS_TYPE"] == "ASV" and config["LIBRARY_LAYOUT"] != "SE" and config["UNPAIRED_DATA_PIPELINE"] != "T"', 'rule skip_dmx_file_creation', 'output']
    (783, '            output:')
    (784, '                "{PROJECT}/runs/{run}/{sample}_data/demultiplexed/summary.txt_tmp" ')
    (785, '                if config["demultiplexing"]["primers"]["remove"].lower() != "f" else')
    (786, '                "{PROJECT}/runs/{run}/{sample}_data/demultiplexed/summary.txt"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['else', 'if config["ANALYSIS_TYPE"] == "ASV" and config["LIBRARY_LAYOUT"] != "SE" and config["UNPAIRED_DATA_PIPELINE"] != "T"', 'rule skip_dmx_file_creation', 'shell']
    (787, '            shell:')
    (788, '                "touch {output} &&  ln -s $PWD/{input.r1} {params}{wildcards.sample}_1.fastq "')
    (789, '                " && ln -s $PWD/{input.r2} {params}{wildcards.sample}_2.fastq "')
    (790, '                if config["gzip_input"] == "F" else')
    (791, '                "touch {output} &&  ln -s $PWD/{input.r1} {params}{wildcards.sample}_1.fastq.gz "')
    (792, '                " && ln -s $PWD/{input.r2} {params}{wildcards.sample}_2.fastq.gz "')
    (793, '')
    (794, '      #  if config["demultiplexing"]["primers"]["remove"].lower() == "cfg":')
    (795, '      #      rule remove_primers_dmx_files:')
    (796, '      #          input:')
    (797, '      #              fw="{PROJECT}/runs/{run}/{sample}_data/demultiplexed/summary.txt_tmp"')
    (798, '      #          params:')
    (799, '                    #dir="{PROJECT}/runs/{run}/{sample}_data/demultiplexed",')
    (800, '                    #ext="fastq"  if config["gzip_input"] == "F" else "fastq.gz"')
    (801, '     #               "{PROJECT}/runs/{run}/{sample}_data/demultiplexed",')
    (802, '     #               config["demultiplexing"]["primers"]["extra_params"],')
    (803, '     #               "fastq"  if config["gzip_input"] == "F" else "fastq.gz",')
    (804, '     #               "PE",')
    (805, '     #               "{PROJECT}/runs/{run}/report_files/cutadapt.{sample}.fastq_summary.tsv"')
    (806, '     #           benchmark:')
    (807, '     #               "{PROJECT}/runs/{run}/{sample}_data/demultiplexed/remove_primers_fq.benchmark"')
    (808, '')
    (809, '    #            output:')
    (810, '    #                "{PROJECT}/runs/{run}/{sample}_data/demultiplexed/summary.txt"')
    (811, '    #            script:')
    (812, '   #                 "Scripts/removePrimersDemultiplex_cfg.py" #{params.dir} {params.ext} {config[demultiplexing][primers][fw_primer]} {config[demultiplexing][primers][rv_primer]} {config[demultiplexing][primers][min_overlap]} {config[demultiplexing][primers][extra_params]}"')
    (813, '   #     elif config["demultiplexing"]["primers"]["remove"].lower() == "metadata":')
    (814, '   #         rule remove_primers_dmx_files:')
    (815, '  #              input:')
    (816, '  #                  config="{PROJECT}/metadata/sampleList_mergedBarcodes_{sample}.txt" if config["demultiplexing"]["demultiplex"] == "T"')
    (817, ' #                   else config["metadata"],')
    (818, '#                    r1="{PROJECT}/samples/{sample}/rawdata/fw.fastq" if config["gzip_input"] == "F" else "{PROJECT}/samples/{sample}/rawdata/fw.fastq.gz",')
    (819, '  #                  fw="{PROJECT}/runs/{run}/{sample}_data/demultiplexed/summary.txt_tmp" #make sure it run the symlink creation')
    (820, ' #               params:')
    (821, ' #                   "{PROJECT}/runs/{run}/{sample}_data/demultiplexed",')
    (822, ' #                   config["demultiplexing"]["primers"]["extra_params"],')
    (823, ' #                   "fastq"  if config["gzip_input"] == "F" else "fastq.gz",')
    (824, '  #                  "PE",')
    (825, ' #                   "{PROJECT}/runs/{run}/report_files/cutadapt.{sample}.fastq_summary.tsv"')
    (826, ' #               benchmark:')
    (827, ' #                   "{PROJECT}/runs/{run}/{sample}_data/demultiplexed/remove_primers_fq.benchmark"')
    (828, '')
    (829, ' #               output:')
    (830, ' #                   "{PROJECT}/runs/{run}/{sample}_data/demultiplexed/summary.txt",')
    (831, ' #                   #"{PROJECT}/runs/{run}/{sample}_data/demultiplexed/no_primer/cutadapt.log"')
    (832, ' #               script:')
    (833, ' #                   "Scripts/removePrimersDemultiplex.py"')
    (834, '')
    (835, ' ')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['else', 'elif config["ANALYSIS_TYPE"] == "ASV" and config["LIBRARY_LAYOUT"] == "SE"', 'rule skip_dmx_file_creation', 'input']
    (836, '    elif config["ANALYSIS_TYPE"] == "ASV" and config["LIBRARY_LAYOUT"] == "SE":')
    (837, '        rule skip_dmx_file_creation:')
    (838, '            input:')
    (839, '                r1="{PROJECT}/samples/{sample}/rawdata/fw.fastq" if config["gzip_input"] == "F" else "{PROJECT}/samples/{sample}/rawdata/fw.fastq.gz"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['else', 'elif config["ANALYSIS_TYPE"] == "ASV" and config["LIBRARY_LAYOUT"] == "SE"', 'rule skip_dmx_file_creation', 'params']
    (840, '            params:')
    (841, '                "{PROJECT}/runs/{run}/{sample}_data/demultiplexed/"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['else', 'elif config["ANALYSIS_TYPE"] == "ASV" and config["LIBRARY_LAYOUT"] == "SE"', 'rule skip_dmx_file_creation', 'output']
    (842, '            output:')
    (843, '                "{PROJECT}/runs/{run}/{sample}_data/demultiplexed/summary.txt_tmp"')
    (844, '                if config["demultiplexing"]["primers"]["remove"] != "F" else')
    (845, '                "{PROJECT}/runs/{run}/{sample}_data/demultiplexed/summary.txt"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['else', 'elif config["ANALYSIS_TYPE"] == "ASV" and config["LIBRARY_LAYOUT"] == "SE"', 'rule skip_dmx_file_creation', 'shell']
    (846, '            shell:')
    (847, '                "touch {output} &&  ln -s $PWD/{input.r1} {params}{wildcards.sample}_1.fastq "')
    (848, '                if config["gzip_input"] == "F" else')
    (849, '                "touch {output} &&  ln -s $PWD/{input.r1} {params}{wildcards.sample}_1.fastq.gz"')
    (850, '')
    (851, '      #  if config["demultiplexing"]["primers"]["remove"].lower() == "cfg":')
    (852, '      #      rule remove_primers_dmx_files:')
    (853, '      #          input:')
    (854, '      #              fw="{PROJECT}/runs/{run}/{sample}_data/demultiplexed/summary.txt_tmp"')
    (855, '      #          params:')
    (856, '                    #dir="{PROJECT}/runs/{run}/{sample}_data/demultiplexed",')
    (857, '                    #ext="fastq"  if config["gzip_input"] == "F" else "fastq.gz"')
    (858, '      #              "{PROJECT}/runs/{run}/{sample}_data/demultiplexed",')
    (859, '      #              config["demultiplexing"]["primers"]["extra_params"],')
    (860, '      #              "fastq"  if config["gzip_input"] == "F" else "fastq.gz",')
    (861, '      #              "SE",')
    (862, '      #              "{PROJECT}/runs/{run}/report_files/cutadapt.{sample}.fastq_summary.tsv"')
    (863, '      #          benchmark:')
    (864, '      #              "{PROJECT}/runs/{run}/{sample}_data/demultiplexed/remove_primers_fq.benchmark"')
    (865, '      #          output:')
    (866, '      #              "{PROJECT}/runs/{run}/{sample}_data/demultiplexed/summary.txt"')
    (867, '      #          script:                    ')
    (868, '      #              "Scripts/removePrimersDemultiplex_cfg.py" ')
    (869, '      #  elif config["demultiplexing"]["primers"]["remove"].lower() == "metadata":')
    (870, '      #      rule remove_primers_dmx_files:')
    (871, '      #          input:')
    (872, '      #              config="{PROJECT}/metadata/sampleList_mergedBarcodes_{sample}.txt" if config["demultiplexing"]["demultiplex"] == "T"')
    (873, '      #              else config["metadata"],')
    (874, '      #              fw="{PROJECT}/runs/{run}/{sample}_data/demultiplexed/summary.txt_tmp"')
    (875, '      #          params:')
    (876, '      #              "{PROJECT}/runs/{run}/{sample}_data/demultiplexed",')
    (877, '      #              config["demultiplexing"]["primers"]["extra_params"],')
    (878, '      #              "fastq"  if config["gzip_input"] == "F" else "fastq.gz",')
    (879, '      #              "SE",')
    (880, '      #              "{PROJECT}/runs/{run}/report_files/cutadapt.{sample}.fastq_summary.tsv"')
    (881, '      #          benchmark:')
    (882, '      #              "{PROJECT}/runs/{run}/{sample}_data/demultiplexed/remove_primers_fq.benchmark"')
    (883, '')
    (884, '      #          output:')
    (885, '        #            "{PROJECT}/runs/{run}/{sample}_data/demultiplexed/summary.txt"')
    (886, '       #         script:')
    (887, '      #              "Scripts/removePrimersDemultiplex.py"  ')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['else', 'elif config["ANALYSIS_TYPE"] == "ASV" and config["LIBRARY_LAYOUT"] != "SE" and config["UNPAIRED_DATA_PIPELINE"] == "T"', 'rule skip_dmx_file_creation', 'input']
    (888, '    elif config["ANALYSIS_TYPE"] == "ASV" and config["LIBRARY_LAYOUT"] != "SE" and config["UNPAIRED_DATA_PIPELINE"] == "T":')
    (889, '         rule skip_dmx_file_creation:')
    (890, '            input:')
    (891, '                r1="{PROJECT}/runs/{run}/{sample}_data/peared/seqs.unassembled.forward.fastq",')
    (892, '                r2="{PROJECT}/runs/{run}/{sample}_data/peared/seqs.unassembled.reverse.fastq" ')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['else', 'elif config["ANALYSIS_TYPE"] == "ASV" and config["LIBRARY_LAYOUT"] != "SE" and config["UNPAIRED_DATA_PIPELINE"] == "T"', 'rule skip_dmx_file_creation', 'params']
    (893, '            params:')
    (894, '                "{PROJECT}/runs/{run}/{sample}_data/demultiplexed/"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['else', 'elif config["ANALYSIS_TYPE"] == "ASV" and config["LIBRARY_LAYOUT"] != "SE" and config["UNPAIRED_DATA_PIPELINE"] == "T"', 'rule skip_dmx_file_creation', 'output']
    (895, '            output:')
    (896, '                "{PROJECT}/runs/{run}/{sample}_data/demultiplexed/summary.txt_tmp"')
    (897, '                if config["demultiplexing"]["primers"]["remove"].lower() != "f" else')
    (898, '                "{PROJECT}/runs/{run}/{sample}_data/demultiplexed/summary.txt"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['else', 'elif config["ANALYSIS_TYPE"] == "ASV" and config["LIBRARY_LAYOUT"] != "SE" and config["UNPAIRED_DATA_PIPELINE"] == "T"', 'rule skip_dmx_file_creation', 'shell']
    (899, '            shell:')
    (900, '                "touch {output} &&  ln -s $PWD/{input.r1} {params}{wildcards.sample}_1.fastq "')
    (901, '                " && ln -s $PWD/{input.r2} {params}{wildcards.sample}_2.fastq "')
    (902, '')
    (903, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['else', 'if config["demultiplexing"]["primers"]["remove"].lower() == "cfg"', 'rule remove_primers_fq_files', 'input']
    (915, '    if config["demultiplexing"]["primers"]["remove"].lower() == "cfg":')
    (916, '        rule remove_primers_fq_files:')
    (917, '            input:')
    (918, '                fw="{PROJECT}/runs/{run}/{sample}_data/demultiplexed/summary.txt_tmp"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['else', 'if config["demultiplexing"]["primers"]["remove"].lower() == "cfg"', 'rule remove_primers_fq_files', 'params']
    (919, '            params:')
    (920, '                #dir="{PROJECT}/runs/{run}/{sample}_data/demultiplexed",')
    (921, '                #ext="fastq"  if config["gzip_input"] == "F" else "fastq.gz"')
    (922, '                "{PROJECT}/runs/{run}/{sample}_data/demultiplexed",')
    (923, '                config["demultiplexing"]["primers"]["extra_params"],')
    (924, '                "fastq"  if config["gzip_input"] == "F" or (config["ANALYSIS_TYPE"] == "ASV" and config["UNPAIRED_DATA_PIPELINE"] == "T") else "fastq.gz",')
    (925, '                config["LIBRARY_LAYOUT"],')
    (926, '                "{PROJECT}/runs/{run}/report_files/cutadapt.{sample}.fastq_summary.tsv"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['else', 'if config["demultiplexing"]["primers"]["remove"].lower() == "cfg"', 'rule remove_primers_fq_files', 'benchmark']
    (927, '            benchmark:')
    (928, '                "{PROJECT}/runs/{run}/{sample}_data/demultiplexed/remove_primers_fq.benchmark"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['else', 'if config["demultiplexing"]["primers"]["remove"].lower() == "cfg"', 'rule remove_primers_fq_files', 'output']
    (929, '            output:')
    (930, '                "{PROJECT}/runs/{run}/{sample}_data/demultiplexed/summary.txt"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['else', 'if config["demultiplexing"]["primers"]["remove"].lower() == "cfg"', 'rule remove_primers_fq_files', 'script']
    (931, '            script:')
    (932, '                "Scripts/removePrimersDemultiplex_cfg.py"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['else', 'elif config["demultiplexing"]["primers"]["remove"].lower() == "metadata"', 'rule remove_primers_fq_files', 'input']
    (933, '    elif config["demultiplexing"]["primers"]["remove"].lower() == "metadata":')
    (934, '        rule remove_primers_fq_files:')
    (935, '            input:')
    (936, '                config="{PROJECT}/metadata/sampleList_mergedBarcodes_{sample}.txt" if config["demultiplexing"]["demultiplex"] == "T"')
    (937, '                else config["metadata"],')
    (938, '                fw="{PROJECT}/runs/{run}/{sample}_data/demultiplexed/summary.txt_tmp"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['else', 'elif config["demultiplexing"]["primers"]["remove"].lower() == "metadata"', 'rule remove_primers_fq_files', 'params']
    (939, '            params:')
    (940, '                "{PROJECT}/runs/{run}/{sample}_data/demultiplexed",')
    (941, '                config["demultiplexing"]["primers"]["extra_params"],')
    (942, '                "fastq"  if config["gzip_input"] == "F"  or (config["ANALYSIS_TYPE"] == "ASV" and config["UNPAIRED_DATA_PIPELINE"] == "T")  else "fastq.gz",')
    (943, '                config["LIBRARY_LAYOUT"],')
    (944, '                "{PROJECT}/runs/{run}/report_files/cutadapt.{sample}.fastq_summary.tsv"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['else', 'elif config["demultiplexing"]["primers"]["remove"].lower() == "metadata"', 'rule remove_primers_fq_files', 'benchmark']
    (945, '            benchmark:')
    (946, '                "{PROJECT}/runs/{run}/{sample}_data/demultiplexed/remove_primers_fq.benchmark"')
    (947, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['else', 'elif config["demultiplexing"]["primers"]["remove"].lower() == "metadata"', 'rule remove_primers_fq_files', 'output']
    (948, '            output:')
    (949, '                "{PROJECT}/runs/{run}/{sample}_data/demultiplexed/summary.txt"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['else', 'elif config["demultiplexing"]["primers"]["remove"].lower() == "metadata"', 'rule remove_primers_fq_files', 'script']
    (950, '            script:')
    (951, '                "Scripts/removePrimersDemultiplex.py"')
    (952, '   ')
    (953, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["ANALYSIS_TYPE"] == "ASV"', 'rule dada2Filter', 'input']
    (954, 'if config["ANALYSIS_TYPE"] == "ASV":')
    (955, '    #if config["dada2_filter"]["generateQAplots"] == "T":')
    (956, '    #    rule dada2_QA_Plots:')
    (957, '    #           input:')
    (958, '    #               expand("{PROJECT}/runs/{run}/{sample}_data/demultiplexed/summary.txt", PROJECT=config["PROJECT"],sample=config["LIBRARY"], run=run)')
    (959, '    #           output:')
    (960, '    #               "{PROJECT}/runs/{run}/asv/fw_QA_plots.pdf"')
    (961, '    #           benchmark:')
    (962, '    #               "{PROJECT}/runs/{run}/asv/qa_plots.benchmark"')
    (963, '    #           params:')
    (964, '    #               "{PROJECT}/runs/{run}/asv/"')
    (965, '    #           shell:')
    (966, '    #               "{config[Rscript][command]} Scripts/asvFilter.R $PWD {params} {input}"')
    (967, '    #else: ')
    (968, '    #    rule skip_QA_Plots:')
    (969, '    #           output:')
    (970, '    #               "{PROJECT}/runs/{run}/asv/no_qa_plots.txt"')
    (971, '    #           shell:')
    (972, '    #               "touch {output}"')
    (973, '    #rule dada2TruncationValues:')
    (974, '    #    input:')
    (975, '    #        "{PROJECT}/runs/{run}/asv/fw_QA_plots.pdf" if config["dada2_filter"]["generateQAplots"] == "T" else "{PROJECT}/runs/{run}/asv/no_qa_plots.txt"')
    (976, ' ')
    (977, '    rule dada2Filter:')
    (978, '        input:')
    (979, '            expand("{PROJECT}/runs/{run}/{sample}_data/demultiplexed/summary.txt", PROJECT=config["PROJECT"],sample=config["LIBRARY"], run=run)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["ANALYSIS_TYPE"] == "ASV"', 'rule dada2Filter', 'output']
    (980, '        output:')
    (981, '            "{PROJECT}/runs/{run}/asv/filter_summary.out"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["ANALYSIS_TYPE"] == "ASV"', 'rule dada2Filter', 'benchmark']
    (982, '        benchmark:')
    (983, '            "{PROJECT}/runs/{run}/asv/filter.benchmark"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["ANALYSIS_TYPE"] == "ASV"', 'rule dada2Filter', 'shell']
    (984, '        shell:')
    (985, '            "{config[Rscript][command]} Scripts/asvFilter.R $PWD " + str(config["dada2_filter"]["generateQAplots"]) + " " + str(config["dada2_filter"]["truncFW"]) + " " + str(config["dada2_filter"]["truncRV"]) + " "+str(config["dada2_filter"]["maxEE_FW"]) + " "+str(config["dada2_filter"]["maxEE_RV"]) + " " +str(config["dada2_filter"]["cpus"]) + " \\\\"" +str(config["dada2_filter"]["extra_params"]) + "\\\\" " +str(config["interactive"])+ " {output} " +config["demultiplexing"]["primers"]["remove"] +" {input} " ')
    (986, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["ANALYSIS_TYPE"] == "ASV"', 'rule validate_dada2Filter', 'input']
    (987, '    rule validate_dada2Filter:')
    (988, '        input:')
    (989, '            "{PROJECT}/runs/{run}/asv/filter_summary.out"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["ANALYSIS_TYPE"] == "ASV"', 'rule validate_dada2Filter', 'output']
    (990, '        output:')
    (991, '            "{PROJECT}/runs/{run}/asv/filter_summary.validation.txt"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["ANALYSIS_TYPE"] == "ASV"', 'rule validate_dada2Filter', 'script']
    (992, '        script:')
    (993, '            "Scripts/validateFilterASV.py"')
    (994, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["ANALYSIS_TYPE"] == "ASV"', 'rule run_dada2', 'input']
    (995, '    rule run_dada2:')
    (996, '        input:')
    (997, '            expand("{PROJECT}/runs/{run}/{sample}_data/demultiplexed/summary.txt", PROJECT=config["PROJECT"],sample=config["LIBRARY"], run=run),')
    (998, '             "{PROJECT}/runs/{run}/asv/filter_summary.validation.txt"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["ANALYSIS_TYPE"] == "ASV"', 'rule run_dada2', 'output']
    (999, '        output:')
    (1000, '            "{PROJECT}/runs/{run}/asv/stats_dada2.txt",')
    (1001, '            "{PROJECT}/runs/{run}/asv/representative_seq_set.fasta",')
    (1002, '            "{PROJECT}/runs/{run}/asv/taxonomy_dada2/representative_seq_set_tax_assignments.txt",')
    (1003, '            temp("{PROJECT}/runs/{run}/asv/dada2_asv_table.txt") ')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["ANALYSIS_TYPE"] == "ASV"', 'rule run_dada2', 'params']
    (1004, '        params:')
    (1005, '            "{PROJECT}/runs/{run}/asv/" #"{config[Rscript][command]} Scripts/asvDada2.R')
    (1006, '            #"$PWD " +str(config["dada2_asv"]["pool"]) + " "+str(config["dada2_asv"]["cpus"]) + " "+str(config["dada2_asv"]["generateErrPlots"]) + " "+str(config["dada2_asv"]["extra_params"]) + " {PROJECT}/runs/{run}/asv/ "  + " "+str(config["rm_reads"]["shorts"])  + " "+str(config["rm_reads"]["longs"]) + " "+str(config["rm_reads"]["offset"])  + " "+str(config["dada2_asv"]["chimeras"])  + " "+str(config["dada2_taxonomy"]["db"]) + " "+str(config["dada2_taxonomy"]["add_sps"]["db_sps"])  + " "+str(config["dada2_taxonomy"]["add_sps"]) + " "+str(config["dada2_taxonomy"]["extra_params"]) ')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["ANALYSIS_TYPE"] == "ASV"', 'rule run_dada2', 'benchmark']
    (1007, '        benchmark:')
    (1008, '            "{PROJECT}/runs/{run}/asv/dada2.benchmark"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["ANALYSIS_TYPE"] == "ASV"', 'rule run_dada2', 'shell']
    (1009, '        shell:')
    (1010, '            #"Scripts/asvDada2_fix.R"')
    (1011, '            #"{config[Rscript][command]} Scripts/asvDada2.R $PWD " +str(config["dada2_asv"]["pool"]) + " "+str(config["dada2_asv"]["cpus"])  + " "+str(config["dada2_asv"]["generateErrPlots"]) + " "+str(config["dada2_asv"]["extra_params"]) + " {params} "  + " "+str(config["rm_reads"]["shorts"])  + " "+str(config["rm_reads"]["longs"]) + " "+str(config["rm_reads"]["offset"])  + " "+str(config["dada2_asv"]["chimeras"])  + " "+str(config["dada2_taxonomy"]["db"]) + " "+str(config["dada2_taxonomy"]["add_sps"]["db_sps"])  + " "+str(config["dada2_taxonomy"]["add_sps"]["add"]) + " \\\\""+str(config["dada2_taxonomy"]["extra_params"]) + "\\\\" "+str(config["dada2_merge"]["minOverlap"]) +" "+str(config["dada2_merge"]["maxMismatch"]) + " \\\\""+str(config["dada2_taxonomy"]["add_sps"]["extra_params"]) + "\\\\" " + "{input}" ')
    (1012, '            "{config[Rscript][command]} Scripts/asvDada2.R $PWD " +str(config["dada2_asv"]["pool"]) + " "')
    (1013, '            " "+ str(config["dada2_asv"]["cpus"])  + " "+str(config["dada2_asv"]["generateErrPlots"]) + " "')
    (1014, '            " "+ str(config["dada2_asv"]["extra_params"]) + " {params} "  + " "+str(config["rm_reads"]["shorts"])  + " "')
    (1015, '            " "+ str(config["rm_reads"]["longs"]) + " "+str(config["rm_reads"]["offset"])  + " "+str(config["dada2_asv"]["chimeras"])  + " "')
    (1016, '            " "+str(config["dada2_taxonomy"]["db"]) + " "+str(config["dada2_taxonomy"]["add_sps"]["db_sps"])  + " "')
    (1017, '            " "+str(config["dada2_taxonomy"]["add_sps"]["add"]) + " \\\\""+str(config["dada2_taxonomy"]["extra_params"]) + "\\\\" "')
    (1018, '            " "+str(config["dada2_merge"]["minOverlap"]) +" "+str(config["dada2_merge"]["maxMismatch"])+" "')
    (1019, '            " "+str(config["UNPAIRED_DATA_PIPELINE"]) +" " + " \\\\""+str(config["dada2_taxonomy"]["add_sps"]["extra_params"]) + "\\\\" " + "{input}"')
    (1020, '')
    (1021, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["ANALYSIS_TYPE"] == "ASV"', 'rule asv_table', 'input']
    (1022, '    rule asv_table:')
    (1023, '        input:')
    (1024, '            "{PROJECT}/runs/{run}/asv/dada2_asv_table.txt" ')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["ANALYSIS_TYPE"] == "ASV"', 'rule asv_table', 'output']
    (1025, '        output:')
    (1026, '            "{PROJECT}/runs/{run}/asv/asv_table.txt"')
    (1027, '            # "{}" ')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["ANALYSIS_TYPE"] == "ASV"', 'rule asv_table', 'shell']
    (1028, '        shell:')
    (1029, '            "cat {input} | awk \\\'{{if(NR==1){{header=\\\\"#OTU_ID\\\\";for(i=1;i<=NF;i++){{header=header\\\\"\\\\\\\\t\\\\"$i}};print header}}else{{print $0}}}}\\\'|   awk \\\'{{ for (i=1; i<=NF; i++){{ a[NR,i] = $i }} }} NF>p {{ p = NF }} END {{ for(j=1; j<=p; j++) {{ str=a[1,j]; for(i=2; i<=NR; i++){{ str=str\\\\"\\\\\\\\t\\\\"a[i,j]; }} print str }} }}\\\' > {output}"')
    (1030, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["ANALYSIS_TYPE"] == "ASV"', 'rule asv_tax_table', 'input']
    (1031, '    rule asv_tax_table:')
    (1032, '        input:')
    (1033, '            "{PROJECT}/runs/{run}/asv/taxonomy_dada2/representative_seq_set_tax_assignments.txt",')
    (1034, '            "{PROJECT}/runs/{run}/asv/asv_table.txt" ')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["ANALYSIS_TYPE"] == "ASV"', 'rule asv_tax_table', 'output']
    (1035, '        output:')
    (1036, '            "{PROJECT}/runs/{run}/asv/taxonomy_dada2/asvTable.txt"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["ANALYSIS_TYPE"] == "ASV"', 'rule asv_tax_table', 'benchmark']
    (1037, '        benchmark:')
    (1038, '            "{PROJECT}/runs/{run}/asv/taxonomy_dada2/dada2.table.benchmark"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["ANALYSIS_TYPE"] == "ASV"', 'rule asv_tax_table', 'shell']
    (1039, '        shell:')
    (1040, '            "cat {input[0]} | awk  -F \\\\"\\\\\\\\t\\\\" \\\'NR==FNR{{if(NR>1){{tax=$2;for(i=3;i<=NF;i++){{tax=tax\\\\";\\\\"$i}};h[$1]=tax;}}next;}} {{if(FNR==1){{print $0\\\\"\\\\\\\\ttaxonomy\\\\"}}else{{print $0\\\\"\\\\\\\\t\\\\"h[$1]}}}}\\\' -  {input[1]} > {output}" ')
    (1041, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["ANALYSIS_TYPE"] == "ASV"', 'rule asv_to_biom', 'input']
    (1042, '    rule asv_to_biom:')
    (1043, '        input:')
    (1044, '            "{PROJECT}/runs/{run}/asv/taxonomy_dada2/asvTable.txt" ')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["ANALYSIS_TYPE"] == "ASV"', 'rule asv_to_biom', 'output']
    (1045, '        output:')
    (1046, '            "{PROJECT}/runs/{run}/asv/taxonomy_dada2/asvTable.biom"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["ANALYSIS_TYPE"] == "ASV"', 'rule asv_to_biom', 'benchmark']
    (1047, '        benchmark:')
    (1048, '            "{PROJECT}/runs/{run}/asv/taxonomy_dada2/dada2.biom.benchmark"')
    (1049, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["ANALYSIS_TYPE"] == "ASV"', 'rule asv_to_biom', 'shell']
    (1050, '        shell:')
    (1051, '            "{config[biom][command]} convert -i {input[0]} -o {output} --table-type \\\\"OTU table\\\\" --to-hdf5 --process-obs-metadata taxonomy "')
    (1052, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["align_vs_reference"]["align"] == "T"', 'rule align_vs_reference', 'input']
    (1053, 'if config["align_vs_reference"]["align"] == "T":')
    (1054, '    rule align_vs_reference:')
    (1055, '        input:')
    (1056, '            "{PROJECT}/runs/{run}/{sample}_data/seqs_fw_rev_accepted.fna"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["align_vs_reference"]["align"] == "T"', 'rule align_vs_reference', 'output']
    (1057, '        output:')
    (1058, '            "{PROJECT}/runs/{run}/{sample}_data/seqs_fw_rev_accepted.align"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["align_vs_reference"]["align"] == "T"', 'rule align_vs_reference', 'params']
    (1059, '        params:')
    (1060, '            "{PROJECT}/runs/{run}/{sample}_data/"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["align_vs_reference"]["align"] == "T"', 'rule align_vs_reference', 'shell']
    (1061, '        shell:')
    (1062, '           mapp= "cd {params} && "')
    (1063, '            "{config[align_vs_reference][mothur_cmd]} \\\'#align.seqs(fasta=seqs_fw_rev_accepted.fna, reference={config[align_vs_reference][dbAligned]}, processors={config[align_vs_reference][cpus]})\\\'"')
    (1064, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["cutAdapters"] != "F"', 'if config["demultiplexing"]["demultiplex"] != "T"', 'rule rev_com_seqs', 'input']
    (1065, 'if config["cutAdapters"] != "F":')
    (1066, '    """')
    (1067, '    If we are going to remove primers/adapters and they do not came from our own')
    (1068, '    demultiplexing, it is likely to have the sequences in both direction, FW and RV')
    (1069, '    thus, we need to rev com the sequences, concatenate them and then when we run cutadapt')
    (1070, '    always in this step, discard-untrimmed so this way we end up with the sequences in the correct orientation')
    (1071, '    """')
    (1072, '    if config["demultiplexing"]["demultiplex"] != "T" :')
    (1073, '        rule rev_com_seqs:')
    (1074, '            input:')
    (1075, '                "{PROJECT}/runs/{run}/{sample}_data/seqs_fw_rev_accepted.fna"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["cutAdapters"] != "F"', 'if config["demultiplexing"]["demultiplex"] != "T"', 'rule rev_com_seqs', 'output']
    (1076, '            output:')
    (1077, '                temp("{PROJECT}/runs/{run}/{sample}_data/seqs_revcomplement.fna")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["cutAdapters"] != "F"', 'if config["demultiplexing"]["demultiplex"] != "T"', 'rule rev_com_seqs', 'shell']
    (1078, '            shell:')
    (1079, '                "vsearch --fastx_revcomp {input} --fastaout {output}"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["cutAdapters"] != "F"', 'if config["demultiplexing"]["demultiplex"] != "T"', 'rule concat_seqs', 'input']
    (1080, '        rule concat_seqs:')
    (1081, '            input:')
    (1082, '                sq="{PROJECT}/runs/{run}/{sample}_data/seqs_fw_rev_accepted.fna",')
    (1083, '                rc="{PROJECT}/runs/{run}/{sample}_data/seqs_revcomplement.fna"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["cutAdapters"] != "F"', 'if config["demultiplexing"]["demultiplex"] != "T"', 'rule concat_seqs', 'output']
    (1084, '            output:')
    (1085, '                temp("{PROJECT}/runs/{run}/{sample}_data/seqs_revcomplement.concat.fna")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["cutAdapters"] != "F"', 'if config["demultiplexing"]["demultiplex"] != "T"', 'rule concat_seqs', 'shell']
    (1086, '            shell:')
    (1087, '                "cat {input.sq} {input.rc} > {output}"')
    (1088, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["cutAdapters"] != "F"', 'if config["demultiplexing"]["demultiplex"] != "T"', 'rule cutadapt', 'input']
    (1089, '        rule cutadapt:')
    (1090, '            input:')
    (1091, '                #"{PROJECT}/runs/{run}/{sample}_data/seqs_fw_rev_accepted.align" if config["align_vs_reference"]["align"] == "T"')
    (1092, '                #else ')
    (1093, '                "{PROJECT}/runs/{run}/{sample}_data/seqs_fw_rev_accepted.fna",')
    (1094, '                config["metadata"]')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["cutAdapters"] != "F"', 'if config["demultiplexing"]["demultiplex"] != "T"', 'rule cutadapt', 'output']
    (1095, '            output:')
    (1096, '                out="{PROJECT}/runs/{run}/{sample}_data/seqs_fw_rev_accepted_no_adapters.fna"')
    (1097, '                #log="{PROJECT}/runs/{run}/{sample}_data/seqs_fw_rev_accepted_no_adapters.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["cutAdapters"] != "F"', 'if config["demultiplexing"]["demultiplex"] != "T"', 'rule cutadapt', 'benchmark']
    (1098, '            benchmark:')
    (1099, '                "{PROJECT}/runs/{run}/{sample}_data/cutadapt.benchmark"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["cutAdapters"] != "F"', 'if config["demultiplexing"]["demultiplex"] != "T"', 'rule cutadapt', 'params']
    (1100, '            params:')
    (1101, '                config["cutadapt"]["extra_params"],')
    (1102, '                "{PROJECT}/runs/{run}/report_files/primers.{sample}.txt",')
    (1103, '                "{PROJECT}/runs/{run}/{sample}_data/seqs_fw_rev_accepted_removed.fna",')
    (1104, '                "{PROJECT}/runs/{run}/report_files/cutadapt.{sample}.summary.tsv",')
    (1105, '                "{sample}",')
    (1106, '                "{PROJECT}/runs/{run}/{sample}_data/seqs_fw_rev_accepted_no_adapters.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["cutAdapters"] != "F"', 'if config["demultiplexing"]["demultiplex"] != "T"', 'rule cutadapt', 'script']
    (1107, '            script:')
    (1108, '                "Scripts/remove_adapters_by_sample.py"')
    (1109, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["cutAdapters"] != "F"', 'else', 'if config["cutAdapters"].lower() == "metadata"', 'rule cutadapt', 'input']
    (1110, '    else:')
    (1111, '        if config["cutAdapters"].lower() == "metadata":')
    (1112, '            rule cutadapt:')
    (1113, '                input:')
    (1114, '                    "{PROJECT}/runs/{run}/{sample}_data/seqs_fw_rev_accepted.align" if config["align_vs_reference"]["align"] == "T"')
    (1115, '                    else "{PROJECT}/runs/{run}/{sample}_data/seqs_fw_rev_accepted.fna",')
    (1116, '                    "{PROJECT}/metadata/sampleList_mergedBarcodes_{sample}.txt" if config["demultiplexing"]["demultiplex"] == "T" ')
    (1117, '                    else config["metadata"]')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["cutAdapters"] != "F"', 'else', 'if config["cutAdapters"].lower() == "metadata"', 'rule cutadapt', 'output']
    (1118, '                output:')
    (1119, '                    out="{PROJECT}/runs/{run}/{sample}_data/seqs_fw_rev_accepted_no_adapters.fna",')
    (1120, '                   # log="{PROJECT}/runs/{run}/{sample}_data/seqs_fw_rev_accepted_no_adapters.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["cutAdapters"] != "F"', 'else', 'if config["cutAdapters"].lower() == "metadata"', 'rule cutadapt', 'benchmark']
    (1121, '                benchmark:')
    (1122, '                    "{PROJECT}/runs/{run}/{sample}_data/cutadapt.benchmark"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["cutAdapters"] != "F"', 'else', 'if config["cutAdapters"].lower() == "metadata"', 'rule cutadapt', 'params']
    (1123, '                params:')
    (1124, '                    config["cutadapt"]["extra_params"],')
    (1125, '                    "{PROJECT}/runs/{run}/report_files/primers.{sample}.txt",')
    (1126, '                    "{PROJECT}/runs/{run}/{sample}_data/seqs_fw_rev_accepted_removed.fna",')
    (1127, '                    "{PROJECT}/runs/{run}/report_files/cutadapt.{sample}.summary.tsv",')
    (1128, '                    "{PROJECT}/runs/{run}/{sample}_data/cutadapt_tmp/",')
    (1129, '                    "{PROJECT}/runs/{run}/{sample}_data/seqs_fw_rev_accepted_no_adapters.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["cutAdapters"] != "F"', 'else', 'if config["cutAdapters"].lower() == "metadata"', 'rule cutadapt', 'script']
    (1130, '                script:')
    (1131, '                     "Scripts/remove_adapters_v2.py" # && ln -s ../../report_files/cutadapt.{wildcards.sample}.summary.tsv {params[4]}   "')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["cutAdapters"] != "F"', 'else', 'elif config["cutAdapters"].lower() == "cfg"', 'rule cutadapt', 'input']
    (1132, '        elif config["cutAdapters"].lower() == "cfg":')
    (1133, '            rule cutadapt:')
    (1134, '                input:')
    (1135, '                    "{PROJECT}/runs/{run}/{sample}_data/seqs_fw_rev_accepted.align" if config["align_vs_reference"]["align"] == "T"')
    (1136, '                    else "{PROJECT}/runs/{run}/{sample}_data/seqs_fw_rev_accepted.fna"')
    (1137, '                    ')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["cutAdapters"] != "F"', 'else', 'elif config["cutAdapters"].lower() == "cfg"', 'rule cutadapt', 'output']
    (1138, '                output:')
    (1139, '                    out="{PROJECT}/runs/{run}/{sample}_data/seqs_fw_rev_accepted_no_adapters.fna"')
    (1140, '                    #log="{PROJECT}/runs/{run}/{sample}_data/seqs_fw_rev_accepted_no_adapters.log"')
    (1141, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["cutAdapters"] != "F"', 'else', 'elif config["cutAdapters"].lower() == "cfg"', 'rule cutadapt', 'benchmark']
    (1142, '                benchmark:')
    (1143, '                    "{PROJECT}/runs/{run}/{sample}_data/cutadapt.benchmark"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["cutAdapters"] != "F"', 'else', 'elif config["cutAdapters"].lower() == "cfg"', 'rule cutadapt', 'params']
    (1144, '                params:')
    (1145, '                    config["cutadapt"]["extra_params"],')
    (1146, '                    "{PROJECT}/runs/{run}/report_files/primers.{sample}.txt", ')
    (1147, '                    "{PROJECT}/runs/{run}/{sample}_data/seqs_fw_rev_accepted_removed.fna",')
    (1148, '                    "{PROJECT}/runs/{run}/report_files/cutadapt.{sample}.summary.tsv",')
    (1149, '                    "{PROJECT}/runs/{run}/{sample}_data/cutadapt_tmp/"')
    (1150, '                    "{PROJECT}/runs/{run}/{sample}_data/seqs_fw_rev_accepted_no_adapters.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["cutAdapters"] != "F"', 'else', 'elif config["cutAdapters"].lower() == "cfg"', 'rule cutadapt', 'script']
    (1151, '                script:')
    (1152, '                    "Scripts/remove_adapters_v2.py"# && ln -s ../../report_files/cutadapt.{wildcards.sample}.summary.tsv {params[4]}  "')
    (1153, '                    #"{config[cutadapt][command]}  {config[cutadapt][adapters]} "')
    (1154, '                    #"{config[cutadapt][extra_params]} -o {output.out} --untrimmed-output {output.no_trim} {input}  > {output.log}" if "--discard-untrimmed" in config["cutadapt"]["extra_params"] ')
    (1155, '                    #else "{config[cutadapt][command]}  {config[cutadapt][adapters]} "')
    (1156, '                    #"{config[cutadapt][extra_params]} -o {output.out} {input}  > {output.log}"  ')
    (1157, '          ')
    (1158, '')
    (1159, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["align_vs_reference"]["align"] == "T"', 'rule degap_alignment', 'input']
    (1160, 'if config["align_vs_reference"]["align"] == "T":')
    (1161, '    rule degap_alignment:')
    (1162, '        input:')
    (1163, '            "{PROJECT}/runs/{run}/{sample}_data/seqs_fw_rev_accepted.align" if config["cutAdapters"] == "F"')
    (1164, '            else "{PROJECT}/runs/{run}/{sample}_data/seqs_fw_rev_accepted_no_adapters.fna"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["align_vs_reference"]["align"] == "T"', 'rule degap_alignment', 'output']
    (1165, '        output:')
    (1166, '            "{PROJECT}/runs/{run}/{sample}_data/seqs_fw_rev_accepted.align.degapped.fna" if config["cutAdapters"] == "F"')
    (1167, '            else "{PROJECT}/runs/{run}/{sample}_data/seqs_fw_rev_accepted.align.no_adapter.degapped.fna"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["align_vs_reference"]["align"] == "T"', 'rule degap_alignment', 'shell']
    (1168, '        shell:')
    (1169, '            "degapseq {input} {output}"')
    (1170, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["align_vs_reference"]["align"] == "T"', 'rule single_line_fasta', 'input']
    (1171, '    rule single_line_fasta:')
    (1172, '        input:')
    (1173, '            "{PROJECT}/runs/{run}/{sample}_data/seqs_fw_rev_accepted.align.degapped.fna" if config["cutAdapters"] == "F"')
    (1174, '            else "{PROJECT}/runs/{run}/{sample}_data/seqs_fw_rev_accepted.align.no_adapter.degapped.fna"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["align_vs_reference"]["align"] == "T"', 'rule single_line_fasta', 'output']
    (1175, '        output:')
    (1176, '            "{PROJECT}/runs/{run}/{sample}_data/seqs_fw_rev_accepted.align.degapped.oneline.fna" if config["cutAdapters"] == "F"')
    (1177, '            else "{PROJECT}/runs/{run}/{sample}_data/seqs_fw_rev_accepted.align.no_adapter.degapped.oneline.fna"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["align_vs_reference"]["align"] == "T"', 'rule single_line_fasta', 'shell']
    (1178, '        shell:')
    (1179, '            "{config[java][command]} -cp Scripts FastaOneLine -f {input} -m 1 --write-discarded -o {output}"')
    (1180, '')
    (1181, '')
    (1182, '#Creates file with sequence length ditribution')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["chimera"]["search"] == "T"', 'if config["chimera"]["method"] == "usearch61"', 'rule search_chimera', 'input']
    (1228, 'if config["chimera"]["search"] == "T":')
    (1229, '#check for chimeric sequences')
    (1230, '    if config["chimera"]["method"] == "usearch61":')
    (1231, '        rule search_chimera:')
    (1232, '            input:')
    (1233, '                "{PROJECT}/runs/{run}/{sample}_data/seqs_fw_rev_filtered.fasta"')
    (1234, '            #if (config["align_vs_reference"]["align"] == "T" and config["cutAdapters"] == "T") "{PROJECT}/runs/{run}/{sample}_data/seqs_fw_rev_accepted.align.no_adapter.degapped.fna"')
    (1235, '            #elif (config["align_vs_reference"]["align"] == "T" and config["cutAdapters"] != "T") "{PROJECT}/runs/{run}/{sample}_data/seqs_fw_rev_accepted.align.degapped.fna"')
    (1236, '            #elif (config["align_vs_reference"]["align"] != "T" and config["cutAdapters"] == "T") "{PROJECT}/runs/{run}/{sample}_data/seqs_fw_rev_accepted_no_adapters.fna"')
    (1237, '            #else "{PROJECT}/runs/{run}/{sample}_data/seqs_fw_rev_accepted.fna"')
    (1238, '            #*selectInput()')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["chimera"]["search"] == "T"', 'if config["chimera"]["method"] == "usearch61"', 'rule search_chimera', 'output']
    (1239, '            output:')
    (1240, '                "{PROJECT}/runs/{run}/{sample}_data/chimera/chimeras.txt"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["chimera"]["search"] == "T"', 'if config["chimera"]["method"] == "usearch61"', 'rule search_chimera', 'params']
    (1241, '            params:')
    (1242, '                "{PROJECT}/runs/{run}/{sample}_data/chimera"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["chimera"]["search"] == "T"', 'if config["chimera"]["method"] == "usearch61"', 'rule search_chimera', 'benchmark']
    (1243, '            benchmark:')
    (1244, '                "{PROJECT}/runs/{run}/{sample}_data/chimera/chimera.benchmark"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["chimera"]["search"] == "T"', 'if config["chimera"]["method"] == "usearch61"', 'rule search_chimera', 'shell']
    (1245, '            shell:')
    (1246, '                "{config[qiime][path]}identify_chimeric_seqs.py -m {config[chimera][method]} -i {input}  -o {params} --threads {config[chimera][threads]} {config[chimera][extra_params]}"')
    (1247, '            #remove chimeras')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["chimera"]["search"] == "T"', 'else', 'rule search_chimera_vsearch', 'input']
    (1248, '    else:')
    (1249, '        rule search_chimera_vsearch:')
    (1250, '            input:')
    (1251, '                "{PROJECT}/runs/{run}/{sample}_data/seqs_fw_rev_filtered.fasta"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["chimera"]["search"] == "T"', 'else', 'rule search_chimera_vsearch', 'output']
    (1252, '            output:')
    (1253, '                "{PROJECT}/runs/{run}/{sample}_data/chimera/chimeras.summary.txt"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["chimera"]["search"] == "T"', 'else', 'rule search_chimera_vsearch', 'benchmark']
    (1254, '            benchmark:')
    (1255, '                "{PROJECT}/runs/{run}/{sample}_data/chimera/chimera.benchmark"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["chimera"]["search"] == "T"', 'else', 'rule search_chimera_vsearch', 'shell']
    (1256, '            shell:')
    (1257, '                "vsearch --{config[chimera][method]} {input} --threads {config[chimera][threads]} {config[chimera][extra_params]} --uchimeout {output}"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["chimera"]["search"] == "T"', 'else', 'rule filter_chimera_vsearch', 'input']
    (1258, '        rule filter_chimera_vsearch:')
    (1259, '            input:')
    (1260, '                "{PROJECT}/runs/{run}/{sample}_data/chimera/chimeras.summary.txt"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["chimera"]["search"] == "T"', 'else', 'rule filter_chimera_vsearch', 'output']
    (1261, '            output:')
    (1262, '                "{PROJECT}/runs/{run}/{sample}_data/chimera/chimeras.txt"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["chimera"]["search"] == "T"', 'else', 'rule filter_chimera_vsearch', 'shell']
    (1263, '            shell:')
    (1264, '                "cat {input} | awk \\\'$18==\\\\"Y\\\\"{{print $2\\\\"\\\\\\\\t\\\\"$1}}\\\' > {output}"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["chimera"]["search"] == "T"', 'rule remove_chimera', 'input']
    (1265, '    rule remove_chimera:')
    (1266, '        """')
    (1267, '        This script counts the sequence in input[0], the chimeras in input[2] if it is interactive it')
    (1268, '        directly removes the chimeras, otherwise ask the user, if the selection is NO, it will rename')
    (1269, '        input[0] as output[0]')
    (1270, '        """')
    (1271, '        input:')
    (1272, '            "{PROJECT}/runs/{run}/{sample}_data/seqs_fw_rev_filtered.fasta",')
    (1273, '            #"{PROJECT}/runs/{run}/{sample}_data/seqs_fw_rev_accepted.align.no_adapter.degapped.fna" if config["align_vs_reference"]["align"] == "T" and config["cutAdapters"] == "T"')
    (1274, '            #"{PROJECT}/runs/{run}/{sample}_data/seqs_fw_rev_accepted.align.degapped.fna" elif config["align_vs_reference"]["align"] == "T" and config["cutAdapters"] != "T"')
    (1275, '            #"{PROJECT}/runs/{run}/{sample}_data/seqs_fw_rev_accepted_no_adapters.fna" elif config["align_vs_reference"]["align"] != "T" and config["cutAdapters"] == "T"')
    (1276, '            #else "{PROJECT}/runs/{run}/{sample}_data/seqs_fw_rev_accepted.fna",')
    (1277, '            #*selectInput(),')
    (1278, '            "{PROJECT}/runs/{run}/{sample}_data/chimera/chimeras.txt"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["chimera"]["search"] == "T"', 'rule remove_chimera', 'output']
    (1279, '        output:')
    (1280, '            "{PROJECT}/runs/{run}/{sample}_data/seqs_fw_rev_filtered_nc.fasta",')
    (1281, '            "{PROJECT}/runs/{run}/{sample}_data/chimera/chimera.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["chimera"]["search"] == "T"', 'rule remove_chimera', 'script']
    (1282, '        script:')
    (1283, '            "Scripts/remove_chimera.py"')
    (1284, '')
    (1285, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T" and  config["ANALYSIS_TYPE"] != "ASV"', 'rule count_samples_final', 'input']
    (1286, 'if config["demultiplexing"]["demultiplex"] == "T" and  config["ANALYSIS_TYPE"] != "ASV":')
    (1287, '    rule count_samples_final:')
    (1288, '        input:')
    (1289, '            fasta="{PROJECT}/runs/{run}/{sample}_data/seqs_fw_rev_filtered_nc.fasta" if config["chimera"]["search"] == "T"')
    (1290, '            else "{PROJECT}/runs/{run}/{sample}_data/seqs_fw_rev_filtered.fasta",')
    (1291, '            metadata="{PROJECT}/metadata/sampleList_mergedBarcodes_{sample}.txt"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T" and  config["ANALYSIS_TYPE"] != "ASV"', 'rule count_samples_final', 'output']
    (1292, '        output:')
    (1293, '            "{PROJECT}/runs/{run}/{sample}_data/seqs_fw_rev_filtered.dist.txt"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["demultiplexing"]["demultiplex"] == "T" and  config["ANALYSIS_TYPE"] != "ASV"', 'rule count_samples_final', 'shell']
    (1294, '        shell:')
    (1295, '            "cat {input.fasta} | grep \\\'^>\\\' |  cut -d\\\'_\\\' -f1 | sed \\\'s/>//g\\\' "')
    (1296, '            "| sort | uniq -c | sort -nr | awk \\\'{{print $1\\\\"\\\\\\\\t\\\\"$2}}\\\' "')
    (1297, '            "| awk \\\'NR==FNR{{h[$2]=$1; next}} {{print $1\\\\"\\\\\\\\t\\\\"h[$1]}}\\\' - {input.metadata} | grep -v \\\\"#\\\\" > {output}"')
    (1298, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['elif config["ANALYSIS_TYPE"] == "ASV" and config["demultiplexing"]["demultiplex"] == "T"', 'rule count_samples_final', 'input']
    (1299, 'elif config["ANALYSIS_TYPE"] == "ASV" and config["demultiplexing"]["demultiplex"] == "T":')
    (1300, '')
    (1301, '    rule count_samples_final:')
    (1302, '        input:')
    (1303, '            "{PROJECT}/runs/{run}/asv/filter_summary.out",')
    (1304, '            "{PROJECT}/metadata/sampleList_mergedBarcodes_{sample}.txt"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['elif config["ANALYSIS_TYPE"] == "ASV" and config["demultiplexing"]["demultiplex"] == "T"', 'rule count_samples_final', 'output']
    (1305, '        output:')
    (1306, '            "{PROJECT}/runs/{run}/{sample}_data/seqs_fw_rev_filtered.dist.txt"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['elif config["ANALYSIS_TYPE"] == "ASV" and config["demultiplexing"]["demultiplex"] == "T"', 'rule count_samples_final', 'shell']
    (1307, '        shell:')
    (1308, '            "cat {input[0]} | awk \\\'NR==FNR{{if(NR>1){{h[$1]=$2;}}next}}{{if(FNR>1){{print $1\\\\"\\\\t\\\\"h[$1]}}}}\\\' - {input[1]} > {output}"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['elif config["ANALYSIS_TYPE"] == "ASV" and config["demultiplexing"]["demultiplex"] != "T"', 'rule count_samples_final', 'input']
    (1309, 'elif config["ANALYSIS_TYPE"] == "ASV" and config["demultiplexing"]["demultiplex"] != "T":')
    (1310, '')
    (1311, '    rule count_samples_final:')
    (1312, '        input:')
    (1313, '            "{PROJECT}/runs/{run}/asv/filter_summary.out",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['elif config["ANALYSIS_TYPE"] == "ASV" and config["demultiplexing"]["demultiplex"] != "T"', 'rule count_samples_final', 'output']
    (1314, '        output:')
    (1315, '            "{PROJECT}/runs/{run}/{sample}_data/seqs_fw_rev_filtered.dist.txt"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['elif config["ANALYSIS_TYPE"] == "ASV" and config["demultiplexing"]["demultiplex"] != "T"', 'rule count_samples_final', 'shell']
    (1316, '        shell:')
    (1317, '            "cat {input} | awk \\\'NR>1{{print $1\\\\"\\\\\\\\t\\\\"$2}}\\\' > {output}"')
    (1318, '')
    (1319, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["ANALYSIS_TYPE"]=="ASV"', 'rule create_sample_log', 'input']
    (1342, 'if config["ANALYSIS_TYPE"]=="ASV":')
    (1343, '    rule create_sample_log:')
    (1344, '        input:')
    (1345, '            ff=expand("{PROJECT}/runs/{run}/{sample}_data/seqs_fw_rev_filtered.dist.txt",PROJECT=config["PROJECT"],sample=config["LIBRARY"], run=run) ')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["ANALYSIS_TYPE"]=="ASV"', 'rule create_sample_log', 'output']
    (1346, '        output:')
    (1347, '            "{PROJECT}/runs/{run}/samples.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["ANALYSIS_TYPE"]=="ASV"', 'rule create_sample_log', 'script']
    (1348, '        script:')
    (1349, '            "Scripts/combineAllReads_asv.py"')
    (1350, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["derep"]["dereplicate"] == "T"  and config["pickOTU"]["m"] != "usearch" and config["pickOTU"]["m"] != "swarm"', 'rule remap_clusters', 'input']
    (1420, 'if config["derep"]["dereplicate"] == "T"  and config["pickOTU"]["m"] != "usearch" and config["pickOTU"]["m"] != "swarm":')
    (1421, '    rule remap_clusters:')
    (1422, '        input:')
    (1423, '            otu_txt="{PROJECT}/runs/{run}/otu/seqs_fw_rev_combined_derep_otus.txt",')
    (1424, '            uc_derep="{PROJECT}/runs/{run}/derep/seqs_fw_rev_combined_derep.uc"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["derep"]["dereplicate"] == "T"  and config["pickOTU"]["m"] != "usearch" and config["pickOTU"]["m"] != "swarm"', 'rule remap_clusters', 'output']
    (1425, '        output:')
    (1426, '            map="{PROJECT}/runs/{run}/otu/seqs_fw_rev_combined_remapped_otus.txt",')
    (1427, '            log="{PROJECT}/runs/{run}/otu/remap.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["derep"]["dereplicate"] == "T"  and config["pickOTU"]["m"] != "usearch" and config["pickOTU"]["m"] != "swarm"', 'rule remap_clusters', 'benchmark']
    (1428, '        benchmark:')
    (1429, '            "{PROJECT}/runs/{run}/derep/remap.benchmark"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["derep"]["dereplicate"] == "T"  and config["pickOTU"]["m"] != "usearch" and config["pickOTU"]["m"] != "swarm"', 'rule remap_clusters', 'shell']
    (1430, '        shell:')
    (1431, '            "{config[java][command]} -cp Scripts/ClusterMapper/build/classes clustermapper.ClusterMapper uc2otu "')
    (1432, '            "-uc {input.uc_derep} -otu {input.otu_txt} -o {output.map} > {output.log}"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['elif config["pickOTU"]["m"] == "swarm"', 'rule remap_clusters', 'input']
    (1433, 'elif config["pickOTU"]["m"] == "swarm":')
    (1434, '    rule remap_clusters:')
    (1435, '        input:')
    (1436, '            uc_swarm="{PROJECT}/runs/{run}/otu/swarms.uc",')
    (1437, '            uc_derep="{PROJECT}/runs/{run}/derep/seqs_fw_rev_combined_derep.uc"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['elif config["pickOTU"]["m"] == "swarm"', 'rule remap_clusters', 'output']
    (1438, '        output:')
    (1439, '            map="{PROJECT}/runs/{run}/otu/seqs_fw_rev_combined_remapped_otus.txt",')
    (1440, '            log="{PROJECT}/runs/{run}/otu/remap.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['elif config["pickOTU"]["m"] == "swarm"', 'rule remap_clusters', 'benchmark']
    (1441, '        benchmark:')
    (1442, '            "{PROJECT}/runs/{run}/derep/remap.benchmark"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['elif config["pickOTU"]["m"] == "swarm"', 'rule remap_clusters', 'shell']
    (1443, '        shell:')
    (1444, '            "{config[java][command]} -cp Scripts/ClusterMapper/build/classes clustermapper.ClusterMapper uc2uc "')
    (1445, '            "-uc {input.uc_derep} -uc2 {input.uc_swarm} -o {output.map} --full-uc --relabel -l OTU -lidx 1 > {output.log}"')
    (1446, '')
    (1447, '')
    (1448, '#pick representative OTUs')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["alignRep"]["align"] == "T"', 'rule align_rep_seqs', 'input']
    (1843, 'if config["alignRep"]["align"] == "T":')
    (1844, '#Align representative sequences')
    (1845, '    rule align_rep_seqs:')
    (1846, '        input:')
    (1847, '            "{PROJECT}/runs/{run}/asv/taxonomy_dada2/representative_seq_set_noSingletons.fasta" if config["ANALYSIS_TYPE"] == "ASV" ')
    (1848, '            else "{PROJECT}/runs/{run}/otu/taxonomy_"+config["assignTaxonomy"]["tool"]+"/representative_seq_set_noSingletons.fasta"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["alignRep"]["align"] == "T"', 'rule align_rep_seqs', 'output']
    (1849, '        output:')
    (1850, '            aligned="{PROJECT}/runs/{run}/asv/taxonomy_dada2/aligned/representative_seq_set_noSingletons_aligned.fasta" if config["ANALYSIS_TYPE"] == "ASV"')
    (1851, '            else "{PROJECT}/runs/{run}/otu/taxonomy_"+config["assignTaxonomy"]["tool"]+"/aligned/representative_seq_set_noSingletons_aligned.fasta",')
    (1852, '            log="{PROJECT}/runs/{run}/asv/taxonomy_dada2/aligned/representative_seq_set_noSingletons_log.txt" if config["ANALYSIS_TYPE"] == "ASV"')
    (1853, '            else "{PROJECT}/runs/{run}/otu/taxonomy_"+config["assignTaxonomy"]["tool"]+"/aligned/representative_seq_set_noSingletons_log.txt"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["alignRep"]["align"] == "T"', 'rule align_rep_seqs', 'params']
    (1854, '        params:')
    (1855, '            outdir="{PROJECT}/runs/{run}/asv/taxonomy_dada2/aligned/" if config["ANALYSIS_TYPE"] == "ASV" ')
    (1856, '            else "{PROJECT}/runs/{run}/otu/taxonomy_"+config["assignTaxonomy"]["tool"]+"/aligned/"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["alignRep"]["align"] == "T"', 'rule align_rep_seqs', 'benchmark']
    (1857, '        benchmark:')
    (1858, '            "{PROJECT}/runs/{run}/asv/taxonomy_dada2/aligned/align_rep_seqs.benchmark" if config["ANALYSIS_TYPE"] == "ASV"')
    (1859, '            else "{PROJECT}/runs/{run}/otu/taxonomy_"+config["assignTaxonomy"]["tool"]+"/aligned/align_rep_seqs.benchmark"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["alignRep"]["align"] == "T"', 'rule align_rep_seqs', 'shell']
    (1860, '        shell:')
    (1861, '            "{config[qiime][path]}align_seqs.py -m {config[alignRep][m]} -i {input} -o {params.outdir} {config[alignRep][extra_params]}"')
    (1862, '')
    (1863, '#This step should be applied to generate a useful tree when aligning against a template alignment (e.g., with PyNAST)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["alignRep"]["align"] == "T"', 'rule filter_alignment', 'input']
    (1864, '    rule filter_alignment:')
    (1865, '        input:')
    (1866, '            "{PROJECT}/runs/{run}/asv/taxonomy_dada2/aligned/representative_seq_set_noSingletons_aligned.fasta" if config["ANALYSIS_TYPE"] == "ASV"')
    (1867, '            else "{PROJECT}/runs/{run}/otu/taxonomy_"+config["assignTaxonomy"]["tool"]+"/aligned/representative_seq_set_noSingletons_aligned.fasta"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["alignRep"]["align"] == "T"', 'rule filter_alignment', 'output']
    (1868, '        output:')
    (1869, '            "{PROJECT}/runs/{run}/asv/taxonomy_dada2/aligned/filtered/representative_seq_set_noSingletons_aligned_pfiltered.fasta" if config["ANALYSIS_TYPE"] == "ASV"')
    (1870, '            else "{PROJECT}/runs/{run}/otu/taxonomy_"+config["assignTaxonomy"]["tool"]+"/aligned/filtered/representative_seq_set_noSingletons_aligned_pfiltered.fasta"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["alignRep"]["align"] == "T"', 'rule filter_alignment', 'params']
    (1871, '        params:')
    (1872, '            outdir="{PROJECT}/runs/{run}/asv/taxonomy_dada2/aligned/filtered/" if config["ANALYSIS_TYPE"] == "ASV"')
    (1873, '            else "{PROJECT}/runs/{run}/otu/taxonomy_"+config["assignTaxonomy"]["tool"]+"/aligned/filtered/"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["alignRep"]["align"] == "T"', 'rule filter_alignment', 'benchmark']
    (1874, '        benchmark:')
    (1875, '            "{PROJECT}/runs/{run}/asv/taxonomy_dada2/aligned/filtered/align_rep_seqs.benchmark"  if config["ANALYSIS_TYPE"] == "ASV"')
    (1876, '            else "{PROJECT}/runs/{run}/otu/taxonomy_"+config["assignTaxonomy"]["tool"]+"/aligned/filtered/align_rep_seqs.benchmark"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["alignRep"]["align"] == "T"', 'rule filter_alignment', 'shell']
    (1877, '        shell:')
    (1878, '            "{config[qiime][path]}filter_alignment.py -i {input} -o {params.outdir} {config[filterAlignment][extra_params]}"')
    (1879, '')
    (1880, '#Many downstream analyses require that the phylogenetic tree relating the OTUs in a study be present.')
    (1881, '#The script make_phylogeny.py produces this tree from a multiple sequence alignment')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["alignRep"]["align"] == "T"', 'rule make_tree', 'input']
    (1882, '    rule make_tree:')
    (1883, '        input:')
    (1884, '            "{PROJECT}/runs/{run}/asv/taxonomy_dada2/aligned/filtered/representative_seq_set_noSingletons_aligned_pfiltered.fasta" if config["ANALYSIS_TYPE"] == "ASV"')
    (1885, '            else "{PROJECT}/runs/{run}/otu/taxonomy_"+config["assignTaxonomy"]["tool"]+"/aligned/filtered/representative_seq_set_noSingletons_aligned_pfiltered.fasta"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["alignRep"]["align"] == "T"', 'rule make_tree', 'output']
    (1886, '        output:')
    (1887, '            "{PROJECT}/runs/{run}/asv/taxonomy_dada2/aligned/filtered/representative_seq_set_noSingletons_aligned_pfiltered.tre" if config["ANALYSIS_TYPE"] == "ASV"')
    (1888, '            else "{PROJECT}/runs/{run}/otu/taxonomy_"+config["assignTaxonomy"]["tool"]+"/aligned/filtered/representative_seq_set_noSingletons_aligned_pfiltered.tre"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["alignRep"]["align"] == "T"', 'rule make_tree', 'benchmark']
    (1889, '        benchmark:')
    (1890, '            "{PROJECT}/runs/{run}/asv/taxonomy_dada2/aligned/filtered/representative_seq_set_noSingletons_aligned_pfiltered.benchmark"  if config["ANALYSIS_TYPE"] == "ASV"')
    (1891, '            else "{PROJECT}/runs/{run}/otu/taxonomy_"+config["assignTaxonomy"]["tool"]+"/aligned/filtered/representative_seq_set_noSingletons_aligned_pfiltered.benchmark"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["alignRep"]["align"] == "T"', 'rule make_tree', 'shell']
    (1892, '        shell:')
    (1893, '            "{config[qiime][path]}make_phylogeny.py -i {input} -o {output} -t {config[makeTree][method]} {config[makeTree][extra_params]}"')
    (1894, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["ANALYSIS_TYPE"] != "ASV"', 'rule report_all', 'input']
    (1895, 'if config["ANALYSIS_TYPE"] != "ASV": ')
    (1896, '    rule report_all:')
    (1897, '       input:')
    (1898, '            a="{PROJECT}/runs/{run}/otu/taxonomy_"+config["assignTaxonomy"]["tool"]+"/otuTable.txt",')
    (1899, '#            if config["ANALYSIS_TYPE"] == "OTU" else')
    (1900, '#            "{PROJECT}/runs/{run}/asv/asv_table.biom",')
    (1901, '            b="{PROJECT}/runs/{run}/otu/taxonomy_"+config["assignTaxonomy"]["tool"]+"/summary/otuTable_L6.txt",')
    (1902, '#            if config["ANALYSIS_TYPE"] == "OTU" else')
    (1903, '#            "{PROJECT}/runs/{run}/asv/summary/asv_table_L6.txt",')
    (1904, '            c="{PROJECT}/runs/{run}/otu/taxonomy_"+config["assignTaxonomy"]["tool"]+"/otuTable_noSingletons.txt",')
    (1905, '            d="{PROJECT}/runs/{run}/otu/taxonomy_"+config["assignTaxonomy"]["tool"]+"/summary_noSingletons/otuTable_noSingletons_L6.txt",')
    (1906, '#            if config["ANALYSIS_TYPE"] == "OTU" else ')
    (1907, '#            "{PROJECT}/runs/{run}/asv/stats_dada2.txt",')
    (1908, '            e="{PROJECT}/runs/{run}/otu/taxonomy_"+config["assignTaxonomy"]["tool"]+"/aligned/filtered/representative_seq_set_noSingletons_aligned_pfiltered.tre"')
    (1909, '            if config["alignRep"]["align"] == "T"')
    (1910, '            else "{PROJECT}/runs/{run}/otu/taxonomy_"+config["assignTaxonomy"]["tool"]+"/representative_seq_set_noSingletons.fasta",')
    (1911, '            f="{PROJECT}/runs/{run}/report_files/krona_report."+config["assignTaxonomy"]["tool"]+".html"')
    (1912, '            if config["krona"]["report"] == "T" and config["ANALYSIS_TYPE"] != "ASV" else ')
    (1913, '            "{PROJECT}/runs/{run}/report_files/krona_report.dada2.html"')
    (1914, '            if config["krona"]["report"] == "T" and config["ANALYSIS_TYPE"] == "ASV" else')
    (1915, '            "{PROJECT}/runs/{run}/otu/taxonomy_"+config["assignTaxonomy"]["tool"]+"/skip.krona",')
    (1916, '            g="{PROJECT}/runs/{run}/samples.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["ANALYSIS_TYPE"] != "ASV"', 'rule report_all', 'output']
    (1917, '       output:')
    (1918, '            temp("{PROJECT}/runs/{run}/reporttmp_all.html")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["ANALYSIS_TYPE"] != "ASV"', 'rule report_all', 'benchmark']
    (1919, '       benchmark:')
    (1920, '            "{PROJECT}/runs/{run}/report_all.benchmark"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["ANALYSIS_TYPE"] != "ASV"', 'rule report_all', 'script']
    (1921, '       script:')
    (1922, '            "Scripts/report_all_v2.py"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["pdfReport"].casefold() == "t"', 'rule translate_to_pdf', 'input']
    (1959, 'if config["pdfReport"].casefold() == "t":')
    (1960, '    rule translate_to_pdf:')
    (1961, '        input:')
    (1962, '            "{PROJECT}/runs/{run}/otu_report_"+config["assignTaxonomy"]["tool"]+".html"')
    (1963, '             if config["ANALYSIS_TYPE"] == "OTU" else')
    (1964, '             "{PROJECT}/runs/{run}/asv_report_dada2.html"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["pdfReport"].casefold() == "t"', 'rule translate_to_pdf', 'output']
    (1965, '        output:')
    (1966, '            "{PROJECT}/runs/{run}/otu_report_"+config["assignTaxonomy"]["tool"]+".pdf"')
    (1967, '             if config["ANALYSIS_TYPE"] == "OTU" else')
    (1968, '             "{PROJECT}/runs/{run}/asv_report_dada2.pdf"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["pdfReport"].casefold() == "t"', 'rule translate_to_pdf', 'shell']
    (1969, '        shell:')
    (1970, '            "{config[wkhtmltopdf_command]}  {input} {output}"')
    (1971, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["pdfReport"].casefold() == "t"', 'rule translate_pdf_final_report', 'input']
    (1994, 'if config["pdfReport"].casefold() == "t":')
    (1995, '    rule translate_pdf_final_report:')
    (1996, '        input:')
    (1997, '            toTranslate="{PROJECT}/runs/{run}/report_{sample}_"+config["assignTaxonomy"]["tool"]+".html"')
    (1998, '            if config["ANALYSIS_TYPE"] == "OTU" else')
    (1999, '            "{PROJECT}/runs/{run}/report_{sample}_dada2.html",')
    (2000, '            tmp="{PROJECT}/runs/{run}/otu_report_"+config["assignTaxonomy"]["tool"]+".pdf"')
    (2001, '            if config["ANALYSIS_TYPE"] == "OTU" else')
    (2002, '            "{PROJECT}/runs/{run}/asv_report_dada2.pdf"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["pdfReport"].casefold() == "t"', 'rule translate_pdf_final_report', 'output']
    (2003, '        output:')
    (2004, '            "{PROJECT}/runs/{run}/report_{sample}_"+config["assignTaxonomy"]["tool"]+".pdf"')
    (2005, '            if config["ANALYSIS_TYPE"] == "OTU" else')
    (2006, '            "{PROJECT}/runs/{run}/report_{sample}_dada2.pdf"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['if config["pdfReport"].casefold() == "t"', 'rule translate_pdf_final_report', 'shell']
    (2007, '        shell:')
    (2008, '            "{config[wkhtmltopdf_command]} {input.toTranslate} {output}"')
    (2009, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Nevada-Bioinformatics-Center/snakemake_rnaseq_SE_workflow, file=rules/align.smk
context_key: ['if config["trimming"]["skip"]']
    (1, '    if config["trimming"]["skip"]:')
    (2, '        # no trimming, use raw reads')
    (3, '        return units.loc[(wildcards.sample, wildcards.unit), ["fq1", "fq2"]].dropna()')
    (4, '    else:')
    (5, '        # yes trimming, use trimmed data')
    (6, '        if not is_single_end(**wildcards):')
    (7, '            # paired-end sample')
    (8, '            #print(expand("trimmed/{sample}-{unit}.{group}.fastq.gz", group=[1, 2], **wildcards))')
    (9, '            return expand("trimmed/{sample}-{unit}.{group}.fastq.gz", group=[1, 2], **wildcards)')
    (10, '        # single end sample')
    (11, '        #print("trimmed/{sample}-{unit}.fastq.gz".format(**wildcards))')
    (12, '        return "trimmed/{sample}-{unit}.fastq.gz".format(**wildcards)')
    (13, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=solida-core/ride, file=Snakefile
context_key: ['if config.get("read_type")=="se"', 'include']
    (55, 'if config.get("read_type")=="se":')
    (56, '    include:')
    (57, '        include_prefix + "/trimming_se.smk"')
    (58, '    include:')
    (59, '        include_prefix + "/qc_se.smk"')
    (60, '    include:')
    (61, '        include_prefix + "/reads_feature_count.smk"')
    (62, '    include:')
    (63, '        include_prefix + "/kallisto.smk"')
    (64, '    include:')
    (65, '        include_prefix + "/star2.smk"')
    (66, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=imgag/ont_tools, file=workflow/rules/qc.smk
context_key: ["if config[\\'vc\\'][\\'create_benchmark\\']"]
    (338, "if config[\\'vc\\'][\\'create_benchmark\\']:")
    (339, '    qc_out[\\\'variant_calling\\\'] +=  expand("qc/happy/{s}.summary.csv", s=ID_samples)')
    (340, '')
    (341, '#if map_samples_barcode: ')
    (342, '#    qc_out += aggregate_sample_pycoqc')
    (343, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=imgag/ont_tools, file=workflow/Snakefile
context_key: ["if config[\\'skip_name_check\\']"]
    (68, "    if config[\\'skip_name_check\\']:")
    (69, '        ID_runs.add(run)')
    (70, '        map_runs_folder[run].append(folder)')
    (71, '    else:')
    (72, '        run_pattern = re.compile("^(?:Q\\\\w{9}_)?\\\\d{5}\\\\w*_\\\\d{5}$")')
    (73, '        if bool(run_pattern.match(run)):')
    (74, '            ID_runs.add(run)')
    (75, '            map_runs_folder[run].append(folder)')
    (76, '        else:')
    (77, '            print("Run name has incorrect name: ", run)')
    (78, '            print("Forgot adding run suffix?")')
    (79, '            exit(1)')
    (80, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=imgag/ont_tools, file=workflow/Snakefile
context_key: ["if config[\\'verbose\\']"]
    (81, "if config[\\'verbose\\']:")
    (82, '    print("Samples: ", ID_samples)')
    (83, '    print("Folders:", ID_folders)')
    (84, '    print("Runs:", ID_runs)')
    (85, '    print("Barcode Folders: ", ID_barcode_folders)')
    (86, '    print("Map Folder:", map_samples_folder)')
    (87, '    print("Map Barcode:", map_samples_barcode)')
    (88, '    print("Map Runs:", map_runs_folder)')
    (89, '')
    (90, '#_____ INCLUDE MODULES ________________________________________________________#')
    (91, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=imgag/ont_tools, file=workflow/Snakefile
context_key: ["if config[\\'vc\\'][\\'pepper\\']"]
    (140, "if config[\\'vc\\'][\\'pepper\\']:")
    (141, '    out[\\\'variant_calling\\\'] += expand("Sample_{s}/{s}.pepper_margin_dv.vcf.gz", s=ID_samples)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=imgag/ont_tools, file=workflow/Snakefile
context_key: ["if config[\\'vc\\'][\\'pepper\\'] and config[\\'vc\\'][\\'haplotagged_bam\\']"]
    (142, "if config[\\'vc\\'][\\'pepper\\'] and config[\\'vc\\'][\\'haplotagged_bam\\']:")
    (143, '    out[\\\'variant_calling\\\'] += expand("Sample_{s}/{s}.haplotagged.bam", s=ID_samples)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=imgag/ont_tools, file=workflow/Snakefile
context_key: ["if config[\\'vc\\'][\\'clair3\\']"]
    (144, "if config[\\'vc\\'][\\'clair3\\']:")
    (145, '    out[\\\'variant_calling\\\'] += expand("Sample_{s}/{s}.clair3.vcf.gz", s=ID_samples)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=imgag/ont_tools, file=workflow/Snakefile
context_key: ["if config[\\'vc\\'][\\'medaka\\']"]
    (146, "if config[\\'vc\\'][\\'medaka\\']:")
    (147, '    out[\\\'variant_calling\\\'] += expand("Sample_{s}/{s}.medaka.vcf.gz", s=ID_samples)')
    (148, '')
    (149, '# Add SV calling outputs:')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=imgag/ont_tools, file=workflow/Snakefile
context_key: ["if config[\\'sv\\'][\\'sniffles\\']"]
    (150, "if config[\\'sv\\'][\\'sniffles\\']:")
    (151, '    out[\\\'structural_variant_calling\\\'] += expand("Sample_{s}/{s}.sv_sniffles.vcf.gz", s=ID_samples),')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=imgag/ont_tools, file=workflow/Snakefile
context_key: ["if config[\\'sv\\'][\\'cutesv\\']"]
    (152, "if config[\\'sv\\'][\\'cutesv\\']:")
    (153, '    out[\\\'structural_variant_calling\\\'] +=expand("Sample_{s}/{s}.sv_cutesv.vcf.gz", s=ID_samples),')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=imgag/ont_tools, file=workflow/Snakefile
context_key: ["if config[\\'sv\\'][\\'dipdiff\\']"]
    (154, "if config[\\'sv\\'][\\'dipdiff\\']:")
    (155, '    out[\\\'structural_variant_calling\\\'] +=expand("Sample_{s}/{s}.sv_dipdiff.vcf.gz", s=ID_samples)')
    (156, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=tgstoecker/MuWU, file=workflow/Snakefile
context_key: ['if config["approach"] == "GRID" and config["TE_TYPING"] != "perform"', 'rule all', 'input']
    (41, 'if config["approach"] == "GRID" and config["TE_TYPING"] != "perform":')
    (42, '    rule all:')
    (43, '        input:')
    (44, '            # final annotation table reagrdless of rule path for annotation file')
    (45, '            "resources/final_annotation_table",')
    (46, '            Checkpoint_ReadSampleSheet_GRID("results/mapped/{sample}.sorted.bam.bai"),')
    (47, '            Checkpoint_ReadSampleSheet_GRID("results/dedup/{sample}.dedup.bam.bai"),')
    (48, '            Checkpoint_ReadSampleSheet_GRID("results/dedup_sam/{sample}.dedup.sam"),')
    (49, '            #multiqc')
    (50, '            "results/multiqc/multiqc.html",')
    (51, '            #insertion identification identification results')
    (52, '            "results/insertions_table_final/all_identified_insertions.csv",')
    (53, '            "results/insertions_table_final/germinal_identified_insertions.csv",')
    (54, '            #insertion annotation')
    (55, '            "results/insertions_table_final/all_identified_insertions_annotated.csv",')
    (56, '            "results/insertions_table_final/germinal_identified_insertions_annotated.csv",')
    (57, '')
    (58, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=tgstoecker/MuWU, file=workflow/Snakefile
context_key: ['elif config["approach"] == "GRID" and config["TE_TYPING"] == "perform"', 'rule all', 'input']
    (59, 'elif config["approach"] == "GRID" and config["TE_TYPING"] == "perform":')
    (60, '    rule all:')
    (61, '        input:')
    (62, '            # final annotation table reagrdless of rule path for annotation file')
    (63, '            "resources/final_annotation_table",')
    (64, '            Checkpoint_ReadSampleSheet_GRID("results/mapped/{sample}.sorted.bam.bai"),')
    (65, '            Checkpoint_ReadSampleSheet_GRID("results/dedup/{sample}.dedup.bam.bai"),')
    (66, '            Checkpoint_ReadSampleSheet_GRID("results/dedup_sam/{sample}.dedup.sam"),           ')
    (67, '            #multiqc')
    (68, '            "results/multiqc/multiqc.html",')
    (69, '            #insertion identification identification results')
    (70, '            "results/insertions_table_final/all_identified_insertions.csv",')
    (71, '            "results/insertions_table_final/germinal_identified_insertions.csv",')
    (72, '            #insertion annotation')
    (73, '            "results/insertions_table_final/all_identified_insertions_annotated.csv",')
    (74, '            "results/insertions_table_final/germinal_identified_insertions_annotated.csv",')
    (75, '            #te/element typing')
    (76, '            "results/insertions_table_final_te_typed/headers_strand_1_uncategorized_all_identified_insertions.csv",')
    (77, '            expand("results/te_typing/uncategorized_clustered/final_clstr_file_{insertion_table}.tsv", insertion_table=INSERTION_TABLES_GRID),')
    (78, '#            "results/insertions_table_final_te_typed/short_germinal_identified_insertions.csv",')
    (79, '')
    (80, '')
    (81, '#### ONLY FOR GENERIC ANALYSIS - NO STOCK MATRIX ####')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=tgstoecker/MuWU, file=workflow/Snakefile
context_key: ['elif config["approach"] == "GENERIC"', 'if not is_single_end_GENERIC_experiment(SAMPLES) and config["TE_TYPING"] != "perform"', 'rule all', 'input']
    (82, 'elif config["approach"] == "GENERIC":')
    (83, '')
    (84, '    if not is_single_end_GENERIC_experiment(SAMPLES) and config["TE_TYPING"] != "perform":')
    (85, '')
    (86, '        rule all:')
    (87, '            input:')
    (88, '                #fastqc')
    (89, '                expand("results/fastqc/raw/{sample}_1_fastqc.html", sample=SAMPLES),')
    (90, '                expand("results/fastqc/raw/{sample}_1_fastqc.zip", sample=SAMPLES),')
    (91, '                expand("results/fastqc/raw/{sample}_2_fastqc.html", sample=SAMPLES),')
    (92, '                expand("results/fastqc/raw/{sample}_2_fastqc.zip", sample=SAMPLES),')
    (93, '                #cutadapt')
    (94, '#                expand("results/cut_reads/{sample}.1.fq.gz", sample=SAMPLES),')
    (95, '#                expand("results/cut_reads/{sample}.2.fq.gz", sample=SAMPLES),')
    (96, '#                expand("results/cut_reads/{sample}.qc.txt", sample=SAMPLES),')
    (97, '                #trimmomatic')
    (98, '                expand("results/trimmed_reads/{sample}.1.fq.gz", sample=SAMPLES),')
    (99, '                expand("results/trimmed_reads/{sample}.2.fq.gz", sample=SAMPLES),')
    (100, '                #fastqc trimmed')
    (101, '                expand("results/fastqc/trimmed/{sample}_1_fastqc.html", sample=SAMPLES),')
    (102, '                expand("results/fastqc/trimmed/{sample}_1_fastqc.zip", sample=SAMPLES),')
    (103, '                expand("results/fastqc/trimmed/{sample}_2_fastqc.html", sample=SAMPLES),')
    (104, '                expand("results/fastqc/trimmed/{sample}_2_fastqc.zip", sample=SAMPLES),')
    (105, '                #bowtie2 align')
    (106, '                expand("results/mapped/{sample}.sam", sample=SAMPLES),')
    (107, '                #samtools; SAM to sorted BAM')
    (108, '                expand("results/mapped/{sample}.sorted.bam", sample=SAMPLES),')
    (109, '                #picard + samtools view conversion to SAM format')
    (110, '                expand("results/dedup_sam/{sample}.dedup.sam", sample=SAMPLES),')
    (111, '                expand("results/dedup/{sample}.dedup.bam", sample=SAMPLES),')
    (112, '                #indexes')
    (113, '                expand("results/mapped/{sample}.sorted.bam.bai", sample=SAMPLES),')
    (114, '                expand("results/dedup/{sample}.dedup.bam.bai", sample=SAMPLES),')
    (115, '                #multiqc')
    (116, '                "results/multiqc/multiqc.html",')
    (117, '                #insertion identification')
    (118, '                "results/insertions_table_final/all_identified_insertions.csv",')
    (119, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=tgstoecker/MuWU, file=workflow/Snakefile
context_key: ['elif config["approach"] == "GENERIC"', 'elif not is_single_end_GENERIC_experiment(SAMPLES) and config["TE_TYPING"] == "perform"', 'rule all', 'input']
    (120, '    elif not is_single_end_GENERIC_experiment(SAMPLES) and config["TE_TYPING"] == "perform":')
    (121, '')
    (122, '        rule all:')
    (123, '            input:')
    (124, '                #fastqc')
    (125, '                expand("results/fastqc/raw/{sample}_1_fastqc.html", sample=SAMPLES),')
    (126, '                expand("results/fastqc/raw/{sample}_1_fastqc.zip", sample=SAMPLES),')
    (127, '                expand("results/fastqc/raw/{sample}_2_fastqc.html", sample=SAMPLES),')
    (128, '                expand("results/fastqc/raw/{sample}_2_fastqc.zip", sample=SAMPLES),')
    (129, '                #cutadapt')
    (130, '#                expand("results/cut_reads/{sample}.1.fq.gz", sample=SAMPLES),')
    (131, '#                expand("results/cut_reads/{sample}.2.fq.gz", sample=SAMPLES),')
    (132, '#                expand("results/cut_reads/{sample}.qc.txt", sample=SAMPLES),')
    (133, '                #trimmomatic')
    (134, '                expand("results/trimmed_reads/{sample}.1.fq.gz", sample=SAMPLES),')
    (135, '                expand("results/trimmed_reads/{sample}.2.fq.gz", sample=SAMPLES),')
    (136, '                #fastqc trimmed')
    (137, '                expand("results/fastqc/trimmed/{sample}_1_fastqc.html", sample=SAMPLES),')
    (138, '                expand("results/fastqc/trimmed/{sample}_1_fastqc.zip", sample=SAMPLES),')
    (139, '                expand("results/fastqc/trimmed/{sample}_2_fastqc.html", sample=SAMPLES),')
    (140, '                expand("results/fastqc/trimmed/{sample}_2_fastqc.zip", sample=SAMPLES),')
    (141, '                #bowtie2 align')
    (142, '                expand("results/mapped/{sample}.sam", sample=SAMPLES),')
    (143, '                #samtools; SAM to sorted BAM')
    (144, '                expand("results/mapped/{sample}.sorted.bam", sample=SAMPLES),')
    (145, '                #picard + samtools view conversion to SAM format')
    (146, '                expand("results/dedup_sam/{sample}.dedup.sam", sample=SAMPLES),')
    (147, '                expand("results/dedup/{sample}.dedup.bam", sample=SAMPLES),')
    (148, '                #indexes')
    (149, '                expand("results/mapped/{sample}.sorted.bam.bai", sample=SAMPLES),')
    (150, '                expand("results/dedup/{sample}.dedup.bam.bai", sample=SAMPLES),')
    (151, '                #multiqc')
    (152, '                "results/multiqc/multiqc.html",')
    (153, '                #insertion identification')
    (154, '                "results/insertions_table_final/all_identified_insertions.csv",')
    (155, '                #insertion annotation')
    (156, '                "results/insertions_table_final/all_identified_insertions_annotated.csv",')
    (157, '                #te/element typing')
    (158, '                expand("results/te_typing/uncategorized_clustered/final_clstr_file_{insertion_table}.tsv", insertion_table=INSERTION_TABLES_GENERIC),')
    (159, '')
    (160, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=tgstoecker/MuWU, file=workflow/Snakefile
context_key: ['elif config["approach"] == "GENERIC"', 'elif is_single_end_GENERIC_experiment(SAMPLES) and config["TE_TYPING"] != "perform"', 'rule all', 'input']
    (161, '    elif is_single_end_GENERIC_experiment(SAMPLES) and config["TE_TYPING"] != "perform":')
    (162, '')
    (163, '        rule all:')
    (164, '            input:')
    (165, '                #fastqc')
    (166, '                expand("results/fastqc/raw/{sample}_1_fastqc.html", sample=SAMPLES),')
    (167, '                expand("results/fastqc/raw/{sample}_1_fastqc.zip", sample=SAMPLES),')
    (168, '                #cutadapt')
    (169, '#                expand("results/cut_reads/{sample}.1.fq.gz", sample=SAMPLES),')
    (170, '#                expand("results/cut_reads/{sample}.qc.txt", sample=SAMPLES),')
    (171, '                #trimmomatic')
    (172, '                expand("results/trimmed_reads/{sample}.1.fq.gz", sample=SAMPLES),')
    (173, '                #trimmed fastqc')
    (174, '                expand("results/fastqc/trimmed/{sample}_1_fastqc.html", sample=SAMPLES),')
    (175, '                expand("results/fastqc/trimmed/{sample}_1_fastqc.zip", sample=SAMPLES),')
    (176, '                #bowtie2 align')
    (177, '                expand("results/mapped/{sample}.sam", sample=SAMPLES),')
    (178, '                #samtools; SAM to sorted BAM')
    (179, '                expand("results/mapped/{sample}.sorted.bam", sample=SAMPLES),')
    (180, '                #picard + samtools view conversion to SAM format')
    (181, '                expand("results/dedup_sam/{sample}.dedup.sam", sample=SAMPLES),')
    (182, '                expand("results/dedup/{sample}.dedup.bam", sample=SAMPLES),')
    (183, '                #indexes')
    (184, '                expand("results/mapped/{sample}.sorted.bam.bai", sample=SAMPLES),')
    (185, '                expand("results/dedup/{sample}.dedup.bam.bai", sample=SAMPLES),')
    (186, '                #multiqc')
    (187, '                "results/multiqc/multiqc.html",')
    (188, '                #insertion identification')
    (189, '                "results/insertions_table_final/all_identified_insertions.csv",')
    (190, '                #insertion annotation')
    (191, '                "results/insertions_table_final/all_identified_insertions_annotated.csv",')
    (192, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=tgstoecker/MuWU, file=workflow/Snakefile
context_key: ['elif config["approach"] == "GENERIC"', 'elif is_single_end_GENERIC_experiment(SAMPLES) and config["TE_TYPING"] == "perform"', 'rule all', 'input']
    (193, '    elif is_single_end_GENERIC_experiment(SAMPLES) and config["TE_TYPING"] == "perform":')
    (194, '')
    (195, '        rule all:')
    (196, '            input:')
    (197, '                #fastqc')
    (198, '                expand("results/fastqc/raw/{sample}_1_fastqc.html", sample=SAMPLES),')
    (199, '                expand("results/fastqc/raw/{sample}_1_fastqc.zip", sample=SAMPLES),')
    (200, '                #cutadapt')
    (201, '#                expand("results/cut_reads/{sample}.1.fq.gz", sample=SAMPLES),')
    (202, '#                expand("results/cut_reads/{sample}.qc.txt", sample=SAMPLES),')
    (203, '                #trimmomatic')
    (204, '                expand("results/trimmed_reads/{sample}.1.fq.gz", sample=SAMPLES),')
    (205, '                #trimmed fastqc')
    (206, '                expand("results/fastqc/trimmed/{sample}_1_fastqc.html", sample=SAMPLES),')
    (207, '                expand("results/fastqc/trimmed/{sample}_1_fastqc.zip", sample=SAMPLES),')
    (208, '                #bowtie2 align')
    (209, '                expand("results/mapped/{sample}.sam", sample=SAMPLES),')
    (210, '                #samtools; SAM to sorted BAM')
    (211, '                expand("results/mapped/{sample}.sorted.bam", sample=SAMPLES),')
    (212, '                #picard + samtools view conversion to SAM format')
    (213, '                expand("results/dedup_sam/{sample}.dedup.sam", sample=SAMPLES),')
    (214, '                expand("results/dedup/{sample}.dedup.bam", sample=SAMPLES),')
    (215, '                #indexes')
    (216, '                expand("results/mapped/{sample}.sorted.bam.bai", sample=SAMPLES),')
    (217, '                expand("results/dedup/{sample}.dedup.bam.bai", sample=SAMPLES),')
    (218, '                #multiqc')
    (219, '                "results/multiqc/multiqc.html",')
    (220, '                #insertion identification')
    (221, '                "results/insertions_table_final/all_identified_insertions.csv",')
    (222, '                #insertion annotation')
    (223, '                "results/insertions_table_final/all_identified_insertions_annotated.csv",')
    (224, '                #te/element typing')
    (225, '                expand("results/te_typing/uncategorized_clustered/final_clstr_file_{insertion_table}.tsv", insertion_table=INSERTION_TABLES_GENERIC),')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=tgstoecker/MuWU, file=workflow/rules/te_typing.smk
context_key: ['if config["approach"] == "GRID"', 'rule te_typing_annotation_propagation_GRID', 'input']
    (77, 'if config["approach"] == "GRID":')
    (78, '    rule te_typing_annotation_propagation_GRID:')
    (79, '        input:')
    (80, '            complete_all_final="results/insertions_table_final_te_typed/complete_all_identified_insertions.csv",')
    (81, '            germinal_identified_insertions="results/insertions_table_final/germinal_identified_insertions.csv",')
    (82, '            all_identified_insertions_annotated="results/insertions_table_final/all_identified_insertions_annotated.csv",')
    (83, '            germinal_identified_insertions_annotated="results/insertions_table_final/germinal_identified_insertions_annotated.csv",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=tgstoecker/MuWU, file=workflow/rules/te_typing.smk
context_key: ['if config["approach"] == "GRID"', 'rule te_typing_annotation_propagation_GRID', 'output']
    (84, '        output:')
    (85, '            #germinal UN-annotated')
    (86, '            "results/insertions_table_final_te_typed/complete_germinal_identified_insertions.csv",')
    (87, '            "results/insertions_table_final_te_typed/short_germinal_identified_insertions.csv",')
    (88, '            "results/insertions_table_final_te_typed/headers_strand_1_uncategorized_germinal_identified_insertions.csv",')
    (89, '            "results/insertions_table_final_te_typed/headers_strand_2_uncategorized_germinal_identified_insertions.csv",')
    (90, '            #all annotated')
    (91, '            "results/insertions_table_final_te_typed/complete_all_identified_insertions_annotated.csv",')
    (92, '            "results/insertions_table_final_te_typed/short_all_identified_insertions_annotated.csv",')
    (93, '            "results/insertions_table_final_te_typed/headers_strand_1_uncategorized_all_identified_insertions_annotated.csv",')
    (94, '            "results/insertions_table_final_te_typed/headers_strand_2_uncategorized_all_identified_insertions_annotated.csv",')
    (95, '            #germinal annotated')
    (96, '            "results/insertions_table_final_te_typed/complete_germinal_identified_insertions_annotated.csv",')
    (97, '            "results/insertions_table_final_te_typed/short_germinal_identified_insertions_annotated.csv",')
    (98, '            "results/insertions_table_final_te_typed/headers_strand_1_uncategorized_germinal_identified_insertions_annotated.csv",')
    (99, '            "results/insertions_table_final_te_typed/headers_strand_2_uncategorized_germinal_identified_insertions_annotated.csv",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=tgstoecker/MuWU, file=workflow/rules/te_typing.smk
context_key: ['if config["approach"] == "GRID"', 'rule te_typing_annotation_propagation_GRID', 'params']
    (100, '        params:')
    (101, '            samples=lambda wildcards: list(config["SAMPLES"]),')
    (102, '            all_types=lambda wildcards: list(config["TE_types"].keys()),')
    (103, '            te_typing_cluster_cores=lambda wildcards: config["te_typing_cluster_cores"],')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=tgstoecker/MuWU, file=workflow/rules/te_typing.smk
context_key: ['if config["approach"] == "GRID"', 'rule te_typing_annotation_propagation_GRID', 'conda']
    (104, '        conda: "../envs/annotation.yaml"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=tgstoecker/MuWU, file=workflow/rules/te_typing.smk
context_key: ['if config["approach"] == "GRID"', 'rule te_typing_annotation_propagation_GRID', 'threads']
    (105, '        threads: 1')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=tgstoecker/MuWU, file=workflow/rules/te_typing.smk
context_key: ['if config["approach"] == "GRID"', 'rule te_typing_annotation_propagation_GRID', 'script']
    (106, '        script:')
    (107, '            "../scripts/te_type_annotation_propagation_GRID.R"')
    (108, '')
    (109, '')
    (110, '#### ONLY FOR GENERIC APPROACH BASED ANALYSIS ####')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=tgstoecker/MuWU, file=workflow/rules/te_typing.smk
context_key: ['if config["approach"] == "GENERIC"', 'rule te_typing_annotation_propagation_GENERIC', 'input']
    (111, 'if config["approach"] == "GENERIC":')
    (112, '')
    (113, '    rule te_typing_annotation_propagation_GENERIC:')
    (114, '        input:')
    (115, '            complete_all_final="results/insertions_table_final_te_typed/complete_all_identified_insertions.csv",')
    (116, '            all_identified_insertions_annotated="results/insertions_table_final/all_identified_insertions_annotated.csv",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=tgstoecker/MuWU, file=workflow/rules/te_typing.smk
context_key: ['if config["approach"] == "GENERIC"', 'rule te_typing_annotation_propagation_GENERIC', 'output']
    (117, '        output:')
    (118, '            #all annotated')
    (119, '            "results/insertions_table_final_te_typed/complete_all_identified_insertions_annotated.csv",')
    (120, '            "results/insertions_table_final_te_typed/short_all_identified_insertions_annotated.csv",')
    (121, '            "results/insertions_table_final_te_typed/headers_strand_1_uncategorized_all_identified_insertions_annotated.csv",')
    (122, '            "results/insertions_table_final_te_typed/headers_strand_2_uncategorized_all_identified_insertions_annotated.csv",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=tgstoecker/MuWU, file=workflow/rules/te_typing.smk
context_key: ['if config["approach"] == "GENERIC"', 'rule te_typing_annotation_propagation_GENERIC', 'conda']
    (123, '        conda: "../envs/annotation.yaml"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=tgstoecker/MuWU, file=workflow/rules/te_typing.smk
context_key: ['if config["approach"] == "GENERIC"', 'rule te_typing_annotation_propagation_GENERIC', 'threads']
    (124, '        threads: 1')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=tgstoecker/MuWU, file=workflow/rules/te_typing.smk
context_key: ['if config["approach"] == "GENERIC"', 'rule te_typing_annotation_propagation_GENERIC', 'script']
    (125, '        script:')
    (126, '            "../scripts/te_type_annotation_propagation_GENERIC.R"')
    (127, '')
    (128, '')
    (129, '')
    (130, '###### once done with annotation  ###########')
    (131, '#extract all reads from fqs that correspond to uncategorized insertions')
    (132, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=mohimanilab/AssociationNetworks, file=Snakefile
context_key: ["if config['associations_parts'] == 1", 'rule associations_serial', 'input']
    (20, "if config['associations_parts'] == 1:")
    (21, '    # SERIAL EXECUTION')
    (22, '    rule associations_serial:')
    (23, '        input:')
    (24, "            mbx_fn='input/mbx.feat.bin_sparse',")
    (25, "            mgx_fn='input/mgx.feat.bin_sparse',")
    (26, "            samples_fn='input/samples.tsv'")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=mohimanilab/AssociationNetworks, file=Snakefile
context_key: ["if config['associations_parts'] == 1", 'rule associations_serial', 'output']
    (27, '        output:')
    (28, "            assn_fn=protected('output/associations.tsv')")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=mohimanilab/AssociationNetworks, file=Snakefile
context_key: ["if config['associations_parts'] == 1", 'rule associations_serial', 'log']
    (29, '        log:')
    (30, "            'log/associations.log'")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=mohimanilab/AssociationNetworks, file=Snakefile
context_key: ["if config['associations_parts'] == 1", 'rule associations_serial', 'script']
    (31, '        script:')
    (32, "            'scripts/associations.py'")
    (33, '')
    (34, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=mohimanilab/AssociationNetworks, file=Snakefile
context_key: ["if config['associations_parts'] == 1", 'rule associations_decoy_serial', 'input']
    (35, '    rule associations_decoy_serial:')
    (36, '        input:')
    (37, "            mbx_fn='input/mbx_decoy.feat.bin_sparse',")
    (38, "            mgx_fn='input/mgx.feat.bin_sparse',")
    (39, "            samples_fn='input/samples.tsv'")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=mohimanilab/AssociationNetworks, file=Snakefile
context_key: ["if config['associations_parts'] == 1", 'rule associations_decoy_serial', 'output']
    (40, '        output:')
    (41, "            assn_fn=protected('output/associations_decoy.tsv')")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=mohimanilab/AssociationNetworks, file=Snakefile
context_key: ["if config['associations_parts'] == 1", 'rule associations_decoy_serial', 'log']
    (42, '        log:')
    (43, "            'log/associations_decoy.log'")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=mohimanilab/AssociationNetworks, file=Snakefile
context_key: ["if config['associations_parts'] == 1", 'rule associations_decoy_serial', 'script']
    (44, '        script:')
    (45, "            'scripts/associations.py'")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=lculibrk/Ploidetect-pipeline, file=Snakefile.gsc.smk
context_key: ['if config["temp_dir"] and not os.path.exists(scratch)']
    (101, 'if config["temp_dir"] and not os.path.exists(scratch):')
    (102, '    print(f\\\'Creating scratch space:  {config["temp_dir"]}\\\')')
    (103, '    os.makedirs(config["temp_dir"])')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=lculibrk/Ploidetect-pipeline, file=Snakefile.gsc.smk
context_key: ['if config["temp_dir"] and not os.path.islink(scratch) and not os.path.exists(scratch)']
    (104, 'if config["temp_dir"] and not os.path.islink(scratch) and not os.path.exists(scratch):')
    (105, '    print(f"Creating symlink: {scratch}")')
    (106, '    os.symlink(config["temp_dir"], scratch)')
    (107, '')
    (108, '')
    (109, '# Setting the workdir is less flexible, but should keep logs and parameters organized.')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=hans-vg/snakemake_rnaseq_combined_workflow, file=rules/align.smk
context_key: ['if config["trimming"]["skip"]']
    (1, '    if config["trimming"]["skip"]:')
    (2, '        # no trimming, use raw reads')
    (3, '        return units.loc[(wildcards.sample, wildcards.unit), ["fq1", "fq2"]].dropna()')
    (4, '    else:')
    (5, '        # yes trimming, use trimmed data')
    (6, '        if not is_single_end(**wildcards):')
    (7, '            # paired-end sample')
    (8, '            #print(expand("trimmed/{sample}-{unit}.{group}.fastq.gz", group=[1, 2], **wildcards))')
    (9, '            return expand("trimmed/{sample}-{unit}.{group}.fastq.gz", group=[1, 2], **wildcards)')
    (10, '        # single end sample')
    (11, '        #print("trimmed/{sample}-{unit}.fastq.gz".format(**wildcards))')
    (12, '        return "trimmed/{sample}-{unit}.fastq.gz".format(**wildcards)')
    (13, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=JieqiongDai/Single-Cell-CNV-Evolution, file=Snakefile
context_key: ['elif config["group"]=="ready"', 'rule all', 'input']
    (57, 'elif config["group"]=="ready":')
    (58, '     include: "modules/Snakefile_gen"')
    (59, '     include: "modules/Snakefile_group"')
    (60, '     rule all:')
    (61, '         input:')
    (62, '               expand(out + "link/summary/{sample}_web_summary.html",sample=sample),')
    (63, '               expand(out + "reanalysis/link/loup/{sample}_dloupe.dloupe",sample=sample),')
    (64, '               "redundant_removed.txt",')
    (65, '               expand(out + "MEDALT/{sample}/medalt.pdf",sample=sample),')
    (66, '               expand(out + "reanalysis/link/tsne/{sample}_plotly_tsne.html",sample=sample), ')
    (67, '               expand(out + "MEDALT_group/{sample}/singlecell.tree.pdf",sample=sample),')
    (68, '               expand(out + "MEDALT_group/{sample}/medalt.group.force.directed.pdf",sample=sample),')
    (69, '               expand(out + "reanalysis/link/tsne/{sample}_plotly_tsne_group.html",sample=sample)')
    (70, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=tjgibson/NGS-workflow-ATACseq, file=workflow/rules/diff_accessibility.smk
context_key: ['if config["run_diff_accessibility"]']
    (20, 'if config["run_diff_accessibility"]:')
    (21, '\\trule DEseq2:')
    (22, '\\t\\tinput:')
    (23, '\\t\\t\\t"results/count_tables/{experiment}.featureCounts"')
    (24, '\\t\\toutput:')
    (25, '\\t\\t\\t"results/DEseq2/{experiment}.dds"')
    (26, '\\t\\tparams:')
    (27, '\\t\\t\\tsamples=config["samples"],')
    (28, '\\t\\t\\tmodel=config["diff_accessibility"]["model"],')
    (29, '\\t\\t\\tcount_threshold=config["diff_accessibility"]["count_threshold"],')
    (30, '\\t\\tconda:')
    (31, '\\t\\t\\t"../envs/DEseq2.yaml",')
    (32, '\\t\\tlog:')
    (33, '\\t\\t\\t"logs/DEseq2/{experiment}.log",')
    (34, '\\t\\tscript:')
    (35, '\\t\\t\\t"../scripts/DEseq2.R"')
    (36, '')
    (37, '\\trule DEseq2_results:')
    (38, '\\t\\tinput:')
    (39, '\\t\\t\\tdds="results/DEseq2/{experiment}.dds",')
    (40, '\\t\\t\\tpeaks="results/peaks/final/{experiment}.narrowPeak"')
    (41, '\\t\\toutput:')
    (42, '\\t\\t\\t"results/DEseq2/{experiment}_{contrast}_results.tsv"')
    (43, '\\t\\tparams:')
    (44, '\\t\\t\\t contrast=get_contrast,')
    (45, '\\t\\t\\t padj_cutoff=config["diff_accessibility"]["padj_cutoff"],')
    (46, '\\t\\t\\t FC_cutoff=config["diff_accessibility"]["log2FC_cutoff"],')
    (47, '\\t\\tconda:')
    (48, '\\t\\t\\t"../envs/DEseq2.yaml",')
    (49, '\\t\\tlog:')
    (50, '\\t\\t\\t"logs/DEseq2_results/{experiment}_{contrast}.log",')
    (51, '\\t\\tscript:')
    (52, '\\t\\t\\t"../scripts/DEseq2_results.R"\'')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=tjgibson/NGS-workflow-ATACseq, file=workflow/rules/filter.smk
context_key: ['if config["filter_chroms"]', 'else', 'rule samtools_index_filtered', 'input']
    (11, 'if config["filter_chroms"]:')
    (12, '\\trule filter_multireads:')
    (13, '\\t\\tinput:')
    (14, '\\t\\t\\t"results/aligned_reads/sorted/{sample}.bam"')
    (15, '\\t\\toutput:')
    (16, '\\t\\t\\ttemp("results/aligned_reads/unireads/{sample}.bam")')
    (17, '\\t\\tlog:')
    (18, '\\t\\t\\t"logs/filter_multireads/{sample}.log"')
    (19, '\\t\\tparams:')
    (20, '\\t\\t\\textra=config["params"]["filter_multireads"] ')
    (21, '\\t\\tthreads: 8')
    (22, '\\t\\twrapper:')
    (23, '\\t\\t\\t"v1.1.0/bio/sambamba/view"')
    (24, '\\t')
    (25, '\\trule samtools_index_unireads:')
    (26, '\\t\\tinput:')
    (27, '\\t\\t\\t"results/aligned_reads/unireads/{sample}.bam"')
    (28, '\\t\\toutput:')
    (29, '\\t\\t\\ttemp("results/aligned_reads/unireads/{sample}.bam.bai")')
    (30, '\\t\\tlog:')
    (31, '\\t\\t\\t"logs/samtools_index/{sample}.log"')
    (32, '\\t\\tparams:')
    (33, '\\t\\t\\t"" # optional params string')
    (34, '\\t\\tthreads:  # Samtools takes additional threads through its option -@')
    (35, '\\t\\t\\t4     # This value - 1 will be sent to -@')
    (36, '\\t\\twrapper:')
    (37, '\\t\\t\\t"v1.1.0/bio/samtools/index"')
    (38, '\\t')
    (39, '\\trule samtools_idxstats_unireads:')
    (40, '\\t\\tinput:')
    (41, '\\t\\t\\tbam="results/aligned_reads/unireads/{sample}.bam",')
    (42, '\\t\\t\\tidx="results/aligned_reads/unireads/{sample}.bam.bai"')
    (43, '\\t\\toutput:')
    (44, '\\t\\t\\t"results/aligned_reads/stats/{sample}_unireads.idxstats"')
    (45, '\\t\\tlog:')
    (46, '\\t\\t\\t"logs/samtools/idxstats/{sample}.log"')
    (47, '\\t\\twrapper:')
    (48, '\\t\\t\\t"v1.1.0/bio/samtools/idxstats"')
    (49, '\\t')
    (50, '\\trule filter_chroms:')
    (51, '\\t\\tinput:')
    (52, '\\t\\t\\tbam="results/aligned_reads/unireads/{sample}.bam",')
    (53, '\\t\\t\\tkeep_chroms="resources/keep_chroms.bed"')
    (54, '\\t\\toutput:')
    (55, '\\t\\t\\t"results/aligned_reads/filtered/{sample}.bam"')
    (56, '\\t\\tlog:')
    (57, '\\t\\t\\t"logs/filter_chroms/{sample}.log"')
    (58, '\\t\\tconda:')
    (59, '\\t\\t\\t"../envs/samtools.yaml"')
    (60, '\\t\\tshell:')
    (61, '\\t\\t\\t"samtools view -bh -L {input.keep_chroms} --output-fmt BAM -o {output} {input.bam} 2>> {log}"')
    (62, 'else:')
    (63, '\\trule filter_multireads:')
    (64, '\\t\\tinput:')
    (65, '\\t\\t\\t"results/aligned_reads/sorted/{sample}.bam"')
    (66, '\\t\\toutput:')
    (67, '\\t\\t\\t"results/aligned_reads/filtered/{sample}.bam"')
    (68, '\\t\\tlog:')
    (69, '\\t\\t\\t"logs/filter_multireads/{sample}.log"')
    (70, '\\t\\tparams:')
    (71, '\\t\\t\\textra=config["params"]["filter_multireads"]')
    (72, '\\t\\tthreads: 8')
    (73, '\\t\\twrapper:')
    (74, '\\t\\t\\t"v1.1.0/bio/sambamba/view"')
    (75, '\\t\\t')
    (76, '')
    (77, 'rule samtools_index_filtered:')
    (78, '    input:')
    (79, '        "results/aligned_reads/filtered/{sample}.bam"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=tjgibson/NGS-workflow-ATACseq, file=workflow/rules/filter.smk
context_key: ['if config["filter_chroms"]', 'output']
    (80, '    output:')
    (81, '        "results/aligned_reads/filtered/{sample}.bam.bai"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=tjgibson/NGS-workflow-ATACseq, file=workflow/rules/filter.smk
context_key: ['if config["filter_chroms"]', 'log']
    (82, '    log:')
    (83, '        "logs/samtools_index/{sample}.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=tjgibson/NGS-workflow-ATACseq, file=workflow/rules/filter.smk
context_key: ['if config["filter_chroms"]', 'params']
    (84, '    params:')
    (85, '        "" # optional params string')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=tjgibson/NGS-workflow-ATACseq, file=workflow/rules/filter.smk
context_key: ['if config["filter_chroms"]', 'threads']
    (86, '    threads:  # Samtools takes additional threads through its option -@')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=tjgibson/NGS-workflow-ATACseq, file=workflow/rules/filter.smk
context_key: ['if config["filter_chroms"]']
    (87, '        4     # This value - 1 will be sent to -@')
    (88, '    wrapper:')
    (89, '        "v1.1.0/bio/samtools/index"')
    (90, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=CBIbigA/ChIP-seq, file=workflow/Snakefile
context_key: ['if config["samtools"]["rm_duplicates"]', 'else', 'rule all']
    (3, 'if config["samtools"]["rm_duplicates"]:')
    (4, '\\tsamtype="rmdups"')
    (5, 'else:')
    (6, '\\tsamtype="sorted"')
    (7, '')
    (8, '')
    (9, 'include:"rules/fastqc.smk"')
    (10, 'include:"rules/bwa.smk"')
    (11, 'include:"rules/samtools.smk"')
    (12, 'include:"rules/bamcoverage.smk"')
    (13, '')
    (14, 'rule all:')
    (15, '\\tinput: ')
    (16, '\\t\\texpand(config["general"]["experiment_name"]+"/mapping/BIGWIG/{sample}_{samtype}.{normalization}.bw",sample=config["general"]["samples"],samtype=samtype,normalization=config["bamcoverage"]["normalization"]),')
    (17, '\\t\\tconfig["general"]["experiment_name"]+"/QC/MULTIQC/"+config["general"]["experiment_name"]+"_multiqc_report.html"')
    (18, "'")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=marykthompson/foursu_steady_state, file=rules/align.smk
context_key: ['if config["trimming"]["skip"]']
    (1, '    if config["trimming"]["skip"]:')
    (2, '        # no trimming, use raw reads')
    (3, '        return units.loc[(wildcards.sample, wildcards.unit), ["fq1", "fq2"]].dropna()')
    (4, '    else:')
    (5, '        # yes trimming, use trimmed data')
    (6, '        if not is_single_end(**wildcards):')
    (7, '            # paired-end sample')
    (8, '            return expand("trimmed/{sample}-{unit}.{group}.fastq.gz",')
    (9, '                          group=[1, 2], **wildcards)')
    (10, '        # single end sample')
    (11, '        return "trimmed/{sample}-{unit}.fastq.gz".format(**wildcards)')
    (12, '            ')
    (13, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=nanoporetech/DTR-phage-pipeline, file=Snakefile
context_key: ["if config[\\'KAIJU\\'].get(\\'run\\', True)", 'if os.path.exists(KAIJU_DB_DIR)']
    (262, "if config[\\'KAIJU\\'].get(\\'run\\', True):")
    (263, '    if os.path.exists(KAIJU_DB_DIR):')
    (264, '        output_files.extend([')
    (265, '            KAIJU_RESULTS_KRONA_HTML,')
    (266, '            expand(str(KMER_FREQS_UMAP_TAX), database=DATABASE_NAME, rank=TAX_RANK),')
    (267, '        ])')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=nanoporetech/DTR-phage-pipeline, file=Snakefile
context_key: ["if config[\\'KAIJU\\'].get(\\'run\\', True)", 'else']
    (268, '    else:')
    (269, '        logger.warning(f"No kaiju DB found in {KAIJU_DB_DIR}.\\')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=maarten-k/realignment, file=workflow/Snakefile
context_key: ['if config["original"]']
    (8, 'if config["original"]:')
    (9, '    print("using original code")')
    (10, '')
    (11, '    include: "rules/original.smk"')
    (12, '')
    (13, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=MGXlab/phap, file=workflow/rules/vhmnet.smk
context_key: ['input', 'params', "if config[\\'vhmnet\\'][\\'short_contig\\'] else \\'\\"]
    (13, "            if config[\\'vhmnet\\'][\\'short_contig\\'] else \\'\\'")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=MGXlab/phap, file=workflow/rules/common.smk
context_key: ["if config.get(\\'taxa_sqlite\\')"]
    (37, "if config.get(\\'taxa_sqlite\\'):")
    (38, "    TAXA_SQLITE = Path(config.get(\\'taxa_sqlite\\'))")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=tniranjan1/RRBS_PIPELINE, file=workflow/Snakefile
context_key: ["if config[\\'lrs\\'][\\'activate\\']"]
    (54, "if config[\\'lrs\\'][\\'activate\\']:")
    (55, "    lrs_methyl_sample_path = abspath(config[\\'lrs\\'][\\'path\\'])")
    (56, "    schema_path = abspath(\\'schemas/lrs-methyl.schema.yaml\\')")
    (57, '    lrs_methyl_sample_sheet = importLRSmethylSheet(sample_path=lrs_methyl_sample_path, schema_path=schema_path)')
    (58, '    lrs_sample_names = lrs_methyl_sample_sheet.index.tolist()')
    (59, '# Distinguish between lrs and rrbs sample names')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=EvoHull/Tapirs, file=workflow/rules/vsearch.smk
context_key: ['if config[\\\'chimera_detection\\\'] == "ref"', 'rule vsearch_uchime_ref', 'input']
    (70, 'if config[\\\'chimera_detection\\\'] == "ref":')
    (71, '')
    (72, '    rule vsearch_uchime_ref:')
    (73, '        input:')
    (74, '            cluster = "results/07_clustered/{LIBRARIES}/{SAMPLES}.cluster.fasta" if config[\\\'cluster_method\\\'] == "cluster" else "results/07_denoised/{LIBRARIES}/{SAMPLES}.denoise.fasta"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=EvoHull/Tapirs, file=workflow/rules/vsearch.smk
context_key: ['if config[\\\'chimera_detection\\\'] == "ref"', 'rule vsearch_uchime_ref', 'output']
    (75, '        output:')
    (76, '            nonchimeras = "results/08_dechimera/{LIBRARIES}/{SAMPLES}.nc.fasta",')
    (77, '            chimeras = "results/08_dechimera/{LIBRARIES}/{SAMPLES}.chimera.fasta"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=EvoHull/Tapirs, file=workflow/rules/vsearch.smk
context_key: ['if config[\\\'chimera_detection\\\'] == "ref"', 'rule vsearch_uchime_ref', 'shell']
    (78, '        shell:')
    (79, '            "vsearch \\\\')
    (80, '            --uchime_ref {input.cluster} \\\\')
    (81, '            --db {config[dechim_blast_db]} \\\\')
    (82, '            --chimeras {output.chimeras} \\\\')
    (83, '            --borderline {output.chimeras} \\\\')
    (84, '            --mindiffs {config[VSEARCH_mindiffs]} \\\\')
    (85, '            --mindiv {config[VSEARCH_mindiv]} \\\\')
    (86, '            --fasta_width 0 \\\\')
    (87, '            --nonchimeras {output.nonchimeras}"')
    (88, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=EvoHull/Tapirs, file=workflow/rules/vsearch.smk
context_key: ['elif config[\\\'chimera_detection\\\'] == "denovo"', 'rule vsearch_uchime3_denovo', 'input']
    (89, 'elif config[\\\'chimera_detection\\\'] == "denovo":')
    (90, '')
    (91, '    rule vsearch_uchime3_denovo:')
    (92, '        input:')
    (93, '            cluster = "results/07_clustered/{LIBRARIES}/{SAMPLES}.cluster.fasta" if config[\\\'cluster_method\\\'] == "cluster" else "results/07_denoised/{LIBRARIES}/{SAMPLES}.denoise.fasta"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=EvoHull/Tapirs, file=workflow/rules/vsearch.smk
context_key: ['elif config[\\\'chimera_detection\\\'] == "denovo"', 'rule vsearch_uchime3_denovo', 'output']
    (94, '        output:')
    (95, '            nonchimeras = "results/08_dechimera/{LIBRARIES}/{SAMPLES}.nc.fasta",')
    (96, '            chimeras = "results/08_dechimera/{LIBRARIES}/{SAMPLES}.chimera.fasta"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=EvoHull/Tapirs, file=workflow/rules/vsearch.smk
context_key: ['elif config[\\\'chimera_detection\\\'] == "denovo"', 'rule vsearch_uchime3_denovo', 'shell']
    (97, '        shell:')
    (98, '            "vsearch \\\\')
    (99, '            --uchime3_denovo {input.cluster} \\\\')
    (100, '            --abskew {config[VSEARCH_abskew]} \\\\')
    (101, '            --chimeras {output.chimeras} \\\\')
    (102, '            --borderline {output.chimeras} \\\\')
    (103, '            --fasta_width 0 \\\\')
    (104, '            --nonchimeras {output.nonchimeras}"')
    (105, '')
    (106, '# ------------------------------------------------------------------------------')
    (107, '# REREPLICATE READS')
    (108, '# ------------------------------------------------------------------------------')
    (109, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=EvoHull/Tapirs, file=workflow/Snakefile
context_key: ['if config["analysis_method"] == "blast" or config["analysis_method"] == "both"']
    (38, 'if config["analysis_method"] == "blast" or config["analysis_method"] == "both":')
    (39, '    myoutput.append(blast)')
    (40, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=EvoHull/Tapirs, file=workflow/Snakefile
context_key: ['if config["analysis_method"] == "kraken2" or config["analysis_method"] == "both"']
    (41, 'if config["analysis_method"] == "kraken2" or config["analysis_method"] == "both":')
    (42, '    myoutput.append(kraken2)')
    (43, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=EvoHull/Tapirs, file=workflow/Snakefile
context_key: ['if config["analysis_method"] == "blast" or config["analysis_method"] == "both"']
    (56, 'if config["analysis_method"] == "blast" or config["analysis_method"] == "both":')
    (57, '    include: "rules/blast.smk"')
    (58, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=EvoHull/Tapirs, file=workflow/Snakefile
context_key: ['if config["analysis_method"] == "kraken2" or config["analysis_method"] == "both"']
    (59, 'if config["analysis_method"] == "kraken2" or config["analysis_method"] == "both":')
    (60, '    include: "rules/kraken2.smk"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=pd321/chipseq, file=Snakefile
context_key: ["if config[\\'addons\\'][\\'se\\']", "if config[\\'addons\\'][\\'homer_annot\\']", "if config[\\'addons\\'][\\'homer_motifs\\']", 'rule all', 'onsuccess', 'onerror']
    (14, "if config[\\'addons\\'][\\'se\\']:")
    (15, '\\tout_files += expand("results/se/{chip_sample}/{chip_sample}_peaks_AllEnhancers_ENHANCER_TO_GENE.txt", chip_sample = chip_samples)')
    (16, '')
    (17, "if config[\\'addons\\'][\\'homer_annot\\']:")
    (18, '\\tout_files += expand("results/peaks/{chip_sample}/{chip_sample}_peaks_annot.xls", chip_sample = chip_samples)')
    (19, '')
    (20, "if config[\\'addons\\'][\\'homer_motifs\\']:")
    (21, '\\tout_files += expand("results/motif/{chip_sample}/homerResults.html", chip_sample = chip_samples)')
    (22, '')
    (23, 'rule all:')
    (24, '\\tinput:')
    (25, '\\t\\tout_files')
    (26, '\\t\\t')
    (27, '\\t\\t')
    (28, 'onsuccess:')
    (29, '\\tshell("if command -v telegram-notify; then telegram-notify --success --text \\\\\\\'snakemake:chipseq:{} completed\\\\\\\'; fi".format(run_name))')
    (30, '')
    (31, 'onerror:')
    (32, '\\tshell("if command -v telegram-notify; then telegram-notify --error --text \\\\\\\'snakemake:chipseq:{} failed\\\\\\\'; fi".format(run_name))')
    (33, "'")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SherineAwad/RNASeqFusion, file=Snakefile
context_key: ["if config[\\'PAIRED\\']", 'rule trim', 'input']
    (10, "if config[\\'PAIRED\\']:")
    (11, '    rule trim:')
    (12, '       input:')
    (13, '           r1 = "{sample}.r_1.fq.gz",')
    (14, '           r2 = "{sample}.r_2.fq.gz"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SherineAwad/RNASeqFusion, file=Snakefile
context_key: ["if config[\\'PAIRED\\']", 'rule trim', 'output']
    (15, '       output:')
    (16, '           "galore/{sample}.r_1_val_1.fq.gz",')
    (17, '           "galore/{sample}.r_2_val_2.fq.gz"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SherineAwad/RNASeqFusion, file=Snakefile
context_key: ["if config[\\'PAIRED\\']", 'rule trim', 'conda']
    (18, "       conda: \\'env/env-trim.yaml\\'")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SherineAwad/RNASeqFusion, file=Snakefile
context_key: ["if config[\\'PAIRED\\']", 'rule trim', 'shell']
    (19, '       shell:')
    (20, '           """')
    (21, '           mkdir -p galore')
    (22, '           mkdir -p fastqc')
    (23, '           trim_galore --gzip --retain_unpaired --trim1 --fastqc --fastqc_args "--outdir fastqc" -o galore --paired {input.r1} {input.r2}')
    (24, '           """')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SherineAwad/RNASeqFusion, file=Snakefile
context_key: ["if config[\\'PAIRED\\']", 'rule align', 'input']
    (25, '    rule align:')
    (26, '        input:')
    (27, '           "galore/{sample}.r_1_val_1.fq.gz",')
    (28, '           "galore/{sample}.r_2_val_2.fq.gz"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SherineAwad/RNASeqFusion, file=Snakefile
context_key: ["if config[\\'PAIRED\\']", 'rule align', 'output']
    (29, '        output:')
    (30, '             "{sample}_Aligned.out.sam"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SherineAwad/RNASeqFusion, file=Snakefile
context_key: ["if config[\\'PAIRED\\']", 'rule align', 'params']
    (31, '        params:')
    (32, "             threads = config[\\'THREADS\\'],")
    (33, "             gtf = config[\\'GTF\\'],")
    (34, '             prefix = "{sample}_",')
    (35, "             index = config[\\'INDEX\\']")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SherineAwad/RNASeqFusion, file=Snakefile
context_key: ["if config[\\'PAIRED\\']", 'rule align', 'shell']
    (36, '        shell:')
    (37, '           """')
    (38, '           STAR --genomeDir {params.index} --runThreadN {params.threads} --chimOutType WithinBAM  --readFilesCommand zcat  --readFilesIn {input[0]} {input[1]}  --outFileNamePrefix {params.prefix} --sjdbGTFfile {params.gtf}  --twopassMode Basic')
    (39, '           """')
    (40, '')
    (41, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=artempronozin95/ICAnnoLncRNA---identification-classification-and-annotation-of-LncRNA, file=Snakefile
context_key: ["if config[\\'diamond\\'][\\'option\\'] == \\'on\\'", 'rule all_1', 'input']
    (5, "if config[\\'diamond\\'][\\'option\\'] == \\'on\\':")
    (6, ' rule all_1:')
    (7, '    input:')
    (8, '        "data/input/test_train/sets.txt",')
    (9, '        "data/output/cpc.txt",')
    (10, '        "data/input/test_train/best_model.txt",')
    (11, '        "data/output/Noncoding.fasta",')
    (12, '        "data/output/lncFinder.csv",')
    (13, '        "data/output/statistic.csv",')
    (14, '        "data/output/Noncoding_trans_out.fasta",')
    (15, '        "data/output/ORF.orf",')
    (16, '        "data/input/test_train/dirs.txt",')
    (17, '        "data/output/tmhmm.csv",')
    (18, '        "data/output/alignm_filter.gff",')
    (19, '        "data/output/gffcmp.alignm_filter.gff.tmap",')
    (20, '        "data/output/filter_alignm.bed",')
    (21, '        "data/output/itron_coordin.tsv",')
    (22, '        "data/output/statistic_bed.tsv",')
    (23, '        "data/output/tissue/tissue_org.png",')
    (24, '        "data/output/blast.outfmt6",')
    (25, '        expand("{out}", out=config[\\\'diamond\\\'][\\\'out\\\']),')
    (26, '        query="data/output/alignm.bed"')
    (27, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=artempronozin95/ICAnnoLncRNA---identification-classification-and-annotation-of-LncRNA, file=Snakefile
context_key: ["if config[\\'diamond\\'][\\'option\\'] == \\'off\\'", 'rule all_2', 'input']
    (28, "if config[\\'diamond\\'][\\'option\\'] == \\'off\\':")
    (29, ' rule all_2:')
    (30, '    input:')
    (31, '        "data/input/test_train/sets.txt",')
    (32, '        "data/output/cpc.txt",')
    (33, '        "data/output/Noncoding.fasta",')
    (34, '        "data/output/lncFinder.csv",')
    (35, '        "data/output/statistic.csv",')
    (36, '        "data/input/test_train/best_model.txt",')
    (37, '        "data/output/Noncoding_trans_out.fasta",')
    (38, '        "data/output/ORF.orf",')
    (39, '        "data/output/tmhmm.csv",')
    (40, '        "data/input/test_train/dirs.txt",')
    (41, '        "data/output/alignm_filter.gff",')
    (42, '        "data/output/gffcmp.alignm_filter.gff.tmap",')
    (43, '        "data/output/filter_alignm.bed",')
    (44, '        "data/output/itron_coordin.tsv",')
    (45, '        "data/output/statistic_bed.tsv",')
    (46, '        "data/output/blast.outfmt6",')
    (47, '        "data/output/tissue/tissue_org.png",')
    (48, '        query="data/output/alignm.bed"')
    (49, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=artempronozin95/ICAnnoLncRNA---identification-classification-and-annotation-of-LncRNA, file=Snakefile
context_key: ["if config[\\'diamond\\'][\\'option\\'] == \\'on\\'", 'rule diamond', 'input']
    (235, "if config[\\'diamond\\'][\\'option\\'] == \\'on\\':")
    (236, '  rule diamond:')
    (237, '     input:')
    (238, '        expand("{database}", database=config[\\\'diamond\\\'][\\\'database\\\']),')
    (239, '        expand("{query}", query=config[\\\'diamond\\\'][\\\'query\\\'])')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=artempronozin95/ICAnnoLncRNA---identification-classification-and-annotation-of-LncRNA, file=Snakefile
context_key: ["if config[\\'diamond\\'][\\'option\\'] == \\'on\\'", 'rule diamond', 'output']
    (240, '     output:')
    (241, '        expand("{out}", out=config[\\\'diamond\\\'][\\\'out\\\'])')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=artempronozin95/ICAnnoLncRNA---identification-classification-and-annotation-of-LncRNA, file=Snakefile
context_key: ["if config[\\'diamond\\'][\\'option\\'] == \\'on\\'", 'rule diamond', 'conda']
    (242, '     conda:')
    (243, '       "env/alignment.yaml"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=artempronozin95/ICAnnoLncRNA---identification-classification-and-annotation-of-LncRNA, file=Snakefile
context_key: ["if config[\\'diamond\\'][\\'option\\'] == \\'on\\'", 'rule diamond', 'shell']
    (244, '     shell:')
    (245, '        "python scripts/diamond.py {input}"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=artempronozin95/ICAnnoLncRNA---identification-classification-and-annotation-of-LncRNA, file=Snakefile
context_key: ["elif config[\\'diamond\\'][\\'option\\'] == \\'off\\'"]
    (246, "elif config[\\'diamond\\'][\\'option\\'] == \\'off\\':")
    (247, '     pass')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=genomewalker/aMGSIM-smk, file=rules/ancient-reads.smk
context_key: ['if config["seq_library"] == "double"', 'rule ancient_reads', 'input']
    (35, 'if config["seq_library"] == "double":')
    (36, '')
    (37, '    rule ancient_reads:')
    (38, '        input:')
    (39, '            ar_config_file=f\\\'{config["rdir"]}/{{smp}}/{{seqlib}}/{{num_reads}}/ar-config.yaml\\\',')
    (40, '            genome_table=f\\\'{config["rdir"]}/{{smp}}/{{seqlib}}/{{num_reads}}/{{smp}}.filepaths.tsv\\\',')
    (41, '            json=f\\\'{config["rdir"]}/{{smp}}/{{seqlib}}/{{num_reads}}/{{smp}}.json\\\',')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=genomewalker/aMGSIM-smk, file=rules/ancient-reads.smk
context_key: ['if config["seq_library"] == "double"', 'rule ancient_reads', 'output']
    (42, '        output:')
    (43, '            fragsim=f\\\'{config["rdir"]}/{{smp}}/{{seqlib}}/{{num_reads}}/reads/{{smp}}_fragSim.fa.gz\\\',')
    (44, '            deamsim=f\\\'{config["rdir"]}/{{smp}}/{{seqlib}}/{{num_reads}}/reads/{{smp}}_deamSim.fa.gz\\\',')
    (45, '            art_p1=f\\\'{config["rdir"]}/{{smp}}/{{seqlib}}/{{num_reads}}/reads/{{smp}}_art.1.fq.gz\\\',')
    (46, '            art_p2=f\\\'{config["rdir"]}/{{smp}}/{{seqlib}}/{{num_reads}}/reads/{{smp}}_art.2.fq.gz\\\',')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=genomewalker/aMGSIM-smk, file=rules/ancient-reads.smk
context_key: ['if config["seq_library"] == "double"', 'rule ancient_reads', 'params']
    (47, '        params:')
    (48, '            results_dir=f\\\'{config["rdir"]}/{{smp}}/{{seqlib}}/{{num_reads}}\\\',')
    (49, '            output_dir=f\\\'{config["rdir"]}/{{smp}}/{{seqlib}}/{{num_reads}}/reads/{{smp}}\\\',')
    (50, '            ar_tmp_dir=f\\\'{config["rdir"]}/{{smp}}/{{seqlib}}/{{num_reads}}/ar-tmp\\\',')
    (51, '            wdir=f\\\'{config["wdir"]}\\\',')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=genomewalker/aMGSIM-smk, file=rules/ancient-reads.smk
context_key: ['if config["seq_library"] == "double"', 'rule ancient_reads', 'threads']
    (52, '        threads: config["cpus"]')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=genomewalker/aMGSIM-smk, file=rules/ancient-reads.smk
context_key: ['if config["seq_library"] == "double"', 'rule ancient_reads', 'log']
    (53, '        log:')
    (54, '            f\\\'{config["rdir"]}/logs/config/{{smp}}/{{seqlib}}/{{num_reads}}/ancient-reads.log\\\',')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=genomewalker/aMGSIM-smk, file=rules/ancient-reads.smk
context_key: ['if config["seq_library"] == "double"', 'rule ancient_reads', 'benchmark']
    (55, '        benchmark:')
    (56, '            f\\\'{config["rdir"]}/benchmarks/config/{{smp}}/{{seqlib}}/{{num_reads}}/ancient-reads.bmk\\\'')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=genomewalker/aMGSIM-smk, file=rules/ancient-reads.smk
context_key: ['if config["seq_library"] == "double"', 'rule ancient_reads', 'conda']
    (57, '        conda:')
    (58, '            "../envs/aMGSIM.yaml"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=genomewalker/aMGSIM-smk, file=rules/ancient-reads.smk
context_key: ['if config["seq_library"] == "double"', 'rule ancient_reads', 'message']
    (59, '        message:')
    (60, '            """--- Generating ancient read data (Paired)"""')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=genomewalker/aMGSIM-smk, file=rules/ancient-reads.smk
context_key: ['if config["seq_library"] == "double"', 'rule ancient_reads', 'shell']
    (61, '        shell:')
    (62, '            """')
    (63, '            cd {params.results_dir} || {{ echo "Cannot change dir"; exit 1; }}')
    (64, '            aMGSIM ancient-reads {input.genome_table} {input.ar_config_file}')
    (65, '            mv {params.output_dir}/*gz {params.results_dir}/reads/')
    (66, '            rm -rf {params.output_dir} {params.ar_tmp_dir} {params.results_dir}/reads/genomes')
    (67, '            cd {params.wdir} || {{ echo "Cannot change dir"; exit 1; }}')
    (68, '            """')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=ESR-NZ/vcf_annotation_pipeline, file=workflow/Snakefile
context_key: ['if config[\\\'DATA\\\'] == "Single" or config[\\\'DATA\\\'] == \\\'single\\\'']
    (12, 'if config[\\\'DATA\\\'] == "Single" or config[\\\'DATA\\\'] == \\\'single\\\':')
    (13, '    SAMPLES, = glob_wildcards("../../human_genomics_pipeline/results/called/{sample}_raw_snps_indels.vcf")')
    (14, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=ESR-NZ/vcf_annotation_pipeline, file=workflow/Snakefile
context_key: ['if config[\\\'DATA\\\'] == "Cohort" or config[\\\'DATA\\\'] == \\\'cohort\\\'']
    (15, 'if config[\\\'DATA\\\'] == "Cohort" or config[\\\'DATA\\\'] == \\\'cohort\\\':')
    (16, '    SAMPLES, = glob_wildcards("../../human_genomics_pipeline/results/called/{sample}_raw_snps_indels.g.vcf")')
    (17, '')
    (18, '##### Setup helper functions #####')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=ESR-NZ/vcf_annotation_pipeline, file=workflow/Snakefile
context_key: ['if config[\\\'DATA\\\'] == "Cohort" or config[\\\'DATA\\\'] == \\\'cohort\\\'']
    (171, 'if config[\\\'DATA\\\'] == "Cohort" or config[\\\'DATA\\\'] == \\\'cohort\\\':')
    (172, '    include: "rules/gatk_CalculateGenotypePosteriors.smk"')
    (173, '    include: "rules/gatk_VariantAnnotator_PossibleDeNovo.smk"')
    (174, '    include: "rules/genmod_models.smk"')
    (175, '')
    (176, '# Filtering to prepare for scout')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=PyPSA/pypsa-eur-sec, file=Snakefile
context_key: ["if config.get(\\'retrieve_sector_databundle\\', True)", 'rule retrieve_sector_databundle']
    (60, "if config.get(\\'retrieve_sector_databundle\\', True):")
    (61, '    rule retrieve_sector_databundle:')
    (62, '        output: *datafiles')
    (63, '        log: "logs/retrieve_sector_databundle.log"')
    (64, "        script: \\'scripts/retrieve_sector_databundle.py\\'")
    (65, '')
    (66, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=PyPSA/pypsa-eur-sec, file=Snakefile
context_key: ['if config["sector"]["gas_network"] or config["sector"]["H2_retrofit"]']
    (107, 'if config["sector"]["gas_network"] or config["sector"]["H2_retrofit"]:')
    (108, '')
    (109, '    datafiles = [')
    (110, '        "IGGIELGN_LNGs.geojson",')
    (111, '        "IGGIELGN_BorderPoints.geojson",')
    (112, '        "IGGIELGN_Productions.geojson",')
    (113, '        "IGGIELGN_PipeSegments.geojson",')
    (114, '    ]')
    (115, '')
    (116, '')
    (117, '    rule retrieve_gas_infrastructure_data:')
    (118, '        output: expand("data/gas_network/scigrid-gas/data/{files}", files=datafiles)')
    (119, "        script: \\'scripts/retrieve_gas_infrastructure_data.py\\'")
    (120, '')
    (121, '')
    (122, '    rule build_gas_network:')
    (123, '        input:')
    (124, '            gas_network="data/gas_network/scigrid-gas/data/IGGIELGN_PipeSegments.geojson"')
    (125, '        output:')
    (126, '            cleaned_gas_network="resources/gas_network.csv"')
    (127, '        resources: mem_mb=4000')
    (128, '        script: "scripts/build_gas_network.py"')
    (129, '')
    (130, '')
    (131, '    rule build_gas_input_locations:')
    (132, '        input:')
    (133, '            lng="data/gas_network/scigrid-gas/data/IGGIELGN_LNGs.geojson",')
    (134, '            entry="data/gas_network/scigrid-gas/data/IGGIELGN_BorderPoints.geojson",')
    (135, '            production="data/gas_network/scigrid-gas/data/IGGIELGN_Productions.geojson",')
    (136, '            planned_lng="data/gas_network/planned_LNGs.csv",')
    (137, '            regions_onshore=pypsaeur("resources/regions_onshore_elec_s{simpl}_{clusters}.geojson"),')
    (138, "            regions_offshore=pypsaeur(\\'resources/regions_offshore_elec_s{simpl}_{clusters}.geojson\\')")
    (139, '        output:')
    (140, '            gas_input_nodes="resources/gas_input_locations_s{simpl}_{clusters}.geojson",')
    (141, '            gas_input_nodes_simplified="resources/gas_input_locations_s{simpl}_{clusters}_simplified.csv"')
    (142, '        resources: mem_mb=2000,')
    (143, '        script: "scripts/build_gas_input_locations.py"')
    (144, '')
    (145, '')
    (146, '    rule cluster_gas_network:')
    (147, '        input:')
    (148, '            cleaned_gas_network="resources/gas_network.csv",')
    (149, '            regions_onshore=pypsaeur("resources/regions_onshore_elec_s{simpl}_{clusters}.geojson"),')
    (150, '            regions_offshore=pypsaeur("resources/regions_offshore_elec_s{simpl}_{clusters}.geojson")')
    (151, '        output:')
    (152, '            clustered_gas_network="resources/gas_network_elec_s{simpl}_{clusters}.csv"')
    (153, '        resources: mem_mb=4000')
    (154, '        script: "scripts/cluster_gas_network.py"')
    (155, '')
    (156, '')
    (157, '    gas_infrastructure = {**rules.cluster_gas_network.output, **rules.build_gas_input_locations.output}')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=PyPSA/pypsa-eur-sec, file=Snakefile
context_key: ['if config["sector"]["biomass_transport"]', 'rule build_biomass_transport_costs', 'input']
    (271, 'if config["sector"]["biomass_transport"]:')
    (272, '    rule build_biomass_transport_costs:')
    (273, '        input:')
    (274, '            transport_cost_data=HTTP.remote("publications.jrc.ec.europa.eu/repository/bitstream/JRC98626/biomass potentials in europe_web rev.pdf", keep_local=True)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=PyPSA/pypsa-eur-sec, file=Snakefile
context_key: ['if config["sector"]["biomass_transport"]', 'rule build_biomass_transport_costs', 'output']
    (275, '        output:')
    (276, '            biomass_transport_costs="resources/biomass_transport_costs.csv",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=PyPSA/pypsa-eur-sec, file=Snakefile
context_key: ['if config["sector"]["biomass_transport"]', 'rule build_biomass_transport_costs', 'threads']
    (277, '        threads: 1')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=PyPSA/pypsa-eur-sec, file=Snakefile
context_key: ['if config["sector"]["biomass_transport"]', 'rule build_biomass_transport_costs', 'resources']
    (278, '        resources: mem_mb=1000')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=PyPSA/pypsa-eur-sec, file=Snakefile
context_key: ['if config["sector"]["biomass_transport"]', 'rule build_biomass_transport_costs', 'benchmark']
    (279, '        benchmark: "benchmarks/build_biomass_transport_costs"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=PyPSA/pypsa-eur-sec, file=Snakefile
context_key: ['if config["sector"]["biomass_transport"]', 'rule build_biomass_transport_costs', 'script']
    (280, "        script: \\'scripts/build_biomass_transport_costs.py\\'")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=PyPSA/pypsa-eur-sec, file=Snakefile
context_key: ['if config["sector"]["biomass_transport"]']
    (281, '    build_biomass_transport_costs_output = rules.build_biomass_transport_costs.output')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=PyPSA/pypsa-eur-sec, file=Snakefile
context_key: ['if config["sector"]["retrofitting"]["retro_endogen"]', 'rule build_retro_cost', 'input']
    (409, 'if config["sector"]["retrofitting"]["retro_endogen"]:')
    (410, '    rule build_retro_cost:')
    (411, '        input:')
    (412, '            building_stock="data/retro/data_building_stock.csv",')
    (413, '            data_tabula="data/retro/tabula-calculator-calcsetbuilding.csv",')
    (414, '            air_temperature = "resources/temp_air_total_elec_s{simpl}_{clusters}.nc",')
    (415, '            u_values_PL="data/retro/u_values_poland.csv",')
    (416, '            tax_w="data/retro/electricity_taxes_eu.csv",')
    (417, '            construction_index="data/retro/comparative_level_investment.csv",')
    (418, '            floor_area_missing="data/retro/floor_area_missing.csv",')
    (419, '            clustered_pop_layout="resources/pop_layout_elec_s{simpl}_{clusters}.csv",')
    (420, '            cost_germany="data/retro/retro_cost_germany.csv",')
    (421, '            window_assumptions="data/retro/window_assumptions.csv",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=PyPSA/pypsa-eur-sec, file=Snakefile
context_key: ['if config["sector"]["retrofitting"]["retro_endogen"]', 'rule build_retro_cost', 'output']
    (422, '        output:')
    (423, '            retro_cost="resources/retro_cost_elec_s{simpl}_{clusters}.csv",')
    (424, '            floor_area="resources/floor_area_elec_s{simpl}_{clusters}.csv"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=PyPSA/pypsa-eur-sec, file=Snakefile
context_key: ['if config["sector"]["retrofitting"]["retro_endogen"]', 'rule build_retro_cost', 'resources']
    (425, '        resources: mem_mb=1000')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=PyPSA/pypsa-eur-sec, file=Snakefile
context_key: ['if config["sector"]["retrofitting"]["retro_endogen"]', 'rule build_retro_cost', 'benchmark']
    (426, '        benchmark: "benchmarks/build_retro_cost/s{simpl}_{clusters}"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=PyPSA/pypsa-eur-sec, file=Snakefile
context_key: ['if config["sector"]["retrofitting"]["retro_endogen"]', 'rule build_retro_cost', 'script']
    (427, '        script: "scripts/build_retro_cost.py"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=PyPSA/pypsa-eur-sec, file=Snakefile
context_key: ['if config["sector"]["retrofitting"]["retro_endogen"]']
    (428, '    build_retro_cost_output = rules.build_retro_cost.output')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=PyPSA/pypsa-eur-sec, file=Snakefile
context_key: ['if config["foresight"] == "overnight"', 'rule solve_network', 'input']
    (585, 'if config["foresight"] == "overnight":')
    (586, '')
    (587, '    rule solve_network:')
    (588, '        input:')
    (589, '            overrides="data/override_component_attrs",')
    (590, '            network=RDIR + "/prenetworks/elec_s{simpl}_{clusters}_lv{lv}_{opts}_{sector_opts}_{planning_horizons}.nc",')
    (591, '            costs=CDIR + "costs_{}.csv".format(config[\\\'costs\\\'][\\\'year\\\']),')
    (592, "            config=SDIR + \\'/configs/config.yaml\\'")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=PyPSA/pypsa-eur-sec, file=Snakefile
context_key: ['if config["foresight"] == "overnight"', 'rule solve_network', 'output']
    (593, '        output: RDIR + "/postnetworks/elec_s{simpl}_{clusters}_lv{lv}_{opts}_{sector_opts}_{planning_horizons}.nc"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=PyPSA/pypsa-eur-sec, file=Snakefile
context_key: ['if config["foresight"] == "overnight"', 'rule solve_network', 'shadow']
    (594, '        shadow: "shallow"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=PyPSA/pypsa-eur-sec, file=Snakefile
context_key: ['if config["foresight"] == "overnight"', 'rule solve_network', 'log']
    (595, '        log:')
    (596, '            solver=RDIR + "/logs/elec_s{simpl}_{clusters}_lv{lv}_{opts}_{sector_opts}_{planning_horizons}_solver.log",')
    (597, '            python=RDIR + "/logs/elec_s{simpl}_{clusters}_lv{lv}_{opts}_{sector_opts}_{planning_horizons}_python.log",')
    (598, '            memory=RDIR + "/logs/elec_s{simpl}_{clusters}_lv{lv}_{opts}_{sector_opts}_{planning_horizons}_memory.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=PyPSA/pypsa-eur-sec, file=Snakefile
context_key: ['if config["foresight"] == "overnight"', 'rule solve_network', 'threads']
    (599, "        threads: config[\\'solving\\'][\\'solver\\'].get(\\'threads\\', 4)")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=PyPSA/pypsa-eur-sec, file=Snakefile
context_key: ['if config["foresight"] == "overnight"', 'rule solve_network', 'resources']
    (600, "        resources: mem_mb=config[\\'solving\\'][\\'mem\\']")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=PyPSA/pypsa-eur-sec, file=Snakefile
context_key: ['if config["foresight"] == "overnight"', 'rule solve_network', 'benchmark']
    (601, '        benchmark: RDIR + "/benchmarks/solve_network/elec_s{simpl}_{clusters}_lv{lv}_{opts}_{sector_opts}_{planning_horizons}"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=PyPSA/pypsa-eur-sec, file=Snakefile
context_key: ['if config["foresight"] == "overnight"', 'rule solve_network', 'script']
    (602, '        script: "scripts/solve_network.py"')
    (603, '')
    (604, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=PyPSA/pypsa-eur-sec, file=Snakefile
context_key: ['if config["foresight"] == "myopic"', 'rule add_existing_baseyear', 'input']
    (605, 'if config["foresight"] == "myopic":')
    (606, '')
    (607, '    rule add_existing_baseyear:')
    (608, '        input:')
    (609, '            overrides="data/override_component_attrs",')
    (610, "            network=RDIR + \\'/prenetworks/elec_s{simpl}_{clusters}_lv{lv}_{opts}_{sector_opts}_{planning_horizons}.nc\\',")
    (611, "            powerplants=pypsaeur(\\'resources/powerplants.csv\\'),")
    (612, '            busmap_s=pypsaeur("resources/busmap_elec_s{simpl}.csv"),')
    (613, '            busmap=pypsaeur("resources/busmap_elec_s{simpl}_{clusters}.csv"),')
    (614, '            clustered_pop_layout="resources/pop_layout_elec_s{simpl}_{clusters}.csv",')
    (615, '            costs=CDIR + "costs_{}.csv".format(config[\\\'scenario\\\'][\\\'planning_horizons\\\'][0]),')
    (616, '            cop_soil_total="resources/cop_soil_total_elec_s{simpl}_{clusters}.nc",')
    (617, '            cop_air_total="resources/cop_air_total_elec_s{simpl}_{clusters}.nc",')
    (618, "            existing_heating=\\'data/existing_infrastructure/existing_heating_raw.csv\\',")
    (619, "            country_codes=\\'data/Country_codes.csv\\',")
    (620, "            existing_solar=\\'data/existing_infrastructure/solar_capacity_IRENA.csv\\',")
    (621, "            existing_onwind=\\'data/existing_infrastructure/onwind_capacity_IRENA.csv\\',")
    (622, "            existing_offwind=\\'data/existing_infrastructure/offwind_capacity_IRENA.csv\\',")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=PyPSA/pypsa-eur-sec, file=Snakefile
context_key: ['if config["foresight"] == "myopic"', 'rule add_existing_baseyear', 'output']
    (623, "        output: RDIR + \\'/prenetworks-brownfield/elec_s{simpl}_{clusters}_lv{lv}_{opts}_{sector_opts}_{planning_horizons}.nc\\'")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=PyPSA/pypsa-eur-sec, file=Snakefile
context_key: ['if config["foresight"] == "myopic"', 'rule add_existing_baseyear', 'wildcard_constraints']
    (624, '        wildcard_constraints:')
    (625, "            planning_horizons=config[\\'scenario\\'][\\'planning_horizons\\'][0] #only applies to baseyear")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=PyPSA/pypsa-eur-sec, file=Snakefile
context_key: ['if config["foresight"] == "myopic"', 'rule add_existing_baseyear', 'threads']
    (626, '        threads: 1')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=PyPSA/pypsa-eur-sec, file=Snakefile
context_key: ['if config["foresight"] == "myopic"', 'rule add_existing_baseyear', 'resources']
    (627, '        resources: mem_mb=2000')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=PyPSA/pypsa-eur-sec, file=Snakefile
context_key: ['if config["foresight"] == "myopic"', 'rule add_existing_baseyear', 'benchmark']
    (628, "        benchmark: RDIR + \\'/benchmarks/add_existing_baseyear/elec_s{simpl}_{clusters}_lv{lv}_{opts}_{sector_opts}_{planning_horizons}\\'")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=PyPSA/pypsa-eur-sec, file=Snakefile
context_key: ['if config["foresight"] == "myopic"', 'rule add_existing_baseyear', 'script']
    (629, '        script: "scripts/add_existing_baseyear.py"')
    (630, '')
    (631, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=nioo-knaw/PhyloFunDB, file=Snakefile
context_key: ["if config[\\'framebot_db\\'] == True", 'rule framebot', 'input']
    (121, "if config[\\'framebot_db\\'] == True:")
    (122, '    rule framebot:')
    (123, '        input:')
    (124, '            fasta="interm/{gene}.renamed.pick.trim.fasta",')
    (125, '            db_framebot="dbs/{gene}.fungene.clean.fasta"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=nioo-knaw/PhyloFunDB, file=Snakefile
context_key: ["if config[\\'framebot_db\\'] == True", 'rule framebot', 'output']
    (126, '        output:')
    (127, '            "interm/{gene}.framebot_corr_nucl.fasta"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=nioo-knaw/PhyloFunDB, file=Snakefile
context_key: ["if config[\\'framebot_db\\'] == True", 'rule framebot', 'params']
    (128, '        params:')
    (129, '            "interm/{gene}.framebot"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=nioo-knaw/PhyloFunDB, file=Snakefile
context_key: ["if config[\\'framebot_db\\'] == True", 'rule framebot', 'conda']
    (130, '        conda:')
    (131, '            "envs/rdptools.yaml"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=nioo-knaw/PhyloFunDB, file=Snakefile
context_key: ["if config[\\'framebot_db\\'] == True", 'rule framebot', 'shell']
    (132, '        shell:')
    (133, '            "FrameBot framebot -o {params} -N {input.db_framebot} {input.fasta}"')
    (134, '       ')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=nioo-knaw/PhyloFunDB, file=Snakefile
context_key: ["if config[\\'update\\']", 'rule cat_EPA', 'input']
    (348, "if config[\\'update\\']:")
    (349, '    rule cat_EPA:')
    (350, '        input:')
    (351, '           fasta_new=expand("interm/{gene}.aligned.good.filter.unique.pick.good.filter.an.{cutoff_otu}.rep.fasta", gene=config["gene"], cutoff_otu=config["cutoff_otu"]),')
    (352, "           fasta=config[\\'path_to_seqs\\']")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=nioo-knaw/PhyloFunDB, file=Snakefile
context_key: ["if config[\\'update\\']", 'rule cat_EPA', 'output']
    (353, '        output:')
    (354, '            "interm/new.{gene}.fasta"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=nioo-knaw/PhyloFunDB, file=Snakefile
context_key: ["if config[\\'update\\']", 'rule cat_EPA', 'shell']
    (355, '        shell:')
    (356, '            """')
    (357, '            cat {input.fasta_new} {input.fasta} > {output}')
    (358, '            """')
    (359, '            ')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=nioo-knaw/PhyloFunDB, file=Snakefile
context_key: ["if config[\\'update\\']", 'rule align_EPA', 'input']
    (360, '    rule align_EPA:')
    (361, '        input:')
    (362, '           "interm/new.{gene}.fasta"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=nioo-knaw/PhyloFunDB, file=Snakefile
context_key: ["if config[\\'update\\']", 'rule align_EPA', 'output']
    (363, '        output:')
    (364, '            "interm/new.{gene}.aligned.fasta"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=nioo-knaw/PhyloFunDB, file=Snakefile
context_key: ["if config[\\'update\\']", 'rule align_EPA', 'conda']
    (365, '        conda:')
    (366, '            "envs/mafft.yaml"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=nioo-knaw/PhyloFunDB, file=Snakefile
context_key: ["if config[\\'update\\']", 'rule align_EPA', 'threads']
    (367, '        threads:10')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=nioo-knaw/PhyloFunDB, file=Snakefile
context_key: ["if config[\\'update\\']", 'rule align_EPA', 'shell']
    (368, '        shell:')
    (369, '            """')
    (370, '            mafft --thread {threads} --auto {input} >{output}')
    (371, '            """')
    (372, '            ')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=nioo-knaw/PhyloFunDB, file=Snakefile
context_key: ["if config[\\'update\\']", 'rule EPA', 'input']
    (373, '    rule EPA:')
    (374, '        input:')
    (375, '           fasta="interm/new.{gene}.aligned.fasta",')
    (376, "           tree=config[\\'path_to_tree\\']")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=nioo-knaw/PhyloFunDB, file=Snakefile
context_key: ["if config[\\'update\\']", 'rule EPA', 'output']
    (377, '        output:')
    (378, '            "RAxML_labelledTree.{gene}"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=nioo-knaw/PhyloFunDB, file=Snakefile
context_key: ["if config[\\'update\\']", 'rule EPA', 'params']
    (379, '        params:')
    (380, '            "{gene}"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=nioo-knaw/PhyloFunDB, file=Snakefile
context_key: ["if config[\\'update\\']", 'rule EPA', 'conda']
    (381, '        conda:')
    (382, '            "envs/raxml.yaml"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=nioo-knaw/PhyloFunDB, file=Snakefile
context_key: ["if config[\\'update\\']", 'rule EPA', 'threads']
    (383, '        threads:10')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=nioo-knaw/PhyloFunDB, file=Snakefile
context_key: ["if config[\\'update\\']", 'rule EPA', 'shell']
    (384, '        shell:')
    (385, '            """')
    (386, '            raxmlHPC -f v -s {input.fasta} -t {input.tree} -m GTRCAT -H -n {params}')
    (387, '            """')
    (388, '            ')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=nioo-knaw/PhyloFunDB, file=Snakefile
context_key: ["if config[\\'update\\']", 'rule cat_db', 'input']
    (389, '    rule cat_db:')
    (390, '        input:')
    (391, '           fasta_new="results/{gene}.aligned.good.filter.unique.pick.good.filter.redundant.fasta",')
    (392, "           fasta_db=config[\\'path_to_db\\']")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=nioo-knaw/PhyloFunDB, file=Snakefile
context_key: ["if config[\\'update\\']", 'rule cat_db', 'output']
    (393, '        output:')
    (394, '            "results/new.{gene}.db.fasta"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=nioo-knaw/PhyloFunDB, file=Snakefile
context_key: ["if config[\\'update\\']", 'rule cat_db', 'shell']
    (395, '        shell:')
    (396, '            """')
    (397, '            cat {input.fasta_new} {input.fasta_db} > {output}')
    (398, '            """')
    (399, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=arabidopsisca/snakemake-rna-seq-kallisto-sleuth, file=workflow/Snakefile
context_key: ['if config["enrichment"]["goatools"]["activate"]']
    (15, '    if config["enrichment"]["goatools"]["activate"]:')
    (16, '        wanted_input.extend(')
    (17, '                expand(')
    (18, '                    [')
    (19, '                        "results/tables/go_terms/{model}.genes-mostsigtrans.diffexp.go_term_enrichment.gene_fdr_{gene_fdr}.go_term_fdr_{go_term_fdr}.tsv",')
    (20, '                        "results/plots/go_terms/{model}.genes-mostsigtrans.diffexp.go_term_enrichment_{go_ns}.gene_fdr_{gene_fdr}.go_term_fdr_{go_term_fdr}.pdf"')
    (21, '                    ],')
    (22, '                    model=config["diffexp"]["models"],')
    (23, '                    go_ns=["BP", "CC", "MF"],')
    (24, '                    gene_fdr=str(config["enrichment"]["goatools"]["fdr_genes"]).replace(\\\'.\\\',\\\'-\\\'),')
    (25, '                    go_term_fdr=str(config["enrichment"]["goatools"]["fdr_go_terms"]).replace(\\\'.\\\',\\\'-\\\')')
    (26, '                )')
    (27, '            )')
    (28, '')
    (29, "    # request fgsea if \\'activated\\' in config.yaml")
    (30, '    if config["enrichment"]["fgsea"]["activate"]:')
    (31, '        wanted_input.extend(')
    (32, '                expand(')
    (33, '                    [')
    (34, '                        "results/tables/fgsea/{model}.all-gene-sets.tsv",')
    (35, '                        "results/tables/fgsea/{model}.sig-gene-sets.tsv",')
    (36, '                        "results/plots/fgsea/{model}.table-plot.pdf",')
    (37, '                        "results/plots/fgsea/{model}"')
    (38, '                    ],')
    (39, '                    model=config["diffexp"]["models"],')
    (40, '                    gene_set_fdr=str(config["enrichment"]["fgsea"]["fdr_gene_set"]).replace(\\\'.\\\',\\\'-\\\'),')
    (41, '                    nperm=str(config["enrichment"]["fgsea"]["nperm"])')
    (42, '                )')
    (43, '            )')
    (44, '')
    (45, "    # request spia if \\'activated\\' in config.yaml")
    (46, '    if config["enrichment"]["spia"]["activate"]:')
    (47, '        wanted_input.extend(')
    (48, '                expand(')
    (49, '                    [ "results/tables/pathways/{model}.pathways.tsv" ],')
    (50, '                    model=config["diffexp"]["models"],')
    (51, '                )')
    (52, '            )')
    (53, '')
    (54, '    # workflow output that is always wanted')
    (55, '')
    (56, '    # general sleuth output')
    (57, '    wanted_input.extend(')
    (58, '            expand(')
    (59, '                [')
    (60, '                    "results/plots/mean-var/{model}.mean-variance-plot.pdf",')
    (61, '                    "results/plots/volcano/{model}.volcano-plots.pdf",')
    (62, '                    "results/plots/ma/{model}.ma-plots.pdf",')
    (63, '                    "results/plots/qq/{model}.qq-plots.pdf",')
    (64, '                    "results/tables/diffexp/{model}.transcripts.diffexp.tsv",')
    (65, '                    "results/plots/diffexp-heatmap/{model}.diffexp-heatmap.pdf",')
    (66, '                    "results/tables/tpm-matrix/{model}.tpm-matrix.tsv",')
    (67, '                ],')
    (68, '                model=config["diffexp"]["models"]')
    (69, '            )')
    (70, '        )')
    (71, '        ')
    (72, '    # ihw false discovery rate control')
    (73, '    wanted_input.extend(')
    (74, '            expand(')
    (75, '                [')
    (76, '                    "results/tables/ihw/{model}.{level}.ihw-results.tsv",')
    (77, '                    "results/plots/ihw/{level}/{model}.{level}.plot-dispersion.pdf",')
    (78, '                    "results/plots/ihw/{level}/{model}.{level}.plot-histograms.pdf",')
    (79, '                    "results/plots/ihw/{level}/{model}.{level}.plot-trends.pdf",')
    (80, '                    "results/plots/ihw/{level}/{model}.{level}.plot-decision.pdf",')
    (81, '                    "results/plots/ihw/{level}/{model}.{level}.plot-adj-pvals.pdf"')
    (82, '                ],')
    (83, '                model=config["diffexp"]["models"],')
    (84, '                level=["transcripts", "genes-aggregated", "genes-mostsigtrans"]')
    (85, '            )')
    (86, '        )')
    (87, '')
    (88, '    # sleuth p-value histogram plots')
    (89, '    wanted_input.extend(')
    (90, '            expand("results/plots/diffexp/{model}.{level}.diffexp-pval-hist.pdf",')
    (91, '                model=config["diffexp"]["models"],')
    (92, '                level=["transcripts", "genes-aggregated", "genes-mostsigtrans" ]')
    (93, '            )')
    (94, '        )')
    (95, '')
    (96, '    # technical variance vs. observed variance')
    (97, '    #wanted_input.extend(')
    (98, '    #        expand("results/plots/variance/{model}.transcripts.plot_vars.pdf", model=config["diffexp"]["models"]),')
    (99, '    #    )')
    (100, '')
    (101, '    # PCA plots of kallisto results, each coloured for a different covariate')
    (102, '    wanted_input.extend(')
    (103, '            expand([')
    (104, '                       "results/plots/pc-variance/{covariate}.pc-variance-plot.pdf",')
    (105, '                       "results/plots/loadings/{covariate}.loadings-plot.pdf",')
    (106, '                       "results/plots/pca/{covariate}.pca.pdf"')
    (107, '                   ],')
    (108, '                   covariate=samples.columns[samples.columns != "sample"])')
    (109, '        )')
    (110, '')
    (111, '    # group-density plot')
    (112, '    wanted_input.extend(')
    (113, '             expand(["results/plots/group_density/{model}.group_density.pdf"],')
    (114, '                 model=config["diffexp"]["models"])')
    (115, '        )')
    (116, '')
    (117, '    # scatter plots')
    (118, '    if config["scatter"]["activate"]:')
    (119, '        wanted_input.extend(')
    (120, '                  expand(["results/plots/scatter/{model}.scatter.pdf"],')
    (121, '                      model=config["diffexp"]["models"])')
    (122, '        )')
    (123, '')
    (124, '    # sleuth bootstrap plots')
    (125, '    wanted_input.extend(')
    (126, '            expand("results/plots/bootstrap/{model}",')
    (127, '                model=config["diffexp"]["models"]')
    (128, '            )')
    (129, '        )')
    (130, '')
    (131, '    # fragment length distribution plots')
    (132, '    wanted_input.extend(')
    (133, '            expand("results/plots/fld/{unit.sample}-{unit.unit}.fragment-length-dist.pdf",')
    (134, '                unit=units[["sample", "unit"]].itertuples()')
    (135, '            )')
    (136, '        )')
    (137, '')
    (138, '    return wanted_input')
    (139, '')
    (140, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AliSaadatV/Variant_Calling_Snakemake, file=workflow/Snakefile
context_key: ['if config[\\\'PED\\\'] != ""', 'rule all', 'input']
    (124, 'if config[\\\'PED\\\'] != "":')
    (125, '    rule all:')
    (126, '        input:')
    (127, '            expand("../results/qc/fastqc/{sample}_R{read}_fastqc.html", sample = SAMPLES, read = [1, 2]),')
    (128, '            "../results/vcf/refined_GQ_denovo.vcf.gz"')
    (129, '')
    (130, '##### Load rules #####')
    (131, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AliSaadatV/Variant_Calling_Snakemake, file=workflow/Snakefile
context_key: ['if config[\\\'FILTER\\\'] == "VQSR"']
    (142, 'if config[\\\'FILTER\\\'] == "VQSR": ')
    (143, '    include: "rules/09_gatk_VQSR.smk"')
    (144, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AliSaadatV/Variant_Calling_Snakemake, file=workflow/Snakefile
context_key: ['if config[\\\'FILTER\\\'] == "HARD"']
    (145, 'if config[\\\'FILTER\\\'] == "HARD": ')
    (146, '    include: "rules/09_gatk_HARD.smk"')
    (147, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AliSaadatV/Variant_Calling_Snakemake, file=workflow/Snakefile
context_key: ['if config[\\\'PED\\\'] != ""']
    (150, 'if config[\\\'PED\\\'] != "":')
    (151, '    include: "rules/11_gatk_denovo.smk"\'')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=KevinLYW366/TBSeqPipe, file=workflow/rules/common.smk
context_key: ['if config["fastq_read_id_format"]']
    (27, 'if config["fastq_read_id_format"]:')
    (28, '    FASTQREAD = "R"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=KevinLYW366/TBSeqPipe, file=workflow/rules/common.smk
context_key: ['if config["fastq_suffix_format"]']
    (32, 'if config["fastq_suffix_format"]:')
    (33, '    FASTQSUFFIX = "fq.gz"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=KevinLYW366/TBSeqPipe, file=workflow/rules/common.smk
context_key: ['if config["data_dir_format"]']
    (38, 'if config["data_dir_format"]:')
    (39, '    DATADIRINDEX = "/{sample}"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=khanlab/greedy_template_neonatal, file=workflow/Snakefile
context_key: ["if config[\\'run_cohort\\'] == None"]
    (6, "if config[\\'run_cohort\\'] == None:")
    (7, "    cohorts = config[\\'cohorts\\']")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=khanlab/greedy_template_neonatal, file=workflow/Snakefile
context_key: ["if config[\\'run_iter\\'] != None", 'rule all_iter', 'input']
    (29, "if config[\\'run_iter\\'] != None:")
    (30, '    rule all_iter:')
    (31, '        input:')
    (32, "             expand(\\'results/cohort-{cohort}/iter_{iter}/template_{channel}.nii.gz\\',cohort=cohorts,channel=channels,iter=config[\\'run_iter\\'])")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=crazyhottommy/Genrich_compare, file=Snakefile
context_key: ['if config["paired_end"]', 'rule merge_fastqs', 'output']
    (99, '        output:')
    (100, '            "01seq/{sample}_R1.fastq.gz", "01seq/{sample}_R2.fastq.gz"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=crazyhottommy/Genrich_compare, file=Snakefile
context_key: ['if config["paired_end"]', 'rule merge_fastqs', 'log']
    (101, '        log: "00log/{sample}_merge_fastq.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=crazyhottommy/Genrich_compare, file=Snakefile
context_key: ['if config["paired_end"]', 'rule merge_fastqs', 'params']
    (102, '        params:')
    (103, '            jobname = "{sample}"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=crazyhottommy/Genrich_compare, file=Snakefile
context_key: ['if config["paired_end"]', 'rule merge_fastqs', 'threads']
    (104, '        threads: 1')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=crazyhottommy/Genrich_compare, file=Snakefile
context_key: ['if config["paired_end"]', 'rule merge_fastqs', 'message']
    (105, '        message: "merging fastqs {input}: {threads} threads"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=crazyhottommy/Genrich_compare, file=Snakefile
context_key: ['if config["paired_end"]', 'rule merge_fastqs', 'shell']
    (106, '        shell:')
    (107, '            """')
    (108, '            gunzip -c {input.r1} | gzip > {output[0]} 2> {log}')
    (109, '            gunzip -c {input.r2} | gzip > {output[1]} 2>> {log}')
    (110, '            """')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=crazyhottommy/Genrich_compare, file=Snakefile
context_key: ['if config["from_fastq"] and config["paired_end"]', 'rule align']
    (144, 'if config["from_fastq"] and config["paired_end"]:')
    (145, '    rule align:')
    (146, '        input:  r1 = "01seq/{sample}_R1.fastq.gz",')
    (147, '                r2 = "01seq/{sample}_R2.fastq.gz"')
    (148, '        output: "03aln/{sample}.sorted.bam", "03aln/{sample}.sorted.bam.bai", "00log/{sample}.align"')
    (149, '        threads: CLUSTER["align"]["n"]')
    (150, '        params:')
    (151, '                jobname = "{sample}",')
    (152, '                ## add read group for bwa mem mapping, change accordingly if you know PL:ILLUMINA, LB:library1 PI:200 etc...')
    (153, '                rg = "@RG\\\\\\\\tID:{sample}\\\\\\\\tSM:{sample}"')
    (154, '        message: "aligning bwa {input}: {threads} threads"')
    (155, '        log:')
    (156, '            bwa = "00log/{sample}.align",')
    (157, '            markdup = "00log/{sample}.markdup"')
    (158, '        run:')
    (159, '            if config["long_reads"]:')
    (160, '                shell(')
    (161, '                    r"""')
    (162, "                    bwa mem -t 5 -M -v 1 -R \\'{params.rg}\\' {config[ref_fa]} {input[0]} {input[1]} 2> {log.bwa} \\\\")
    (163, '                    | samblaster 2> {log.markdup} \\\\')
    (164, '                    | samtools view -Sb -F 4 - \\\\')
    (165, '                    | samtools sort -m 2G -@ 5 -T {output[0]}.tmp -o {output[0]}')
    (166, '                    samtools index {output[0]}')
    (167, '                    """)')
    (168, '            ## short reads < 70bp')
    (169, '            ## Probably one of the most important is how many mismatches you will allow between a read and a potential mapping location for that location to be considered a match.')
    (170, '            ## The default is 4% of the read length, but you can set this to be either another proportion of the read length, or a fixed integer')
    (171, '            else:')
    (172, '                shell(')
    (173, '                    r"""')
    (174, '                    bwa aln -t 5 {config[ref_fa]} {input[0]} 2> {log.bwa} > 03aln/{wildcards.sample}_R1.sai')
    (175, '                    bwa aln -t 5 {config[ref_fa]} {input[1]} 2>> {log.bwa} > 03aln/{wildcards.sample}_R2.sai')
    (176, "                    bwa sampe -s -r \\'{params.rg}\\' {config[ref_fa]} 03aln/{wildcards.sample}_R1.sai 03aln/{wildcards.sample}_R2.sai {input[0]} {input[1]} 2>> {log.bwa} \\\\")
    (177, '                    | samblaster 2> {log.markdup} \\\\')
    (178, '                    | samtools view -Sb -F 4 - \\\\')
    (179, '                    | samtools sort -m 2G -@ 5 -T {output[0]}.tmp -o {output[0]}')
    (180, '                    rm 03aln/{wildcards.sample}_R1.sai 03aln/{wildcards.sample}_R2.sai')
    (181, '                    samtools index {output[0]}')
    (182, '                    """)')
    (183, '')
    (184, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=crazyhottommy/Genrich_compare, file=Snakefile
context_key: ['if config["from_fastq"] and not config["paired_end"]', 'rule align', 'params']
    (185, 'if config["from_fastq"] and not config["paired_end"]:')
    (186, '    rule align:')
    (187, '        input:  "01seq/{sample}.fastq.gz"')
    (188, '        output: "03aln/{sample}.sorted.bam", "03aln/{sample}.sorted.bam.bai", "00log/{sample}.align"')
    (189, '        threads: CLUSTER["align"]["n"]')
    (190, '        params:')
    (191, '                jobname = "{sample}",')
    (192, '                ## add read group for bwa mem mapping, change accordingly if you know PL:ILLUMINA, LB:library1 PI:200 etc...')
    (193, '                rg = "@RG\\\\\\\\tID:{sample}\\\\\\\\tSM:{sample}"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=crazyhottommy/Genrich_compare, file=Snakefile
context_key: ['if config["from_fastq"] and not config["paired_end"]', 'rule align', 'message']
    (194, '        message: "aligning bwa {input}: {threads} threads"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=crazyhottommy/Genrich_compare, file=Snakefile
context_key: ['if config["from_fastq"] and not config["paired_end"]', 'rule align', 'log']
    (195, '        log:')
    (196, '            bwa = "00log/{sample}.align",')
    (197, '            markdup = "00log/{sample}.markdup"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=crazyhottommy/Genrich_compare, file=Snakefile
context_key: ['if config["from_fastq"] and not config["paired_end"]', 'rule align', 'run', 'if config["long_reads"]']
    (198, '        run:')
    (199, '            if config["long_reads"]:')
    (200, '                shell(')
    (201, '                    r"""')
    (202, "                    bwa mem -t 5 -M -v 1 -R \\'{params.rg}\\' {config[ref_fa]} {input} 2> {log.bwa} \\\\")
    (203, '                    | samblaster -r 2> {log.markdup} \\\\')
    (204, '                    | samtools view -Sb -F 4 - \\\\')
    (205, '                    | samtools sort -m 2G -@ 5 -T {output[0]}.tmp -o {output[0]}')
    (206, '                    samtools index {output[0]}')
    (207, '                    """)')
    (208, '            ## short reads < 70bp')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=crazyhottommy/Genrich_compare, file=Snakefile
context_key: ['if config["from_fastq"] and not config["paired_end"]', 'rule align', 'run', 'else']
    (209, '            else:')
    (210, '                shell(')
    (211, '                    r"""')
    (212, '                    bwa aln -t 5 {config[ref_fa]} {input} 2> {log.bwa} > 03aln/{wildcards.sample}.sai')
    (213, "                    bwa samse -r \\'{params.rg}\\' {config[ref_fa]} 03aln/{wildcards.sample}.sai {input} 2>> {log.bwa} \\\\")
    (214, '                    | samblaster -r 2> {log.markdup} \\\\')
    (215, '                    | samtools view -Sb -F 4 - \\\\')
    (216, '                    | samtools sort -m 2G -@ 5 -T {output[0]}.tmp -o {output[0]}')
    (217, '                    rm 03aln/{wildcards.sample}.sai')
    (218, '                    samtools index {output[0]}')
    (219, '                    """)')
    (220, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=hans-vg/snakemake_rnaseq_workflow, file=rules/align.smk
context_key: ['if config["trimming"]["skip"]']
    (1, '    if config["trimming"]["skip"]:')
    (2, '        # no trimming, use raw reads')
    (3, '        return units.loc[(wildcards.sample, wildcards.unit), ["fq1", "fq2"]].dropna()')
    (4, '    else:')
    (5, '        # yes trimming, use trimmed data')
    (6, '        if not is_single_end(**wildcards):')
    (7, '            # paired-end sample')
    (8, '            #print(expand("trimmed/{sample}-{unit}.{group}.fastq.gz", group=[1, 2], **wildcards))')
    (9, '            return expand("trimmed/{sample}-{unit}.{group}.fastq.gz", group=[1, 2], **wildcards)')
    (10, '        # single end sample')
    (11, '        #print("trimmed/{sample}-{unit}.fastq.gz".format(**wildcards))')
    (12, '        return "trimmed/{sample}-{unit}.fastq.gz".format(**wildcards)')
    (13, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=cbg-ethz/SARS-CoV-2_Analysis, file=workflow/rules/data_retrieval.smk
context_key: ['if config["job_grouping_mode"]']
    (17, 'if config["job_grouping_mode"]:')
    (18, "    # to be used with \\'--group-components data_processing=10\\'")
    (19, '    job_resources = {')
    (20, '        "download_fastq": {"mem_mb": 200, "threads": 1},')
    (21, '        "vpipe_trim": {"mem_mb": 200, "threads": 1},')
    (22, '        "bwa_mem": {"mem_mb": 200, "threads": 1},')
    (23, '    }')
    (24, '')
    (25, '')
    (26, '# workflow')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=jaleezyy/covid-19-signal, file=Snakefile
context_key: ["if config[\\'run_breseq\\'] and config[\\'run_freebayes\\']", 'if breseq_ref == ""']
    (170, "if config[\\'run_breseq\\'] and config[\\'run_freebayes\\']:")
    (171, '    if breseq_ref == "":')
    (172, '        print("Invalid BreSeq reference (paramter: breseq_reference) in config file. Please double check and restart")')
    (173, '        exit(1)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=jaleezyy/covid-19-signal, file=Snakefile
context_key: ["if config[\\'run_breseq\\'] and config[\\'run_freebayes\\']", 'rule variant_calling', 'input']
    (174, '    rule variant_calling:')
    (175, '        input:')
    (176, '            rules.breseq.input,')
    (177, '            rules.ivar_variants.input,')
    (178, '            rules.consensus.input,')
    (179, '            rules.freebayes.input')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=jaleezyy/covid-19-signal, file=Snakefile
context_key: ["elif config[\\'run_breseq\\'] and not config[\\'run_freebayes\\']", 'if breseq_ref == ""']
    (180, "elif config[\\'run_breseq\\'] and not config[\\'run_freebayes\\']:")
    (181, '    if breseq_ref == "":')
    (182, '        print("Invalid BreSeq reference (paramter: breseq_reference) in config file. Please double check and restart")')
    (183, '        exit(1)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=jaleezyy/covid-19-signal, file=Snakefile
context_key: ["elif config[\\'run_breseq\\'] and not config[\\'run_freebayes\\']", 'rule variant_calling', 'input']
    (184, '    rule variant_calling:')
    (185, '        input:')
    (186, '            rules.breseq.input,')
    (187, '            rules.ivar_variants.input,')
    (188, '            rules.consensus.input')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=yiolino/snakemake-deepvariant, file=workflow/rules/mapping.smk
context_key: ['if config["processing"]["trimming"]=="fastp"', 'rule fastp_pe', 'input']
    (33, 'if config["processing"]["trimming"]=="fastp":')
    (34, '    rule fastp_pe: ')
    (35, '        input: ')
    (36, '            unpack(get_fastq_for_fastp)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=yiolino/snakemake-deepvariant, file=workflow/rules/mapping.smk
context_key: ['if config["processing"]["trimming"]=="fastp"', 'rule fastp_pe', 'output']
    (37, '        output:')
    (38, '            trimmed=temp(["data/output/trimmed/{sample}.1.fq.gz", "data/output/trimmed/{sample}.2.fq.gz"]),')
    (39, '            html="data/output/qc/fastp/{sample}_fastp.html",')
    (40, '            json="data/output/qc/fastp/{sample}_fastp.json"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=yiolino/snakemake-deepvariant, file=workflow/rules/mapping.smk
context_key: ['if config["processing"]["trimming"]=="fastp"', 'rule fastp_pe', 'log']
    (41, '        log:')
    (42, '            "logs/fastp/{sample}.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=yiolino/snakemake-deepvariant, file=workflow/rules/mapping.smk
context_key: ['if config["processing"]["trimming"]=="fastp"', 'rule fastp_pe', 'params']
    (43, '        params:')
    (44, '            extra=" ".join([*config["params"]["fastp"]])')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=yiolino/snakemake-deepvariant, file=workflow/rules/mapping.smk
context_key: ['if config["processing"]["trimming"]=="fastp"', 'rule fastp_pe', 'threads']
    (45, '        threads: 2')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=yiolino/snakemake-deepvariant, file=workflow/rules/mapping.smk
context_key: ['if config["processing"]["trimming"]=="fastp"', 'rule fastp_pe', 'wrapper']
    (46, '        wrapper:')
    (47, '            "0.50.4/bio/fastp"')
    (48, '')
    (49, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=alexpenson/rna-seq-kallisto-sleuth, file=workflow/Snakefile
context_key: ['if config["enrichment"]["goatools"]["activate"]']
    (15, '    if config["enrichment"]["goatools"]["activate"]:')
    (16, '        wanted_input.extend(')
    (17, '                expand(')
    (18, '                    [')
    (19, '                        "results/tables/go_terms/{model}.genes-mostsigtrans.diffexp.go_term_enrichment.gene_fdr_{gene_fdr}.go_term_fdr_{go_term_fdr}.tsv",')
    (20, '                        "results/plots/go_terms/{model}.genes-mostsigtrans.diffexp.go_term_enrichment_{go_ns}.gene_fdr_{gene_fdr}.go_term_fdr_{go_term_fdr}.pdf"')
    (21, '                    ],')
    (22, '                    model=config["diffexp"]["models"],')
    (23, '                    go_ns=["BP", "CC", "MF"],')
    (24, '                    gene_fdr=str(config["enrichment"]["goatools"]["fdr_genes"]).replace(\\\'.\\\',\\\'-\\\'),')
    (25, '                    go_term_fdr=str(config["enrichment"]["goatools"]["fdr_go_terms"]).replace(\\\'.\\\',\\\'-\\\')')
    (26, '                )')
    (27, '            )')
    (28, '')
    (29, "    # request fgsea if \\'activated\\' in config.yaml")
    (30, '    if config["enrichment"]["fgsea"]["activate"]:')
    (31, '        wanted_input.extend(')
    (32, '                expand(')
    (33, '                    [')
    (34, '                        "results/tables/fgsea/{model}.all-gene-sets.tsv",')
    (35, '                        "results/tables/fgsea/{model}.sig-gene-sets.tsv",')
    (36, '                        "results/plots/fgsea/{model}.table-plot.pdf",')
    (37, '                        "results/plots/fgsea/{model}"')
    (38, '                    ],')
    (39, '                    model=config["diffexp"]["models"],')
    (40, '                    gene_set_fdr=str(config["enrichment"]["fgsea"]["fdr_gene_set"]).replace(\\\'.\\\',\\\'-\\\'),')
    (41, '                    nperm=str(config["enrichment"]["fgsea"]["nperm"])')
    (42, '                )')
    (43, '            )')
    (44, '')
    (45, "    # request spia if \\'activated\\' in config.yaml")
    (46, '    if config["enrichment"]["spia"]["activate"]:')
    (47, '        wanted_input.extend(')
    (48, '                expand(')
    (49, '                    [ "results/tables/pathways/{model}.pathways.tsv" ],')
    (50, '                    model=config["diffexp"]["models"],')
    (51, '                )')
    (52, '            )')
    (53, '')
    (54, '    # workflow output that is always wanted')
    (55, '')
    (56, '    # general sleuth output')
    (57, '    wanted_input.extend(')
    (58, '            expand(')
    (59, '                [')
    (60, '                    "results/plots/mean-var/{model}.mean-variance-plot.pdf",')
    (61, '                    "results/plots/volcano/{model}.volcano-plots.pdf",')
    (62, '                    "results/plots/ma/{model}.ma-plots.pdf",')
    (63, '                    "results/plots/qq/{model}.qq-plots.pdf",')
    (64, '                    "results/tables/diffexp/{model}.transcripts.diffexp.tsv",')
    (65, '                    "results/plots/diffexp-heatmap/{model}.diffexp-heatmap.pdf",')
    (66, '                    "results/tables/tpm-matrix/{model}.tpm-matrix.tsv",')
    (67, '                ],')
    (68, '                model=config["diffexp"]["models"]')
    (69, '            )')
    (70, '        )')
    (71, '        ')
    (72, '    # ihw false discovery rate control')
    (73, '    wanted_input.extend(')
    (74, '            expand(')
    (75, '                [')
    (76, '                    "results/tables/ihw/{model}.{level}.ihw-results.tsv",')
    (77, '                    "results/plots/ihw/{level}/{model}.{level}.plot-dispersion.pdf",')
    (78, '                    "results/plots/ihw/{level}/{model}.{level}.plot-histograms.pdf",')
    (79, '                    "results/plots/ihw/{level}/{model}.{level}.plot-trends.pdf",')
    (80, '                    "results/plots/ihw/{level}/{model}.{level}.plot-decision.pdf",')
    (81, '                    "results/plots/ihw/{level}/{model}.{level}.plot-adj-pvals.pdf"')
    (82, '                ],')
    (83, '                model=config["diffexp"]["models"],')
    (84, '                level=["transcripts", "genes-aggregated", "genes-mostsigtrans"]')
    (85, '            )')
    (86, '        )')
    (87, '')
    (88, '    # sleuth p-value histogram plots')
    (89, '    wanted_input.extend(')
    (90, '            expand("results/plots/diffexp/{model}.{level}.diffexp-pval-hist.pdf",')
    (91, '                model=config["diffexp"]["models"],')
    (92, '                level=["transcripts", "genes-aggregated", "genes-mostsigtrans" ]')
    (93, '            )')
    (94, '        )')
    (95, '')
    (96, '    # technical variance vs. observed variance')
    (97, '    #wanted_input.extend(')
    (98, '    #        expand("results/plots/variance/{model}.transcripts.plot_vars.pdf", model=config["diffexp"]["models"]),')
    (99, '    #    )')
    (100, '')
    (101, '    # PCA plots of kallisto results, each coloured for a different covariate')
    (102, '    wanted_input.extend(')
    (103, '            expand([')
    (104, '                       "results/plots/pc-variance/{covariate}.pc-variance-plot.pdf",')
    (105, '                       "results/plots/loadings/{covariate}.loadings-plot.pdf",')
    (106, '                       "results/plots/pca/{covariate}.pca.pdf"')
    (107, '                   ],')
    (108, '                   covariate=samples.columns[samples.columns != "sample"])')
    (109, '        )')
    (110, '')
    (111, '    # group-density plot')
    (112, '    wanted_input.extend(')
    (113, '             expand(["results/plots/group_density/{model}.group_density.pdf"],')
    (114, '                 model=config["diffexp"]["models"])')
    (115, '        )')
    (116, '')
    (117, '    # scatter plots')
    (118, '    if config["scatter"]["activate"]:')
    (119, '        wanted_input.extend(')
    (120, '                  expand(["results/plots/scatter/{model}.scatter.pdf"],')
    (121, '                      model=config["diffexp"]["models"])')
    (122, '        )')
    (123, '')
    (124, '    # sleuth bootstrap plots')
    (125, '    wanted_input.extend(')
    (126, '            expand("results/plots/bootstrap/{model}",')
    (127, '                model=config["diffexp"]["models"]')
    (128, '            )')
    (129, '        )')
    (130, '')
    (131, '    # fragment length distribution plots')
    (132, '    wanted_input.extend(')
    (133, '            expand("results/plots/fld/{unit.sample}-{unit.unit}.fragment-length-dist.pdf",')
    (134, '                unit=units[["sample", "unit"]].itertuples()')
    (135, '            )')
    (136, '        )')
    (137, '')
    (138, '    return wanted_input')
    (139, '')
    (140, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=cnobles/iGUIDE, file=Snakefile
context_key: ['if config["suppFile"]', 'if not "Supplemental_Info" in config']
    (59, 'if config["suppFile"]:')
    (60, '    if not "Supplemental_Info" in config:')
    (61, '        raise SystemExit(')
    (62, '            "\\')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=cnobles/iGUIDE, file=Snakefile
context_key: ['if config["suppFile"]']
    (63, '  Supplemental_Info parameter missing in config file."')
    (64, '            "\\')
    (65, "  If not including a file, please specify with \\'.\\' .\\")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=cnobles/iGUIDE, file=Snakefile
context_key: ['else', 'if config["Supplemental_Info"] == "."']
    (69, '        if config["Supplemental_Info"] == ".":')
    (70, '            SUPPINFO_PATH = "."')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=cnobles/iGUIDE, file=Snakefile
context_key: ['if config["UMItags"] and not config["Alternate_UMI_Method"]']
    (111, 'if config["UMItags"] and not config["Alternate_UMI_Method"]: ')
    (112, '    REQ_TYPES.append("I2")')
    (113, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=cnobles/iGUIDE, file=Snakefile
context_key: ['if config["Alternate_UMI_Method"]']
    (119, 'if config["Alternate_UMI_Method"]:')
    (120, '    R1_LEAD_ODN=choose_sequence_data(config["R1_Leading_Trim_ODN"], sampleInfo)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=danab9/asa-finalProject, file=workflow/rules/decontamination.smk
context_key: ['input', 'if config["trimming"]["short"]==\\\'False\\\' else "results/fastq/trimmed/short/{sample}_1_P.fastq.gz"']
    (8, '            if config["trimming"]["short"]==\\\'False\\\' else "results/fastq/trimmed/short/{sample}_1_P.fastq.gz",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=danab9/asa-finalProject, file=workflow/rules/decontamination.smk
context_key: ['input', 'if config["trimming"]["short"]==\\\'False\\\' else "results/fastq/trimmed/short/{sample}_2_P.fastq.gz']
    (10, '            if config["trimming"]["short"]==\\\'False\\\' else "results/fastq/trimmed/short/{sample}_2_P.fastq.gz"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=leylabmpi/Struo, file=Snakefile
context_key: ["if config['samples'].shape[0] < 1"]
    (44, "if config['samples'].shape[0] < 1:")
    (45, "    raise ValueError('No genomes remaining after filtering!')")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=metagenome-atlas/genome-annotator, file=rules/genomeproperties.smk
context_key: ["if config[\\'function_predicton\\']==\\'interproscan\\'", 'rule interproscan', 'input']
    (35, "if config[\\'function_predicton\\']==\\'interproscan\\':")
    (36, '')
    (37, '    rule interproscan:')
    (38, '        input:')
    (39, '            faa_input')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=metagenome-atlas/genome-annotator, file=rules/genomeproperties.smk
context_key: ["if config[\\'function_predicton\\']==\\'interproscan\\'", 'rule interproscan', 'output']
    (40, '        output:')
    (41, '            "annotations/interproscan/{genome}.tsv"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=metagenome-atlas/genome-annotator, file=rules/genomeproperties.smk
context_key: ["if config[\\'function_predicton\\']==\\'interproscan\\'", 'rule interproscan', 'params']
    (42, '        params:')
    (43, "            appl=\\'Pfam,TIGRFAM\\',#,PRINTS,Gene3D,ProSiteProfiles")
    (44, "            extra = config[\\'interproscan_extra\\']")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=metagenome-atlas/genome-annotator, file=rules/genomeproperties.smk
context_key: ["if config[\\'function_predicton\\']==\\'interproscan\\'", 'rule interproscan', 'log']
    (45, '        log:')
    (46, '            "logs/interproscan/{genome}.txt"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=metagenome-atlas/genome-annotator, file=rules/genomeproperties.smk
context_key: ["if config[\\'function_predicton\\']==\\'interproscan\\'", 'rule interproscan', 'singularity']
    (47, '        singularity:')
    (48, '            "docker://continuumio/miniconda3:4.4.10"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=metagenome-atlas/genome-annotator, file=rules/genomeproperties.smk
context_key: ["if config[\\'function_predicton\\']==\\'interproscan\\'", 'rule interproscan', 'threads']
    (49, '        threads:')
    (50, "            config[\\'threads_interproscan\\']")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=metagenome-atlas/genome-annotator, file=rules/genomeproperties.smk
context_key: ["if config[\\'function_predicton\\']==\\'interproscan\\'", 'rule interproscan', 'shell']
    (51, '        shell:')
    (52, '            " interproscan.sh "')
    (53, '            " --input {input} "')
    (54, '            " -appl {params.appl}"')
    (55, '            " --disable-precalc "')
    (56, '            " --cpu {threads} "')
    (57, '            " --formats tsv "')
    (58, '            " --outfile {output} "')
    (59, '            " &> >(tee {log}) "')
    (60, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=metagenome-atlas/genome-annotator, file=rules/genomeproperties.smk
context_key: ["if config[\\'function_predicton\\']==\\'interproscan\\'"]
    (61, '    inut_genome_properties=rules.interproscan.output')
    (62, '')
    (63, '')
    (64, '')
    (65, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=nanoporetech/Pore-C-Snakemake, file=rules/common.smk
context_key: ['if config["pore_c_version"] == "rel"']
    (9, 'if config["pore_c_version"] == "rel":')
    (10, '    PORE_C_CONDA_FILE = "../envs/pore_c.yml"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skchronicles/RNA-seek, file=workflow/rules/single-end.smk
context_key: ["if config[\\'options\\'][\\'small_rna\\']", 'rule trim_se']
    (58, "if config[\\'options\\'][\\'small_rna\\']:")
    (59, "    # Run STAR with ENCODE\\'s recommendations for small RNA sequencing.")
    (60, '    # Set the min read legth to ')
    (61, '    rule trim_se:')
    (62, '        """')
    (63, '        Data-processing step to remove adapter sequences and perform quality trimming')
    (64, '        prior to alignment the reference genome.  Adapters are composed of synthetic')
    (65, '        sequences and should be removed prior to alignment.')
    (66, '        @Input:')
    (67, '            Raw FastQ file (scatter)')
    (68, '        @Output:')
    (69, '            Trimmed FastQ file')
    (70, '        """')
    (71, '        input:')
    (72, '            infq=join(workpath,"{name}.R1.fastq.gz"),')
    (73, '        output:')
    (74, '            outfq=temp(join(workpath,trim_dir,"{name}.R1.trim.fastq.gz"))')
    (75, '        params:')
    (76, "            rname=\\'pl:trim_se\\',")
    (77, '            # Exposed Parameters: modify config/templates/tools.json to change defaults')
    (78, "            fastawithadaptersetd=config[\\'bin\\'][pfamily][\\'tool_parameters\\'][\\'FASTAWITHADAPTERSETD\\'],")
    (79, "            leadingquality=config[\\'bin\\'][pfamily][\\'tool_parameters\\'][\\'LEADINGQUALITY\\'],")
    (80, "            trailingquality=config[\\'bin\\'][pfamily][\\'tool_parameters\\'][\\'TRAILINGQUALITY\\'],")
    (81, "            minlen=config[\\'bin\\'][pfamily][\\'tool_parameters\\'][\\'MINLEN\\'],")
    (82, '        threads: int(allocated("threads", "trim_se", cluster)),')
    (83, "        envmodules: config[\\'bin\\'][pfamily][\\'tool_versions\\'][\\'CUTADAPTVER\\']")
    (84, "        container: config[\\'images\\'][\\'cutadapt\\']")
    (85, '        shell: """')
    (86, '        cutadapt --nextseq-trim=2 --trim-n \\\\')
    (87, '            -n 5 -O 5 -q {params.leadingquality},{params.trailingquality} \\\\')
    (88, '            -m 16 -b file:{params.fastawithadaptersetd} -j {threads} \\\\')
    (89, '            -o {output.outfq} {input.infq}')
    (90, '        """')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skchronicles/RNA-seek, file=workflow/rules/single-end.smk
context_key: ["if config[\\'options\\'][\\'star_2_pass_basic\\']", 'rule star_basic']
    (241, "if config[\\'options\\'][\\'star_2_pass_basic\\']:")
    (242, "    # Run STAR with per-sample 2-pass mapping using \\'--twopassMode Basic\\' option")
    (243, '    # STAR will perform the 1st pass mapping, then it will automatically extract')
    (244, '    # splice junctions, insert them into the genome index, and, finally, re-map')
    (245, '    # all reads in the 2nd mapping pass.')
    (246, '    rule star_basic:')
    (247, '        """')
    (248, '        Data processing step to align reads against reference genome using STAR in')
    (249, '        per sample two-pass basic mode. STAR will perform the 1st pass mapping, then')
    (250, '        it will automatically extract splice junctions, insert them into the genome')
    (251, '        index, and, finally, re-map all reads in the 2nd mapping pass. Agian, Splice')
    (252, '        junctions are detected at a per sample level.')
    (253, '        @Input:')
    (254, '            Trimmed FastQ files (scatter)')
    (255, '        @Output:')
    (256, '            Genomic and transcriptomic BAM file')
    (257, '        """')
    (258, '        input:')
    (259, '            file1=join(workpath,trim_dir,"{name}.R1.trim.fastq.gz"),')
    (260, '        output:')
    (261, '            out1=temp(join(workpath,star_dir,"{name}.p2.Aligned.sortedByCoord.out.bam")),')
    (262, '            out2=join(workpath,star_dir,"{name}.p2.ReadsPerGene.out.tab"),')
    (263, '            out3=join(workpath,bams_dir,"{name}.p2.Aligned.toTranscriptome.out.bam"),')
    (264, '            out4=join(workpath,star_dir,"{name}.p2.SJ.out.tab"),')
    (265, '            out5=join(workpath,log_dir,"{name}.p2.Log.final.out"),')
    (266, '        params:')
    (267, "            rname=\\'pl:star_basic\\',")
    (268, '            prefix=join(workpath, star_dir, "{name}.p2"),')
    (269, '            best_rl_script=join("workflow", "scripts", "optimal_read_length.py"),')
    (270, '            # Exposed Parameters: modify config/genomes/{genome}.json to change default')
    (271, "            stardir=config[\\'references\\'][pfamily][\\'GENOME_STARDIR\\'],")
    (272, "            gtffile=config[\\'references\\'][pfamily][\\'GTFFILE\\'],")
    (273, '            # Exposed STAR Parameters: modify config/templates/tools.json to change defaults')
    (274, "            filterintronmotifs=config[\\'bin\\'][pfamily][\\'FILTERINTRONMOTIFS\\'],")
    (275, "            samstrandfield=config[\\'bin\\'][pfamily][\\'SAMSTRANDFIELD\\'],")
    (276, "            filtertype=config[\\'bin\\'][pfamily][\\'FILTERTYPE\\'],")
    (277, "            filtermultimapnmax=config[\\'bin\\'][pfamily][\\'FILTERMULTIMAPNMAX\\'],")
    (278, "            alignsjoverhangmin=config[\\'bin\\'][pfamily][\\'ALIGNSJOVERHANGMIN\\'],")
    (279, "            alignsjdboverhangmin=config[\\'bin\\'][pfamily][\\'ALIGNSJDBOVERHANGMIN\\'],")
    (280, "            filtermismatchnmax=config[\\'bin\\'][pfamily][\\'FILTERMISMATCHNMAX\\'],")
    (281, "            filtermismatchnoverlmax=config[\\'bin\\'][pfamily][\\'FILTERMISMATCHNOVERLMAX\\'],")
    (282, "            alignintronmin=config[\\'bin\\'][pfamily][\\'ALIGNINTRONMIN\\'],")
    (283, "            alignintronmax=config[\\'bin\\'][pfamily][\\'ALIGNINTRONMAX\\'],")
    (284, "            alignmatesgapmax=config[\\'bin\\'][pfamily][\\'ALIGNMATESGAPMAX\\'],")
    (285, "            adapter1=config[\\'bin\\'][pfamily][\\'ADAPTER1\\'],")
    (286, "            adapter2=config[\\'bin\\'][pfamily][\\'ADAPTER2\\'],")
    (287, "            outsamunmapped=config[\\'bin\\'][pfamily][\\'OUTSAMUNMAPPED\\'],")
    (288, "            wigtype=config[\\'bin\\'][pfamily][\\'WIGTYPE\\'],")
    (289, "            wigstrand=config[\\'bin\\'][pfamily][\\'WIGSTRAND\\'],")
    (290, "            nbjuncs=config[\\'bin\\'][pfamily][\\'NBJUNCS\\'],")
    (291, '            tmpdir=tmpdir,')
    (292, '        threads: int(allocated("threads", "star_basic", cluster)),')
    (293, "        envmodules: config[\\'bin\\'][pfamily][\\'tool_versions\\'][\\'STARVER\\']")
    (294, "        container: config[\\'images\\'][\\'arriba\\']")
    (295, '        shell: """')
    (296, '        # Setups temporary directory for')
    (297, '        # intermediate files with built-in ')
    (298, '        # mechanism for deletion on exit')
    (299, '        if [ ! -d "{params.tmpdir}" ]; then mkdir -p "{params.tmpdir}"; fi')
    (300, '        tmp=$(mktemp -d -p "{params.tmpdir}")')
    (301, '        trap \\\'rm -rf "${{tmp}}"\\\' EXIT')
    (302, '')
    (303, '        # Optimal readlength for sjdbOverhang = max(ReadLength) - 1 [Default: 100]')
    (304, "        readlength=$(zcat {input.file1} | awk -v maxlen=100 \\'NR%4==2 {{if (length($1) > maxlen+0) maxlen=length($1)}}; END {{print maxlen-1}}\\')")
    (305, '        echo "sjdbOverhang for STAR: ${{readlength}}"')
    (306, '')
    (307, '        STAR --genomeDir {params.stardir} \\\\')
    (308, '            --outFilterIntronMotifs {params.filterintronmotifs} \\\\')
    (309, '            --outSAMstrandField {params.samstrandfield} \\\\')
    (310, '            --outFilterType {params.filtertype} \\\\')
    (311, '            --outFilterMultimapNmax {params.filtermultimapnmax} \\\\')
    (312, '            --alignSJoverhangMin {params.alignsjoverhangmin} \\\\')
    (313, '            --alignSJDBoverhangMin {params.alignsjdboverhangmin} \\\\')
    (314, '            --outFilterMismatchNmax {params.filtermismatchnmax} \\\\')
    (315, '            --outFilterMismatchNoverLmax {params.filtermismatchnoverlmax} \\\\')
    (316, '            --alignIntronMin {params.alignintronmin} \\\\')
    (317, '            --alignIntronMax {params.alignintronmax} \\\\')
    (318, '            --alignMatesGapMax {params.alignmatesgapmax} \\\\')
    (319, '            --clip3pAdapterSeq {params.adapter1} {params.adapter2} \\\\')
    (320, '            --readFilesIn {input.file1} --readFilesCommand zcat \\\\')
    (321, '            --runThreadN {threads} \\\\')
    (322, '            --outFileNamePrefix {params.prefix}. \\\\')
    (323, '            --outSAMunmapped {params.outsamunmapped} \\\\')
    (324, '            --outWigType {params.wigtype} \\\\')
    (325, '            --outWigStrand {params.wigstrand} \\\\')
    (326, '            --twopassMode Basic \\\\')
    (327, '            --sjdbGTFfile {params.gtffile} \\\\')
    (328, '            --limitSjdbInsertNsj {params.nbjuncs} \\\\')
    (329, '            --quantMode TranscriptomeSAM GeneCounts \\\\')
    (330, '            --outSAMtype BAM SortedByCoordinate \\\\')
    (331, '            --alignEndsProtrude 10 ConcordantPair \\\\')
    (332, '            --peOverlapNbasesMin 10 \\\\')
    (333, '            --outTmpDir=${{tmp}}/STARtmp_{wildcards.name} \\\\')
    (334, '            --sjdbOverhang ${{readlength}}')
    (335, '')
    (336, '        mv {params.prefix}.Aligned.toTranscriptome.out.bam {workpath}/{bams_dir};')
    (337, '        mv {params.prefix}.Log.final.out {workpath}/{log_dir}')
    (338, '        """')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skchronicles/RNA-seek, file=workflow/rules/single-end.smk
context_key: ["elif config[\\'options\\'][\\'small_rna\\']", 'rule star_small']
    (339, "elif config[\\'options\\'][\\'small_rna\\']:")
    (340, "    # Run STAR with ENCODE\\'s recommendations for small RNA sequencing.")
    (341, '    rule star_small:')
    (342, '        """')
    (343, '        Data processing step to align reads against reference genome using STAR using')
    (344, "        ENCODE\\'s recommendations for small RNA. ")
    (345, '        Please see this links for more information:')
    (346, '        https://www.encodeproject.org/pipelines/ENCPL337CSA/')
    (347, '        https://github.com/ENCODE-DCC/long-rna-seq-pipeline/tree/master/dnanexus/small-rna')
    (348, '        @Input:')
    (349, '            Trimmed FastQ files (scatter)')
    (350, '        @Output:')
    (351, '            Genomic and transcriptomic BAM file')
    (352, '        """')
    (353, '        input:')
    (354, '            file1=join(workpath,trim_dir,"{name}.R1.trim.fastq.gz"),')
    (355, '        output:')
    (356, '            out1=temp(join(workpath,star_dir,"{name}.p2.Aligned.sortedByCoord.out.bam")),')
    (357, '            out2=join(workpath,star_dir,"{name}.p2.ReadsPerGene.out.tab"),')
    (358, '            out3=join(workpath,bams_dir,"{name}.p2.Aligned.toTranscriptome.out.bam"),')
    (359, '            out5=join(workpath,log_dir,"{name}.p2.Log.final.out"),')
    (360, '        params:')
    (361, "            rname=\\'pl:star_small\\',")
    (362, '            prefix=join(workpath, star_dir, "{name}.p2"),')
    (363, '            best_rl_script=join("workflow", "scripts", "optimal_read_length.py"),')
    (364, '            # Exposed Parameters: modify config/genomes/{genome}.json to change default')
    (365, "            stardir=config[\\'references\\'][pfamily][\\'GENOME_STARDIR\\'],")
    (366, "            gtffile=config[\\'references\\'][pfamily][\\'GTFFILE\\'],")
    (367, '            # Exposed STAR Parameters: modify config/templates/tools.json to change defaults')
    (368, "            filterintronmotifs=config[\\'bin\\'][pfamily][\\'FILTERINTRONMOTIFS\\'],")
    (369, "            samstrandfield=config[\\'bin\\'][pfamily][\\'SAMSTRANDFIELD\\'],")
    (370, "            filtertype=config[\\'bin\\'][pfamily][\\'FILTERTYPE\\'],")
    (371, "            filtermultimapnmax=config[\\'bin\\'][pfamily][\\'FILTERMULTIMAPNMAX\\'],")
    (372, "            alignsjoverhangmin=config[\\'bin\\'][pfamily][\\'ALIGNSJOVERHANGMIN\\'],")
    (373, "            alignsjdboverhangmin=config[\\'bin\\'][pfamily][\\'ALIGNSJDBOVERHANGMIN\\'],")
    (374, "            filtermismatchnmax=config[\\'bin\\'][pfamily][\\'FILTERMISMATCHNMAX\\'],")
    (375, "            filtermismatchnoverlmax=config[\\'bin\\'][pfamily][\\'FILTERMISMATCHNOVERLMAX\\'],")
    (376, "            alignintronmin=config[\\'bin\\'][pfamily][\\'ALIGNINTRONMIN\\'],")
    (377, "            alignintronmax=config[\\'bin\\'][pfamily][\\'ALIGNINTRONMAX\\'],")
    (378, "            alignmatesgapmax=config[\\'bin\\'][pfamily][\\'ALIGNMATESGAPMAX\\'],")
    (379, "            adapter1=config[\\'bin\\'][pfamily][\\'ADAPTER1\\'],")
    (380, "            adapter2=config[\\'bin\\'][pfamily][\\'ADAPTER2\\'],")
    (381, "            outsamunmapped=config[\\'bin\\'][pfamily][\\'OUTSAMUNMAPPED\\'],")
    (382, "            wigtype=config[\\'bin\\'][pfamily][\\'WIGTYPE\\'],")
    (383, "            wigstrand=config[\\'bin\\'][pfamily][\\'WIGSTRAND\\'],")
    (384, "            nbjuncs=config[\\'bin\\'][pfamily][\\'NBJUNCS\\'],")
    (385, '            tmpdir=tmpdir,')
    (386, '        threads: int(allocated("threads", "star_small", cluster)),')
    (387, "        envmodules: config[\\'bin\\'][pfamily][\\'tool_versions\\'][\\'STARVER\\']")
    (388, "        container: config[\\'images\\'][\\'arriba\\']")
    (389, '        shell: """')
    (390, '        # Setups temporary directory for')
    (391, '        # intermediate files with built-in ')
    (392, '        # mechanism for deletion on exit')
    (393, '        if [ ! -d "{params.tmpdir}" ]; then mkdir -p "{params.tmpdir}"; fi')
    (394, '        tmp=$(mktemp -d -p "{params.tmpdir}")')
    (395, '        trap \\\'rm -rf "${{tmp}}"\\\' EXIT')
    (396, '')
    (397, '        # Optimal readlength for sjdbOverhang = max(ReadLength) - 1 [Default: 100]')
    (398, "        readlength=$(zcat {input.file1} | awk -v maxlen=100 \\'NR%4==2 {{if (length($1) > maxlen+0) maxlen=length($1)}}; END {{print maxlen-1}}\\')")
    (399, '        echo "sjdbOverhang for STAR: ${{readlength}}"')
    (400, '')
    (401, '        STAR --genomeDir {params.stardir} \\\\')
    (402, '            --outFilterMultimapNmax {params.filtermultimapnmax} \\\\')
    (403, '            --alignSJDBoverhangMin 1000 \\\\')
    (404, '            --outFilterScoreMinOverLread 0 \\\\')
    (405, '            --outFilterMatchNminOverLread 0 \\\\')
    (406, '            --outFilterMatchNmin 16 \\\\')
    (407, '            --outFilterMismatchNoverLmax {params.filtermismatchnoverlmax} \\\\')
    (408, '            --alignIntronMax 1 \\\\')
    (409, '            --clip3pAdapterSeq {params.adapter1} {params.adapter2} \\\\')
    (410, '            --readFilesIn {input.file1} --readFilesCommand zcat \\\\')
    (411, '            --runThreadN {threads} \\\\')
    (412, '            --outFileNamePrefix {params.prefix}. \\\\')
    (413, '            --outSAMunmapped Within \\\\')
    (414, '            --sjdbGTFfile {params.gtffile} \\\\')
    (415, '            --limitSjdbInsertNsj {params.nbjuncs} \\\\')
    (416, '            --quantMode TranscriptomeSAM GeneCounts \\\\')
    (417, '            --outSAMtype BAM Unsorted \\\\')
    (418, '            --outTmpDir=${{tmp}}/STARtmp_{wildcards.name} \\\\')
    (419, '            --sjdbOverhang ${{readlength}}')
    (420, '')
    (421, '        # SAMtools sort (uses less memory than STAR SortedByCoordinate)')
    (422, '        samtools sort -@ {threads} \\\\')
    (423, '            -m 2G -T ${{tmp}}/SORTtmp_{wildcards.name} \\\\')
    (424, '            -O bam {params.prefix}.Aligned.out.bam \\\\')
    (425, '            > {output.out1}')
    (426, '')
    (427, '        rm {params.prefix}.Aligned.out.bam')
    (428, '        mv {params.prefix}.Aligned.toTranscriptome.out.bam {workpath}/{bams_dir};')
    (429, '        mv {params.prefix}.Log.final.out {workpath}/{log_dir}')
    (430, '        """')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skchronicles/RNA-seek, file=workflow/rules/paired-end.smk
context_key: ["if config[\\'options\\'][\\'star_2_pass_basic\\']", 'rule star_basic']
    (261, "if config[\\'options\\'][\\'star_2_pass_basic\\']:")
    (262, "    # Run STAR with per-sample 2-pass mapping using \\'--twopassMode Basic\\' option")
    (263, '    # STAR will perform the 1st pass mapping, then it will automatically extract')
    (264, '    # splice junctions, insert them into the genome index, and, finally, re-map')
    (265, '    # all reads in the 2nd mapping pass.')
    (266, '    rule star_basic:')
    (267, '        """')
    (268, '        Data processing step to align reads against reference genome using STAR in')
    (269, '        two-pass mode. This step represents the second step of STAR. Here set of splice')
    (270, '        all novel junctions that were detected in the first-pass of STAR are then inserted')
    (271, '        into the genome indices. In this second-pass, all reads are re-mapped using')
    (272, '        the annotated junctions from the GTF file and novel junctions that were')
    (273, '        detected in the first-pass of STAR.')
    (274, '        @Input:')
    (275, '            Trimmed FastQ files (scatter)')
    (276, '        @Output:')
    (277, '            Genomic and transcriptomic BAM file')
    (278, '        """')
    (279, '        input:')
    (280, '            file1=join(workpath,trim_dir,"{name}.R1.trim.fastq.gz"),')
    (281, '            file2=join(workpath,trim_dir,"{name}.R2.trim.fastq.gz"),')
    (282, '        output:')
    (283, '            out1=temp(join(workpath,star_dir,"{name}.p2.Aligned.sortedByCoord.out.bam")),')
    (284, '            out2=join(workpath,star_dir,"{name}.p2.ReadsPerGene.out.tab"),')
    (285, '            out3=join(workpath,bams_dir,"{name}.p2.Aligned.toTranscriptome.out.bam"),')
    (286, '            out4=join(workpath,star_dir,"{name}.p2.SJ.out.tab"),')
    (287, '            out5=join(workpath,log_dir,"{name}.p2.Log.final.out"),')
    (288, '        params:')
    (289, "            rname=\\'pl:star_basic\\',")
    (290, '            prefix=join(workpath, star_dir, "{name}.p2"),')
    (291, '            best_rl_script=join("workflow", "scripts", "optimal_read_length.py"),')
    (292, '            # Exposed Parameters: modify config/genomes/{genome}.json to change default')
    (293, "            stardir=config[\\'references\\'][pfamily][\\'GENOME_STARDIR\\'],")
    (294, "            gtffile=config[\\'references\\'][pfamily][\\'GTFFILE\\'],")
    (295, '            # Exposed Parameters: modify config/templates/tools.json to change defaults')
    (296, "            filterintronmotifs=config[\\'bin\\'][pfamily][\\'FILTERINTRONMOTIFS\\'],")
    (297, "            samstrandfield=config[\\'bin\\'][pfamily][\\'SAMSTRANDFIELD\\'],")
    (298, "            filtertype=config[\\'bin\\'][pfamily][\\'FILTERTYPE\\'],")
    (299, "            filtermultimapnmax=config[\\'bin\\'][pfamily][\\'FILTERMULTIMAPNMAX\\'],")
    (300, "            alignsjoverhangmin=config[\\'bin\\'][pfamily][\\'ALIGNSJOVERHANGMIN\\'],")
    (301, "            alignsjdboverhangmin=config[\\'bin\\'][pfamily][\\'ALIGNSJDBOVERHANGMIN\\'],")
    (302, "            filtermismatchnmax=config[\\'bin\\'][pfamily][\\'FILTERMISMATCHNMAX\\'],")
    (303, "            filtermismatchnoverlmax=config[\\'bin\\'][pfamily][\\'FILTERMISMATCHNOVERLMAX\\'],")
    (304, "            alignintronmin=config[\\'bin\\'][pfamily][\\'ALIGNINTRONMIN\\'],")
    (305, "            alignintronmax=config[\\'bin\\'][pfamily][\\'ALIGNINTRONMAX\\'],")
    (306, "            alignmatesgapmax=config[\\'bin\\'][pfamily][\\'ALIGNMATESGAPMAX\\'],")
    (307, "            adapter1=config[\\'bin\\'][pfamily][\\'ADAPTER1\\'],")
    (308, "            adapter2=config[\\'bin\\'][pfamily][\\'ADAPTER2\\'],")
    (309, "            outsamunmapped=config[\\'bin\\'][pfamily][\\'OUTSAMUNMAPPED\\'],")
    (310, "            wigtype=config[\\'bin\\'][pfamily][\\'WIGTYPE\\'],")
    (311, "            wigstrand=config[\\'bin\\'][pfamily][\\'WIGSTRAND\\'],")
    (312, "            nbjuncs=config[\\'bin\\'][pfamily][\\'NBJUNCS\\'],")
    (313, '            tmpdir=tmpdir,')
    (314, '        threads: int(allocated("threads", "star_basic", cluster)),')
    (315, "        envmodules: config[\\'bin\\'][pfamily][\\'tool_versions\\'][\\'STARVER\\']")
    (316, "        container: config[\\'images\\'][\\'arriba\\']")
    (317, '        shell: """')
    (318, '        # Setups temporary directory for')
    (319, '        # intermediate files with built-in ')
    (320, '        # mechanism for deletion on exit')
    (321, '        if [ ! -d "{params.tmpdir}" ]; then mkdir -p "{params.tmpdir}"; fi')
    (322, '        tmp=$(mktemp -d -p "{params.tmpdir}")')
    (323, '        trap \\\'rm -rf "${{tmp}}"\\\' EXIT')
    (324, '')
    (325, '        # Optimal readlength for sjdbOverhang = max(ReadLength) - 1 [Default: 100]')
    (326, '        readlength=$(')
    (327, '            zcat {input.file1} | \\\\')
    (328, "            awk -v maxlen=100 \\'NR%4==2 {{if (length($1) > maxlen+0) maxlen=length($1)}}; \\\\")
    (329, "            END {{print maxlen-1}}\\'")
    (330, '        )')
    (331, '')
    (332, '        echo "sjdbOverhang for STAR: ${{readlength}}"')
    (333, '')
    (334, '        STAR --genomeDir {params.stardir} \\\\')
    (335, '            --outFilterIntronMotifs {params.filterintronmotifs} \\\\')
    (336, '            --outSAMstrandField {params.samstrandfield}  \\\\')
    (337, '            --outFilterType {params.filtertype} \\\\')
    (338, '            --outFilterMultimapNmax {params.filtermultimapnmax} \\\\')
    (339, '            --alignSJoverhangMin {params.alignsjoverhangmin} \\\\')
    (340, '            --alignSJDBoverhangMin {params.alignsjdboverhangmin} \\\\')
    (341, '            --outFilterMismatchNmax {params.filtermismatchnmax} \\\\')
    (342, '            --outFilterMismatchNoverLmax {params.filtermismatchnoverlmax} \\\\')
    (343, '            --alignIntronMin {params.alignintronmin} \\\\')
    (344, '            --alignIntronMax {params.alignintronmax} \\\\')
    (345, '            --alignMatesGapMax {params.alignmatesgapmax} \\\\')
    (346, '            --clip3pAdapterSeq {params.adapter1} {params.adapter2} \\\\')
    (347, '            --readFilesIn {input.file1} {input.file2} \\\\')
    (348, '            --readFilesCommand zcat \\\\')
    (349, '            --runThreadN {threads} \\\\')
    (350, '            --outFileNamePrefix {params.prefix}. \\\\')
    (351, '            --outSAMunmapped {params.outsamunmapped} \\\\')
    (352, '            --outWigType {params.wigtype} \\\\')
    (353, '            --outWigStrand {params.wigstrand} \\\\')
    (354, '            --twopassMode Basic \\\\')
    (355, '            --sjdbGTFfile {params.gtffile} \\\\')
    (356, '            --limitSjdbInsertNsj {params.nbjuncs} \\\\')
    (357, '            --quantMode TranscriptomeSAM GeneCounts \\\\')
    (358, '            --outSAMtype BAM Unsorted \\\\')
    (359, '            --alignEndsProtrude 10 ConcordantPair \\\\')
    (360, '            --peOverlapNbasesMin 10 \\\\')
    (361, '            --outTmpDir=${{tmp}}/STARtmp_{wildcards.name} \\\\')
    (362, '            --sjdbOverhang ${{readlength}}')
    (363, '')
    (364, '        # SAMtools sort (uses less memory than STAR SortedByCoordinate)')
    (365, '        samtools sort -@ {threads} \\\\')
    (366, '            -m 2G -T ${{tmp}}/SORTtmp_{wildcards.name} \\\\')
    (367, '            -O bam {params.prefix}.Aligned.out.bam \\\\')
    (368, '            > {output.out1}')
    (369, '')
    (370, '        rm {params.prefix}.Aligned.out.bam')
    (371, '        mv {params.prefix}.Aligned.toTranscriptome.out.bam {workpath}/{bams_dir};')
    (372, '        mv {params.prefix}.Log.final.out {workpath}/{log_dir}')
    (373, '        """')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=akhanf/greedy_template_camcan, file=workflow/Snakefile
context_key: ["if config[\\'run_cohort\\'] == None"]
    (6, "if config[\\'run_cohort\\'] == None:")
    (7, "    cohorts = config[\\'cohorts\\']")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=akhanf/greedy_template_camcan, file=workflow/Snakefile
context_key: ["if config[\\'run_iter\\'] != None", 'rule all_iter', 'input']
    (36, "if config[\\'run_iter\\'] != None:")
    (37, '    rule all_iter:')
    (38, '        input:')
    (39, "             expand(\\'results/cohort-{cohort}/iter_{iter}/template_{channel}.nii.gz\\',cohort=cohorts,channel=channels,iter=config[\\'run_iter\\'])")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=keyuxi/array_analysis, file=Snakefile
context_key: ['if config["processingType"] == "pre-array"']
    (20, 'if config["processingType"] == "pre-array":')
    (21, '    fluor_files = []')
    (22, '    requested_output = ["%s_STATS.csv" % sequencingResult.strip(\\\'.CPseq\\\'),')
    (23, '                        expand(expdir + "fig/fiducial/{tile}_Bottom_fiducial.png", tile=TILES)]')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=keyuxi/array_analysis, file=Snakefile
context_key: ['elif config["processingType"] == "post-array"', 'if config["fitting"] == "NNN"']
    (24, 'elif config["processingType"] == "post-array":')
    (25, '    fluor_files = get_fluor_names_from_mapfile(config["mapfile"], config["tifdir"], config["fluordir"])')
    (26, '    if config["fitting"] == "NNN":')
    (27, '        requested_output = fittedVariant')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=keyuxi/array_analysis, file=Snakefile
context_key: ['elif config["processingType"] == "post-array"', 'else']
    (28, '    else:')
    (29, '        requested_output = config["seriesfile"]')
    (30, '    ')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=khayer/rna_seq_standard_pipeline, file=workflow/rules/mapping.smk
context_key: ['if config["single_end"]', 'rule salmon_single', 'resources']
    (101, 'if config["single_end"]:')
    (102, '    rule salmon_single:')
    (103, '        input: get_trimmed_reads')
    (104, '        output: "results/quant/salmon_quant_{sample_name}/quant.sf"')
    (105, '        log:    "00log/Salmon_quant_{sample_name}.log"')
    (106, '        conda: "../envs/salmon.yaml"')
    (107, '        resources: ')
    (108, '            cpu = 10,')
    (109, '            mem = "40",')
    (110, '            time = "12:00:00"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=khayer/rna_seq_standard_pipeline, file=workflow/rules/mapping.smk
context_key: ['if config["single_end"]', 'rule salmon_single', 'params']
    (111, '        params: ')
    (112, '            salmon_index = config["salmon_index"],')
    (113, '            tmp_dir = config["tmp_dir"],')
    (114, '            sample_name = "{sample_name}"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=khayer/rna_seq_standard_pipeline, file=workflow/rules/mapping.smk
context_key: ['if config["single_end"]', 'rule salmon_single', 'message']
    (115, '        message: "salmon quant {input}: {resources.cpu} threads / {resources.mem}"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=khayer/rna_seq_standard_pipeline, file=workflow/rules/mapping.smk
context_key: ['if config["single_end"]', 'rule salmon_single', 'shell']
    (116, '        shell:')
    (117, '            """')
    (118, '            salmon quant -i {params.salmon_index} -p {resources.cpu} -l A --validateMappings -r {input[0]} -o results/quant/salmon_quant_{params.sample_name}')
    (119, '            """')
    (120, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=khayer/rna_seq_standard_pipeline, file=workflow/rules/quantification.smk
context_key: ['if config["single_end"]', 'rule run_TPMCalculator', 'resources']
    (17, 'if config["single_end"]:')
    (18, '    rule run_TPMCalculator:')
    (19, '        input: "results/mapped/{sample_name}_Aligned.sortedByCoord.out.bam", "results/mapped/{sample_name}_Aligned.sortedByCoord.out.bam.bai"')
    (20, '        output: "results/mapped/{sample_name}_Aligned.sortedByCoord.out_genes.ent","results/mapped/{sample_name}_Aligned.sortedByCoord.out_genes.out"')
    (21, '        log:    "00log/run_TPMCalculator_{sample_name}.log"')
    (22, '        conda: "../envs/bioinf_tools.yaml"')
    (23, '        resources: ')
    (24, '            cpu = 2,')
    (25, '            mem = "10",')
    (26, '            time = "34:00:00"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=khayer/rna_seq_standard_pipeline, file=workflow/rules/quantification.smk
context_key: ['if config["single_end"]', 'rule run_TPMCalculator', 'params']
    (27, '        params: ')
    (28, '            gtf_anno = config["gtf"],')
    (29, '            in_file = "{sample_name}_Aligned.sortedByCoord.out.bam"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=khayer/rna_seq_standard_pipeline, file=workflow/rules/quantification.smk
context_key: ['if config["single_end"]', 'rule run_TPMCalculator', 'message']
    (30, '        message: "run_TPMCalculator {input}: {resources.cpu} threads / {resources.mem}"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=khayer/rna_seq_standard_pipeline, file=workflow/rules/quantification.smk
context_key: ['if config["single_end"]', 'rule run_TPMCalculator', 'shell']
    (31, '        shell:')
    (32, '            """')
    (33, '            cd results/mapped/')
    (34, '            TPMCalculator -g {params.gtf_anno} -b {params.in_file} -q 200 -e ')
    (35, '            """')
    (36, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SherineAwad/lncRNA, file=Snakefile
context_key: ["if config[\\'PAIRED\\']", 'rule tofasta', 'input']
    (10, "if config[\\'PAIRED\\']:")
    (11, '    rule tofasta:')
    (12, '       input:')
    (13, '           r1 = "{sample}.r_1.fq.gz",')
    (14, '           r2 = "{sample}.r_2.fq.gz"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SherineAwad/lncRNA, file=Snakefile
context_key: ["if config[\\'PAIRED\\']", 'rule tofasta', 'output']
    (15, '       output:')
    (16, '           "{sample}.fasta"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SherineAwad/lncRNA, file=Snakefile
context_key: ["if config[\\'PAIRED\\']", 'rule tofasta', 'conda']
    (17, "       conda: \\'env/env-bbmap.yaml\\'")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SherineAwad/lncRNA, file=Snakefile
context_key: ["if config[\\'PAIRED\\']", 'rule tofasta', 'shell']
    (18, '       shell:')
    (19, '           """')
    (20, '           reformat.sh in={input.r1} in2={input.r2} out={output}')
    (21, '           """')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=pughlab/cfMeDIP-seq-analysis-pipeline, file=Snakefile
context_key: ["if config[\\'data\\'][\\'cohorts\\'][c][\\'active\\']"]
    (537, "    if config[\\'data\\'][\\'cohorts\\'][c][\\'active\\']:")
    (538, "        chr_data = get_cohort_config(c)[\\'chromosomes\\']")
    (539, "        chromosome_tuples = [(species, chrom) for species in chr_data for chrom in chr_data[species].split(\\',\\')]")
    (540, '        chromosomes[c] = chromosome_tuples')
    (541, '')
    (542, '# Merge the bin stats across all chromosomes.')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=TriassicSalamander/nimagen_snakemake, file=Snakefile
context_key: ['if config.get("input_path")']
    (4, 'if config.get("input_path"):')
    (5, '    config["input_path"] = config["input_path"].rstrip(\\\'/\\\')')
    (6, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=TriassicSalamander/nimagen_snakemake, file=Snakefile
context_key: ['if config.get("output_path")']
    (7, 'if config.get("output_path"):')
    (8, '    config["output_path"] = config["output_path"].rstrip(\\\'/\\\')')
    (9, '')
    (10, '')
    (11, '##### Get Sample IDs from Sample Sheet #####')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=bwinnacott/SNP-Pipeline, file=workflow/rules/call_germline.smk
context_key: ["if config[\\'use_freebayes\\']", 'rule Freebayes', 'input']
    (54, "if config[\\'use_freebayes\\']:")
    (55, '    rule Freebayes:')
    (56, '        input:')
    (57, '            ref = ref_dir + ref,')
    (58, '            bam = lambda wc: get_input_bam(wc,calling=True),')
    (59, '            index = lambda wc: get_input_bam(wc,calling=True,ind=True)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=bwinnacott/SNP-Pipeline, file=workflow/rules/call_germline.smk
context_key: ["if config[\\'use_freebayes\\']", 'rule Freebayes', 'params']
    (60, '        params:')
    (61, "            ploidy = config[\\'ploidy\\'],")
    (62, "            min_count = config[\\'min_alternate_count\\'],")
    (63, "            min_freq = config[\\'min_alternate_freq\\'],")
    (64, "            min_cov = config[\\'min_coverage\\'],")
    (65, "            min_map_qual = config[\\'min_map_qual\\'],")
    (66, "            min_base_qual = config[\\'min_base_qual\\'],")
    (67, "            chunksize = config[\\'chunksize\\']")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=bwinnacott/SNP-Pipeline, file=workflow/rules/call_germline.smk
context_key: ["if config[\\'use_freebayes\\']", 'rule Freebayes', 'output']
    (68, '        output:')
    (69, "            \\'../results/{sample}/{aligner}/Freebayes/raw_variants_Freebayes_{sample}.vcf\\'")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=bwinnacott/SNP-Pipeline, file=workflow/rules/call_germline.smk
context_key: ["if config[\\'use_freebayes\\']", 'rule Freebayes', 'conda']
    (70, '        conda:')
    (71, '            "../envs/freebayes.yaml"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=bwinnacott/SNP-Pipeline, file=workflow/rules/call_germline.smk
context_key: ["if config[\\'use_freebayes\\']", 'rule Freebayes', 'threads']
    (72, '        threads:')
    (73, "            max(config[\\'cores\\'],config[\\'free_cores\\'])")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=bwinnacott/SNP-Pipeline, file=workflow/rules/call_germline.smk
context_key: ["if config[\\'use_freebayes\\']", 'rule Freebayes', 'script']
    (74, '        script:')
    (75, "            \\'../scripts/freebayes.py\\'")
    (76, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=bwinnacott/SNP-Pipeline, file=workflow/rules/call_germline.smk
context_key: ["if config[\\'use_freebayes\\']", 'rule FilterFreebayesCalls', 'input']
    (77, '    rule FilterFreebayesCalls:')
    (78, '        input:')
    (79, "            \\'../results/{sample}/{aligner}/Freebayes/raw_variants_Freebayes_{sample}.vcf\\'")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=bwinnacott/SNP-Pipeline, file=workflow/rules/call_germline.smk
context_key: ["if config[\\'use_freebayes\\']", 'rule FilterFreebayesCalls', 'params']
    (80, '        params:')
    (81, "            qual = config[\\'qual_filter_free\\']")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=bwinnacott/SNP-Pipeline, file=workflow/rules/call_germline.smk
context_key: ["if config[\\'use_freebayes\\']", 'rule FilterFreebayesCalls', 'output']
    (82, '        output:')
    (83, "            \\'../results/{sample}/{aligner}/Freebayes/final_Freebayes_variants_{sample}.vcf\\'")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=bwinnacott/SNP-Pipeline, file=workflow/rules/call_germline.smk
context_key: ["if config[\\'use_freebayes\\']", 'rule FilterFreebayesCalls', 'conda']
    (84, '        conda:')
    (85, '            "../envs/freebayes.yaml"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=bwinnacott/SNP-Pipeline, file=workflow/rules/call_germline.smk
context_key: ["if config[\\'use_freebayes\\']", 'rule FilterFreebayesCalls', 'shell']
    (86, '        shell:')
    (87, '            \\\'vcffilter -f "QUAL > {params.qual}" {input} > {output}\\\'')
    (88, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=bwinnacott/SNP-Pipeline, file=workflow/rules/call_germline.smk
context_key: ["if config[\\'use_bcftools\\']", 'rule BcftoolsCall', 'input']
    (89, "if config[\\'use_bcftools\\']:")
    (90, '    rule BcftoolsCall:')
    (91, '        input:')
    (92, '            bam = lambda wc: get_input_bam(wc,calling=True),')
    (93, '            ref = ref_dir + ref')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=bwinnacott/SNP-Pipeline, file=workflow/rules/call_germline.smk
context_key: ["if config[\\'use_bcftools\\']", 'rule BcftoolsCall', 'params']
    (94, '        params:')
    (95, "            ploidy = \\'--ploidy 1 \\' if config[\\'ploidy\\'] == 1 else \\'\\',")
    (96, "            max_dp = config[\\'max_depth\\'],")
    (97, "            min_MQ = config[\\'min_MQ\\'],")
    (98, "            min_BQ = config[\\'min_BQ\\'],")
    (99, "            caller = config[\\'caller\\']")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=bwinnacott/SNP-Pipeline, file=workflow/rules/call_germline.smk
context_key: ["if config[\\'use_bcftools\\']", 'rule BcftoolsCall', 'output']
    (100, '        output:')
    (101, "            \\'../results/{sample}/{aligner}/Bcftools/raw_variants_Bcftools_{sample}.vcf\\'")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=bwinnacott/SNP-Pipeline, file=workflow/rules/call_germline.smk
context_key: ["if config[\\'use_bcftools\\']", 'rule BcftoolsCall', 'conda']
    (102, '        conda:')
    (103, '            "../envs/bcftools.yaml"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=bwinnacott/SNP-Pipeline, file=workflow/rules/call_germline.smk
context_key: ["if config[\\'use_bcftools\\']", 'rule BcftoolsCall', 'threads']
    (104, '        threads:')
    (105, "            max(config[\\'cores\\'],config[\\'bcftools_cores\\'])")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=bwinnacott/SNP-Pipeline, file=workflow/rules/call_germline.smk
context_key: ["if config[\\'use_bcftools\\']", 'rule BcftoolsCall', 'shell']
    (106, '        shell:')
    (107, "            \\'bcftools mpileup -Ou \\'")
    (108, "            \\'--max-depth {params.max_dp} \\'")
    (109, "            \\'--min-MQ {params.min_MQ} \\'")
    (110, "            \\'--min-BQ {params.min_BQ} \\'")
    (111, "            \\'--threads {threads} \\'")
    (112, "            \\'-f {input.ref} {input.bam} | \\'")
    (113, "            \\'bcftools call -Ov -v {params.caller} {params.ploidy}> {output}\\'")
    (114, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=bwinnacott/SNP-Pipeline, file=workflow/rules/call_germline.smk
context_key: ["if config[\\'use_bcftools\\']", 'rule FilterBcftoolsCalls', 'input']
    (115, '    rule FilterBcftoolsCalls:')
    (116, '        input:')
    (117, "            \\'../results/{sample}/{aligner}/Bcftools/raw_variants_Bcftools_{sample}.vcf\\'")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=bwinnacott/SNP-Pipeline, file=workflow/rules/call_germline.smk
context_key: ["if config[\\'use_bcftools\\']", 'rule FilterBcftoolsCalls', 'params']
    (118, '        params:')
    (119, "            qual_filter = config[\\'qual_filter_bcf\\'],")
    (120, "            depth_filter = config[\\'depth_filter_bcf\\']")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=bwinnacott/SNP-Pipeline, file=workflow/rules/call_germline.smk
context_key: ["if config[\\'use_bcftools\\']", 'rule FilterBcftoolsCalls', 'output']
    (121, '        output:')
    (122, "            \\'../results/{sample}/{aligner}/Bcftools/filtered_Bcftools_variants_{sample}.vcf\\',")
    (123, "            \\'../results/{sample}/{aligner}/Bcftools/final_Bcftools_variants_{sample}.vcf\\'")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=bwinnacott/SNP-Pipeline, file=workflow/rules/call_germline.smk
context_key: ["if config[\\'use_bcftools\\']", 'rule FilterBcftoolsCalls', 'conda']
    (124, '        conda:')
    (125, '            "../envs/bcftools.yaml"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=bwinnacott/SNP-Pipeline, file=workflow/rules/call_germline.smk
context_key: ["if config[\\'use_bcftools\\']", 'rule FilterBcftoolsCalls', 'shell']
    (126, '        shell:')
    (127, '            \\\'bcftools filter -s LowQual -i "{params.qual_filter} & {params.depth_filter}" {input} > {output[0]} && \\\'')
    (128, "            \\'bcftools view -f .,PASS {output[0]} > {output[1]}\\''")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=bwinnacott/SNP-Pipeline, file=workflow/Snakefile
context_key: ["if config[\\'apply_bqsr\\']"]
    (64, "if config[\\'apply_bqsr\\']:")
    (65, '    include: "rules/bqsr.smk"')
    (66, '')
    (67, '# call and filter variants')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=bwinnacott/SNP-Pipeline, file=workflow/Snakefile
context_key: ["if config[\\'apply_snpeff\\']", 'rule all', 'input']
    (72, "if config[\\'apply_snpeff\\']:")
    (73, '    include: "rules/variant_annotation.smk"')
    (74, '    # target rule')
    (75, '    rule all:')
    (76, '        input:')
    (77, "            expand(\\'../results/{sample}/final_calls/final_calls_{sample}_snps_snpeff.vcf\\',sample=samples)")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=bwinnacott/SNP-Pipeline, file=workflow/Snakefile
context_key: ["if config[\\'check_ploidy\\']", 'rule all', 'input']
    (85, "if config[\\'check_ploidy\\']:")
    (86, '    include: "rules/ploidy_check.smk"')
    (87, '    # target rule')
    (88, '    rule all:')
    (89, '        input:')
    (90, "            expand(\\'../results/{sample}/final_calls/ploidy_check_report.html\\',sample=samples)")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=tjgibson/NGS-workflow-chipseq, file=workflow/rules/filter.smk
context_key: ['if config["filter_chroms"]', 'else', 'rule samtools_index_filtered', 'input']
    (11, 'if config["filter_chroms"]:')
    (12, '\\trule filter_multireads:')
    (13, '\\t\\tinput:')
    (14, '\\t\\t\\t"results/aligned_reads/sorted/{sample}.bam"')
    (15, '\\t\\toutput:')
    (16, '\\t\\t\\ttemp("results/aligned_reads/unireads/{sample}.bam")')
    (17, '\\t\\tlog:')
    (18, '\\t\\t\\t"logs/filter_multireads/{sample}.log"')
    (19, '\\t\\tparams:')
    (20, '\\t\\t\\textra=config["params"]["filter_multireads"] ')
    (21, '\\t\\tthreads: 8')
    (22, '\\t\\twrapper:')
    (23, '\\t\\t\\t"v1.1.0/bio/sambamba/view"')
    (24, '\\t')
    (25, '\\trule samtools_index_unireads:')
    (26, '\\t\\tinput:')
    (27, '\\t\\t\\t"results/aligned_reads/unireads/{sample}.bam"')
    (28, '\\t\\toutput:')
    (29, '\\t\\t\\ttemp("results/aligned_reads/unireads/{sample}.bam.bai")')
    (30, '\\t\\tlog:')
    (31, '\\t\\t\\t"logs/samtools_index/{sample}.log"')
    (32, '\\t\\tparams:')
    (33, '\\t\\t\\t"" # optional params string')
    (34, '\\t\\tthreads:  # Samtools takes additional threads through its option -@')
    (35, '\\t\\t\\t4     # This value - 1 will be sent to -@')
    (36, '\\t\\twrapper:')
    (37, '\\t\\t\\t"v1.1.0/bio/samtools/index"')
    (38, '\\t')
    (39, '\\trule samtools_idxstats_unireads:')
    (40, '\\t\\tinput:')
    (41, '\\t\\t\\tbam="results/aligned_reads/unireads/{sample}.bam",')
    (42, '\\t\\t\\tidx="results/aligned_reads/unireads/{sample}.bam.bai"')
    (43, '\\t\\toutput:')
    (44, '\\t\\t\\t"results/aligned_reads/stats/{sample}_unireads.idxstats"')
    (45, '\\t\\tlog:')
    (46, '\\t\\t\\t"logs/samtools/idxstats/{sample}.log"')
    (47, '\\t\\twrapper:')
    (48, '\\t\\t\\t"v1.1.0/bio/samtools/idxstats"')
    (49, '\\t')
    (50, '\\trule filter_chroms:')
    (51, '\\t\\tinput:')
    (52, '\\t\\t\\tbam="results/aligned_reads/unireads/{sample}.bam",')
    (53, '\\t\\t\\tkeep_chroms="resources/keep_chroms.bed"')
    (54, '\\t\\toutput:')
    (55, '\\t\\t\\t"results/aligned_reads/filtered/{sample}.bam"')
    (56, '\\t\\tlog:')
    (57, '\\t\\t\\t"logs/filter_chroms/{sample}.log"')
    (58, '\\t\\tconda:')
    (59, '\\t\\t\\t"../envs/samtools.yaml"')
    (60, '\\t\\tshell:')
    (61, '\\t\\t\\t"samtools view -bh -L {input.keep_chroms} --output-fmt BAM -o {output} {input.bam} 2>> {log}"')
    (62, 'else:')
    (63, '\\trule filter_multireads:')
    (64, '\\t\\tinput:')
    (65, '\\t\\t\\t"results/aligned_reads/sorted/{sample}.bam"')
    (66, '\\t\\toutput:')
    (67, '\\t\\t\\t"results/aligned_reads/filtered/{sample}.bam"')
    (68, '\\t\\tlog:')
    (69, '\\t\\t\\t"logs/filter_multireads/{sample}.log"')
    (70, '\\t\\tparams:')
    (71, '\\t\\t\\textra=config["params"]["filter_multireads"] ')
    (72, '\\t\\tthreads: 8')
    (73, '\\t\\twrapper:')
    (74, '\\t\\t\\t"v1.1.0/bio/sambamba/view"')
    (75, '\\t\\t')
    (76, '')
    (77, 'rule samtools_index_filtered:')
    (78, '    input:')
    (79, '        "results/aligned_reads/filtered/{sample}.bam"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=tjgibson/NGS-workflow-chipseq, file=workflow/rules/filter.smk
context_key: ['if config["filter_chroms"]', 'output']
    (80, '    output:')
    (81, '        "results/aligned_reads/filtered/{sample}.bam.bai"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=tjgibson/NGS-workflow-chipseq, file=workflow/rules/filter.smk
context_key: ['if config["filter_chroms"]', 'log']
    (82, '    log:')
    (83, '        "logs/samtools_index/{sample}.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=tjgibson/NGS-workflow-chipseq, file=workflow/rules/filter.smk
context_key: ['if config["filter_chroms"]', 'params']
    (84, '    params:')
    (85, '        "" # optional params string')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=tjgibson/NGS-workflow-chipseq, file=workflow/rules/filter.smk
context_key: ['if config["filter_chroms"]', 'threads']
    (86, '    threads:  # Samtools takes additional threads through its option -@')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=tjgibson/NGS-workflow-chipseq, file=workflow/rules/filter.smk
context_key: ['if config["filter_chroms"]']
    (87, '        4     # This value - 1 will be sent to -@')
    (88, '    wrapper:')
    (89, '        "v1.1.0/bio/samtools/index"')
    (90, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=tjgibson/NGS-workflow-chipseq, file=workflow/rules/ref.smk
context_key: ['if config["use_spikeIn"]', 'else', 'if config["filter_chroms"]', 'rule bowtie2_index']
    (15, 'if config["use_spikeIn"]:')
    (16, '\\trule get_spikeIn_genome:')
    (17, '\\t\\toutput:')
    (18, '\\t\\t\\ttemp("resources/spikeIn_genome.fasta.gz"),')
    (19, '\\t\\tlog:')
    (20, '\\t\\t\\t"logs/get_spikeIn_genome.log",')
    (21, '\\t\\tconda:')
    (22, '\\t\\t\\t"../envs/curl.yaml"')
    (23, '\\t\\tparams:')
    (24, '\\t\\t\\tlink=config["spikeIn_genome"]["link"],')
    (25, '\\t\\tcache: True')
    (26, '\\t\\tshell:')
    (27, '\\t\\t\\t"curl {params.link} > {output} 2> {log}"')
    (28, '')
    (29, '\\trule combine_genomes:')
    (30, '\\t\\tinput:')
    (31, '\\t\\t\\tref="resources/ref_genome.fasta.gz",')
    (32, '\\t\\t\\tspikeIn="resources/spikeIn_genome.fasta.gz",')
    (33, '\\t\\toutput:')
    (34, '\\t\\t\\t"resources/genome.fasta.gz",')
    (35, '\\t\\tlog:')
    (36, '\\t\\t\\t"logs/combine_genomes.log",')
    (37, '\\t\\tconda:')
    (38, '\\t\\t\\t"../envs/seqkit.yaml"')
    (39, '\\t\\tcache: True')
    (40, '\\t\\tshell:')
    (41, '\\t\\t\\t"""')
    (42, '\\t\\t\\tseqkit replace -p "(.+)" -r "spikeIn_\\\\$1" -o resources/tmp_spikeIn.fasta.gz {input.spikeIn} 2> {log}')
    (43, '\\t\\t\\tcat {input.ref} resources/tmp_spikeIn.fasta.gz > {output} 2>> {log}')
    (44, '\\t\\t\\trm resources/tmp_spikeIn.fasta.gz')
    (45, '\\t\\t\\t"""')
    (46, 'else:')
    (47, '\\t\\trule rename_genome:')
    (48, '\\t\\t\\tinput:')
    (49, '\\t\\t\\t\\t"resources/ref_genome.fasta.gz",')
    (50, '\\t\\t\\toutput:')
    (51, '\\t\\t\\t\\t"resources/genome.fasta.gz",')
    (52, '\\t\\t\\tlog:')
    (53, '\\t\\t\\t\\t"logs/rename_genome.log",')
    (54, '\\t\\t\\tcache: True')
    (55, '\\t\\t\\tshell:')
    (56, '\\t\\t\\t\\t"mv {input} {output} 2> {log}"')
    (57, '')
    (58, '\\t\\t\\t\\t')
    (59, 'if config["filter_chroms"]:')
    (60, '\\trule define_keep_chroms:')
    (61, '\\t\\tinput:')
    (62, '\\t\\t\\tgenome="resources/genome.fasta.gz",')
    (63, '\\t\\t\\tkeep_chroms=config["keep_chroms"]')
    (64, '\\t\\toutput:')
    (65, '\\t\\t\\t"resources/keep_chroms.bed",')
    (66, '\\t\\tlog:')
    (67, '\\t\\t\\t"logs/define_keep_chroms.log",')
    (68, '\\t\\tconda:')
    (69, '\\t\\t\\t"../envs/seqkit.yaml"')
    (70, '\\t\\tcache: True')
    (71, '\\t\\tshell:')
    (72, '\\t\\t\\t"seqkit grep -f {input.keep_chroms} {input.genome}"')
    (73, '\\t\\t\\t" | seqkit fx2tab -nil"')
    (74, '\\t\\t\\t" |  awk -v OFS=\\\'\\\\t\\\' \\\'{{print $1, 1, $2}}\\\' > {output}"')
    (75, '\\t\\t\\t\\t')
    (76, 'rule bowtie2_index:')
    (77, '\\tinput:')
    (78, '\\t\\treference="resources/genome.fasta.gz"')
    (79, '\\toutput:')
    (80, '\\t\\tmultiext(')
    (81, '\\t\\t\\t"resources/genome",')
    (82, '\\t\\t\\t".1.bt2", ".2.bt2", ".3.bt2", ".4.bt2", ".rev.1.bt2", ".rev.2.bt2",')
    (83, '\\t\\t),')
    (84, '\\tlog:')
    (85, '\\t\\t"logs/bowtie2_build/build.log"')
    (86, '\\tparams:')
    (87, '\\t\\textra=config["params"]["bowtie2_index"] # optional parameters')
    (88, '\\tthreads: 8')
    (89, '\\twrapper:')
    (90, '\\t\\t"v1.1.0/bio/bowtie2/build"')
    (91, '\\t\\t')
    (92, "'")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=akhanf/ants_build_template_smk, file=workflow/Snakefile
context_key: ["if config[\\'enable_quick_dirty\\'] == True"]
    (20, "if config[\\'enable_quick_dirty\\'] == True:")
    (21, "    config[\\'ants\\'] = config[\\'ants_quick_dirty\\']")
    (22, '')
    (23, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=vgteam/vg_snakemake, file=Snakefile
context_key: ["if config[\\'nb_split_reads\\'] > 0", 'output']
    (224, "if config[\\'nb_split_reads\\'] > 0:")
    (225, '    # split fastq into chunks')
    (226, '    checkpoint split_reads_1:')
    (227, "        input: \\'{sample}/{sample}_1.fastq.gz\\'")
    (228, '        output:')
    (229, "            dir=directory(\\'{sample}/read_chunks/1\\')")
    (230, "        threads: config[\\'cores_split_reads\\']")
    (231, "        benchmark: \\'benchmarks/{sample}-1-splitreads.benchmark.txt\\'")
    (232, '        run:')
    (233, "            NLINES=config[\\'nb_split_reads\\'] * 4")
    (234, "            shell(\\'mkdir -p {output.dir}\\')")
    (235, '            shell("gzip -cd {input} | split -d -l {NLINES} --filter=\\\'pigz -p {threads} > ${{FILE}}.fastq.gz\\\' - \\\\"{output.dir}/{wildcards.sample}_1.part\\\\"")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=vgteam/vg_snakemake, file=Snakefile
context_key: ["if config[\\'nb_split_reads\\'] > 0", 'output']
    (236, '    checkpoint split_reads_2:')
    (237, "        input: \\'{sample}/{sample}_2.fastq.gz\\'")
    (238, '        output:')
    (239, "            dir=directory(\\'{sample}/read_chunks/2\\')")
    (240, "        threads: config[\\'cores_split_reads\\']")
    (241, "        benchmark: \\'benchmarks/{sample}-2-splitreads.benchmark.txt\\'")
    (242, '        run:')
    (243, "            NLINES=config[\\'nb_split_reads\\'] * 4")
    (244, "            shell(\\'mkdir -p {output.dir}\\')")
    (245, '            shell("gzip -cd {input} | split -d -l {NLINES} --filter=\\\'pigz -p {threads} > ${{FILE}}.fastq.gz\\\' - \\\\"{output.dir}/{wildcards.sample}_2.part\\\\"")')
    (246, '    # set the input paths for the mapping rules')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=vgteam/vg_snakemake, file=Snakefile
context_key: ["if config[\\'nb_split_reads\\'] > 0"]
    (247, "    read1_in = \\'{sample}/read_chunks/1/{sample}_1.part{part}.fastq.gz\\'")
    (248, "    read2_in = \\'{sample}/read_chunks/2/{sample}_2.part{part}.fastq.gz\\'")
    (249, "    map_lab = \\'{sample}.part{part}\\'")
    (250, "    map_out = \\'{sample}/read_chunks/{sample}-{genome}-{svs}.part{part}\\'")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=vgteam/vg_snakemake, file=Snakefile
context_key: ["if config[\\'nb_split_reads\\'] > 0"]
    (318, "if config[\\'nb_split_reads\\'] > 0:")
    (319, '    # merge aligned reads')
    (320, '    def aggregate_reads(wildcards):')
    (321, '        checkpoint_output = checkpoints.split_reads_1.get(**wildcards).output[0]')
    (322, '        checkpoint_output2 = checkpoints.split_reads_2.get(**wildcards).output[0]')
    (323, '        return expand("{sample}/read_chunks/{sample}-{graph}.part{part}.{map}.gam",')
    (324, '                      sample=wildcards.sample, graph=wildcards.graph, map=wildcards.map,')
    (325, '                      part=glob_wildcards(os.path.join(checkpoint_output, wildcards.sample + "_1.part{part}.fastq.gz")).part)')
    (326, '    rule merge_gam:')
    (327, '        input: aggregate_reads')
    (328, "        output: \\'{sample}/{sample}-{graph}.{map}.gam\\'")
    (329, "        benchmark: \\'benchmarks/{sample}-{graph}-{map}-mergegam.benchmark.txt\\'")
    (330, '        run:')
    (331, '            shell("cat {input} > {output}")')
    (332, "            if config[\\'s3save\\']:")
    (333, '                shell("aws s3 cp --quiet {output} {SROOT}/{wildcards.sample}/")')
    (334, '')
    (335, '')
    (336, '# compute packed coverage from aligned reads')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Monia234/admixMap, file=workflow/Snakefile
context_key: ['if config[\\\'singularity\\\'][\\\'use_singularity\\\'] == \\\'true\\\' and config[\\\'singularity\\\'][\\\'image\\\'] != "none"']
    (33, 'if config[\\\'singularity\\\'][\\\'use_singularity\\\'] == \\\'true\\\' and config[\\\'singularity\\\'][\\\'image\\\'] != "none":')
    (34, '    bind_dirs = [x for x in [QUERY, VCF, config[\\\'samples\\\'], config[\\\'annotation\\\'][\\\'rsIDs\\\'], config[\\\'annotation\\\'][\\\'typed_key\\\']] if os.path.exists(os.path.dirname(x)) and x!="/"]')
    (35, '    bind_paths = ",".join([x for x in set([os.path.dirname(x) for x in bind_dirs] + dirs) if os.path.isdir(x) and x!="/"])')
    (36, '    if config[\\\'admixMapping\\\'][\\\'skip\\\'].lower() != \\\'true\\\': bind_paths += f",{RFMIX}"')
    (37, '    CMD_PREFIX = f"set +u; {config[\\\'singularity\\\'][\\\'module\\\']}; singularity exec --bind {bind_paths} {config[\\\'singularity\\\'][\\\'image\\\']}"')
    (38, "    CODE = config[\\'singularity\\'][\\'code\\']")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Monia234/admixMap, file=workflow/Snakefile
context_key: ["if config[\\'samples\\'] == \\'all\\'"]
    (53, "if config[\\'samples\\'] == \\'all\\': ind_num = len(samps)")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Monia234/admixMap, file=workflow/Snakefile
context_key: ["if config[\\'run_settings\\'][\\'local_run\\'] == \\'true\\'"]
    (71, "if config[\\'run_settings\\'][\\'local_run\\'] == \\'true\\':")
    (72, '    localrules: all, calcFreq, calcIBS, catIBS, calcPCA, controlMatch, admixMap, extract_optimum_popnum, cat_admixMap')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Monia234/admixMap, file=workflow/Snakefile
context_key: ['run', "if config[\\'match_controls\\'] == \\'true\\'"]
    (366, "        if config[\\'match_controls\\'] == \\'true\\': #Run control-matching and parse results into a format that PLINK can use to extract matched samples.")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Monia234/admixMap, file=workflow/Snakefile
context_key: ['run', "if config[\\'annotation\\'][\\'download_refs\\'] == \\'true\\'"]
    (512, "        if config[\\'annotation\\'][\\'download_refs\\'] == \\'true\\':")
    (513, '            shell(f" wget {config[\\\'annotation\\\'][\\\'gff\\\']} -O {gff}")')
    (514, '            shell(f" wget {config[\\\'annotation\\\'][\\\'genome\\\']} -O {genome}")')
    (515, "        elif os.path.exists(config[\\'annotation\\'][\\'gff\\']) and os.path.exists(config[\\'annotation\\'][\\'genome\\']):")
    (516, '            shell(f"cp {config[\\\'annotation\\\'][\\\'gff\\\']} {gff}")')
    (517, '            shell(f"cp {config[\\\'annotation\\\'][\\\'genome\\\']} {genome}")')
    (518, '        else:')
    (519, '            print("Could not find reference .gff and/or .genome file.  Check config file that paths are correctly specified and/or download requested.")')
    (520, '        shell(f"{CMD_PREFIX} bedtools slop -i {BASE}.admixmap.tmp.bed -g {genome} -b {config[\\\'admixMapping\\\'][\\\'annotation_buffer\\\']} > {BASE}.admixmap.bed")')
    (521, '        cmd = f"{CMD_PREFIX} bedtools intersect -a {BASE}.admixmap.bed -b {gff} -loj | "  \\\\')
    (522, '        "awk \\\'{{if($11==\\\\"gene\\\\") print $0}}\\\' | awk \\\'{{split($NF,a,\\\\";\\\\"); $NF=\\\\"\\\\"; for(x in a) if(a[x] ~ /Name=/) print $0,a[x]}}\\\' | sed \\\'s/Name=//\\\' > {BASE}.admixmap.preannt.txt"')
    (523, '        shell(cmd)')
    (524, '        shell(f"{CMD_PREFIX} Rscript {CODE}/admixAnnt.R -i input/ -p {BASE}.admixmap.preannt.txt -b {config[\\\'admixMapping\\\'][\\\'annotation_buffer\\\']} -o {{output}}")')
    (525, '')
    (526, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=arabidopsisca/snakemake-rna-seq-star-deseq2, file=rules/align.smk
context_key: ['if config["trimming"]["skip"]']
    (1, '    if config["trimming"]["skip"]:')
    (2, '        # no trimming, use raw reads')
    (3, '        return units.loc[(wildcards.sample, wildcards.unit), ["fq1", "fq2"]].dropna()')
    (4, '    else:')
    (5, '        # yes trimming, use trimmed data')
    (6, '        if not is_single_end(**wildcards):')
    (7, '            # paired-end sample')
    (8, '            return expand("trimmed/{sample}-{unit}.{group}.fastq.gz",')
    (9, '                          group=[1, 2], **wildcards)')
    (10, '        # single end sample')
    (11, '        return "trimmed/{sample}-{unit}.fastq.gz".format(**wildcards)')
    (12, '            ')
    (13, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=ebi-gene-expression-group/bulk-recalculations, file=Snakefile
context_key: ["if config[\\'goal\\'] == \\'reprocess\\'", "if experiment_type==\\'rnaseq_mrna_differential\\'"]
    (268, "    if config[\\'goal\\'] == \\'reprocess\\':")
    (269, "        if experiment_type==\\'rnaseq_mrna_differential\\':")
    (270, '            return [ f"logs/{wildcards[\\\'accession\\\']}-decorate_differential_rnaseq.done" ]')
    (271, "        elif experiment_type==\\'proteomics_differential\\':")
    (272, '            return [ f"logs/{wildcards[\\\'accession\\\']}-decorate_differential_proteomics.done" ]')
    (273, "        elif experiment_type == \\'microarray_1colour_mrna_differential\\' or experiment_type ==\\'microarray_2colour_mrna_differential\\' or experiment_type ==\\'microarray_1colour_microrna_differential\\':")
    (274, '            inputs = []')
    (275, '            arr_designs=get_array_design_from_xml()')
    (276, '            for s in arr_designs:')
    (277, '                inputs.append( f"logs/{wildcards[\\\'accession\\\']}_{s}-decorate_differential_microarray.done" )')
    (278, '            return inputs')
    (279, '        else:')
    (280, '            return None')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=ebi-gene-expression-group/bulk-recalculations, file=Snakefile
context_key: ["if config[\\'goal\\'] == \\'reprocess\\'", "if config[\\'goal\\'] == \\'recalculations\\'"]
    (281, "    if config[\\'goal\\'] == \\'recalculations\\':")
    (282, '        # No input file needed - trick to force rule execution')
    (283, '        return f"{wildcards[\\\'accession\\\']}.metadata_summary.yaml"')
    (284, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=ebi-gene-expression-group/bulk-recalculations, file=Snakefile
context_key: ["if config[\\'goal\\'] == \\'reprocess\\'", "if experiment_type==\\'rnaseq_mrna_differential\\'"]
    (290, "    if config[\\'goal\\'] == \\'reprocess\\':")
    (291, "        if experiment_type==\\'rnaseq_mrna_differential\\':")
    (292, '            return [ f"logs/{wildcards[\\\'accession\\\']}-decorate_differential_rnaseq.done" ]')
    (293, "        elif experiment_type==\\'proteomics_differential\\':")
    (294, '            return [ f"logs/{wildcards[\\\'accession\\\']}-decorate_differential_proteomics.done" ]')
    (295, "        elif experiment_type == \\'microarray_1colour_mrna_differential\\' or experiment_type ==\\'microarray_2colour_mrna_differential\\' or experiment_type ==\\'microarray_1colour_microrna_differential\\':")
    (296, '            inputs = []')
    (297, '            arr_designs=get_array_design_from_xml()')
    (298, '            for s in arr_designs:')
    (299, '                inputs.append( f"logs/{wildcards[\\\'accession\\\']}_{s}-decorate_differential_microarray.done" )')
    (300, '            return inputs')
    (301, '        else:')
    (302, '            return None')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=ebi-gene-expression-group/bulk-recalculations, file=Snakefile
context_key: ["if config[\\'goal\\'] == \\'reprocess\\'", "if config[\\'goal\\'] == \\'recalculations\\'"]
    (303, "    if config[\\'goal\\'] == \\'recalculations\\':")
    (304, '        # No input file needed - trick to force rule execution')
    (305, "        return wildcards[\\'accession\\']+\\'.metadata_summary.yaml\\'")
    (306, '')
    (307, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=ebi-gene-expression-group/bulk-recalculations, file=Snakefile
context_key: ["if config[\\'goal\\'] == \\'reprocess\\'", "if experiment_type ==\\'rnaseq_mrna_baseline\\' or experiment_type==\\'rnaseq_mrna_differential\\'"]
    (313, "    if config[\\'goal\\'] == \\'reprocess\\':")
    (314, "        if experiment_type ==\\'rnaseq_mrna_baseline\\' or experiment_type==\\'rnaseq_mrna_differential\\': ")
    (315, "            return [ wildcards[\\'accession\\']+\\'-raw-counts.tsv.undecorated\\' ]")
    (316, "        elif experiment_type == \\'microarray_1colour_mrna_differential\\' or experiment_type ==\\'microarray_1colour_microrna_differential\\':")
    (317, '            inputs = []')
    (318, '            arr_designs=get_array_design_from_xml()')
    (319, '            for s in arr_designs:')
    (320, '                inputs.append( f"logs/{wildcards[\\\'accession\\\']}_{s}-decorate_differential_microarray.done" )')
    (321, '            return inputs')
    (322, "        elif experiment_type ==\\'microarray_2colour_mrna_differential\\':")
    (323, '            inputs = []')
    (324, '            arr_designs=get_array_design_from_xml()')
    (325, '            for s in arr_designs:')
    (326, '                inputs.append( f"{wildcards[\\\'accession\\\']}_{s}-log-fold-changes.tsv.undecorated" )')
    (327, '                inputs.append( f"{wildcards[\\\'accession\\\']}_{s}-average-intensities.tsv.undecorated" )')
    (328, '            return inputs')
    (329, '        else:')
    (330, '            return None')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=ebi-gene-expression-group/bulk-recalculations, file=Snakefile
context_key: ["if config[\\'goal\\'] == \\'reprocess\\'", "if config[\\'goal\\'] == \\'recalculations\\'"]
    (331, "    if config[\\'goal\\'] == \\'recalculations\\':")
    (332, "        return wildcards[\\'accession\\']+\\'-configuration.xml\\'")
    (333, '')
    (334, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=ebi-gene-expression-group/bulk-recalculations, file=Snakefile
context_key: ["if config[\\'goal\\'] == \\'reprocess\\'"]
    (352, "    if config[\\'goal\\'] == \\'reprocess\\':")
    (353, '        inputs = get_outputs()')
    (354, '        inputs.remove( f"logs/{wildcards[\\\'accession\\\']}-copy_experiment_from_analysis_to_atlas_exps.done" )')
    (355, '        inputs.remove( f"logs/{wildcards[\\\'accession\\\']}-get_magetab_for_experiment.done" )')
    (356, '        return inputs')
    (357, '    else:')
    (358, '        return None')
    (359, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=ebi-gene-expression-group/bulk-recalculations, file=Snakefile-recalculations
context_key: ['if config[\\\'tool\\\']=="all-baseline" or \\\'baseline-tracks\\\' in config[\\\'tool\\\'] or \\\'baseline-heatmap\\\' in config[\\\'tool\\\'] or \\\'baseline-coexpression\\\' in config[\\\'tool\\\']']
    (27, '    if config[\\\'tool\\\']=="all-baseline" or \\\'baseline-tracks\\\' in config[\\\'tool\\\'] or \\\'baseline-heatmap\\\' in config[\\\'tool\\\'] or \\\'baseline-coexpression\\\' in config[\\\'tool\\\']:')
    (28, '        metrics = get_metrics_recalculations()')
    (29, '')
    (30, '    # Read this now so that it is available for all other needs')
    (31, '    read_metadata_summary()')
    (32, '    global skip_accession')
    (33, '    skip_accession = read_skip_steps_file()')
    (34, "    required_config=[\\'tool\\']")
    (35, '    check_config_required(fields=required_config)')
    (36, '    if \\\'percentile-ranks\\\' in config[\\\'tool\\\'] or config[\\\'tool\\\']=="all-diff" and skip(config[\\\'accession\\\'],\\\'percentile_ranks\\\'):')
    (37, '        outputs.append(f"{config[\\\'accession\\\']}-percentile-ranks.tsv")')
    (38, '    if \\\'differential-tracks\\\' in config[\\\'tool\\\'] or config[\\\'tool\\\']=="all-diff" and skip(config[\\\'accession\\\'],\\\'differential-tracks\\\'):')
    (39, "        check_config_required(fields=[\\'metadata_summary\\'], method=\\'differential-tracks\\')")
    (40, '        # fake elements to mix contrasts labels and ids')
    (41, '        outputs.extend(expand(config[\\\'accession\\\']+".{id}.{type}", id=get_contrast_ids(), type=["genes.pval.bedGraph", "genes.log2foldchange.bedGraph"]))')
    (42, '    if \\\'baseline-tracks\\\' in config[\\\'tool\\\'] or config[\\\'tool\\\']=="all-baseline" and skip(config[\\\'accession\\\'],\\\'baseline-tracks\\\'):')
    (43, "        check_config_required(fields=[\\'metadata_summary\\'], method=\\'baseline-tracks\\')")
    (44, '        # combine metric (fpkm / tpm) with assay_id/assay_label (zip based)')
    (45, '        # in a product manner')
    (46, '        outputs.extend(expand(config[\\\'accession\\\']+".{a_id}.genes.expressions_{metric}.bedGraph",')
    (47, '                            a_id=get_assay_ids(),')
    (48, '                            metric=metrics))')
    (49, '    if \\\'differential-gsea\\\' in config[\\\'tool\\\'] or config[\\\'tool\\\']=="all-diff" and skip(config[\\\'accession\\\'],\\\'differential-gsea\\\'):')
    (50, "        check_config_required(fields=[\\'bioentities_properties\\'], method=\\'differential-gsea\\')")
    (51, '        outputs.extend(')
    (52, '                expand( config[\\\'accession\\\']+".{c_id}.{ext_db}.{type}",')
    (53, '                        c_id=get_contrast_ids(),')
    (54, '                        ext_db=get_ext_db(),')
    (55, '                        type=["gsea.tsv", "gsea_list.tsv"]))')
    (56, '        outputs.extend(')
    (57, '                expand("logs/"+config[\\\'accession\\\']+".{c_id}.{ext_db}.{type}",')
    (58, '                        c_id=get_contrast_ids(),')
    (59, '                        ext_db=get_ext_db(),')
    (60, '                        type=["check_differential_gsea.done", "check_differential_gsea_list.done"]))')
    (61, "    if \\'atlas-experiment-summary\\' in config[\\'tool\\'] or \\'all\\' in config[\\'tool\\'] and skip(config[\\'accession\\'],\\'atlas_experiment_summary\\'):")
    (62, '        outputs.append(f"{config[\\\'accession\\\']}-atlasExperimentSummary.Rdata")')
    (63, "    if \\'baseline-heatmap\\' in config[\\'tool\\'] or \\'all-baseline\\' in config[\\'tool\\'] and skip(config[\\'accession\\'],\\'baseline-heatmap\\'):")
    (64, '        outputs.extend(expand(f"{config[\\\'accession\\\']}"+"-heatmap-{metric}.pdf", metric=metrics ))')
    (65, '        outputs.append(f"{config[\\\'accession\\\']}-heatmap.pdf")')
    (66, "    if \\'baseline-coexpression\\' in config[\\'tool\\'] or \\'all-baseline\\' in config[\\'tool\\'] and skip(config[\\'accession\\'],\\'baseline-coexpression\\'):   ")
    (67, '        metric_link_coexp=False')
    (68, '        for m in metrics:')
    (69, '            expression_file=f"{config[\\\'accession\\\']}-{m}.tsv"')
    (70, '            print(f"Checking file size for {expression_file} and number of columns")')
    (71, '            if os.path.getsize(expression_file) > 0 and get_number_columns(expression_file)>4:')
    (72, '                metric_link_coexp=True')
    (73, '                outputs.extend(expand(f"{config[\\\'accession\\\']}-{m}-coexpressions.tsv.gz"))')
    (74, '')
    (75, '        if metric_link_coexp == True:')
    (76, '            outputs.extend(expand(f"{config[\\\'accession\\\']}-coexpressions.tsv.gz" ))')
    (77, '')
    (78, '    print(outputs)')
    (79, "    print(\\'Getting list of outputs.. done\\')")
    (80, '    print(datetime.datetime.now())')
    (81, '')
    (82, '    return outputs')
    (83, '')
    (84, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=tiramisutes/Snakemake_Gene_Family, file=rules/Identify_Gene_Family.smk
context_key: ['if config["module"]["InterProScan"]', 'rule InterProScan_genome', 'output']
    (30, '        output:')
    (31, '            "InterProScan/{}.tsv".format(genome_pep_name())')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=tiramisutes/Snakemake_Gene_Family, file=rules/Identify_Gene_Family.smk
context_key: ['if config["module"]["InterProScan"]', 'rule InterProScan_genome', 'threads']
    (32, '        threads: 40')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=tiramisutes/Snakemake_Gene_Family, file=rules/Identify_Gene_Family.smk
context_key: ['if config["module"]["InterProScan"]', 'rule InterProScan_genome', 'params']
    (33, '        params:')
    (34, '            workdir = config["workdir"],')
    (35, '            InterProScan_name = config["InterProScan_name"],')
    (36, '            outdir = lambda w, output: os.path.dirname(output[0])')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=tiramisutes/Snakemake_Gene_Family, file=rules/Identify_Gene_Family.smk
context_key: ['if config["module"]["InterProScan"]', 'rule InterProScan_genome', 'conda']
    (37, '        conda:')
    (38, '            "../envs/Identify_Gene_Family.yaml"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=tiramisutes/Snakemake_Gene_Family, file=rules/Identify_Gene_Family.smk
context_key: ['if config["module"]["InterProScan"]', 'rule InterProScan_genome', 'log']
    (39, '        log:')
    (40, '            "logs/InterProScan_genome.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=tiramisutes/Snakemake_Gene_Family, file=rules/Identify_Gene_Family.smk
context_key: ['if config["module"]["InterProScan"]', 'rule InterProScan_genome', 'shell']
    (41, '        shell:')
    (42, "            \\'\\'\\'")
    (43, '            cd {params.workdir}/bin/{params.InterProScan_name}')
    (44, '            ./interproscan.sh -appl Pfam -i {input.genome_pep} \\\\')
    (45, '            -goterms -iprlookup -pa -f TSV,XML,GFF3,HTML \\\\')
    (46, '            -d {params.workdir}/{params.outdir} \\\\')
    (47, '            -cpu {threads} > {params.workdir}/{log} 2>&1')
    (48, "            \\'\\'\\'")
    (49, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=tiramisutes/Snakemake_Gene_Family, file=rules/Identify_Gene_Family.smk
context_key: ['if config["module"]["InterProScan"]']
    (162, 'if config["module"]["InterProScan"]:')
    (163, '    pass')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=tiramisutes/Snakemake_Gene_Family, file=rules/Identify_Gene_Family.smk
context_key: ['if config["module"]["paircoil2"]', 'rule paircoil2', 'input']
    (232, 'if config["module"]["paircoil2"]:')
    (233, '    rule paircoil2:')
    (234, '        input:')
    (235, '            "HMMER/{Domain_ID}_pep.fa"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=tiramisutes/Snakemake_Gene_Family, file=rules/Identify_Gene_Family.smk
context_key: ['if config["module"]["paircoil2"]', 'rule paircoil2', 'output']
    (236, '        output:')
    (237, '            "paircoil2/{Domain_ID}_CC_pep.fa"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=tiramisutes/Snakemake_Gene_Family, file=rules/Identify_Gene_Family.smk
context_key: ['if config["module"]["paircoil2"]', 'rule paircoil2', 'threads']
    (238, '        threads: 1')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=tiramisutes/Snakemake_Gene_Family, file=rules/Identify_Gene_Family.smk
context_key: ['if config["module"]["paircoil2"]', 'rule paircoil2', 'conda']
    (239, '        conda:')
    (240, '            "../envs/Identify_Gene_Family.yaml"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=tiramisutes/Snakemake_Gene_Family, file=rules/Identify_Gene_Family.smk
context_key: ['if config["module"]["paircoil2"]', 'rule paircoil2', 'params']
    (241, '        params:')
    (242, '            workdir = config["workdir"],')
    (243, '            Pfam_id = "{Domain_ID}"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=tiramisutes/Snakemake_Gene_Family, file=rules/Identify_Gene_Family.smk
context_key: ['if config["module"]["paircoil2"]', 'rule paircoil2', 'log']
    (244, '        log:')
    (245, '            "logs/paircoil2_{Domain_ID}.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=tiramisutes/Snakemake_Gene_Family, file=rules/Identify_Gene_Family.smk
context_key: ['if config["module"]["paircoil2"]', 'rule paircoil2', 'shell']
    (246, '        shell:')
    (247, "            \\'\\'\\'")
    (248, '            cd {params.workdir}/bin/paircoil2')
    (249, '            ./paircoil2 -win 28 {params.workdir}/{input} {params.workdir}/{output} > {params.workdir}/{log} 2>&1')
    (250, "            \\'\\'\\'")
    (251, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=tiramisutes/Snakemake_Gene_Family, file=rules/Identify_Gene_Family.smk
context_key: ['if config["module"]["paircoil2"]', 'rule merge_family_fasta', 'input']
    (252, '    rule merge_family_fasta:')
    (253, '        input:')
    (254, '            fa = expand("HMMER/{u.Domain_ID}_pep.fa", u = Pfam_ids.itertuples()),')
    (255, '            cc_fa = expand("paircoil2/{u.Domain_ID}_CC_pep.fa", u = Pfam_ids.itertuples())')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=tiramisutes/Snakemake_Gene_Family, file=rules/Identify_Gene_Family.smk
context_key: ['if config["module"]["paircoil2"]', 'rule merge_family_fasta', 'output']
    (256, '        output:')
    (257, '            fa = report("Gene_Family/All_{}_pep.fa".format(config["prefix"]), caption="../report/merge_family_fasta.rst", category="2. Protein sequences of all gene family"),')
    (258, '            cc_fa = "Gene_Family/All_{}_CC_pep.fa".format(config["prefix"])')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=tiramisutes/Snakemake_Gene_Family, file=rules/Identify_Gene_Family.smk
context_key: ['if config["module"]["paircoil2"]', 'rule merge_family_fasta', 'threads']
    (259, '        threads: 1')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=tiramisutes/Snakemake_Gene_Family, file=rules/Identify_Gene_Family.smk
context_key: ['if config["module"]["paircoil2"]', 'rule merge_family_fasta', 'log']
    (260, '        log:')
    (261, '            "logs/merge_family_fasta.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=tiramisutes/Snakemake_Gene_Family, file=rules/Identify_Gene_Family.smk
context_key: ['if config["module"]["paircoil2"]', 'rule merge_family_fasta', 'shell']
    (262, '        shell:')
    (263, "            \\'\\'\\'")
    (264, '            cat {input.fa} > {output.fa}')
    (265, '            cat {input.cc_fa} > {output.cc_fa}')
    (266, "            \\'\\'\\'")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=jbloomlab/SARS-CoV-2-RBD_B.1.351, file=Snakefile
context_key: ["if config[\\'seqdata_source\\'] == \\'HutchServer\\'", 'rule get_ccs', 'input']
    (418, "if config[\\'seqdata_source\\'] == \\'HutchServer\\':")
    (419, '')
    (420, '    rule get_ccs:')
    (421, '        """Symbolically link CCS files."""')
    (422, '        input:')
    (423, '            ccs_fastq=lambda wildcards: (pacbio_runs')
    (424, "                                        .set_index(\\'pacbioRun\\')")
    (425, "                                        .at[wildcards.pacbioRun, \\'ccs\\']")
    (426, '                                        )')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=jbloomlab/SARS-CoV-2-RBD_B.1.351, file=Snakefile
context_key: ["if config[\\'seqdata_source\\'] == \\'HutchServer\\'", 'rule get_ccs', 'output']
    (427, '        output:')
    (428, '            ccs_fastq=os.path.join(config[\\\'ccs_dir\\\'], "{pacbioRun}_ccs.fastq.gz")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=jbloomlab/SARS-CoV-2-RBD_B.1.351, file=Snakefile
context_key: ["if config[\\'seqdata_source\\'] == \\'HutchServer\\'", 'rule get_ccs', 'run']
    (429, '        run:')
    (430, '            os.symlink(input.ccs_fastq, output.ccs_fastq)')
    (431, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=jbloomlab/SARS-CoV-2-RBD_B.1.351, file=Snakefile
context_key: ["elif config[\\'seqdata_source\\'] == \\'SRA\\'"]
    (432, "elif config[\\'seqdata_source\\'] == \\'SRA\\':")
    (433, "    raise RuntimeError(\\'getting sequence data from SRA not yet implemented\\')")
    (434, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=jrderuiter/snakemake-exome, file=rules/qc.smk
context_key: ['if config["options"]["pdx"]']
    (13, '    if config["options"]["pdx"]:')
    (14, '        inputs += [expand("qc/disambiguate/{sample}.txt", sample=get_samples())]')
    (15, '')
    (16, '    return [input_ for sub_inputs in inputs for input_ in sub_inputs]')
    (17, '')
    (18, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=nextstrain/monkeypox, file=ingest/Snakefile
context_key: ['if config.get("upload")']
    (69, 'if config.get("upload"):')
    (70, '')
    (71, '    include: "workflow/snakemake_rules/upload.smk"')
    (72, '')
    (73, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=nextstrain/monkeypox, file=ingest/Snakefile
context_key: ['if config.get("trigger_rebuild")']
    (79, 'if config.get("trigger_rebuild"):')
    (80, '')
    (81, '    include: "workflow/snakemake_rules/trigger_rebuild.smk"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=nextstrain/monkeypox, file=Snakefile
context_key: ['if config.get("data_source", None) == "lapis"']
    (43, 'if config.get("data_source", None) == "lapis":')
    (44, '')
    (45, '    include: "workflow/snakemake_rules/download_via_lapis.smk"')
    (46, '')
    (47, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=nextstrain/monkeypox, file=Snakefile
context_key: ['if config.get("deploy_url")']
    (59, 'if config.get("deploy_url"):')
    (60, '')
    (61, '    include: "workflow/snakemake_rules/nextstrain_automation.smk"')
    (62, '')
    (63, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Vyoming/Immune_Tumor_Bulk_RNA, file=rules/diffexp.smk
context_key: ['if config["params"]["enrichment"]', 'rule fgsea', 'input']
    (99, 'if config["params"]["enrichment"]:')
    (100, '    rule fgsea:')
    (101, '        input:')
    (102, '            table ="results/diffexp/{contrast}.diffexp.csv"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Vyoming/Immune_Tumor_Bulk_RNA, file=rules/diffexp.smk
context_key: ['if config["params"]["enrichment"]', 'rule fgsea', 'output']
    (103, '        output:')
    (104, '            table= "results/fgsea/results_{contrast}.csv",')
    (105, '            top_gene_sets_pdf = report("results/fgsea/top_gene_sets_{contrast}.pdf", "../report/top_gene_sets.rst"),')
    (106, '            rds = "results/fgsea/res_{contrast}.rds",')
    (107, '            rds_sig = "results/fgsea/res_sig_{contrast}.rds",')
    (108, '            table_sig = "results/fgsea/results_sig_{contrast}.csv",')
    (109, '            pathways_pdf = report("results/fgsea/enriched_pathways_{contrast}.pdf", caption = "../report/top_pathways.rst"),')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Vyoming/Immune_Tumor_Bulk_RNA, file=rules/diffexp.smk
context_key: ['if config["params"]["enrichment"]', 'rule fgsea', 'params']
    (110, '        params:')
    (111, '            contrast = get_contrast,')
    (112, '            gene_sets = config["fgsea"]["gene_sets"],')
    (113, '            species = config["diffexp"]["organism"],')
    (114, '            descriptions = config["fgsea"]["descriptions"],')
    (115, '            msigdb_categories = config["fgsea"]["msigdb_categories"]')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Vyoming/Immune_Tumor_Bulk_RNA, file=rules/diffexp.smk
context_key: ['if config["params"]["enrichment"]', 'rule fgsea', 'threads']
    (116, '        threads: 1')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Vyoming/Immune_Tumor_Bulk_RNA, file=rules/diffexp.smk
context_key: ['if config["params"]["enrichment"]', 'rule fgsea', 'resources']
    (117, '        resources:')
    (118, '            mem_mb = 60000')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Vyoming/Immune_Tumor_Bulk_RNA, file=rules/diffexp.smk
context_key: ['if config["params"]["enrichment"]', 'rule fgsea', 'conda']
    (119, '        conda:')
    (120, '            "../envs/deseq2.yaml"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Vyoming/Immune_Tumor_Bulk_RNA, file=rules/diffexp.smk
context_key: ['if config["params"]["enrichment"]', 'rule fgsea', 'log']
    (121, '        log:')
    (122, '            "logs/fgsea_{contrast}.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Vyoming/Immune_Tumor_Bulk_RNA, file=rules/diffexp.smk
context_key: ['if config["params"]["enrichment"]', 'rule fgsea', 'script']
    (123, '        script:')
    (124, '            "../scripts/fgsea.R"')
    (125, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Vyoming/Immune_Tumor_Bulk_RNA, file=Snakefile
context_key: ['if config["params"]["enrichment"] == "yes"', 'rule all', 'input']
    (18, 'if config["params"]["enrichment"] == "yes":')
    (19, '  rule all:')
    (20, '        input:')
    (21, '            expand(["results/diffexp/{contrast}.diffexp.csv",')
    (22, '                    "results/heatmap_{contrast}.pdf", ')
    (23, '                    "results/fgsea/results_{contrast}.csv",')
    (24, '                    "results/volcano_{contrast}.pdf"],')
    (25, '                    contrast=config["diffexp"]["contrasts"]),')
    (26, '            "results/pca.svg",')
    (27, '            "qc/multiqc_report.html",')
    (28, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=bnelsj/bwa_mem_mapping, file=Snakefile
context_key: ['if config == {}']
    (41, 'if config == {}:')
    (42, '    configfile: "%s/config.yaml" % SNAKEMAKE_DIR')
    (43, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=bnelsj/bwa_mem_mapping, file=Snakefile
context_key: ['if config["input_type"] != "bam"']
    (45, 'if config["input_type"] != "bam":')
    (46, '    manifest.lane = manifest.lane.astype(str)')
    (47, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=bnelsj/bwa_mem_mapping, file=Snakefile
context_key: ['if config["input_type"] == "bam"', 'rule bwa_mem_map_from_bam']
    (115, 'if config["input_type"] == "bam":')
    (116, '    rule bwa_mem_map_from_bam:')
    (117, '        input:  lambda wildcards: config["references"][wildcards.reference],')
    (118, '                get_bam')
    (119, '        output: "mapping/{reference}/merged/{sample}.bam"')
    (120, '        params:')
    (121, '            sample="{sample}",')
    (122, '            custom=config.get("params_bwa_mem", ""),')
    (123, '            sge_opts="-l mfree=8G -pe serial 10 -N bwa_mem_map -l disk_free=20G -l h_rt=7:0:0:0 -q eichler-short.q -l ssd=True",')
    (124, '            bwa_threads = "10",')
    (125, '            samtools_threads = "9", samtools_memory = "4G",')
    (126, '            outdir = "mapping/{reference}/merged/"')
    (127, '        priority: 10')
    (128, '        log:')
    (129, '            "mapping/log/{reference}/{sample}.log"')
    (130, '        shell:')
    (131, '            """set -eo pipefail')
    (132, '               run-bwamem -t {params.bwa_threads} -dso $TMPDIR/tmp {input[0]} {input[1]} | bash')
    (133, '               rsync --bwlimit=50000 $TMPDIR/tmp.aln.bam {output}')
    (134, '               samtools index {output}"""')
    (135, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=bnelsj/bwa_mem_mapping, file=Snakefile
context_key: ['elif config["input_type"] in ["fastq", "fastq.gz"]', 'rule bwa_mem_map_and_mark_dups']
    (136, 'elif config["input_type"] in ["fastq", "fastq.gz"]:')
    (137, '    rule bwa_mem_map_and_mark_dups:')
    (138, '        input:  lambda wildcards: config["references"][wildcards.reference],')
    (139, '                get_files')
    (140, '        output:')
    (141, '            "mapping/{reference}/{sample}/{flowcell}/{lane}.bam"')
    (142, '        params:')
    (143, '            sample="{sample}",')
    (144, '            flowcell="{flowcell}",')
    (145, '            custom=config.get("params_bwa_mem", ""),')
    (146, '            sge_opts="-l mfree=6G -pe serial 10 -N bwa_mem_map -l disk_free=10G -l h_rt=3:0:0:0 -q eichler-short.q -soft -l ssd=True -R y",')
    (147, '            bwa_threads = "10",')
    (148, '            samtools_threads = "9", samtools_memory = "1G"')
    (149, '        priority: 10')
    (150, '        log:')
    (151, '            "mapping/log/{reference}/{sample}/{flowcell}/{lane}.log"')
    (152, '        shell:')
    (153, '            """set -eo pipefail')
    (154, "            bwa mem {params.custom} -R \\'@RG\\\\\\\\tID:{params.flowcell}_{wildcards.lane}\\\\\\\\tSM:{params.sample}\\\\\\\\tLB:{params.sample}\\\\\\\\tPL:{config[platform]}\\\\\\\\tPU:{params.flowcell}\\' \\\\")
    (155, '                -t {params.bwa_threads} {input} 2> {log} | \\\\')
    (156, '            samblaster | \\\\')
    (157, '            samtools sort -@ {params.samtools_threads} -m {params.samtools_memory} -O bam -T $TMPDIR/{wildcards.lane} -o {output}')
    (158, '            samtools index {output}"""')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=TasnubaS/Snakemake-WorkFlow, file=rules/align.smk
context_key: ['if config["trimming"]["skip"]']
    (1, '    if config["trimming"]["skip"]:')
    (2, '        # no trimming, use raw reads')
    (3, '        return units.loc[(wildcards.sample, wildcards.unit), ["fq1", "fq2"]].dropna()')
    (4, '    else:')
    (5, '        # yes trimming, use trimmed data')
    (6, '        if not is_single_end(**wildcards):')
    (7, '            # paired-end sample')
    (8, '            return expand("trimmed/{sample}-{unit}.{group}.fastq.gz",')
    (9, '                          group=[1, 2], **wildcards)')
    (10, '        # single end sample')
    (11, '        return "trimmed/{sample}-{unit}.fastq.gz".format(**wildcards)')
    (12, '            ')
    (13, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=wuaipinglab/covSampler, file=Snakefile
context_key: ['if config.get("start_subsampling")']
    (4, 'if config.get("start_subsampling"):')
    (5, '    all_input.append(config["subsampling"]["output_path"])')
    (6, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=DimitriMeistermann/checkChrHeterozygosity, file=Snakefile
context_key: ['if config=={}', 'if not os.path.exists(WORKING_DIR+"/log")', 'if not os.path.exists(FASTQ_PATH)', 'else', 'if IS_PAIRED_END', 'if USE_TRIMMOMATIC', 'else', 'rule all', 'if IS_PAIRED_END', 'else', 'rule FASTQC', 'rule BWA_INDEX', 'rule ALIGN', 'rule SORT_BAM', 'rule INDEX_BAM', 'rule mpileUp', 'rule vcf2tsv', 'rule mergeVCF', 'rule HTSEQ_COUNT', 'rule COUNTS_TABLE', 'rule MULTIQC']
    (4, 'if config=={}:')
    (5, '\\tprint("Default config file loaded, from " + WORKING_DIR + "/config.json")')
    (6, '\\tconfigfile: WORKING_DIR+"/config.json"')
    (7, '')
    (8, '## creation of the logs subdirectory')
    (9, 'if not os.path.exists(WORKING_DIR+"/log"):')
    (10, '\\tos.mkdir(WORKING_DIR+"/log")')
    (11, '')
    (12, '#put all config variable as variable in the snakefile')
    (13, 'for configVar in config:')
    (14, '\\tif isinstance(config[configVar], str): exec(configVar+"= \\\'"+config[configVar]+"\\\'")')
    (15, '\\telse: exec(configVar+"="+str(config[configVar]))')
    (16, '')
    (17, '')
    (18, '## test of the path provided in the config.json file')
    (19, 'if not os.path.exists(FASTQ_PATH):')
    (20, '\\tprint("The directory " + FASTQ_PATH + " doesn\\\'t exist. Check the field FASTQ_PATH into the config.json file.")')
    (21, '\\tsys.exit(0)')
    (22, 'else:')
    (23, '\\t## If the path ends by /, the / is suppressed')
    (24, '\\tif ( FASTQ_PATH[-1:] == "/" ):')
    (25, '\\t\\tFASTQ_PATH = FASTQ_PATH[:-1]')
    (26, '')
    (27, "INPUT_FASTQS = glob.glob(FASTQ_PATH+\\'/*.fastq.gz\\')")
    (28, '')
    (29, 'SAMPLESsplitted = [os.path.basename(f).split(".") for f in INPUT_FASTQS]')
    (30, 'SAMPLES=[]')
    (31, '')
    (32, '#remove .fastq.gz to get sample names')
    (33, 'for s in SAMPLESsplitted:')
    (34, '\\tSAMPLES.append(".".join(s[0:-2]))')
    (35, '')
    (36, 'if(OUTPUT_PATH[-1] == "/") : OUTPUT_PATH = OUTPUT_PATH[:-1]')
    (37, '')
    (38, '## suppress the .R1. and .R2. elements for paired-end fastq files for the alignement processus in SAMPLES')
    (39, 'if IS_PAIRED_END:')
    (40, '\\tSAMPLES = [itemR2 for itemR2 in SAMPLES if (PAIR_END_FILE_PATTERN+"2") not in itemR2]\\t')
    (41, '\\tSAMPLES = [itemR1.replace((PAIR_END_FILE_PATTERN+"1"),\\\'\\\') for itemR1 in SAMPLES]')
    (42, '')
    (43, '')
    (44, 'if USE_TRIMMOMATIC:')
    (45, '\\tALIGN_FASTQ_FOLDER = OUTPUT_PATH + "/FASTQ_TRIM"')
    (46, 'else:')
    (47, '\\tALIGN_FASTQ_FOLDER = FASTQ_PATH')
    (48, '')
    (49, 'if IS_PAIRED_END: PAIR_SUFFIX = [PAIR_END_FILE_PATTERN+"1",PAIR_END_FILE_PATTERN+"2"]')
    (50, 'else: PAIR_SUFFIX = [""]')
    (51, '')
    (52, '')
    (53, 'if IS_PAIRED_END:  print("Workflow set on paired end mode")')
    (54, 'else : print("Workflow set on single end mode")')
    (55, '')
    (56, '')
    (57, '##############')
    (58, 'rule all: ')
    (59, '\\tinput: OUTPUT_PATH+"/results/multiqc_report.html"')
    (60, '')
    (61, 'if IS_PAIRED_END : ')
    (62, '\\trule TRIMMOMATIC:')
    (63, '\\t\\tinput: expand(FASTQ_PATH+"/{{sample}}{pair}.fastq.gz",pair=PAIR_SUFFIX)')
    (64, '\\t\\toutput:')
    (65, '\\t\\t\\tpairedR1=OUTPUT_PATH+"/FASTQ_TRIM/{sample}"+PAIR_SUFFIX[0]+".fastq.gz",')
    (66, '\\t\\t\\tpairedR2=OUTPUT_PATH+"/FASTQ_TRIM/{sample}"+PAIR_SUFFIX[1]+".fastq.gz",')
    (67, '\\t\\t\\tunpairedR1=OUTPUT_PATH+"/FASTQ_TRIM_UNPAIR/{sample}"+PAIR_SUFFIX[0]+".fastq.gz",')
    (68, '\\t\\t\\tunpairedR2=OUTPUT_PATH+"/FASTQ_TRIM_UNPAIR/{sample}"+PAIR_SUFFIX[1]+".fastq.gz",')
    (69, '\\t\\tshell: """')
    (70, '\\t\\ttrimmomatic PE {input} {output.pairedR1} {output.unpairedR1} {output.pairedR2} {output.unpairedR2} \\\\')
    (71, '\\t\\tILLUMINACLIP:TruSeq3-PE.fa:2:30:10:2:True LEADING:3 TRAILING:3 MINLEN:36')
    (72, '\\t\\t"""\\t')
    (73, 'else:')
    (74, '\\trule TRIMMOMATIC:')
    (75, '\\t\\tinput: FASTQ_PATH+"/{sample}.fastq.gz"')
    (76, '\\t\\toutput: OUTPUT_PATH+"/FASTQ_TRIM/{sample}.fastq.gz",')
    (77, '\\t\\tshell: """')
    (78, '\\t\\ttrimmomatic SE {input} {output} ILLUMINACLIP:TruSeq3-SE.fa:2:30:10 LEADING:3 TRAILING:3 MINLEN:36')
    (79, '\\t\\t"""\\t')
    (80, '')
    (81, 'rule FASTQC:')
    (82, '\\tinput: ALIGN_FASTQ_FOLDER+"/{sample}{pair}.fastq.gz"')
    (83, '\\toutput: multiext(OUTPUT_PATH+"/fastQC/{sample}{pair}_fastqc",".zip",".html")')
    (84, '\\tshell: """')
    (85, '\\tfastqc -o {OUTPUT_PATH}/fastQC {input}')
    (86, '\\t"""')
    (87, 'rule BWA_INDEX:')
    (88, '\\tinput: FASTA_REFERENCE')
    (89, '\\toutput: FASTA_REFERENCE+".bwt"')
    (90, '\\tshell: """')
    (91, '\\tbwa index {input}')
    (92, '\\t"""')
    (93, '')
    (94, '# rule CreateSequenceDictionary:')
    (95, '# \\tinput: FASTA_REFERENCE')
    (96, '# \\toutput: FASTA_REFERENCE+".dict"')
    (97, '# \\tshell: """')
    (98, '# \\tpicard CreateSequenceDictionary R={input} O={output}')
    (99, '# \\t"""')
    (100, '### ALIGN EACH PAIR OF FASTQ FILES')
    (101, 'rule ALIGN:')
    (102, '\\tinput:')
    (103, '\\t\\tfastq = expand(ALIGN_FASTQ_FOLDER+"/{{sample}}{pair}.fastq.gz",pair=PAIR_SUFFIX),')
    (104, '\\t\\tindex = FASTA_REFERENCE+".bwt"')
    (105, '\\tlog: out=OUTPUT_PATH+"/log/ALIGN_{sample}.out"')
    (106, '\\toutput:\\tOUTPUT_PATH+"/BAM/{sample}.bam"')
    (107, '\\tshell:\\t"""')
    (108, '\\tbwa mem -t 1 -M \\\\')
    (109, "\\t-R \\'@RG\\\\\\\\tID:{wildcards.sample}\\\\\\\\tLB:{wildcards.sample}\\\\\\\\tSM:{wildcards.sample}\\\\\\\\tPL:Illumina\\\\\\\\tCN:CENTER\\' \\\\")
    (110, '\\t{FASTA_REFERENCE} {input.fastq} 2> {log.out} | samtools view -bS > {output}')
    (111, '\\t"""\\t\\t')
    (112, '')
    (113, 'rule SORT_BAM:')
    (114, '\\tinput: OUTPUT_PATH+"/BAM/{sample}.bam"')
    (115, '\\toutput: OUTPUT_PATH+"/SORTED_BAM/{sample}.bam"')
    (116, '\\tparams: cpu = THREAD_PER_SAMPLE')
    (117, '\\tshell: """')
    (118, '\\tsamtools sort -@{params.cpu} -o {output} {input} ')
    (119, '\\t"""')
    (120, '')
    (121, 'rule INDEX_BAM:')
    (122, '\\tinput: OUTPUT_PATH+"/SORTED_BAM/{sample}.bam"')
    (123, '\\toutput: OUTPUT_PATH+"/SORTED_BAM/{sample}.bam.bai"')
    (124, '\\tparams: cpu = THREAD_PER_SAMPLE')
    (125, '\\tshell: """')
    (126, '\\tsamtools index -@{params.cpu} {input}')
    (127, '\\t"""')
    (128, '\\t')
    (129, '###############')
    (130, 'rule mpileUp:')
    (131, '\\tinput:')
    (132, '\\t\\tsorted = OUTPUT_PATH+"/SORTED_BAM/{sample}.bam",')
    (133, '\\t\\tindex = OUTPUT_PATH+"/SORTED_BAM/{sample}.bam.bai"')
    (134, '\\toutput: OUTPUT_PATH+"/VCF/{sample}.vcf"')
    (135, '\\tshell: """')
    (136, '\\tbcftools mpileup -Ou -f {FASTA_REFERENCE} {input.sorted} | bcftools call -Ou -mv  | bcftools norm -Ou -f {FASTA_REFERENCE}  -o {output}')
    (137, '\\t"""')
    (138, '')
    (139, '### FILTER SNVS')
    (140, '#rule filterSNVs:')
    (141, '#\\tinput:')
    (142, '#\\t\\tvcf = OUTPUT_PATH+"/VCF/{sample}.vcf",')
    (143, '#\\t\\tdict = FASTA_REFERENCE+".dict"')
    (144, '#\\toutput:\\tvcf = OUTPUT_PATH+"/filteredVCF/{sample}.vcf"')
    (145, '#\\tshell: """')
    (146, '#\\tgatk -Xmx3g -T VariantFiltration \\\\')
    (147, '#\\t-R {FASTA_REFERENCE} \\\\')
    (148, '#\\t--logging_level FATAL  \\\\')
    (149, "#\\t--filterExpression \\'QD < 2.0\\' --filterName \\'FAILS_HARD_FILTER_SNP_QD\\' \\\\")
    (150, "#\\t--filterExpression \\'FS > 60.0\\' --filterName \\'FAILS_HARD_FILTER_SNP_FS\\' \\\\")
    (151, "#\\t--filterExpression \\'MQ < 30.0\\' --filterName \\'FAILS_HARD_FILTER_SNP_MQ\\' \\\\")
    (152, "#\\t--filterExpression \\'MQRankSum < -12.5\\' --filterName \\'FAILS_HARD_FILTER_SNP_MQRankSum\\' \\\\")
    (153, "#\\t--filterExpression \\'ReadPosRankSum < -8.0\\' --filterName \\'FAILS_HARD_FILTER_SNP_ReadPosRankSum\\' \\\\")
    (154, '#\\t--variant {input.vcf} \\\\')
    (155, '#\\t-o {output.vcf}')
    (156, '#\\t"""')
    (157, '\\t')
    (158, '############')
    (159, 'rule vcf2tsv:')
    (160, '\\tinput:')
    (161, '\\t\\tOUTPUT_PATH+"/VCF/{sample}.vcf"')
    (162, '\\toutput:')
    (163, '\\t\\tOUTPUT_PATH+"/TSV/{sample}.tsv"')
    (164, '\\tparams:')
    (165, '\\t\\tscript=WORKING_DIR+"/processVCF.R",')
    (166, '\\t\\tgeneralRfun=WORKING_DIR+"/general.R"')
    (167, '\\tshell: """')
    (168, '\\t\\tRscript {params.script} {input} {output} {params.generalRfun}')
    (169, '\\t"""')
    (170, '')
    (171, 'rule mergeVCF:')
    (172, '\\tinput:')
    (173, '\\t\\texpand(OUTPUT_PATH+"/TSV/{sample}.tsv", sample=SAMPLES)')
    (174, '\\toutput:')
    (175, '\\t\\tOUTPUT_PATH+"/results/merged.tsv"')
    (176, '\\tshell: """')
    (177, '\\t\\tRscript {WORKING_DIR}/mergeVCF.R {OUTPUT_PATH} {WORKING_DIR}/general.R')
    (178, '\\t"""')
    (179, '')
    (180, 'rule HTSEQ_COUNT:')
    (181, '\\tinput: OUTPUT_PATH+"/BAM/{sample}.bam"')
    (182, '\\toutput: OUTPUT_PATH+"/counts/{sample}.counts"')
    (183, '\\tparams:')
    (184, '\\t\\tgtf = GTF_REFERENCE,')
    (185, '\\t\\tfeatureID = FEATURE_ID,')
    (186, '\\t\\tfeatureType = FEATURE_TYPE')
    (187, '\\tlog: err=OUTPUT_PATH+"/log/HTSEQ_COUNT_{sample}.err"')
    (188, '\\tshell: """')
    (189, '\\thtseq-count -f bam -t {params.featureType} -i {params.featureID} -s no {input} {params.gtf} 1> {output} 2> {log.err}')
    (190, '\\t"""')
    (191, '\\t')
    (192, 'rule COUNTS_TABLE:')
    (193, '\\tinput: expand(OUTPUT_PATH+"/counts/{sample}.counts",sample=SAMPLES)')
    (194, '\\toutput:')
    (195, '\\t\\ttable = OUTPUT_PATH+"/results/rawCountsTable.tsv",')
    (196, '\\t\\tstat = OUTPUT_PATH+"/results/alignStatTable.tsv"')
    (197, '\\tparams: cpu = 1')
    (198, '\\tlog:')
    (199, '\\t\\tout=OUTPUT_PATH+"/log/COUNTS_TABLE.out",')
    (200, '\\t\\terr=OUTPUT_PATH+"/log/COUNTS_TABLE.err"')
    (201, '\\tshell: "Rscript {WORKING_DIR}/countsTable.R {OUTPUT_PATH}  1> {log.out} 2> {log.err}"')
    (202, '')
    (203, 'rule MULTIQC:')
    (204, '\\tinput:')
    (205, '\\t\\tfastqc=expand(OUTPUT_PATH+"/fastQC/{sample}{pair}_fastqc{ext}", sample=SAMPLES,pair=PAIR_SUFFIX,ext=[".zip",".html"]),')
    (206, '\\t\\ttsv=OUTPUT_PATH+"/results/merged.tsv",')
    (207, '\\t\\ttable = OUTPUT_PATH+"/results/rawCountsTable.tsv",')
    (208, '\\t\\tstat = OUTPUT_PATH+"/results/alignStatTable.tsv"')
    (209, '\\toutput: OUTPUT_PATH+"/results/multiqc_report.html"')
    (210, '\\tparams:')
    (211, '\\t\\toutpath = OUTPUT_PATH + "/results",')
    (212, '\\t\\tcpu = 1')
    (213, '\\tshell: """')
    (214, '\\tmultiqc -f -e general_stats -e tophat -e bowtie2 {OUTPUT_PATH} -o {params.outpath}')
    (215, '\\t"""')
    (216, "'")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=snakemake-workflows/chipseq, file=workflow/rules/peak_analysis.smk
context_key: ['input', 'params', 'if config["single_end"] else "']
    (29, '                if config["single_end"] else ""')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=leomorelli/scGET, file=Snakefile
context_key: ["if config[\\'atac\\']==True"]
    (29, "if config[\\'atac\\']==True:")
    (30, "    exp=\\'atac\\'")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=leomorelli/scGET, file=Snakefile
context_key: ["if config[\\'tn5\\']!=True"]
    (39, "if config[\\'tn5\\']!=True:")
    (40, "    TN_BARCODE=config[\\'barcodes\\']")
    (41, "    TN_BARCODES={\\'tnh\\':TN_BARCODE[\\'tnh\\']}")
    (42, "    BARCODES=TN_BARCODES[\\'tnh\\']")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=leomorelli/scGET, file=Snakefile
context_key: ["elif config[\\'tnh\\']!=True"]
    (43, "elif config[\\'tnh\\']!=True:")
    (44, "    TN_BARCODE=config[\\'barcodes\\']")
    (45, "    TN_BARCODES={\\'tn5\\':TN_BARCODE[\\'tn5\\']}")
    (46, "    BARCODES=TN_BARCODES[\\'tn5\\']")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=iobis/PacMAN-pipeline, file=workflow/Snakefile
context_key: ['if config["meta"]["sequencing"]["lib_layout"] == "Paired"', 'rule dada2_filter', 'input']
    (241, 'if config["meta"]["sequencing"]["lib_layout"] == "Paired":')
    (242, '    rule dada2_filter:')
    (243, '        input:')
    (244, '            #files = expand("{PROJECT}/runs/{RUN}/02-cutadapt/{samples}/", PROJECT=PROJECT, RUN=RUN, samples=samples),')
    (245, '            f1 = expand("results/{PROJECT}/runs/{RUN}/02-cutadapt/{samples}/{samples}_1P.fastq.gz",')
    (246, '                        PROJECT=PROJECT, RUN=RUN, samples=samples),')
    (247, '            #f2 = expand("{PROJECT}/runs/{RUN}/02-cutadapt/{samples}/{samples}_2P.fastq.gz", PROJECT=PROJECT, RUN=RUN, samples=samples),')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=iobis/PacMAN-pipeline, file=workflow/Snakefile
context_key: ['if config["meta"]["sequencing"]["lib_layout"] == "Paired"', 'rule dada2_filter', 'output']
    (248, '        output:')
    (249, '            FiltF = expand("results/{PROJECT}/runs/{RUN}/03-dada2/filtered/{samples}/{samples}_1P.fastq.gz",')
    (250, '                           PROJECT=PROJECT, RUN=RUN, samples=samples),')
    (251, '            FiltR = expand("results/{PROJECT}/runs/{RUN}/03-dada2/filtered/{samples}/{samples}_2P.fastq.gz",')
    (252, '                           PROJECT=PROJECT, RUN=RUN, samples=samples),')
    (253, '            #directory(expand("{PROJECT}/runs/{RUN}/dada2/filtered/{samples}/"), PROJECT=PROJECT, RUN=RUN, samples=samples),')
    (254, '            #stats="{PROJECT}/runs/{RUN}/dada2/dada2_filtering_stats.txt",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=iobis/PacMAN-pipeline, file=workflow/Snakefile
context_key: ['if config["meta"]["sequencing"]["lib_layout"] == "Paired"', 'rule dada2_filter', 'conda']
    (255, '        conda:')
    (256, '            "envs/dada2.yaml"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=iobis/PacMAN-pipeline, file=workflow/Snakefile
context_key: ['if config["meta"]["sequencing"]["lib_layout"] == "Paired"', 'rule dada2_filter', 'shell']
    (257, '        shell:')
    (258, '            "Rscript ./workflow/scripts/Dada2_FilterAndTrim_combined.R \\\\')
    (259, '            results/{config[PROJECT]}/runs/{config[RUN]}/ \\\\')
    (260, '            "+config_path+" \\\\')
    (261, '            {input.f1}"')
    (262, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=iobis/PacMAN-pipeline, file=workflow/Snakefile
context_key: ['if config["meta"]["sequencing"]["lib_layout"] == "Paired"', 'rule dada2_ASV', 'input']
    (263, '    rule dada2_ASV:')
    (264, '        input:')
    (265, '            FiltF = expand("results/{PROJECT}/runs/{RUN}/03-dada2/filtered/{samples}/{samples}_1P.fastq.gz",')
    (266, '                           PROJECT=PROJECT, RUN=RUN, samples=samples),')
    (267, '            FiltR = expand("results/{PROJECT}/runs/{RUN}/03-dada2/filtered/{samples}/{samples}_2P.fastq.gz",')
    (268, '                           PROJECT=PROJECT, RUN=RUN, samples=samples),')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=iobis/PacMAN-pipeline, file=workflow/Snakefile
context_key: ['if config["meta"]["sequencing"]["lib_layout"] == "Paired"', 'rule dada2_ASV', 'output']
    (269, '        output:')
    (270, '            #o1 = expand("results/{PROJECT}/runs/{RUN}/03-dada2/dada2_stats.txt", PROJECT=PROJECT, RUN=RUN),')
    (271, '            #o2 = expand("results/{PROJECT}/runs/{RUN}/03-dada2/seqtab-nochim.txt", PROJECT=PROJECT, RUN=RUN),')
    (272, '            #o3 = expand("results/{PROJECT}/runs/{RUN}/03-dada2/rep-seqs.fna", PROJECT=PROJECT, RUN=RUN),')
    (273, '            o2 = expand("results/{PROJECT}/runs/{RUN}/03-dada2/seqtab-nochim.txt", PROJECT=PROJECT, RUN=RUN, samples=samples),')
    (274, '            o3 = expand("results/{PROJECT}/runs/{RUN}/03-dada2/rep-seqs.fna", PROJECT=PROJECT, RUN=RUN, samples=samples),')
    (275, '            o4 = expand("results/{PROJECT}/runs/{RUN}/03-dada2/mapping/{samples}/{samples}_mapping.txt", PROJECT=PROJECT, RUN=RUN, samples=samples),')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=iobis/PacMAN-pipeline, file=workflow/Snakefile
context_key: ['if config["meta"]["sequencing"]["lib_layout"] == "Paired"', 'rule dada2_ASV', 'log']
    (276, '        log:')
    (277, '            o1 = expand("results/{PROJECT}/runs/{RUN}/06-report/dada2/dada2_stats.txt", PROJECT=PROJECT, RUN=RUN, samples=samples),')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=iobis/PacMAN-pipeline, file=workflow/Snakefile
context_key: ['if config["meta"]["sequencing"]["lib_layout"] == "Paired"', 'rule dada2_ASV', 'conda']
    (278, '        conda:')
    (279, '            "envs/dada2.yaml"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=iobis/PacMAN-pipeline, file=workflow/Snakefile
context_key: ['if config["meta"]["sequencing"]["lib_layout"] == "Paired"', 'rule dada2_ASV', 'shell']
    (280, '        shell:')
    (281, '            "Rscript ./workflow/scripts/Dada2_ASVInference_Single.R \\\\')
    (282, '            results/{config[PROJECT]}/runs/{config[RUN]}/ \\\\')
    (283, '            "+config_path+" \\\\')
    (284, '            {input.FiltF}"')
    (285, '')
    (286, '')
    (287, '# RULES: TAXONOMIC ASSIGNMENT ----------------------------------------------------------------')
    (288, '')
    (289, '# In this part we will perform the taxonomic assignment of the reads with bowtie2 and blca')
    (290, '# Following the strategy of the ANACAPA pipeline')
    (291, '')
    (292, '# First we will build the bowtie2 database if it is not given in the configfile:')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=iobis/PacMAN-pipeline, file=workflow/Snakefile
context_key: ['if config["DATABASE"]["location_bowtie2"] == None', 'rule bowtie2_build', 'input']
    (293, 'if config["DATABASE"]["location_bowtie2"] == None:')
    (294, '    rule bowtie2_build:')
    (295, '        input:')
    (296, '          fasta = config["DATABASE"]["fasta"],')
    (297, '          #prefix=expand("resources/bowtie2_dbs/{DATABASE}/{DATABASE}", DATABASE=DATABASE),')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=iobis/PacMAN-pipeline, file=workflow/Snakefile
context_key: ['if config["DATABASE"]["location_bowtie2"] == None', 'rule bowtie2_build', 'output']
    (298, '        output:')
    (299, '          expand("resources/bowtie2_dbs/{DATABASE}/{DATABASE}.{index}.bt2",')
    (300, '                 DATABASE=DATABASE, index=range(1, 5)),')
    (301, '          expand("resources/bowtie2_dbs/{DATABASE}/{DATABASE}.rev.{index}.bt2",')
    (302, '                 DATABASE=DATABASE, index=range(1, 3))')
    (303, '        #params:')
    (304, '          #prefix="resources/bowtie2_dbs/{DATABASE}/{DATABASE}",')
    (305, "          #tmp_dir=config[\\'global_tmp_dir\\']")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=iobis/PacMAN-pipeline, file=workflow/Snakefile
context_key: ['if config["DATABASE"]["location_bowtie2"] == None', 'rule bowtie2_build', 'conda']
    (306, '        conda:')
    (307, '          "envs/bowtie2.yaml"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=iobis/PacMAN-pipeline, file=workflow/Snakefile
context_key: ['if config["DATABASE"]["location_bowtie2"] == None', 'rule bowtie2_build', 'shell']
    (308, '        shell:')
    (309, '          "bowtie2-build {input.fasta} resources/bowtie2_dbs/" + \\\\')
    (310, '            config["DATABASE"]["name"]+"/"+config["DATABASE"]["name"]')
    (311, '')
    (312, '')
    (313, '# Input for bowtie2 depends on if the mapping was given or not: now if statement, could be changed to something else?')
    (314, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=iobis/PacMAN-pipeline, file=workflow/Snakefile
context_key: ['if config["DATABASE"]["location_bowtie2"] != None', 'rule bowtie2', 'input']
    (315, 'if config["DATABASE"]["location_bowtie2"] != None:')
    (316, '    rule bowtie2:')
    (317, '      input:')
    (318, '        rep_seqs = expand(')
    (319, '          "results/{PROJECT}/runs/{RUN}/03-dada2/rep-seqs.fna", PROJECT=PROJECT, RUN=RUN),')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=iobis/PacMAN-pipeline, file=workflow/Snakefile
context_key: ['if config["DATABASE"]["location_bowtie2"] != None', 'rule bowtie2', 'output']
    (320, '      output:')
    (321, '        o1 = "results/{PROJECT}/runs/{RUN}/04-taxonomy/bowtie2/{DATABASE}_bowtie2_local.sam",')
    (322, '        o2 = "results/{PROJECT}/runs/{RUN}/04-taxonomy/bowtie2/{DATABASE}_bowtie2_rejects.fasta",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=iobis/PacMAN-pipeline, file=workflow/Snakefile
context_key: ['if config["DATABASE"]["location_bowtie2"] != None', 'rule bowtie2', 'log']
    (323, '      log:')
    (324, '        f1 = "results/{PROJECT}/runs/{RUN}/06-report/bowtie2/bowtie2_{DATABASE}_log.txt"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=iobis/PacMAN-pipeline, file=workflow/Snakefile
context_key: ['if config["DATABASE"]["location_bowtie2"] != None', 'rule bowtie2', 'conda']
    (325, '      conda:')
    (326, '        "envs/bowtie2.yaml"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=iobis/PacMAN-pipeline, file=workflow/Snakefile
context_key: ['if config["DATABASE"]["location_bowtie2"] != None', 'rule bowtie2', 'shell']
    (327, '      shell:')
    (328, '        "bowtie2 -x {config[DATABASE][location_bowtie2]} \\\\')
    (329, '        -f -U {input.rep_seqs} \\\\')
    (330, '        -S {output.o1} \\\\')
    (331, '        --no-hd \\\\')
    (332, '        --no-sq \\\\')
    (333, '        --very-sensitive \\\\')
    (334, '        --local \\\\')
    (335, '        --no-unal \\\\')
    (336, '        -p {config[TAXONOMY][threads]} \\\\')
    (337, '        -k {config[TAXONOMY][distinct_alignments]} \\\\')
    (338, '        --un {output.o2} \\\\')
    (339, '        2> {log.f1}"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=iobis/PacMAN-pipeline, file=workflow/Snakefile
context_key: ['if config["BLAST"]["include"] == True', 'rule blast_unknown', 'input']
    (411, 'if config["BLAST"]["include"] == True:')
    (412, '    rule blast_unknown:')
    (413, '        input:')
    (414, '            taxa = "results/{PROJECT}/runs/{RUN}/04-taxonomy/blca/{DATABASE}_bowtie2_local.sam.blca.out",')
    (415, '            filtered = "results/{PROJECT}/runs/{RUN}/04-taxonomy/identity_filtered/{DATABASE}_blca_tax_table_{CUTOFF}.txt",')
    (416, '            fasta = "results/{PROJECT}/runs/{RUN}/03-dada2/rep-seqs.fna",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=iobis/PacMAN-pipeline, file=workflow/Snakefile
context_key: ['if config["BLAST"]["include"] == True', 'rule blast_unknown', 'output']
    (417, '        output:')
    (418, '            o1 = "results/{PROJECT}/runs/{RUN}/04-taxonomy/blca/{DATABASE}_bowtie2_local_unknowns_cutoff{CUTOFF}.sam.blca.out",')
    (419, '            o2 = "results/{PROJECT}/runs/{RUN}/04-taxonomy/blca/{DATABASE}_unclassified-seqs_cutoff{CUTOFF}.fna",')
    (420, '            o3 = "results/{PROJECT}/runs/{RUN}/04-taxonomy/blast/{DATABASE}_unclassified_blast_results_cutoff{CUTOFF}.tab",')
    (421, '            #o2 = add information to the sam.blca.out table.')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=iobis/PacMAN-pipeline, file=workflow/Snakefile
context_key: ['if config["BLAST"]["include"] == True', 'rule blast_unknown', 'conda']
    (422, '        conda:')
    (423, '            "envs/seqs.yaml",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=iobis/PacMAN-pipeline, file=workflow/Snakefile
context_key: ['if config["BLAST"]["include"] == True', 'rule blast_unknown', 'shell']
    (424, '        shell:')
    (425, '            "awk \\\'/Unclassified/ {{print $1}}\\\' {input.taxa} > {output.o1}; \\\\')
    (426, "            awk \\'/;;;;;;/ {{print $1}}\\' {input.filtered} | cat >> {output.o1}; \\\\")
    (427, '            sort -t . -k 2n -o {output.o1} {output.o1}; \\\\')
    (428, '            seqtk subseq {input.fasta} {output.o1}  > {output.o2}; \\\\')
    (429, '            blastn \\\\')
    (430, '            -query {output.o2} \\\\')
    (431, '            -out {output.o3} \\\\')
    (432, '            -outfmt 6 \\\\')
    (433, '            {config[BLAST][database]}"')
    (434, '            # removed this as can be filtered later: -evalue 5e-13 \\\\')
    (435, '')
    (436, '# Here we add those that were completely unclassified (no matches in the provided reference database),')
    (437, '# As well as those that did not have a good match in the database (lower confidence tha the cutoff value at Kingdom)')
    (438, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=iobis/PacMAN-pipeline, file=workflow/Snakefile
context_key: ['if config["BLAST"]["include"] == True', 'if config["BLAST"]["tax_db"] != None', 'rule lca_blast', 'input']
    (439, '    if config["BLAST"]["tax_db"] != None:')
    (440, '        rule lca_blast:')
    (441, '            input:')
    (442, '                blast_results = "results/{PROJECT}/runs/{RUN}/04-taxonomy/blast/{DATABASE}_unclassified_blast_results_cutoff{CUTOFF}.tab",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=iobis/PacMAN-pipeline, file=workflow/Snakefile
context_key: ['if config["BLAST"]["include"] == True', 'if config["BLAST"]["tax_db"] != None', 'rule lca_blast', 'output']
    (443, '            output:')
    (444, '                basta_results = "results/{PROJECT}/runs/{RUN}/04-taxonomy/blast/{DATABASE}_unclassified_blast_results_lca_cutoff{CUTOFF}.tab"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=iobis/PacMAN-pipeline, file=workflow/Snakefile
context_key: ['if config["BLAST"]["include"] == True', 'if config["BLAST"]["tax_db"] != None', 'rule lca_blast', 'conda']
    (445, '            conda:')
    (446, '                "envs/seqs.yaml"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=iobis/PacMAN-pipeline, file=workflow/Snakefile
context_key: ['if config["BLAST"]["include"] == True', 'if config["BLAST"]["tax_db"] != None', 'rule lca_blast', 'shell']
    (447, '            shell:')
    (448, '                "basta sequence \\\\')
    (449, '                -p {config[BLAST][portion_of_hits]} \\\\')
    (450, '                -i {config[BLAST][percent_identity]} \\\\')
    (451, '                -e {config[BLAST][e-value]} \\\\')
    (452, '                -n {config[BLAST][max_hits]} \\\\')
    (453, '                -m {config[BLAST][min_hits]} \\\\')
    (454, '                -d {config[BLAST][tax_db]} \\\\')
    (455, '                {input.blast_results} \\\\')
    (456, '                {output.basta_results} \\\\')
    (457, '                gb"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=iobis/PacMAN-pipeline, file=workflow/Snakefile
context_key: ['if config["BLAST"]["include"] == True', 'else', 'rule lca_blast', 'input']
    (458, '    else:')
    (459, '        rule lca_blast:')
    (460, '            input:')
    (461, '                blast_results = "results/{PROJECT}/runs/{RUN}/04-taxonomy/blast/{DATABASE}_unclassified_blast_results_cutoff{CUTOFF}.tab",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=iobis/PacMAN-pipeline, file=workflow/Snakefile
context_key: ['if config["BLAST"]["include"] == True', 'else', 'rule lca_blast', 'output']
    (462, '            output:')
    (463, '                basta_results = "results/{PROJECT}/runs/{RUN}/04-taxonomy/blast/{DATABASE}_unclassified_blast_results_lca_cutoff{CUTOFF}.tab"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=iobis/PacMAN-pipeline, file=workflow/Snakefile
context_key: ['if config["BLAST"]["include"] == True', 'else', 'rule lca_blast', 'conda']
    (464, '            conda:')
    (465, '                "envs/seqs.yaml"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=iobis/PacMAN-pipeline, file=workflow/Snakefile
context_key: ['if config["BLAST"]["include"] == True', 'else', 'rule lca_blast', 'shell']
    (466, '            shell:')
    (467, '                "basta download gb -d ./resources/tax_db/; \\\\')
    (468, '                basta sequence \\\\')
    (469, '                -p {config[BLAST][portion_of_hits]} \\\\')
    (470, '                -i {config[BLAST][percent_identity]} \\\\')
    (471, '                -e {config[BLAST][e-value]} \\\\')
    (472, '                -n {config[BLAST][max_hits]} \\\\')
    (473, '                -m {config[BLAST][min_hits]} \\\\')
    (474, '                -d ./resources/tax_db/ \\\\')
    (475, '                {input.blast_results} \\\\')
    (476, '                {output.basta_results} \\\\')
    (477, '                gb"')
    (478, '')
    (479, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SherineAwad/RNASeqVariantCalling, file=Snakefile
context_key: ["if config[\\'PAIRED\\']", 'rule trim', 'input']
    (18, "if config[\\'PAIRED\\']:")
    (19, '    rule trim:')
    (20, '       input:')
    (21, '           r1 = "{sample}.r_1.fq.gz",')
    (22, '           r2 = "{sample}.r_2.fq.gz"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SherineAwad/RNASeqVariantCalling, file=Snakefile
context_key: ["if config[\\'PAIRED\\']", 'rule trim', 'output']
    (23, '       output:')
    (24, '           "galore/{sample}.r_1_val_1.fq.gz",')
    (25, '           "galore/{sample}.r_2_val_2.fq.gz"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SherineAwad/RNASeqVariantCalling, file=Snakefile
context_key: ["if config[\\'PAIRED\\']", 'rule trim', 'conda']
    (26, "       conda: \\'env/env-trim.yaml\\'")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SherineAwad/RNASeqVariantCalling, file=Snakefile
context_key: ["if config[\\'PAIRED\\']", 'rule trim', 'shell']
    (27, '       shell:')
    (28, '           """')
    (29, '           mkdir -p galore')
    (30, '           mkdir -p fastqc')
    (31, '           trim_galore --gzip --retain_unpaired --trim1 --fastqc --fastqc_args "--outdir fastqc" -o galore --paired {input.r1} {input.r2}')
    (32, '           """')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SherineAwad/RNASeqVariantCalling, file=Snakefile
context_key: ["if config[\\'PAIRED\\']", 'rule align', 'input']
    (33, '    rule align:')
    (34, '        input:')
    (35, '           "galore/{sample}.r_1_val_1.fq.gz",')
    (36, '           "galore/{sample}.r_2_val_2.fq.gz"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SherineAwad/RNASeqVariantCalling, file=Snakefile
context_key: ["if config[\\'PAIRED\\']", 'rule align', 'output']
    (37, '        output:')
    (38, '             "{sample}_Aligned.out.sam"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SherineAwad/RNASeqVariantCalling, file=Snakefile
context_key: ["if config[\\'PAIRED\\']", 'rule align', 'params']
    (39, '        params:')
    (40, "             threads = config[\\'THREADS\\'],")
    (41, "             gtf = config[\\'GTF\\'],")
    (42, '             prefix = "{sample}_",')
    (43, "             index = config[\\'INDEX\\']")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SherineAwad/RNASeqVariantCalling, file=Snakefile
context_key: ["if config[\\'PAIRED\\']", 'rule align', 'shell']
    (44, '        shell:')
    (45, '           """')
    (46, '           STAR --genomeDir {params.index} --runThreadN {params.threads}  --readFilesCommand zcat  --readFilesIn {input[0]} {input[1]}  --outFileNamePrefix {params.prefix} --sjdbGTFfile {params.gtf}  --twopassMode Basic')
    (47, '           """')
    (48, '')
    (49, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=panprostate/RNA, file=workflow/Snakefile
context_key: ['if config["library_type"] == "PE"']
    (38, 'if config["library_type"] == "PE":')
    (39, '    include:"rules/PE/inputFunctions.smk"')
    (40, '    include:"rules/downloads.smk"')
    (41, '    include:"rules/PE/RNASeq.smk"')
    (42, '    include:"rules/PE/variantCalling.smk"')
    (43, '    include:"rules/PE/QC.smk"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=aryarm/as_analysis, file=Snakefiles/Snakefile-counts
context_key: ["if config[\\'rna_only\\']", 'rule prepare_counts', 'input']
    (169, "if config[\\'rna_only\\']:")
    (170, '    rule prepare_counts:')
    (171, '        """prepare counts for detecting imbalance, adding gene info')
    (172, '        and calculating genotype error"""')
    (173, '        input:')
    (174, '            rna_counts = lambda wildcards:')
    (175, '                rules.remove_indel_counts.output[0].format(')
    (176, '                    sample=wildcards.sample, type="rna"')
    (177, '                ),')
    (178, '            gq_file = lambda wildcards:')
    (179, "                [] if \\'default_gq\\' in config and config[\\'default_gq\\'] else \\\\")
    (180, '                rules.extract_gq_scores.output[0].format(')
    (181, '                    vcf_sample=SAMP_TO_VCF_ID[wildcards.sample]')
    (182, '                ),')
    (183, "            gene_info = config[\\'gene_info\\']")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=aryarm/as_analysis, file=Snakefiles/Snakefile-counts
context_key: ["if config[\\'rna_only\\']", 'rule prepare_counts', 'params']
    (184, '        params:')
    (185, '            output_dir = lambda wildcards, output: str(Path(output[0]).parent)+"/",')
    (186, "            gq = lambda wildcards, input: config[\\'default_gq\\'] if \\'default_gq\\' in config \\\\")
    (187, "                and config[\\'default_gq\\'] else input.gq_file")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=aryarm/as_analysis, file=Snakefiles/Snakefile-counts
context_key: ["if config[\\'rna_only\\']", 'rule prepare_counts', 'output']
    (188, '        output:')
    (189, '            rna = config[\\\'output_dir\\\'] + "/final/{sample}/rna.csv.gz"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=aryarm/as_analysis, file=Snakefiles/Snakefile-counts
context_key: ["if config[\\'rna_only\\']", 'rule prepare_counts', 'conda']
    (190, '        conda: "../envs/default.yaml"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=aryarm/as_analysis, file=Snakefiles/Snakefile-counts
context_key: ["if config[\\'rna_only\\']", 'rule prepare_counts', 'benchmark']
    (191, '        benchmark: config[\\\'output_dir\\\'] + "/benchmark/counts/prepare_counts/{sample}.tsv"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=aryarm/as_analysis, file=Snakefiles/Snakefile-counts
context_key: ["if config[\\'rna_only\\']", 'rule prepare_counts', 'resources']
    (192, '        resources:')
    (193, '            mem_mb = 12500')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=aryarm/as_analysis, file=Snakefiles/Snakefile-counts
context_key: ["if config[\\'rna_only\\']", 'rule prepare_counts', 'shell']
    (194, '        shell:')
    (195, '            "Rscript --no-save --no-restore scripts/"')
    (196, '            "prepare_counts-rna.r {input.rna_counts} "')
    (197, '            "{params.gq} {input.gene_info} {params.output_dir}"')
    (198, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=aryarm/as_analysis, file=Snakefiles/Snakefile-counts
context_key: ["if config[\\'rna_only\\']", 'rule detect_imbalance', 'input']
    (199, '    rule detect_imbalance:')
    (200, '        """quantify allelic imbalance in genes for each sample"""')
    (201, '        input:')
    (202, '            rna = rules.prepare_counts.output.rna,')
    (203, "            gene_info = config[\\'gene_info\\']")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=aryarm/as_analysis, file=Snakefiles/Snakefile-counts
context_key: ["if config[\\'rna_only\\']", 'rule detect_imbalance', 'params']
    (204, '        params:')
    (205, '            imbalance_script_path = "scripts/allele_imbalance-rna.r"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=aryarm/as_analysis, file=Snakefiles/Snakefile-counts
context_key: ["if config[\\'rna_only\\']", 'rule detect_imbalance', 'output']
    (206, '        output:')
    (207, '            config[\\\'output_dir\\\'] + "/final/{sample}/result.csv.gz"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=aryarm/as_analysis, file=Snakefiles/Snakefile-counts
context_key: ["if config[\\'rna_only\\']", 'rule detect_imbalance', 'conda']
    (208, '        conda: "../envs/default.yaml"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=aryarm/as_analysis, file=Snakefiles/Snakefile-counts
context_key: ["if config[\\'rna_only\\']", 'rule detect_imbalance', 'benchmark']
    (209, '        benchmark: config[\\\'output_dir\\\'] + "/benchmark/counts/detect_imbalance/{sample}.tsv"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=aryarm/as_analysis, file=Snakefiles/Snakefile-counts
context_key: ["if config[\\'rna_only\\']", 'rule detect_imbalance', 'resources']
    (210, '        resources:')
    (211, '            mem_mb = 1950')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=aryarm/as_analysis, file=Snakefiles/Snakefile-counts
context_key: ["if config[\\'rna_only\\']", 'rule detect_imbalance', 'shell']
    (212, '        shell:')
    (213, '            "Rscript --no-save --no-restore scripts/"')
    (214, '            "find_imbalance-rna.r {params.imbalance_script_path} "')
    (215, '            "{input.rna} {input.gene_info} "')
    (216, '            "| gzip >{output}"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NCI-CGR/PING_BIOWULF, file=Snakefile
context_key: ['if config["step3"]=="yes"', 'rule all', 'input']
    (16, 'if config["step3"]=="yes":')
    (17, '   rule all:')
    (18, '       input:')
    (19, '             out_dir + "/ping12.html",')
    (20, '             out_dir + "/ping3.html"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=crazyhottommy/pyflow-cellranger, file=Snakefile
context_key: ["if config[\\'download\\']"]
    (14, "if config[\\'download\\']:\\t")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=crazyhottommy/pyflow-cellranger, file=Snakefile
context_key: ["if config[\\'download\\']", "if config[\\'make_seurat\\']", 'rule all']
    (37, "if config[\\'download\\']:")
    (38, '\\tTARGETS.extend(RUNS)')
    (39, '')
    (40, 'TARGETS.extend(FASTQ)')
    (41, 'TARGETS.extend(COUNT)')
    (42, '')
    (43, "if config[\\'make_seurat\\']:")
    (44, '\\tSEURAT_OBJ = expand("seurat_objs/{sample}_seurat.rds", sample = SAMPLES)')
    (45, '\\tTARGETS.extend(SEURAT_OBJ)')
    (46, '')
    (47, 'localrules: all')
    (48, 'rule all:')
    (49, '    input: TARGETS')
    (50, '')
    (51, '## if the bcl files are in BaseSpace, need to download')
    (52, '## the downloaded folder is named with the run_id')
    (53, '')
    (54, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=crazyhottommy/pyflow-cellranger, file=Snakefile
context_key: ["if config[\\'make_seurat\\']", 'onsuccess', 'onerror']
    (155, "if config[\\'make_seurat\\']:")
    (156, '\\trule make_seurat_obj:')
    (157, '\\t\\tinput: "count_stamps/{sample}.stamp"')
    (158, '\\t\\toutput: "seurat_objs/{sample}_seurat.rds"')
    (159, '\\t\\tlog: "00log/{sample}_make_seurat_obj.log"')
    (160, '\\t\\tthreads: 4')
    (161, '\\t\\tparams:')
    (162, '\\t\\t\\tmake_seurat_obj_args = config.get("make_seurat_obj_args", ""),')
    (163, '\\t\\t\\tcellranger_count_dir = lambda wildcards: "{sample}/outs/filtered_gene_bc_matrices/{count_dir}".format(sample = wildcards.sample, count_dir = count_dir)')
    (164, '\\t\\tmessage: "making seurat object for {sample}"')
    (165, '\\t\\tscript: "scripts/make_seurat.R"')
    (166, '')
    (167, '')
    (168, 'onsuccess:')
    (169, '\\tprint("Success: Snakemake completed!")')
    (170, '\\tshell("mail -s \\\'Snakemake workflow completed: Have a beer!\\\' {config[email]} < {log}")')
    (171, '')
    (172, 'onerror:')
    (173, '\\tprint("Error: Snakemake aborted!")')
    (174, '\\tshell("mail -s \\\'Snakemake workflow aborted: Have a coffee and see log inside!\\\' {config[email]} < {log}")')
    (175, '\\tshell("exit 1")')
    (176, "'")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=kevinrue/snakemake_cellranger_count, file=workflow/Snakefile
context_key: ["if config[\\'cellranger\\'][\\'jobmode\\'] in cellranger_local_jobmodes"]
    (26, "if config[\\'cellranger\\'][\\'jobmode\\'] in cellranger_local_jobmodes:")
    (27, "    _localrules.append(\\'cellranger_count\\')")
    (28, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=hydra-genetics/prealignment, file=workflow/rules/common.smk
context_key: ['if config.get("trimmer_software", None) == "fastp_pe"']
    (58, 'if config.get("trimmer_software", None) == "fastp_pe":')
    (59, '    merged_input = lambda wildcards: expand(')
    (60, '        "prealignment/fastp_pe/{{sample}}_{flowcell_lane_barcode}_{{type}}_{{read}}.fastq.gz",')
    (61, '        flowcell_lane_barcode=[')
    (62, '            "{}_{}_{}".format(unit.flowcell, unit.lane, unit.barcode) for unit in get_units(units, wildcards, wildcards.type)')
    (63, '        ],')
    (64, '    )')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=macsx82/VariantCalling-snakemake, file=Snakefile
context_key: ['onstart', 'if config.get("files_path").get("base_joint_call_path") == ""']
    (118, '    if config.get("files_path").get("base_joint_call_path") == "":')
    (119, '        print("The parameter base_joint_call_path is not defined!!")')
    (120, '        print("You need to define this parameter in order to start the pipeline!")')
    (121, '        shell("exit 1")')
    (122, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=ibebio/tiger-pipeline, file=workflow/rules/04_variant_calling_f2.smk
context_key: ["if config[\\'debug\\'][\\'call_variants_f2\\'][\\'create_vcf_for_f2\\'] == \\'yes\\'", 'rule dbg_call_variants_f2', 'input']
    (57, "if config[\\'debug\\'][\\'call_variants_f2\\'][\\'create_vcf_for_f2\\'] == \\'yes\\':")
    (58, '    rule dbg_call_variants_f2:')
    (59, '        input:')
    (60, '            bam="results/rmdup/{f2_sample_vc}.rmdup.bam"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=ibebio/tiger-pipeline, file=workflow/rules/04_variant_calling_f2.smk
context_key: ["if config[\\'debug\\'][\\'call_variants_f2\\'][\\'create_vcf_for_f2\\'] == \\'yes\\'", 'rule dbg_call_variants_f2', 'output']
    (61, '        output:')
    (62, '            gvcf=temp("results/variants/f2/gvcf/{crossing_id}.{f2_sample_vc}.g.vcf.gz"),')
    (63, '            gvcf_idx=temp("results/variants/f2/gvcf/{crossing_id}.{f2_sample_vc}.g.vcf.gz.tbi"),')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=ibebio/tiger-pipeline, file=workflow/rules/04_variant_calling_f2.smk
context_key: ["if config[\\'debug\\'][\\'call_variants_f2\\'][\\'create_vcf_for_f2\\'] == \\'yes\\'", 'rule dbg_call_variants_f2', 'params']
    (64, '        params:')
    (65, '            index=config["ref"]["genome"],')
    (66, '            java_options=config["gatk_options"]["java_options"],')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=ibebio/tiger-pipeline, file=workflow/rules/04_variant_calling_f2.smk
context_key: ["if config[\\'debug\\'][\\'call_variants_f2\\'][\\'create_vcf_for_f2\\'] == \\'yes\\'", 'rule dbg_call_variants_f2', 'threads']
    (67, '        threads: 4')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=ibebio/tiger-pipeline, file=workflow/rules/04_variant_calling_f2.smk
context_key: ["if config[\\'debug\\'][\\'call_variants_f2\\'][\\'create_vcf_for_f2\\'] == \\'yes\\'", 'rule dbg_call_variants_f2', 'resources']
    (68, '        resources:')
    (69, '            n=4,')
    (70, '            time=lambda wildcards, attempt: 48 * 59 * attempt,')
    (71, '            mem_gb_pt=lambda wildcards, attempt: 12 * attempt')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=ibebio/tiger-pipeline, file=workflow/rules/04_variant_calling_f2.smk
context_key: ["if config[\\'debug\\'][\\'call_variants_f2\\'][\\'create_vcf_for_f2\\'] == \\'yes\\'", 'rule dbg_call_variants_f2', 'log']
    (72, '        log:')
    (73, '            "results/logs/dbg_call_variants_f2/{crossing_id}.{f2_sample_vc}.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=ibebio/tiger-pipeline, file=workflow/rules/04_variant_calling_f2.smk
context_key: ["if config[\\'debug\\'][\\'call_variants_f2\\'][\\'create_vcf_for_f2\\'] == \\'yes\\'", 'rule dbg_call_variants_f2', 'conda']
    (74, '        conda:')
    (75, '            "../envs/gatk4.yaml"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=ibebio/tiger-pipeline, file=workflow/rules/04_variant_calling_f2.smk
context_key: ["if config[\\'debug\\'][\\'call_variants_f2\\'][\\'create_vcf_for_f2\\'] == \\'yes\\'", 'rule dbg_call_variants_f2', 'shell']
    (76, '        shell:')
    (77, '            """')
    (78, '            gatk --java-options "{params.java_options}" HaplotypeCaller \\\\')
    (79, '                -ERC GVCF \\\\')
    (80, '                -R {params.index} \\\\')
    (81, '                -I {input.bam} \\\\')
    (82, '                -O {output.gvcf} 2> {log}')
    (83, '            """')
    (84, '')
    (85, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=ibebio/tiger-pipeline, file=workflow/rules/04_variant_calling_f2.smk
context_key: ["if config[\\'debug\\'][\\'call_variants_f2\\'][\\'create_vcf_for_f2\\'] == \\'yes\\'", 'rule dbg_combine_calls_f2', 'input']
    (86, '    rule dbg_combine_calls_f2:')
    (87, '        input:')
    (88, '            gvcfs=lambda wildcards: expand("results/variants/f2/gvcf/{{crossing_id}}.{f2_sample_vc}.g.vcf.gz",')
    (89, '                f2_sample_vc=[c["f2_samples"] for c in config["crossings"] if c["id"] == wildcards.crossing_id][0]),')
    (90, '            gvcfs_idx=lambda wildcards: expand("results/variants/f2/gvcf/{{crossing_id}}.{f2_sample_vc}.g.vcf.gz.tbi",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=ibebio/tiger-pipeline, file=workflow/rules/04_variant_calling_f2.smk
context_key: ["if config[\\'debug\\'][\\'call_variants_f2\\'][\\'create_vcf_for_f2\\'] == \\'yes\\'", 'rule dbg_combine_calls_f2', 'output']
    (91, '        f2_sample_vc=[c["f2_samples"] for c in config["crossings"] if c["id"] == wildcards.crossing_id][0])')
    (92, '')
    (93, '        output:')
    (94, '            gvcf=temp("results/variants/f2/gvcf/{crossing_id}.g.vcf.gz"),')
    (95, '            gvcf_idx=temp("results/variants/f2/gvcf/{crossing_id}.g.vcf.gz.tbi"),')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=ibebio/tiger-pipeline, file=workflow/rules/04_variant_calling_f2.smk
context_key: ["if config[\\'debug\\'][\\'call_variants_f2\\'][\\'create_vcf_for_f2\\'] == \\'yes\\'", 'rule dbg_combine_calls_f2', 'params']
    (96, '        params:')
    (97, '            index=config["ref"]["genome"],')
    (98, '            java_options=config["gatk_options"]["java_options"],')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=ibebio/tiger-pipeline, file=workflow/rules/04_variant_calling_f2.smk
context_key: ["if config[\\'debug\\'][\\'call_variants_f2\\'][\\'create_vcf_for_f2\\'] == \\'yes\\'", 'rule dbg_combine_calls_f2', 'threads']
    (99, '        threads: 4')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=ibebio/tiger-pipeline, file=workflow/rules/04_variant_calling_f2.smk
context_key: ["if config[\\'debug\\'][\\'call_variants_f2\\'][\\'create_vcf_for_f2\\'] == \\'yes\\'", 'rule dbg_combine_calls_f2', 'resources']
    (100, '        resources:')
    (101, '            n=4,')
    (102, '            time=lambda wildcards, attempt: 24 * 59 * attempt,')
    (103, '            mem_gb_pt=lambda wildcards, attempt: 12 * attempt')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=ibebio/tiger-pipeline, file=workflow/rules/04_variant_calling_f2.smk
context_key: ["if config[\\'debug\\'][\\'call_variants_f2\\'][\\'create_vcf_for_f2\\'] == \\'yes\\'", 'rule dbg_combine_calls_f2', 'log']
    (104, '        log:')
    (105, '            "results/logs/dbg_combine_calls_f2/{crossing_id}.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=ibebio/tiger-pipeline, file=workflow/rules/04_variant_calling_f2.smk
context_key: ["if config[\\'debug\\'][\\'call_variants_f2\\'][\\'create_vcf_for_f2\\'] == \\'yes\\'", 'rule dbg_combine_calls_f2', 'conda']
    (106, '        conda:')
    (107, '            "../envs/gatk4.yaml"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=ibebio/tiger-pipeline, file=workflow/rules/04_variant_calling_f2.smk
context_key: ["if config[\\'debug\\'][\\'call_variants_f2\\'][\\'create_vcf_for_f2\\'] == \\'yes\\'", 'rule dbg_combine_calls_f2', 'shell']
    (108, '        shell:')
    (109, '            """')
    (110, '            gatk --java-options "{params.java_options}" CombineGVCFs \\\\')
    (111, '                -V $(echo "{input.gvcfs}" | sed \\\'s/ / -V /g\\\') \\\\')
    (112, '                -R {params.index} \\\\')
    (113, '                -O {output.gvcf} 2> {log}')
    (114, '            """')
    (115, '')
    (116, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=ibebio/tiger-pipeline, file=workflow/rules/04_variant_calling_f2.smk
context_key: ["if config[\\'debug\\'][\\'call_variants_f2\\'][\\'create_vcf_for_f2\\'] == \\'yes\\'", 'rule dbg_genotype_variants_f2', 'input']
    (117, '    rule dbg_genotype_variants_f2:')
    (118, '        input:')
    (119, '            gvcf="results/variants/f2/gvcf/{crossing_id}.g.vcf.gz",')
    (120, '            gvcf_idx=temp("results/variants/f2/gvcf/{crossing_id}.g.vcf.gz.tbi"),')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=ibebio/tiger-pipeline, file=workflow/rules/04_variant_calling_f2.smk
context_key: ["if config[\\'debug\\'][\\'call_variants_f2\\'][\\'create_vcf_for_f2\\'] == \\'yes\\'", 'rule dbg_genotype_variants_f2', 'output']
    (121, '        output:')
    (122, '            vcf="results/variants/raw/{crossing_id}.vcf.gz",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=ibebio/tiger-pipeline, file=workflow/rules/04_variant_calling_f2.smk
context_key: ["if config[\\'debug\\'][\\'call_variants_f2\\'][\\'create_vcf_for_f2\\'] == \\'yes\\'", 'rule dbg_genotype_variants_f2', 'params']
    (123, '        params:')
    (124, '            index=config["ref"]["genome"],')
    (125, '            java_options=config["gatk_options"]["java_options"],')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=ibebio/tiger-pipeline, file=workflow/rules/04_variant_calling_f2.smk
context_key: ["if config[\\'debug\\'][\\'call_variants_f2\\'][\\'create_vcf_for_f2\\'] == \\'yes\\'", 'rule dbg_genotype_variants_f2', 'threads']
    (126, '        threads: 4')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=ibebio/tiger-pipeline, file=workflow/rules/04_variant_calling_f2.smk
context_key: ["if config[\\'debug\\'][\\'call_variants_f2\\'][\\'create_vcf_for_f2\\'] == \\'yes\\'", 'rule dbg_genotype_variants_f2', 'resources']
    (127, '        resources:')
    (128, '            n=4,')
    (129, '            time=lambda wildcards, attempt: 24 * 59 * attempt,')
    (130, '            mem_gb_pt=lambda wildcards, attempt: 12 * attempt')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=ibebio/tiger-pipeline, file=workflow/rules/04_variant_calling_f2.smk
context_key: ["if config[\\'debug\\'][\\'call_variants_f2\\'][\\'create_vcf_for_f2\\'] == \\'yes\\'", 'rule dbg_genotype_variants_f2', 'log']
    (131, '        log:')
    (132, '            "results/logs/dbg_genotype_variants_f2/{crossing_id}.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=ibebio/tiger-pipeline, file=workflow/rules/04_variant_calling_f2.smk
context_key: ["if config[\\'debug\\'][\\'call_variants_f2\\'][\\'create_vcf_for_f2\\'] == \\'yes\\'", 'rule dbg_genotype_variants_f2', 'conda']
    (133, '        conda:')
    (134, '            "../envs/gatk4.yaml"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=ibebio/tiger-pipeline, file=workflow/rules/04_variant_calling_f2.smk
context_key: ["if config[\\'debug\\'][\\'call_variants_f2\\'][\\'create_vcf_for_f2\\'] == \\'yes\\'", 'rule dbg_genotype_variants_f2', 'shell']
    (135, '        shell:')
    (136, '            """')
    (137, '            gatk --java-options "{params.java_options}" GenotypeGVCFs \\\\')
    (138, '                -V {input.gvcf} \\\\')
    (139, '                -R {params.index} \\\\')
    (140, '                -O {output.vcf} 2> {log}')
    (141, '            """')
    (142, '')
    (143, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=ibebio/tiger-pipeline, file=workflow/rules/04_variant_calling_f2.smk
context_key: ["if config[\\'debug\\'][\\'call_variants_f2\\'][\\'create_vcf_for_f2\\'] == \\'yes\\'", 'rule dbg_filter_variants_f2', 'input']
    (144, '    rule dbg_filter_variants_f2:')
    (145, '        input:')
    (146, '            vcf="results/variants/raw/{crossing_id}.vcf.gz",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=ibebio/tiger-pipeline, file=workflow/rules/04_variant_calling_f2.smk
context_key: ["if config[\\'debug\\'][\\'call_variants_f2\\'][\\'create_vcf_for_f2\\'] == \\'yes\\'", 'rule dbg_filter_variants_f2', 'output']
    (147, '        output:')
    (148, '            snps=temp("results/variants/f2/raw/{crossing_id}.snps.vcf"),')
    (149, '            indels=temp("results/variants/f2/raw/{crossing_id}.indels.vcf"),')
    (150, '            filtered_snps=temp("results/variants/f2/filtered/{crossing_id}.snps.vcf"),')
    (151, '            filtered_indels=temp("results/variants/f2/filtered/{crossing_id}.indels.vcf"),')
    (152, '            filtered_vcf="results/variants/f2/filtered/{crossing_id}.vcf",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=ibebio/tiger-pipeline, file=workflow/rules/04_variant_calling_f2.smk
context_key: ["if config[\\'debug\\'][\\'call_variants_f2\\'][\\'create_vcf_for_f2\\'] == \\'yes\\'", 'rule dbg_filter_variants_f2', 'params']
    (153, '        params:')
    (154, '            index=config["ref"]["genome"],')
    (155, '            snp_filter=config["debug"]["call_variants_f2"]["variant_filtering"]["snps_filter"],')
    (156, '            indel_filter=config["debug"]["call_variants_f2"]["variant_filtering"]["indels_filter"],')
    (157, '            java_options=config["gatk_options"]["java_options"],')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=ibebio/tiger-pipeline, file=workflow/rules/04_variant_calling_f2.smk
context_key: ["if config[\\'debug\\'][\\'call_variants_f2\\'][\\'create_vcf_for_f2\\'] == \\'yes\\'", 'rule dbg_filter_variants_f2', 'resources']
    (158, '        resources:')
    (159, '            n=1,')
    (160, '            time=lambda wildcards, attempt: 12 * 59 * attempt,')
    (161, '            mem_gb_pt=lambda wildcards, attempt: 48 * attempt')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=ibebio/tiger-pipeline, file=workflow/rules/04_variant_calling_f2.smk
context_key: ["if config[\\'debug\\'][\\'call_variants_f2\\'][\\'create_vcf_for_f2\\'] == \\'yes\\'", 'rule dbg_filter_variants_f2', 'log']
    (162, '        log:')
    (163, '            "results/logs/dbg_filter_variants_f2/{crossing_id}.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=ibebio/tiger-pipeline, file=workflow/rules/04_variant_calling_f2.smk
context_key: ["if config[\\'debug\\'][\\'call_variants_f2\\'][\\'create_vcf_for_f2\\'] == \\'yes\\'", 'rule dbg_filter_variants_f2', 'conda']
    (164, '        conda:')
    (165, '            "../envs/gatk4.yaml"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=ibebio/tiger-pipeline, file=workflow/rules/04_variant_calling_f2.smk
context_key: ["if config[\\'debug\\'][\\'call_variants_f2\\'][\\'create_vcf_for_f2\\'] == \\'yes\\'", 'rule dbg_filter_variants_f2', 'shell']
    (166, '        shell:')
    (167, '            """')
    (168, '            gatk --java-options "{params.java_options}" SelectVariants \\\\')
    (169, '                 -R {params.index} \\\\')
    (170, '                 -V {input.vcf} \\\\')
    (171, '                 --select-type-to-include SNP \\\\')
    (172, '                 -O {output.snps} \\\\')
    (173, '            ; \\\\')
    (174, '            gatk --java-options "{params.java_options}" VariantFiltration \\\\')
    (175, '                 -R {params.index} \\\\')
    (176, '                 -V {output.snps} \\\\')
    (177, '                 --filter-name "snps-hard-filter" \\\\')
    (178, '                 --filter-expression "{params.snp_filter}" \\\\')
    (179, '                 -O {output.filtered_snps} \\\\')
    (180, '            ; \\\\')
    (181, '            gatk --java-options "{params.java_options}" SelectVariants \\\\')
    (182, '                 -R {params.index} \\\\')
    (183, '                 -V {input.vcf} \\\\')
    (184, '                 --select-type-to-include INDEL \\\\')
    (185, '                 -O {output.indels} \\\\')
    (186, '            ; \\\\')
    (187, '            gatk --java-options "{params.java_options}" VariantFiltration \\\\')
    (188, '                 -R {params.index} \\\\')
    (189, '                 -V {output.indels} \\\\')
    (190, '                 --filter-name "indels-hard-filter" \\\\')
    (191, '                 --filter-expression "{params.indel_filter}" \\\\')
    (192, '                 -O {output.filtered_indels} \\\\')
    (193, '            ; \\\\')
    (194, '            picard MergeVcfs \\\\')
    (195, '                   INPUT={output.filtered_snps} \\\\')
    (196, '                   INPUT={output.filtered_indels} \\\\')
    (197, '                   OUTPUT={output.filtered_vcf} 2> {log}')
    (198, '            """')
    (199, '')
    (200, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=ibebio/tiger-pipeline, file=workflow/rules/04_variant_calling_f2.smk
context_key: ["if config[\\'debug\\'][\\'call_variants_f2\\'][\\'create_vcf_for_f2\\'] == \\'yes\\'", 'rule dbg_extract_strict_biallelic_snps_f2', 'input']
    (201, '    rule dbg_extract_strict_biallelic_snps_f2:')
    (202, '        input:')
    (203, '            vcf="results/variants/f2/filtered/{crossing_id}.vcf"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=ibebio/tiger-pipeline, file=workflow/rules/04_variant_calling_f2.smk
context_key: ["if config[\\'debug\\'][\\'call_variants_f2\\'][\\'create_vcf_for_f2\\'] == \\'yes\\'", 'rule dbg_extract_strict_biallelic_snps_f2', 'output']
    (204, '        output:')
    (205, '            snps=temp("results/variants/f2/filtered/{crossing_id}.biallelic-snps.raw.vcf"),')
    (206, '            vcf="results/variants/f2/filtered/{crossing_id}.biallelic-snps.vcf"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=ibebio/tiger-pipeline, file=workflow/rules/04_variant_calling_f2.smk
context_key: ["if config[\\'debug\\'][\\'call_variants_f2\\'][\\'create_vcf_for_f2\\'] == \\'yes\\'", 'rule dbg_extract_strict_biallelic_snps_f2', 'params']
    (207, '        params:')
    (208, '            index=config["ref"]["genome"],')
    (209, '            filter=config["debug"]["call_variants_f2"]["biallelic_snps"]["filter"],')
    (210, '            allowed_missing_fraction=config["debug"]["call_variants_f2"]["biallelic_snps"]["allowed_missing_fraction"],')
    (211, '            java_options=config["gatk_options"]["java_options"]')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=ibebio/tiger-pipeline, file=workflow/rules/04_variant_calling_f2.smk
context_key: ["if config[\\'debug\\'][\\'call_variants_f2\\'][\\'create_vcf_for_f2\\'] == \\'yes\\'", 'rule dbg_extract_strict_biallelic_snps_f2', 'resources']
    (212, '        resources:')
    (213, '            n=1,')
    (214, '            time=lambda wildcards, attempt: 12 * 59 * attempt,')
    (215, '            mem_gb_pt=lambda wildcards, attempt: 48 * attempt')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=ibebio/tiger-pipeline, file=workflow/rules/04_variant_calling_f2.smk
context_key: ["if config[\\'debug\\'][\\'call_variants_f2\\'][\\'create_vcf_for_f2\\'] == \\'yes\\'", 'rule dbg_extract_strict_biallelic_snps_f2', 'log']
    (216, '        log:')
    (217, '            "results/logs/dbg_extract_strict_biallelic_snps_f2/{crossing_id}.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=ibebio/tiger-pipeline, file=workflow/rules/04_variant_calling_f2.smk
context_key: ["if config[\\'debug\\'][\\'call_variants_f2\\'][\\'create_vcf_for_f2\\'] == \\'yes\\'", 'rule dbg_extract_strict_biallelic_snps_f2', 'conda']
    (218, '        conda:')
    (219, '            "../envs/gatk4.yaml"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=ibebio/tiger-pipeline, file=workflow/rules/04_variant_calling_f2.smk
context_key: ["if config[\\'debug\\'][\\'call_variants_f2\\'][\\'create_vcf_for_f2\\'] == \\'yes\\'", 'rule dbg_extract_strict_biallelic_snps_f2', 'shell']
    (220, '        shell:')
    (221, '            """')
    (222, '            gatk SelectVariants \\\\')
    (223, '                 -R {params.index} \\\\')
    (224, '                 -V {input.vcf} \\\\')
    (225, '                 --exclude-filtered \\\\')
    (226, '                 --select-type-to-include SNP \\\\')
    (227, '                 --select-type-to-exclude INDEL \\\\')
    (228, '                 --restrict-alleles-to BIALLELIC \\\\')
    (229, '                 --max-nocall-fraction {params.allowed_missing_fraction} \\\\')
    (230, '                 -O {output.snps}  2> {log} ;\\\\')
    (231, '            if [[ "{params.filter}" != "" ]] ; then \\\\')
    (232, '               gatk VariantFiltration \\\\')
    (233, '                    -R {params.index} \\\\')
    (234, '                    -V {output.snps} \\\\')
    (235, '                    --filter-name "biallelic-snps-filter" \\\\')
    (236, '                    --filter-expression "{params.filter}" \\\\')
    (237, '                    -O {output.vcf} 2>> {log} \\\\;')
    (238, '            else \\\\')
    (239, '               cp {output.snps} {output.vcf} 2>> {log} ;\\\\')
    (240, '            fi')
    (241, '            """')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=akhanf/greedy_template_marm, file=workflow/Snakefile
context_key: ["if config[\\'run_cohort\\'] == None"]
    (7, "if config[\\'run_cohort\\'] == None:")
    (8, "    cohorts = config[\\'cohorts\\']")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=crazyhottommy/pyflow-ChIPseq, file=Snakefile
context_key: ['if config["chromHMM"]']
    (84, 'if config["chromHMM"]:')
    (85, '    HISTONE_INCLUDED = config["histone_for_chromHMM"].split(" ")')
    (86, '    HISTONE_CASES = [sample for sample in MARK_SAMPLES if sample.split("_")[-1] in HISTONE_INCLUDED ]')
    (87, '    ALL_BED = expand("12bed/{sample}.bed", sample = HISTONE_CASES + CONTROLS)')
    (88, '    CHROMHMM = ["13chromHMM/MYOUTPUT", "13chromHMM/binarizedData"]')
    (89, '    CHROMHMM_TABLE = ["12bed/cellmarkfiletable.txt"]')
    (90, '    TARGETS.extend(ALL_BED)')
    (91, '    TARGETS.extend(CHROMHMM)')
    (92, '    TARGETS.extend(CHROMHMM_TABLE)')
    (93, '')
    (94, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=crazyhottommy/pyflow-ChIPseq, file=Snakefile
context_key: ['if config["chromHMM"]', 'rule make_table', 'run', 'if os.path.exists(join("12bed", case_bed))']
    (339, 'if config["chromHMM"]:')
    (340, '    rule make_table:')
    (341, '        input : expand("12bed/{sample}.bed", sample = HISTONE_CASES + CONTROLS)')
    (342, '        output : "12bed/cellmarkfiletable.txt"')
    (343, '        log: "00log/make_table_chromHMM.log"')
    (344, '        message: "making a table for chromHMM"')
    (345, '        run:')
    (346, '            import os')
    (347, '            from os.path import join')
    (348, '            with open (output[0], "w") as f:')
    (349, '                for case in HISTONE_CASES:')
    (350, '                    sample = "_".join(case.split("_")[0:-1])')
    (351, '                    mark = case.split("_")[-1]')
    (352, '                    control = sample + "_" + CONTROL')
    (353, '                    case_bed = case + ".bed"')
    (354, '                    if os.path.exists(join("12bed", case_bed)):')
    (355, '                        f.write(sample + "\\\\t" +  mark + "\\\\t" + case + ".bed" + "\\\\t" + control + ".bed" + "\\')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=crazyhottommy/pyflow-ChIPseq, file=Snakefile
context_key: ['if config["chromHMM"]', 'rule chromHmm_binarize']
    (358, 'if config["chromHMM"]:')
    (359, '    rule chromHmm_binarize:')
    (360, '        input :')
    (361, '            expand("12bed/{sample}.bed", sample = HISTONE_CASES + CONTROLS), "12bed/cellmarkfiletable.txt"')
    (362, '        output:')
    (363, '            "13chromHMM/binarizedData"')
    (364, '        log:')
    (365, '            chromhmm_binarize = "00log/chromhmm_bin.log"')
    (366, '        params: chromhmm = "-mx12000M -jar /scratch/genomic_med/apps/chromhmm/chromhmm_v1.11/ChromHMM.jar"')
    (367, '        shell:')
    (368, '            """')
    (369, '            java {params.chromhmm} BinarizeBed -b {config[binsize]}  /scratch/genomic_med/apps/chromhmm/chromhmm_v1.11/CHROMSIZES/{config[chromHmm_g]}.txt 12bed/ 12bed/cellmarkfiletable.txt {output} 2> {log.chromhmm_binarize}')
    (370, '            """')
    (371, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=crazyhottommy/pyflow-ChIPseq, file=Snakefile
context_key: ['if config["chromHMM"]', 'rule chromHmm_learn', 'shell']
    (372, 'if config["chromHMM"]:')
    (373, '    rule chromHmm_learn:')
    (374, '        input: "13chromHMM/binarizedData"')
    (375, '        output: "13chromHMM/MYOUTPUT"')
    (376, '        log: chromhmm_learn = "00log/chromhmm_learn.log"')
    (377, '        params: chromhmm = "-mx12000M -jar /scratch/genomic_med/apps/chromhmm/chromhmm_v1.11/ChromHMM.jar"')
    (378, '        shell:')
    (379, '            """')
    (380, '            java {params.chromhmm} LearnModel -p 10 -b {config[binsize]} {input} {output} {config[state]} {config[chromHmm_g]} 2> {log.chromhmm_learn}')
    (381, '            """')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=kircherlab/hemoMIPs, file=Snakefile
context_key: ['if config["parameters"]["paired_end_reads"] == "yes"', 'if config["parameters"]["double_index"] == "no"', 'rule splithemophilia_PairedEnd_SingleIndex', 'input']
    (35, 'if config["parameters"]["paired_end_reads"] == "yes":    ')
    (36, '  if config["parameters"]["double_index"] == "no":')
    (37, '    rule splithemophilia_PairedEnd_SingleIndex:')
    (38, '      input:')
    (39, '        R1="input/{dataset}/Undetermined_S0_L00{lane}_R1_001.fastq.gz",')
    (40, '        I="input/{dataset}/Undetermined_S0_L00{lane}_I1_001.fastq.gz",')
    (41, '        R2="input/{dataset}/Undetermined_S0_L00{lane}_R2_001.fastq.gz",')
    (42, '        lst="input/{dataset}/sample_index.lst"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=kircherlab/hemoMIPs, file=Snakefile
context_key: ['if config["parameters"]["paired_end_reads"] == "yes"', 'if config["parameters"]["double_index"] == "no"', 'rule splithemophilia_PairedEnd_SingleIndex', 'output']
    (43, '      output:')
    (44, '        bam="output/{dataset}/mapping/sample_l{lane}.bam"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=kircherlab/hemoMIPs, file=Snakefile
context_key: ['if config["parameters"]["paired_end_reads"] == "yes"', 'if config["parameters"]["double_index"] == "no"', 'rule splithemophilia_PairedEnd_SingleIndex', 'log']
    (45, '      log:')
    (46, '        "output/{dataset}/mapping/processing_stats_l{lane}.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=kircherlab/hemoMIPs, file=Snakefile
context_key: ['if config["parameters"]["paired_end_reads"] == "yes"', 'if config["parameters"]["double_index"] == "no"', 'rule splithemophilia_PairedEnd_SingleIndex', 'conda']
    (47, '      conda: "envs/python27.yml"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=kircherlab/hemoMIPs, file=Snakefile
context_key: ['if config["parameters"]["paired_end_reads"] == "yes"', 'if config["parameters"]["double_index"] == "no"', 'rule splithemophilia_PairedEnd_SingleIndex', 'shell']
    (48, '      shell:"""')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=kircherlab/hemoMIPs, file=Snakefile
context_key: ['if config["parameters"]["paired_end_reads"] == "yes"', 'if config["parameters"]["double_index"] == "no"', 'rule splithemophilia_PairedEnd_SingleIndex']
    (49, '        set +o pipefail')
    (50, "        read1length=$(zcat {input.R1} | head -n 2 | tail -n 1 | awk \\'{{ print length($1) }}\\')")
    (51, "        index1length=$(zcat {input.I} | head -n 2 | tail -n 1 | awk \\'{{ print length($1) }}\\')")
    (52, '        read2start=$((read1length+index1length+1)) ')
    (53, '        ( paste <( zcat {input.R1} ) \\\\')
    (54, '        <( zcat {input.I} ) \\\\')
    (55, '        <( zcat {input.R2} ) | \\\\')
    (56, "        awk \\'{{ count+=1; if ((count == 1) || (count == 3)) {{ print $1 }} else {{ print $1$2$3 }}; if (count == 4) {{ count=0 }} }}\\' | \\\\")
    (57, "        scripts/pipeline2.0/SplitFastQdoubleIndexBAM.py --bases_after_index=ATCTCGTATGCCGTCTTCTGCTTG --bases_after_2ndindex=\\'\\' -l $index1length -m 0 -s $read2start --summary -i {input.lst} -q 10 -p --remove | scripts/pipeline2.0/MergeTrimReadsBAM.py --mergeoverlap -p \\\\")
    (58, '        > {output.bam} ) 2> {log}')
    (59, '        """')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=kircherlab/hemoMIPs, file=Snakefile
context_key: ['if config["parameters"]["paired_end_reads"] == "yes"', 'else', 'rule splithemophilia_PairedEnd_DoubleIndex', 'input']
    (60, '  else:')
    (61, '    rule splithemophilia_PairedEnd_DoubleIndex:')
    (62, '      input:')
    (63, '        R1="input/{dataset}/Undetermined_S0_L00{lane}_R1_001.fastq.gz",')
    (64, '        I1="input/{dataset}/Undetermined_S0_L00{lane}_I1_001.fastq.gz",')
    (65, '        I2="input/{dataset}/Undetermined_S0_L00{lane}_I2_001.fastq.gz",')
    (66, '        R2="input/{dataset}/Undetermined_S0_L00{lane}_R2_001.fastq.gz",')
    (67, '        lst="input/{dataset}/sample_index.lst"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=kircherlab/hemoMIPs, file=Snakefile
context_key: ['if config["parameters"]["paired_end_reads"] == "yes"', 'else', 'rule splithemophilia_PairedEnd_DoubleIndex', 'output']
    (68, '      output:')
    (69, '        bam="output/{dataset}/mapping/sample_l{lane}.bam"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=kircherlab/hemoMIPs, file=Snakefile
context_key: ['if config["parameters"]["paired_end_reads"] == "yes"', 'else', 'rule splithemophilia_PairedEnd_DoubleIndex', 'log']
    (70, '      log:')
    (71, '        "output/{dataset}/mapping/processing_stats_l{lane}.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=kircherlab/hemoMIPs, file=Snakefile
context_key: ['if config["parameters"]["paired_end_reads"] == "yes"', 'else', 'rule splithemophilia_PairedEnd_DoubleIndex', 'conda']
    (72, '      conda: "envs/python27.yml"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=kircherlab/hemoMIPs, file=Snakefile
context_key: ['if config["parameters"]["paired_end_reads"] == "yes"', 'else', 'rule splithemophilia_PairedEnd_DoubleIndex', 'shell']
    (73, '      shell:"""')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=kircherlab/hemoMIPs, file=Snakefile
context_key: ['if config["parameters"]["paired_end_reads"] == "yes"', 'else', 'rule splithemophilia_PairedEnd_DoubleIndex']
    (74, '        set +o pipefail')
    (75, "        read1length=$(zcat {input.R1} | head -n 2 | tail -n 1 | awk \\'{{ print length($1) }}\\')")
    (76, "        index1length=$(zcat {input.I1} | head -n 2 | tail -n 1 | awk \\'{{ print length($1) }}\\')")
    (77, "        index2length=$(zcat {input.I2} | head -n 2 | tail -n 1 | awk \\'{{ print length($1) }}\\')")
    (78, '        read2start=$((read1length+index1length+1)) ')
    (79, '        ( paste <( zcat {input.R1} ) \\\\')
    (80, '        <( zcat {input.I1} ) \\\\')
    (81, '        <( zcat {input.R2} ) \\\\')
    (82, '        <( zcat {input.I2} ) | \\\\')
    (83, "        awk \\'{{ count+=1; if ((count == 1) || (count == 3)) {{ print $1 }} else {{ print $1$2$3$4 }}; if (count == 4) {{ count=0 }} }}\\' | \\\\")
    (84, "        scripts/pipeline2.0/SplitFastQdoubleIndexBAM.py --bases_after_index=ATCTCGTATGCCGTCTTCTGCTTG --bases_after_2ndindex=\\'\\' -l $index1length -m $index2length -s $read2start --summary -i {input.lst} -q 10 -p --remove | scripts/pipeline2.0/MergeTrimReadsBAM.py --mergeoverlap -p \\\\")
    (85, '        > {output.bam} ) 2> {log}')
    (86, '        """')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=kircherlab/hemoMIPs, file=Snakefile
context_key: ['else', 'if config["parameters"]["double_index"] == "no"', 'rule splithemophilia_SingleRead_SingleIndex', 'input']
    (88, '  if config["parameters"]["double_index"] == "no":')
    (89, '    rule splithemophilia_SingleRead_SingleIndex:')
    (90, '      input:')
    (91, '        R1="input/{dataset}/Undetermined_S0_L00{lane}_R1_001.fastq.gz",')
    (92, '        I="input/{dataset}/Undetermined_S0_L00{lane}_I1_001.fastq.gz",')
    (93, '        lst="input/{dataset}/sample_index.lst"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=kircherlab/hemoMIPs, file=Snakefile
context_key: ['else', 'if config["parameters"]["double_index"] == "no"', 'rule splithemophilia_SingleRead_SingleIndex', 'output']
    (94, '      output:')
    (95, '        bam="output/{dataset}/mapping/sample_l{lane}.bam"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=kircherlab/hemoMIPs, file=Snakefile
context_key: ['else', 'if config["parameters"]["double_index"] == "no"', 'rule splithemophilia_SingleRead_SingleIndex', 'log']
    (96, '      log:')
    (97, '        "output/{dataset}/mapping/processing_stats_l{lane}.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=kircherlab/hemoMIPs, file=Snakefile
context_key: ['else', 'if config["parameters"]["double_index"] == "no"', 'rule splithemophilia_SingleRead_SingleIndex', 'conda']
    (98, '      conda: "envs/python27.yml"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=kircherlab/hemoMIPs, file=Snakefile
context_key: ['else', 'if config["parameters"]["double_index"] == "no"', 'rule splithemophilia_SingleRead_SingleIndex', 'shell']
    (99, '      shell:"""')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=kircherlab/hemoMIPs, file=Snakefile
context_key: ['else', 'if config["parameters"]["double_index"] == "no"', 'rule splithemophilia_SingleRead_SingleIndex']
    (100, '        set +o pipefail')
    (101, "        index1length=$(zcat {input.I} | head -n 2 | tail -n 1 | awk \\'{{ print length($1) }}\\')")
    (102, '        ( paste <( zcat {input.R1} ) \\\\')
    (103, '        <( zcat {input.I} ) | \\\\')
    (104, "        awk \\'{{ count+=1; if ((count == 1) || (count == 3)) {{ print $1 }} else {{ print $1$2 }}; if (count == 4) {{ count=0 }} }}\\' | \\\\")
    (105, "        scripts/pipeline2.0/SplitFastQdoubleIndexBAM.py --bases_after_index=ATCTCGTATGCCGTCTTCTGCTTG --bases_after_2ndindex=\\'\\' -l $index1length -m 0 --summary -i {input.lst} -q 10 -p --remove | scripts/pipeline2.0/MergeTrimReadsBAM.py --mergeoverlap -p \\\\")
    (106, '        > {output.bam} ) 2> {log}')
    (107, '        """')
    (108, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=kircherlab/hemoMIPs, file=Snakefile
context_key: ['if config["parameters"]["inv"] == "yes"', 'rule inversionmips']
    (213, 'if config["parameters"]["inv"] == "yes":')
    (214, '  rule inversionmips:')
    (215, '    input:bam="output/{dataset}/mapping/sample.bam",')
    (216, '          sam="input/{dataset}/new_header.sam",')
    (217, '          inv=config["references"]["inv"]')
    (218, '    output: "output/{dataset}/mapping/inversion_mips/{plate}.bam"')
    (219, '    params:')
    (220, '      plate="{plate}"')
    (221, '    conda: "envs/prep.yml"')
    (222, '    shell: """')
    (223, '      (   grep "@RG" {input.sam}; \\\\')
    (224, '          bwa mem -M -L 80 -C {input.inv} <(')
    (225, '              samtools view -r {params.plate} -F 1 {input.bam} | awk \\\'BEGIN{{ OFS="\\\\\\')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=MW55/Natrix, file=rules/demultiplexing.smk
context_key: ['output', 'if config["general"]["already_assembled"]']
    (3, '        if config["general"]["already_assembled"] ')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SherineAwad/miRNA, file=Snakefile
context_key: ["if config[\\'PAIRED\\']", 'rule trim', 'input']
    (44, "if config[\\'PAIRED\\']: ")
    (45, '    rule trim:')
    (46, '       input:')
    (47, '          r1 = "{sample}.r_1.fq.gz",')
    (48, '          r2 = "{sample}.r_2.fq.gz"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SherineAwad/miRNA, file=Snakefile
context_key: ["if config[\\'PAIRED\\']", 'rule trim', 'log']
    (49, '       log: "logs/{sample}.trim.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SherineAwad/miRNA, file=Snakefile
context_key: ["if config[\\'PAIRED\\']", 'rule trim', 'benchmark']
    (50, '       benchmark: "logs/{sample}.trim.benchmark"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SherineAwad/miRNA, file=Snakefile
context_key: ["if config[\\'PAIRED\\']", 'rule trim', 'output']
    (51, "       conda :\\'env/env-trim.yaml\\'")
    (52, '       output:')
    (53, '          val1 = "fastp/{sample}.r_1_val_1.fq.gz",')
    (54, '          val2 = "fastp/{sample}.r_2_val_2.fq.gz",')
    (55, '          html = "fastp/{sample}.quality.html"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SherineAwad/miRNA, file=Snakefile
context_key: ["if config[\\'PAIRED\\']", 'rule trim', 'shell']
    (56, '       shell:')
    (57, '          """')
    (58, '           mkdir -p fastp')
    (59, '           fastp --in1 {input.r1} --in2 {input.r2} --out1 {output.val1} --out2 {output.val2} -l 50 -h {output.html} -g &> {log}')
    (60, '          """')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SherineAwad/miRNA, file=Snakefile
context_key: ["if config[\\'PAIRED\\']", 'rule bowtie', 'input']
    (61, '    rule bowtie: ')
    (62, '       input: ')
    (63, '         "fastp/{sample}.r_1_val_1.fq.gz",')
    (64, '         "fastp/{sample}.r_2_val_2.fq.gz",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SherineAwad/miRNA, file=Snakefile
context_key: ["if config[\\'PAIRED\\']", 'rule bowtie', 'params']
    (65, '       params: ')
    (66, "         PREFIX = config[\\'PREFIX\\']")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SherineAwad/miRNA, file=Snakefile
context_key: ["if config[\\'PAIRED\\']", 'rule bowtie', 'conda']
    (67, "       conda: \\'env/env-bowtie.yaml\\' ")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SherineAwad/miRNA, file=Snakefile
context_key: ["if config[\\'PAIRED\\']", 'rule bowtie', 'output']
    (68, '       output: ')
    (69, '         "{sample}.sam" ')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SherineAwad/miRNA, file=Snakefile
context_key: ["if config[\\'PAIRED\\']", 'rule bowtie', 'shell']
    (70, '       shell: ')
    (71, '         """')
    (72, '         bowtie -x {params.PREFIX} -1 {input[0]} -2 {input[1]} ')
    (73, '         """ ')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=maxlcummins/pipelord3, file=workflow/Snakefile
context_key: ["if config[\\'trim_reads\\'] == True"]
    (9, "if config[\\'trim_reads\\'] == True:")
    (10, '    include: "rules/fastp_pe_QC_trim.smk"')
    (11, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=maxlcummins/pipelord3, file=workflow/Snakefile
context_key: ["elif config[\\'trim_reads\\'] == False"]
    (12, "elif config[\\'trim_reads\\'] == False:")
    (13, '    include: "rules/fastp_pe_QC.smk"')
    (14, '')
    (15, '#Genome assembly')
    (16, '#Check input type')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=maxlcummins/pipelord3, file=workflow/Snakefile
context_key: ["if config[\\'input_type\\'] not in [\\'raw_reads\\', \\'filtered_reads\\', \\'assemblies\\']"]
    (17, "if config[\\'input_type\\'] not in [\\'raw_reads\\', \\'filtered_reads\\', \\'assemblies\\']:")
    (18, "    print(\\'Valid options for \\\\\\'input_type\\\\\\' are: \\\\\\'raw_reads\\\\\\', \\\\\\'filtered_reads\\\\\\', \\\\\\'assemblies\\\\\\'\\')")
    (19, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=maxlcummins/pipelord3, file=workflow/Snakefile
context_key: ["elif config[\\'input_type\\'] == \\'raw_reads\\'"]
    (20, "elif config[\\'input_type\\'] == \\'raw_reads\\':")
    (21, '    include: "rules/shovill.smk"')
    (22, '')
    (23, '#Assembly stats')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=maxlcummins/pipelord3, file=workflow/Snakefile
context_key: ["if config[\\'assembly_stats\\'] != False"]
    (24, "if config[\\'assembly_stats\\'] != False:")
    (25, '    include: "rules/assembly-stats.smk"')
    (26, '')
    (27, '    ')
    (28, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=mahajrod/BuscoPhylo, file=workflow/rules/busco.smk
context_key: ["elif config[\\'busco_version\\'] == 5", 'if config[\\\'gene_prediction_tool\\\'] == "metaeuk"', 'rule busco5_metaeuk', 'input']
    (31, "elif config[\\'busco_version\\'] == 5:")
    (32, '    if config[\\\'gene_prediction_tool\\\'] == "metaeuk":')
    (33, '        rule busco5_metaeuk:')
    (34, '            input:')
    (35, '                genome_dir_path / "{species}.fasta"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=mahajrod/BuscoPhylo, file=workflow/rules/busco.smk
context_key: ["elif config[\\'busco_version\\'] == 5", 'if config[\\\'gene_prediction_tool\\\'] == "metaeuk"', 'rule busco5_metaeuk', 'output']
    (36, '            output:')
    (37, '                busco_outdir=directory(busco_dir_path / "{species}"),')
    (38, '                single_copy_busco_sequences=directory(busco_dir_path / "{species}/busco_sequences/single_copy_busco_sequences"),')
    (39, '                metaeuk_rerun_results=directory(busco_dir_path / "{species}/metaeuk_output/rerun_results"),')
    (40, '                metaeuk_initial_results=directory(busco_dir_path / "{species}/metaeuk_output/initial_results"),')
    (41, '                summary=busco_dir_path / "{species}/short_summary_{species}.txt"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=mahajrod/BuscoPhylo, file=workflow/rules/busco.smk
context_key: ["elif config[\\'busco_version\\'] == 5", 'if config[\\\'gene_prediction_tool\\\'] == "metaeuk"', 'rule busco5_metaeuk', 'params']
    (42, '            params:')
    (43, '                mode=config["busco_mode"],')
    (44, '                busco_dataset_path=config["busco_dataset_path"],')
    (45, '                output_prefix="{species}"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=mahajrod/BuscoPhylo, file=workflow/rules/busco.smk
context_key: ["elif config[\\'busco_version\\'] == 5", 'if config[\\\'gene_prediction_tool\\\'] == "metaeuk"', 'rule busco5_metaeuk', 'log']
    (46, '            log:')
    (47, '                std=log_dir_path / "busco.{species}.log",')
    (48, '                cluster_log=cluster_log_dir_path / "busco.{species}.cluster.log",')
    (49, '                cluster_err=cluster_log_dir_path / "busco.{species}.cluster.err"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=mahajrod/BuscoPhylo, file=workflow/rules/busco.smk
context_key: ["elif config[\\'busco_version\\'] == 5", 'if config[\\\'gene_prediction_tool\\\'] == "metaeuk"', 'rule busco5_metaeuk', 'benchmark']
    (50, '            benchmark:')
    (51, '                benchmark_dir_path / "busco.{species}.benchmark.txt"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=mahajrod/BuscoPhylo, file=workflow/rules/busco.smk
context_key: ["elif config[\\'busco_version\\'] == 5", 'if config[\\\'gene_prediction_tool\\\'] == "metaeuk"', 'rule busco5_metaeuk', 'conda']
    (52, '            conda:')
    (53, '                "../../%s" % config["conda_config"]')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=mahajrod/BuscoPhylo, file=workflow/rules/busco.smk
context_key: ["elif config[\\'busco_version\\'] == 5", 'if config[\\\'gene_prediction_tool\\\'] == "metaeuk"', 'rule busco5_metaeuk', 'resources']
    (54, '            resources:')
    (55, '                cpus=config["busco_threads"],')
    (56, '                time=config["busco_time"],')
    (57, '                mem=config["busco_mem_mb"],')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=mahajrod/BuscoPhylo, file=workflow/rules/busco.smk
context_key: ["elif config[\\'busco_version\\'] == 5", 'if config[\\\'gene_prediction_tool\\\'] == "metaeuk"', 'rule busco5_metaeuk', 'threads']
    (58, '            threads:')
    (59, '                config["busco_threads"]')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=mahajrod/BuscoPhylo, file=workflow/rules/busco.smk
context_key: ["elif config[\\'busco_version\\'] == 5", 'if config[\\\'gene_prediction_tool\\\'] == "metaeuk"', 'rule busco5_metaeuk', 'shell']
    (60, '            shell:')
    (61, '                "mkdir -p {output.busco_outdir}; cd {output.busco_outdir}; "')
    (62, '                "busco -m {params.mode} -i {input} -c {threads} "')
    (63, '                "-l {params.busco_dataset_path} -o {params.output_prefix} 1>../../../{log.std} 2>&1; "')
    (64, '                "mv {params.output_prefix}/* ./; rm -r {params.output_prefix}/; "')
    (65, '                "rm -r busco_downloads/; mv run*/* ./; rm -r run*; "')
    (66, '                "mv full_table.tsv full_table_{params.output_prefix}.tsv; "')
    (67, '                "mv missing_busco_list.tsv missing_busco_list_{params.output_prefix}.tsv; "')
    (68, '                "mv short_summary.txt short_summary_{params.output_prefix}.txt; "')
    (69, '')
    (70, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=mahajrod/BuscoPhylo, file=workflow/rules/busco.smk
context_key: ["elif config[\\'busco_version\\'] == 5", 'if config[\\\'gene_prediction_tool\\\'] == "metaeuk"', 'rule get_CDs_sequences_from_metaeuk_output', 'input']
    (71, '        rule get_CDs_sequences_from_metaeuk_output:')
    (72, '            input:')
    (73, '                single_copy_busco_sequences=busco_dir_path / "{species}/busco_sequences/single_copy_busco_sequences",')
    (74, '                metaeuk_rerun_results=busco_dir_path / "{species}/metaeuk_output/rerun_results",')
    (75, '                metaeuk_initial_results=busco_dir_path / "{species}/metaeuk_output/initial_results"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=mahajrod/BuscoPhylo, file=workflow/rules/busco.smk
context_key: ["elif config[\\'busco_version\\'] == 5", 'if config[\\\'gene_prediction_tool\\\'] == "metaeuk"', 'rule get_CDs_sequences_from_metaeuk_output', 'output']
    (76, '            output:')
    (77, '                single_copy_CDs_sequences=directory(busco_dir_path / "{species}/single_copy_busco_sequences")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=mahajrod/BuscoPhylo, file=workflow/rules/busco.smk
context_key: ["elif config[\\'busco_version\\'] == 5", 'if config[\\\'gene_prediction_tool\\\'] == "metaeuk"', 'rule get_CDs_sequences_from_metaeuk_output', 'log']
    (78, '            log:')
    (79, '                std=log_dir_path / "get_CDs_sequences_from_metaeuk_output.{species}.log",')
    (80, '                cluster_log=cluster_log_dir_path / "get_CDs_sequences_from_metaeuk_output.{species}.cluster.log",')
    (81, '                cluster_err=cluster_log_dir_path / "get_CDs_sequences_from_metaeuk_output.{species}.cluster.err"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=mahajrod/BuscoPhylo, file=workflow/rules/busco.smk
context_key: ["elif config[\\'busco_version\\'] == 5", 'if config[\\\'gene_prediction_tool\\\'] == "metaeuk"', 'rule get_CDs_sequences_from_metaeuk_output', 'benchmark']
    (82, '            benchmark:')
    (83, '                benchmark_dir_path / "get_CDs_sequences_from_metaeuk_output.{species}.benchmark.txt"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=mahajrod/BuscoPhylo, file=workflow/rules/busco.smk
context_key: ["elif config[\\'busco_version\\'] == 5", 'if config[\\\'gene_prediction_tool\\\'] == "metaeuk"', 'rule get_CDs_sequences_from_metaeuk_output', 'conda']
    (84, '            conda:')
    (85, '                "../../%s" % config["conda_config"]')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=mahajrod/BuscoPhylo, file=workflow/rules/busco.smk
context_key: ["elif config[\\'busco_version\\'] == 5", 'if config[\\\'gene_prediction_tool\\\'] == "metaeuk"', 'rule get_CDs_sequences_from_metaeuk_output', 'resources']
    (86, '            resources:')
    (87, '                cpus=config["common_ids_threads"],')
    (88, '                time=config["common_ids_time"],')
    (89, '                mem=config["common_ids_mem_mb"],')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=mahajrod/BuscoPhylo, file=workflow/rules/busco.smk
context_key: ["elif config[\\'busco_version\\'] == 5", 'if config[\\\'gene_prediction_tool\\\'] == "metaeuk"', 'rule get_CDs_sequences_from_metaeuk_output', 'threads']
    (90, '            threads:')
    (91, '                config["common_ids_threads"]')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=mahajrod/BuscoPhylo, file=workflow/rules/busco.smk
context_key: ["elif config[\\'busco_version\\'] == 5", 'if config[\\\'gene_prediction_tool\\\'] == "metaeuk"', 'rule get_CDs_sequences_from_metaeuk_output', 'shell']
    (92, '            shell:')
    (93, '                "workflow/scripts/CDs_from_MetaEuk.py "')
    (94, '                "--initial_results {input.metaeuk_initial_results} "')
    (95, '                "--rerun_results {input.metaeuk_rerun_results} "')
    (96, '                "--single_copy_busco_sequences {input.single_copy_busco_sequences} "')
    (97, '                "--outdir {output.single_copy_CDs_sequences} > {log.std} 2>&1 "')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=mahajrod/BuscoPhylo, file=workflow/rules/busco.smk
context_key: ["elif config[\\'busco_version\\'] == 5", 'elif config[\\\'gene_prediction_tool\\\'] == "augustus"', 'rule busco5_augustus', 'input']
    (98, '    elif config[\\\'gene_prediction_tool\\\'] == "augustus":')
    (99, '        rule busco5_augustus:')
    (100, '            input:')
    (101, '                genome_dir_path / "{species}.fasta"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=mahajrod/BuscoPhylo, file=workflow/rules/busco.smk
context_key: ["elif config[\\'busco_version\\'] == 5", 'elif config[\\\'gene_prediction_tool\\\'] == "augustus"', 'rule busco5_augustus', 'output']
    (102, '            output:')
    (103, '                busco_outdir=directory(busco_dir_path / "{species}"),')
    (104, '                single_copy_busco_sequences=directory(busco_dir_path / "{species}/single_copy_busco_sequences"),')
    (105, '                augustus_gff=directory(busco_dir_path / "{species}/augustus_output/gff"),')
    (106, '                summary=busco_dir_path / "{species}/short_summary_{species}.txt"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=mahajrod/BuscoPhylo, file=workflow/rules/busco.smk
context_key: ["elif config[\\'busco_version\\'] == 5", 'elif config[\\\'gene_prediction_tool\\\'] == "augustus"', 'rule busco5_augustus', 'params']
    (107, '            params:')
    (108, '                mode=config["busco_mode"],')
    (109, '                species=config["augustus_species"],')
    (110, '                busco_dataset_path=config["busco_dataset_path"],')
    (111, '                output_prefix="{species}"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=mahajrod/BuscoPhylo, file=workflow/rules/busco.smk
context_key: ["elif config[\\'busco_version\\'] == 5", 'elif config[\\\'gene_prediction_tool\\\'] == "augustus"', 'rule busco5_augustus', 'log']
    (112, '            log:')
    (113, '                std=log_dir_path / "busco.{species}.log",')
    (114, '                cluster_log=cluster_log_dir_path / "busco.{species}.cluster.log",')
    (115, '                cluster_err=cluster_log_dir_path / "busco.{species}.cluster.err"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=mahajrod/BuscoPhylo, file=workflow/rules/busco.smk
context_key: ["elif config[\\'busco_version\\'] == 5", 'elif config[\\\'gene_prediction_tool\\\'] == "augustus"', 'rule busco5_augustus', 'benchmark']
    (116, '            benchmark:')
    (117, '                benchmark_dir_path / "busco.{species}.benchmark.txt"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=mahajrod/BuscoPhylo, file=workflow/rules/busco.smk
context_key: ["elif config[\\'busco_version\\'] == 5", 'elif config[\\\'gene_prediction_tool\\\'] == "augustus"', 'rule busco5_augustus', 'conda']
    (118, '            conda:')
    (119, '                "../../%s" % config["conda_config"]')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=mahajrod/BuscoPhylo, file=workflow/rules/busco.smk
context_key: ["elif config[\\'busco_version\\'] == 5", 'elif config[\\\'gene_prediction_tool\\\'] == "augustus"', 'rule busco5_augustus', 'resources']
    (120, '            resources:')
    (121, '                cpus=config["busco_threads"],')
    (122, '                time=config["busco_time"],')
    (123, '                mem=config["busco_mem_mb"],')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=mahajrod/BuscoPhylo, file=workflow/rules/busco.smk
context_key: ["elif config[\\'busco_version\\'] == 5", 'elif config[\\\'gene_prediction_tool\\\'] == "augustus"', 'rule busco5_augustus', 'threads']
    (124, '            threads:')
    (125, '                config["busco_threads"]')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=mahajrod/BuscoPhylo, file=workflow/rules/busco.smk
context_key: ["elif config[\\'busco_version\\'] == 5", 'elif config[\\\'gene_prediction_tool\\\'] == "augustus"', 'rule busco5_augustus', 'shell']
    (126, '            shell:')
    (127, '                "mkdir -p {output.busco_outdir}; cd {output.busco_outdir}; "')
    (128, '                "busco --augustus --augustus_species {params.species} -m {params.mode} "')
    (129, '                "-i {input} -c {threads} -l {params.busco_dataset_path} -o {params.output_prefix} 1>../../../{log.std} 2>&1; "')
    (130, '                "mv {params.output_prefix}/* ./; rm -r {params.output_prefix}/; "')
    (131, '                "rm -r busco_downloads/; mv run*/* ./; rm -r run*; "')
    (132, '                "mv full_table.tsv full_table_{params.output_prefix}.tsv; "')
    (133, '                "mv missing_busco_list.tsv missing_busco_list_{params.output_prefix}.tsv; "')
    (134, '                "mv short_summary.txt short_summary_{params.output_prefix}.txt; "')
    (135, '                "mv busco_sequences/single_copy_busco_sequences . "')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=mahajrod/BuscoPhylo, file=workflow/rules/busco.smk
context_key: ["elif config[\\'busco_version\\'] == 5", 'else']
    (136, '    else:')
    (137, '        print("Specify the tool name in \\\'gene_prediction_tool\\\' parameter! Use \\\'metaeuk\\\' or \\\'augustus\\\'")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=mahajrod/BuscoPhylo, file=Snakefile
context_key: ['if config["iqtree_dna_method"] in ["yes", "+", "true"]']
    (74, 'if config["iqtree_dna_method"] in ["yes", "+", "true"]:')
    (75, '    output_files.append(phylogenetic_methods_dict["iqtree_dna"])')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=mahajrod/BuscoPhylo, file=Snakefile
context_key: ['if config["iqtree_protein_method"] in ["yes", "+", "true"]']
    (76, 'if config["iqtree_protein_method"] in ["yes", "+", "true"]:')
    (77, '    output_files.append(phylogenetic_methods_dict["iqtree_protein"])')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=mahajrod/BuscoPhylo, file=Snakefile
context_key: ['if config["mrbayes_dna_method"] in ["yes", "+", "true"]']
    (78, 'if config["mrbayes_dna_method"] in ["yes", "+", "true"]:')
    (79, '    output_files.append(phylogenetic_methods_dict["mrbayes_dna"])')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=mahajrod/BuscoPhylo, file=Snakefile
context_key: ['if config["mrbayes_protein_method"] in ["yes", "+", "true"]']
    (80, 'if config["mrbayes_protein_method"] in ["yes", "+", "true"]:')
    (81, '    output_files.append(phylogenetic_methods_dict["mrbayes_protein"])')
    (82, '')
    (83, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=zavolanlab/SCUREL, file=workflow/Snakefile
context_key: ["if config[\\'mode\\'] == \\'cell_state_comparison\\'"]
    (31, "if config[\\'mode\\'] == \\'cell_state_comparison\\':")
    (32, "    include: os.path.join(\\'rules\\', \\'cell_state_comparison.smk\\')")
    (33, "    final_files = [os.path.join(config[\\'out_dir\\'], ")
    (34, '        "auc", "analysis_out", ')
    (35, '        config[\\\'analysis_prefix\\\'] + "_TEs_shorter_" + x + ".tsv") ')
    (36, "        for x in [\\'merged\\'] + CELL_TYPES]")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=zavolanlab/SCUREL, file=workflow/Snakefile
context_key: ["elif config[\\'mode\\'] == \\'cell_type_comparison\\'"]
    (37, "elif config[\\'mode\\'] == \\'cell_type_comparison\\':")
    (38, '    cmprs = pd.read_table(config["comparisons"], sep="\\\\t", header = None, names = [\\\'comparison\\\', \\\'ct1\\\', \\\'ct2\\\']).set_index("comparison", drop = False)')
    (39, "    include: os.path.join(\\'rules\\', \\'cell_type_comparison.smk\\')")
    (40, "    final_files = [os.path.join(config[\\'out_dir\\'], ")
    (41, '        "auc_comparisons", "analysis_out", ')
    (42, '        config[\\\'analysis_prefix\\\'] + "_TEs_shorter_" + x + ".tsv") ')
    (43, '        for x in cmprs.index.values]')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=hevmarriott/DNAscanv2_snakemake, file=Snakefile
context_key: ['if config["USE_OWN_TEMP_DIR"] == "true"']
    (123, 'if config["USE_OWN_TEMP_DIR"] == "true":')
    (124, '    tmp_dir = config["TEMPORARY_DIR"]')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=hevmarriott/DNAscanv2_snakemake, file=Snakefile
context_key: ['if config["HISAT_CUSTOM_OPTIONS"] == "None"']
    (135, 'if config["HISAT_CUSTOM_OPTIONS"] == "None":')
    (136, '    config["HISAT_CUSTOM_OPTIONS"] = ""')
    (137, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=hevmarriott/DNAscanv2_snakemake, file=Snakefile
context_key: ['if config["BWA_CUSTOM_OPTIONS"] == "None"']
    (138, 'if config["BWA_CUSTOM_OPTIONS"] == "None":')
    (139, '    config["BWA_CUSTOM_OPTIONS"] = ""')
    (140, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=hevmarriott/DNAscanv2_snakemake, file=Snakefile
context_key: ['if config["MELT_CUSTOM_OPTIONS"] == "None"']
    (141, 'if config["MELT_CUSTOM_OPTIONS"] == "None":')
    (142, '    config["MELT_CUSTOM_OPTIONS"] = ""')
    (143, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=hevmarriott/DNAscanv2_snakemake, file=Snakefile
context_key: ['if config["ANNOTSV_CUSTOM_OPTIONS"] == "None"']
    (144, 'if config["ANNOTSV_CUSTOM_OPTIONS"] == "None":')
    (145, '    config["ANNOTSV_CUSTOM_OPTIONS"] = ""')
    (146, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=geparada/rna-seq-kallisto-sleuth, file=workflow/Snakefile
context_key: ['if config["enrichment"]["goatools"]["activate"]']
    (15, '    if config["enrichment"]["goatools"]["activate"]:')
    (16, '        wanted_input.extend(')
    (17, '                expand(')
    (18, '                    [')
    (19, '                        "results/tables/go_terms/{model}.genes-mostsigtrans.diffexp.go_term_enrichment.gene_fdr_{gene_fdr}.go_term_fdr_{go_term_fdr}.tsv",')
    (20, '                        "results/plots/go_terms/{model}.genes-mostsigtrans.diffexp.go_term_enrichment_{go_ns}.gene_fdr_{gene_fdr}.go_term_fdr_{go_term_fdr}.pdf"')
    (21, '                    ],')
    (22, '                    model=config["diffexp"]["models"],')
    (23, '                    go_ns=["BP", "CC", "MF"],')
    (24, '                    gene_fdr=str(config["enrichment"]["goatools"]["fdr_genes"]).replace(\\\'.\\\',\\\'-\\\'),')
    (25, '                    go_term_fdr=str(config["enrichment"]["goatools"]["fdr_go_terms"]).replace(\\\'.\\\',\\\'-\\\')')
    (26, '                )')
    (27, '            )')
    (28, '')
    (29, "    # request fgsea if \\'activated\\' in config.yaml")
    (30, '    if config["enrichment"]["fgsea"]["activate"]:')
    (31, '        wanted_input.extend(')
    (32, '                expand(')
    (33, '                    [')
    (34, '                        "results/tables/fgsea/{model}.all-gene-sets.tsv",')
    (35, '                        "results/tables/fgsea/{model}.sig-gene-sets.tsv",')
    (36, '                        "results/plots/fgsea/{model}.table-plot.pdf",')
    (37, '                        "results/plots/fgsea/{model}"')
    (38, '                    ],')
    (39, '                    model=config["diffexp"]["models"],')
    (40, '                    gene_set_fdr=str(config["enrichment"]["fgsea"]["fdr_gene_set"]).replace(\\\'.\\\',\\\'-\\\'),')
    (41, '                    nperm=str(config["enrichment"]["fgsea"]["nperm"])')
    (42, '                )')
    (43, '            )')
    (44, '')
    (45, "    # request spia if \\'activated\\' in config.yaml")
    (46, '    if config["enrichment"]["spia"]["activate"]:')
    (47, '        wanted_input.extend(')
    (48, '                expand(')
    (49, '                    [ "results/tables/pathways/{model}.pathways.tsv" ],')
    (50, '                    model=config["diffexp"]["models"],')
    (51, '                )')
    (52, '            )')
    (53, '')
    (54, '    # workflow output that is always wanted')
    (55, '')
    (56, '    # general sleuth output')
    (57, '    wanted_input.extend(')
    (58, '            expand(')
    (59, '                [')
    (60, '                    "results/plots/mean-var/{model}.mean-variance-plot.pdf",')
    (61, '                    "results/plots/volcano/{model}.volcano-plots.pdf",')
    (62, '                    "results/plots/ma/{model}.ma-plots.pdf",')
    (63, '                    "results/plots/qq/{model}.qq-plots.pdf",')
    (64, '                    "results/tables/diffexp/{model}.transcripts.diffexp.tsv",')
    (65, '                    "results/plots/diffexp-heatmap/{model}.diffexp-heatmap.pdf",')
    (66, '                    "results/tables/tpm-matrix/{model}.tpm-matrix.tsv",')
    (67, '                ],')
    (68, '                model=config["diffexp"]["models"]')
    (69, '            )')
    (70, '        )')
    (71, '        ')
    (72, '    # ihw false discovery rate control')
    (73, '    wanted_input.extend(')
    (74, '            expand(')
    (75, '                [')
    (76, '                    "results/tables/ihw/{model}.{level}.ihw-results.tsv",')
    (77, '                    "results/plots/ihw/{level}/{model}.{level}.plot-dispersion.pdf",')
    (78, '                    "results/plots/ihw/{level}/{model}.{level}.plot-histograms.pdf",')
    (79, '                    "results/plots/ihw/{level}/{model}.{level}.plot-trends.pdf",')
    (80, '                    "results/plots/ihw/{level}/{model}.{level}.plot-decision.pdf",')
    (81, '                    "results/plots/ihw/{level}/{model}.{level}.plot-adj-pvals.pdf"')
    (82, '                ],')
    (83, '                model=config["diffexp"]["models"],')
    (84, '                level=["transcripts", "genes-aggregated", "genes-mostsigtrans"]')
    (85, '            )')
    (86, '        )')
    (87, '')
    (88, '    # sleuth p-value histogram plots')
    (89, '    wanted_input.extend(')
    (90, '            expand("results/plots/diffexp/{model}.{level}.diffexp-pval-hist.pdf",')
    (91, '                model=config["diffexp"]["models"],')
    (92, '                level=["transcripts", "genes-aggregated", "genes-mostsigtrans" ]')
    (93, '            )')
    (94, '        )')
    (95, '')
    (96, '    # technical variance vs. observed variance')
    (97, '    #wanted_input.extend(')
    (98, '    #        expand("results/plots/variance/{model}.transcripts.plot_vars.pdf", model=config["diffexp"]["models"]),')
    (99, '    #    )')
    (100, '')
    (101, '    # PCA plots of kallisto results, each coloured for a different covariate')
    (102, '    wanted_input.extend(')
    (103, '            expand([')
    (104, '                       "results/plots/pc-variance/{covariate}.pc-variance-plot.pdf",')
    (105, '                       "results/plots/loadings/{covariate}.loadings-plot.pdf",')
    (106, '                       "results/plots/pca/{covariate}.pca.pdf"')
    (107, '                   ],')
    (108, '                   covariate=samples.columns[samples.columns != "sample"])')
    (109, '        )')
    (110, '')
    (111, '    # group-density plot')
    (112, '    wanted_input.extend(')
    (113, '             expand(["results/plots/group_density/{model}.group_density.pdf"],')
    (114, '                 model=config["diffexp"]["models"])')
    (115, '        )')
    (116, '')
    (117, '    # scatter plots')
    (118, '    if config["scatter"]["activate"]:')
    (119, '        wanted_input.extend(')
    (120, '                  expand(["results/plots/scatter/{model}.scatter.pdf"],')
    (121, '                      model=config["diffexp"]["models"])')
    (122, '        )')
    (123, '')
    (124, '    # sleuth bootstrap plots')
    (125, '    wanted_input.extend(')
    (126, '            expand("results/plots/bootstrap/{model}",')
    (127, '                model=config["diffexp"]["models"]')
    (128, '            )')
    (129, '        )')
    (130, '')
    (131, '    # fragment length distribution plots')
    (132, '    wanted_input.extend(')
    (133, '            expand("results/plots/fld/{unit.sample}-{unit.unit}.fragment-length-dist.pdf",')
    (134, '                unit=units[["sample", "unit"]].itertuples()')
    (135, '            )')
    (136, '        )')
    (137, '')
    (138, '    return wanted_input')
    (139, '')
    (140, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=robinmeyers/atac-encode-snakemake, file=Snakefile
context_key: ["if config[\\'local_main_job\\']"]
    (48, "if config[\\'local_main_job\\']:")
    (49, "    _localrules.append(\\'run_cromwell_workflow\\') # add rules as required")
    (50, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=PrincetonUniversity/gtex-gatk4, file=Snakefile
context_key: ["if config[\\'center\\'] != \\'all\\'"]
    (21, "if config[\\'center\\'] != \\'all\\':")
    (22, '    sample_details = {sample: detail')
    (23, '                      for sample, detail in sample_details.items()')
    (24, "                      if detail.center == config[\\'center\\']}")
    (25, '')
    (26, '')
    (27, '## remove ids not found in sample details')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=lczech/ratatosk, file=Snakefile
context_key: ['if config["settings"]["use-chunkify"]']
    (38, 'if config["settings"]["use-chunkify"]:')
    (39, '    include: "rules/chunkify.smk"')
    (40, '    run_mode = "chunked"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=lczech/ratatosk, file=Snakefile
context_key: ['if config["settings"]["alignment-tool"] not in [ "hmmer" ]']
    (46, 'if config["settings"]["alignment-tool"] not in [ "hmmer" ]:')
    (47, '    raise Exception("Unknown alignment-tool: " + config["settings"]["alignment-tool"])')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=lczech/ratatosk, file=Snakefile
context_key: ['if config["settings"]["placement-tool"] not in [ "epa-ng" ]']
    (48, 'if config["settings"]["placement-tool"] not in [ "epa-ng" ]:')
    (49, '    raise Exception("Unknown placement-tool: " + config["settings"]["placement-tool"])')
    (50, '')
    (51, '# Now use the tool choice to load the correct rules.')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=nioo-knaw/epiGBS2, file=Snakefile
context_key: ['if config["mode"] == "reference"']
    (18, 'if config["mode"] == "reference":')
    (19, '    include: "src/rules/fastqc-ref.rules"')
    (20, '    include: "src/rules/reference.rules"')
    (21, '    include: "src/rules/demultiplex.rules"')
    (22, '    include: "src/rules/trimming.rules"')
    (23, '')
    (24, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=nioo-knaw/epiGBS2, file=Snakefile
context_key: ['if config["mode"] == "denovo"']
    (25, 'if config["mode"] == "denovo":')
    (26, '    include: "src/rules/demultiplex.rules"')
    (27, '    include: "src/rules/denovo.rules"')
    (28, '    include: "src/rules/trimming.rules"')
    (29, '    include: "src/rules/fastqc.rules"')
    (30, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=nioo-knaw/epiGBS2, file=Snakefile
context_key: ['if config["mode"] == "paramTest"']
    (31, 'if config["mode"] == "paramTest":')
    (32, '    include: "src/rules/demultiplex.rules"')
    (33, '    include: "src/rules/paramTest.rules"')
    (34, '    include: "src/rules/trimming.rules"')
    (35, '')
    (36, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=nioo-knaw/epiGBS2, file=Snakefile
context_key: ['if config["mode"]== "reference"', 'rule all']
    (37, 'if config["mode"]== "reference":')
    (38, '    rule all:')
    (39, '        input: expand("{out}/output_demultiplex/clone-stacks/{sample}-Watson.1.fq.gz \\\\')
    (40, '            {out}/output_demultiplex/clone-stacks/{sample}-Watson.2.fq.gz \\\\')
    (41, '            {out}/output_demultiplex/clone-stacks/{sample}-Crick.1.fq.gz \\\\')
    (42, '            {out}/output_demultiplex/clone-stacks/{sample}-Crick.2.fq.gz \\\\')
    (43, '            {out}/fastqc/ \\\\')
    (44, '            {out}/multiQC_report.html \\\\')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=nioo-knaw/epiGBS2, file=Snakefile
context_key: ['if config["mode"]== "denovo"', 'rule all']
    (51, 'if config["mode"]== "denovo":')
    (52, '    rule all:')
    (53, '        input: expand("{out}/output_demultiplex/Watson_R2.fq.gz \\\\')
    (54, '            {out}/output_demultiplex/Watson_R1.fq.gz \\\\')
    (55, '            {out}/output_demultiplex/Crick_R2.fq.gz \\\\')
    (56, '            {out}/output_demultiplex/Crick_R1.fq.gz \\\\')
    (57, '            {out}/fastqc/ \\\\')
    (58, '            {out}/multiQC_report.html \\\\')
    (59, '            {out}/output_denovo/consensus_cluster.renamed.fa \\\\')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=nioo-knaw/epiGBS2, file=Snakefile
context_key: ['if config["mode"]== "paramTest"', 'rule all']
    (66, 'if config["mode"]== "paramTest":')
    (67, '    rule all:')
    (68, '        input: expand("{out}/output_demultiplex/clone-stacks/{samples}-Watson.1.fq.gz \\\\')
    (69, '            {out}/output_demultiplex/clone-stacks/{samples}-Watson.2.fq.gz \\\\')
    (70, '            {out}/output_demultiplex/clone-stacks/{samples}-Crick.1.fq.gz \\\\')
    (71, '            {out}/output_demultiplex/clone-stacks/{samples}-Crick.2.fq.gz \\\\')
    (72, '            {out}/output_demultiplex/Watson_R2.fq.gz \\\\')
    (73, '            {out}/output_demultiplex/Watson_R1.fq.gz \\\\')
    (74, '            {out}/output_demultiplex/Crick_R2.fq.gz \\\\')
    (75, '            {out}/output_demultiplex/Crick_R1.fq.gz \\\\')
    (76, '            {out}/paramTest/{params}/alignment/{sample}_trimmed_filt_merged.1_bismark_bt2_pe.bam \\\\')
    (77, '            {out}/paramTest/{params}/output_denovo/consensus_cluster.renamed.fa \\\\')
    (78, '            {out}/paramTest/Assembled.txt \\\\')
    (79, '            {out}/paramTest/averageDepth.txt \\\\')
    (80, '            {out}/paramTest/denovoParameter.tsv \\\\')
    (81, '            {out}/paramTest/denovoParameter.tiff \\\\')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=nioo-knaw/epiGBS2, file=Snakefile
context_key: ['if config["mode"] == "legacy"']
    (86, 'if config["mode"] == "legacy":')
    (87, '    include: "src/rules/legacy.rules"')
    (88, '    include: "src/rules/demultiplex.rules"')
    (89, '    include: "src/rules/report.rules"')
    (90, '')
    (91, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=nioo-knaw/epiGBS2, file=Snakefile
context_key: ['if config["mode"]== "legacy"', 'rule all']
    (92, 'if config["mode"]== "legacy":')
    (93, '    rule all:')
    (94, '        input: expand("{out}/output_demultiplex/Watson_R2.fq.gz \\\\')
    (95, '            {out}/output_demultiplex/Watson_R1.fq.gz \\\\')
    (96, '            {out}/output_demultiplex/Crick_R2.fq.gz \\\\')
    (97, '            {out}/output_demultiplex/Crick_R1.fq.gz \\\\')
    (98, '            {out}/mapping/watson.bam \\\\')
    (99, '            {out}/mapping/crick.bam \\\\')
    (100, '            {out}/output_denovo/consensus_cluster.renamed.fa \\\\')
    (101, '            {out}/mapping/methylation.bed \\\\')
    (102, '            {out}/mapping/snp.vcf.gz".split(), out=config["output_dir"])')
    (103, '')
    (104, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Monia234/admix-map, file=workflow/Snakefile
context_key: ['if config[\\\'singularity\\\'][\\\'use_singularity\\\'] == \\\'true\\\' and config[\\\'singularity\\\'][\\\'image\\\'] != "none"']
    (33, 'if config[\\\'singularity\\\'][\\\'use_singularity\\\'] == \\\'true\\\' and config[\\\'singularity\\\'][\\\'image\\\'] != "none":')
    (34, '    bind_dirs = [x for x in [QUERY, VCF, config[\\\'samples\\\'], config[\\\'annotation\\\'][\\\'rsIDs\\\'], config[\\\'annotation\\\'][\\\'typed_key\\\']] if os.path.exists(os.path.dirname(x)) and x!="/"]')
    (35, '    bind_paths = ",".join([x for x in set([os.path.dirname(x) for x in bind_dirs] + dirs) if os.path.isdir(x) and x!="/"])')
    (36, '    if config[\\\'admixMapping\\\'][\\\'skip\\\'].lower() != \\\'true\\\': bind_paths += f",{RFMIX}"')
    (37, '    CMD_PREFIX = f"set +u; {config[\\\'singularity\\\'][\\\'module\\\']}; singularity exec --bind {bind_paths} {config[\\\'singularity\\\'][\\\'image\\\']}"')
    (38, "    CODE = config[\\'singularity\\'][\\'code\\']")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Monia234/admix-map, file=workflow/Snakefile
context_key: ["if config[\\'samples\\'] == \\'all\\'"]
    (53, "if config[\\'samples\\'] == \\'all\\': ind_num = len(samps)")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Monia234/admix-map, file=workflow/Snakefile
context_key: ["if config[\\'run_settings\\'][\\'local_run\\'] == \\'true\\'"]
    (71, "if config[\\'run_settings\\'][\\'local_run\\'] == \\'true\\':")
    (72, '    localrules: all, calcFreq, calcIBS, catIBS, calcPCA, controlMatch, admixMap, extract_optimum_popnum, cat_admixMap')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Monia234/admix-map, file=workflow/Snakefile
context_key: ['run', "if config[\\'match_controls\\'] == \\'true\\'"]
    (366, "        if config[\\'match_controls\\'] == \\'true\\': #Run control-matching and parse results into a format that PLINK can use to extract matched samples.")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Monia234/admix-map, file=workflow/Snakefile
context_key: ['run', "if config[\\'annotation\\'][\\'download_refs\\'] == \\'true\\'"]
    (512, "        if config[\\'annotation\\'][\\'download_refs\\'] == \\'true\\':")
    (513, '            shell(f" wget {config[\\\'annotation\\\'][\\\'gff\\\']} -O {gff}")')
    (514, '            shell(f" wget {config[\\\'annotation\\\'][\\\'genome\\\']} -O {genome}")')
    (515, "        elif os.path.exists(config[\\'annotation\\'][\\'gff\\']) and os.path.exists(config[\\'annotation\\'][\\'genome\\']):")
    (516, '            shell(f"cp {config[\\\'annotation\\\'][\\\'gff\\\']} {gff}")')
    (517, '            shell(f"cp {config[\\\'annotation\\\'][\\\'genome\\\']} {genome}")')
    (518, '        else:')
    (519, '            print("Could not find reference .gff and/or .genome file.  Check config file that paths are correctly specified and/or download requested.")')
    (520, '        shell(f"{CMD_PREFIX} bedtools slop -i {BASE}.admixmap.tmp.bed -g {genome} -b {config[\\\'admixMapping\\\'][\\\'annotation_buffer\\\']} > {BASE}.admixmap.bed")')
    (521, '        cmd = f"{CMD_PREFIX} bedtools intersect -a {BASE}.admixmap.bed -b {gff} -loj | "  \\\\')
    (522, '        "awk \\\'{{if($11==\\\\"gene\\\\") print $0}}\\\' | awk \\\'{{split($NF,a,\\\\";\\\\"); $NF=\\\\"\\\\"; for(x in a) if(a[x] ~ /Name=/) print $0,a[x]}}\\\' | sed \\\'s/Name=//\\\' > {BASE}.admixmap.preannt.txt"')
    (523, '        shell(cmd)')
    (524, '        shell(f"{CMD_PREFIX} Rscript {CODE}/admixAnnt.R -i input/ -p {BASE}.admixmap.preannt.txt -b {config[\\\'admixMapping\\\'][\\\'annotation_buffer\\\']} -o {{output}}")')
    (525, '')
    (526, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=konnorve/DGE-co-culture-workflow, file=workflow/Snakefile
context_key: ['if config["aligner"] == "hisat2"']
    (69, 'if config["aligner"] == "hisat2":')
    (70, '')
    (71, '    include: "rules/map_reads_hisat2.smk"')
    (72, '')
    (73, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=konnorve/DGE-co-culture-workflow, file=workflow/Snakefile
context_key: ['if config["aligner"] == "bwa"']
    (74, 'if config["aligner"] == "bwa":')
    (75, '')
    (76, '    include: "rules/map_reads_bwa.smk"')
    (77, '')
    (78, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=konnorve/DGE-co-culture-workflow, file=workflow/Snakefile
context_key: ['if config["aligner"] == "bowtie2"']
    (79, 'if config["aligner"] == "bowtie2":')
    (80, '')
    (81, '    include: "rules/map_reads_bowtie2.smk"')
    (82, '')
    (83, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=cshlwyang/RNAseq, file=rules/align.smk
context_key: ['if config["trimming"]["skip"]']
    (1, '    if config["trimming"]["skip"]:')
    (2, '        # no trimming, use raw reads')
    (3, '        return {"fq1":units.loc[(wildcards.sample, wildcards.unit), ["fq1"]].dropna(),')
    (4, '                "fq2":units.loc[(wildcards.sample, wildcards.unit), ["fq2"]].dropna()}')
    (5, '    else:')
    (6, '        # yes trimming, use trimmed data')
    (7, '        if not is_single_end(**wildcards):')
    (8, '            # paired-end sample')
    (9, '            return {"fq1": expand("trimmed/{sample}-{unit}.{group}.fastq.gz",')
    (10, '                          group=1, **wildcards),')
    (11, '                    "fq2": expand("trimmed/{sample}-{unit}.{group}.fastq.gz",')
    (12, '                          group=2, **wildcards)}')
    (13, '        # single end sample')
    (14, '        return {"fq1":"trimmed/{sample}-{unit}.fastq.gz".format(**wildcards)}')
    (15, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=yzeng-lol/tcge-cfmedip-seq-pipeline, file=workflow/rules/common.smk
context_key: ['if config["aggreate"]']
    (16, 'if config["aggreate"]:')
    (17, '    SAMPLES_AGGR = (')
    (18, '        pd.read_csv(config["samples_aggr"], sep="\\\\t")')
    (19, '        .set_index("sample_id", drop=False)')
    (20, '        .sort_index()')
    (21, '    )')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=jbloomlab/SARS-CoV-2-RBD_DMS_variants, file=Snakefile
context_key: ["if config[\\'seqdata_source\\'] == \\'HutchServer\\'", 'rule get_ccs', 'input']
    (428, "if config[\\'seqdata_source\\'] == \\'HutchServer\\':")
    (429, '')
    (430, '    rule get_ccs:')
    (431, '        """Symbolically link CCS files."""')
    (432, '        input:')
    (433, '            ccs_fastq=lambda wildcards: (pacbio_runs')
    (434, "                                        .set_index(\\'pacbioRun\\')")
    (435, "                                        .at[wildcards.pacbioRun, \\'ccs\\']")
    (436, '                                        )')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=jbloomlab/SARS-CoV-2-RBD_DMS_variants, file=Snakefile
context_key: ["if config[\\'seqdata_source\\'] == \\'HutchServer\\'", 'rule get_ccs', 'output']
    (437, '        output:')
    (438, '            ccs_fastq=os.path.join(config[\\\'ccs_dir\\\'], "{pacbioRun}_ccs.fastq.gz")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=jbloomlab/SARS-CoV-2-RBD_DMS_variants, file=Snakefile
context_key: ["if config[\\'seqdata_source\\'] == \\'HutchServer\\'", 'rule get_ccs', 'run']
    (439, '        run:')
    (440, '            os.symlink(input.ccs_fastq, output.ccs_fastq)')
    (441, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=jbloomlab/SARS-CoV-2-RBD_DMS_variants, file=Snakefile
context_key: ["elif config[\\'seqdata_source\\'] == \\'SRA\\'"]
    (442, "elif config[\\'seqdata_source\\'] == \\'SRA\\':")
    (443, "    raise RuntimeError(\\'getting sequence data from SRA not yet implemented\\')")
    (444, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=kelly-sovacool/meta-repo, file=Snakefile
context_key: ["elif config[\\'token_filename\\']"]
    (7, "elif config[\\'token_filename\\']:")
    (8, "    with open(config[\\'token_filename\\'], \\'r\\') as file:")
    (9, '        token = file.readline().strip()')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=ctmrbio/stag-mwc, file=Snakefile
context_key: ['if config["email"]']
    (138, '    if config["email"]:')
    (139, '        shell("""mail -s "StaG-mwc run failed!" {config[email]} < {log}""")')
    (140, '')
    (141, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=ctmrbio/stag-mwc, file=Snakefile
context_key: ['if config["email"]']
    (163, '    if config["email"]:')
    (164, '        shell("""mail -s "StaG-mwc run completed" {config[email]} < {log}""")')
    (165, '')
    (166, '    if config["report"]:')
    (167, '        from sys import argv')
    (168, '        from datetime import datetime')
    (169, '')
    (170, '        report_datetime = datetime.now().strftime("%Y%m%d-%H%S")')
    (171, '')
    (172, '        citation_filename = f"citations-{report_datetime}.rst"')
    (173, '        with open(citation_filename, "w") as citation_file:')
    (174, '            for citation in sorted(citations):')
    (175, '                citation_file.write("* "+citation+"\\')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=ctmrbio/stag-mwc, file=rules/taxonomic_profiling/kraken2.smk
context_key: ['if config["taxonomic_profile"]["kraken2"]', 'if not (kraken2_config["db"] and Path(kraken2_config["db"]).exists())']
    (26, 'if config["taxonomic_profile"]["kraken2"]:')
    (27, '    if not (kraken2_config["db"] and Path(kraken2_config["db"]).exists()):')
    (28, '        err_message = "No Kraken2 database folder at: \\\'{}\\\'!\\')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=ctmrbio/stag-mwc, file=rules/taxonomic_profiling/kraken2.smk
context_key: ['if config["taxonomic_profile"]["kraken2"] and kraken2_config["bracken"]["kmer_distrib"]', 'if not Path(kraken2_config["bracken"]["kmer_distrib"]).exists()']
    (263, 'if config["taxonomic_profile"]["kraken2"] and kraken2_config["bracken"]["kmer_distrib"]:')
    (264, '    if not Path(kraken2_config["bracken"]["kmer_distrib"]).exists():')
    (265, '        err_message = "No Bracken kmer_distrib database file at: \\\'{}\\\'!\\')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=ctmrbio/stag-mwc, file=rules/preproc/host_removal.smk
context_key: ['if config["host_removal"]', 'if not Path(db_path/"taxo.k2d").is_file()']
    (8, 'if config["host_removal"]:')
    (9, '    db_path = Path(config["remove_host"]["db_path"])')
    (10, '    if not Path(db_path/"taxo.k2d").is_file():')
    (11, '        err_message = "Cannot find database for host sequence removal at: \\\'{}/*.k2d\\\'!\\')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=ctmrbio/stag-mwc, file=rules/antibiotic_resistance/groot.smk
context_key: ['if config["antibiotic_resistance"]["groot"]', 'if not Path(groot_db_path).exists()']
    (12, 'if config["antibiotic_resistance"]["groot"]:')
    (13, '    if not Path(groot_db_path).exists():')
    (14, '        err_message = "No groot database found at: \\\'{}\\\'!\\')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=ctmrbio/stag-mwc, file=rules/naive/sketch_compare.smk
context_key: ['if config["naive"]["sketch_compare"]']
    (9, 'if config["naive"]["sketch_compare"]:')
    (10, "    # Add final output files from this module to \\'all_outputs\\' from the")
    (11, '    # main Snakefile scope.')
    (12, '    sample_similarity_plot = str(OUTDIR/"sketch_compare/sample_similarity.pdf")')
    (13, '    all_outputs.append(sample_similarity_plot)')
    (14, '')
    (15, '    citations.add(publications["BBMap"])')
    (16, '')
    (17, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=ctmrbio/stag-mwc, file=rules/mappers/bbmap.smk
context_key: ['if config["mappers"]["bbmap"]', 'if not Path(db_path/"ref").exists()']
    (12, '    if config["mappers"]["bbmap"]:')
    (13, '        if not Path(db_path/"ref").exists():')
    (14, '            err_message = "BBMap index not found at: \\\'{}\\\'\\')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=ctmrbio/stag-mwc, file=rules/naive/bbcountunique.smk
context_key: ['if config["naive"]["assess_depth"]']
    (4, 'if config["naive"]["assess_depth"]:')
    (5, "    # Add final output files from this module to \\'all_outputs\\' from")
    (6, '    # the main Snakefile scope. SAMPLES is also from the main Snakefile scope.')
    (7, '    bcu_output = expand(str(OUTDIR/"bbcountunique/{sample}.{output_type}"),')
    (8, '            sample=SAMPLES,')
    (9, '            output_type=["bbcountunique.txt", "bbcountunique.pdf"])')
    (10, '    all_outputs.extend(bcu_output)')
    (11, '')
    (12, '    citations.add(publications["BBMap"])')
    (13, '')
    (14, '    rule bbcountunique:')
    (15, '        """Assess sequencing depth using BBCountUnique."""')
    (16, '        input:')
    (17, '            INPUTDIR/config["input_fn_pattern"].format(sample="{sample}", readpair="1")')
    (18, '        output:')
    (19, '            txt=OUTDIR/"bbcountunique/{sample}.bbcountunique.txt",')
    (20, '            pdf=report(OUTDIR/"bbcountunique/{sample}.bbcountunique.pdf",')
    (21, '                       caption="../../report/bbcountunique.rst",')
    (22, '                       category="Sequencing depth")')
    (23, '        log:')
    (24, '            stdout=str(LOGDIR/"bbcountunique/{sample}.bbcountunique.stdout.log"),')
    (25, '            stderr=str(LOGDIR/"bbcountunique/{sample}.bbcountunique.stderr.log"),')
    (26, '        shadow: ')
    (27, '            "shallow"')
    (28, '        threads:')
    (29, '            cluster_config["bbcountunique"]["n"] if "bbcountunique" in cluster_config else 2')
    (30, '        conda:')
    (31, '            "../../envs/stag-mwc.yaml",')
    (32, '        singularity:')
    (33, '            "oras://ghcr.io/ctmrbio/stag-mwc:stag-mwc"+singularity_branch_tag')
    (34, '        params:')
    (35, '            interval=config["bbcountunique"]["interval"]')
    (36, '        shell:')
    (37, '            """')
    (38, '            bbcountunique.sh in={input} out={output.txt} interval={params.interval} > {log.stdout} 2> {log.stderr}')
    (39, '            scripts/plot_bbcountunique.py {output.txt} {output.pdf} >> {log.stdout} 2>> {log.stderr}')
    (40, '            """')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=ctmrbio/stag-mwc, file=rules/assembly/metawrap.smk
context_key: ['if config["binning"]']
    (20, 'if config["binning"]:')
    (21, '    primary_bins = expand(f"{OUTDIR}/metawrap/binning/{mw_config[\\\'assembler\\\']}/{{sample}}/concoct_bins", sample=SAMPLES)')
    (22, '    consolidated_bins = expand(f"{OUTDIR}/metawrap/consolidated_bins/{mw_config[\\\'assembler\\\']}/{{sample}}/metawrap", sample=SAMPLES)')
    (23, '    blobology = expand(f"{OUTDIR}/metawrap/blobology/{mw_config[\\\'assembler\\\']}/{{sample}}", sample=SAMPLES)')
    (24, '    all_outputs.extend(primary_bins)')
    (25, '    all_outputs.extend(consolidated_bins)')
    (26, '    all_outputs.extend(blobology)')
    (27, '')
    (28, '    citations.add(publications["MetaWRAP"])')
    (29, '    citations.add(publications["CONCOCT"])')
    (30, '    citations.add(publications["MetaBAT2"])')
    (31, '    citations.add(publications["MaxBin2"])')
    (32, '')
    (33, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=ctmrbio/stag-mwc, file=rules/preproc/preprocessing_summary.smk
context_key: ['if config["qc_reads"] and config["host_removal"]']
    (10, 'if config["qc_reads"] and config["host_removal"]:')
    (11, "    # Add final output files from this module to \\'all_outputs\\' from the main")
    (12, '    # Snakefile scope. SAMPLES is also from the main Snakefile scope.')
    (13, '    read_counts = str(OUTDIR/"preprocessing_read_counts.txt")')
    (14, '    read_counts_plot = str(OUTDIR/"preprocessing_read_counts.pdf")')
    (15, '')
    (16, '    all_outputs.append(read_counts)')
    (17, '    all_outputs.append(read_counts_plot)')
    (18, '')
    (19, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=ctmrbio/stag-mwc, file=rules/antibiotic_resistance/amrplusplus.smk
context_key: ['if config["antibiotic_resistance"]["amrplusplus"]', 'if not Path(amrplusplus_config["megares"]["fasta"]).exists()']
    (15, 'if config["antibiotic_resistance"]["amrplusplus"]:')
    (16, '    if not Path(amrplusplus_config["megares"]["fasta"]).exists():')
    (17, '        err_message = "No database exists at: \\\'{}\\\' !\\')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=cbg-ethz/V-pipe, file=resources/auxiliary_workflows/benchmark/workflow/Snakefile
context_key: ['if config["method_list"] is None']
    (21, 'if config["method_list"] is None:')
    (22, '    (method_list,) = glob_wildcards(')
    (23, '        srcdir("../resources/method_definitions/{method}.py")')
    (24, '    )')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=cbg-ethz/V-pipe, file=resources/auxiliary_workflows/benchmark/workflow/Snakefile
context_key: ['if config["haplotype_generation"] == "distance"', 'rule collect_haplo_populations_visualizations', 'input']
    (195, 'if config["haplotype_generation"] == "distance":')
    (196, '')
    (197, '    rule collect_haplo_populations_visualizations:')
    (198, '        input:')
    (199, '            dname_work=[')
    (200, '                f"results/simulated_reads/{params}/replicates/{replicate}/work/"')
    (201, '                for params in paramspace.instance_patterns')
    (202, '                for replicate in range(config["replicate_count"])')
    (203, '            ],')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=cbg-ethz/V-pipe, file=resources/auxiliary_workflows/benchmark/workflow/Snakefile
context_key: ['if config["haplotype_generation"] == "distance"', 'rule collect_haplo_populations_visualizations', 'output']
    (204, '        output:')
    (205, '            dname_out=directory(f"results/haplotype_populations/"),')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=cbg-ethz/V-pipe, file=resources/auxiliary_workflows/benchmark/workflow/Snakefile
context_key: ['if config["haplotype_generation"] == "distance"', 'rule collect_haplo_populations_visualizations', 'script']
    (206, '        script:')
    (207, '            "scripts/collect_haplo_populations.py"')
    (208, '')
    (209, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=nchris5/diffparc-smk_piriform, file=workflow/Snakefile
context_key: ["if config[\\'lhrh_targets_independent_condition\\']"]
    (18, "if config[\\'lhrh_targets_independent_condition\\']:")
    (19, "    f = open(config[\\'targets_txt_lh-rh_separate_358regions\\'],\\'r\\')")
    (20, '    targets = [line.strip() for line in f.readlines()]')
    (21, '    f.close()')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=supermaxiste/ARPEGGIO, file=Snakefile
context_key: ['if config["RUN_BISMARK"] == False']
    (23, 'if config["RUN_BISMARK"] == False:')
    (24, '    if (')
    (25, '        config["RUN_READ_SORTING"]')
    (26, '        or config["RUN_DMR_ANALYSIS"]')
    (27, '        or config["RUN_DOWNSTREAM"]')
    (28, '    ):')
    (29, '        sys.exit(')
    (30, '            "Your conditional parameters are set incorrectly: one step is stopping the workflow and one downstream step is set to True. Please fix this problem before running ARPEGGIO"')
    (31, '        )')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=supermaxiste/ARPEGGIO, file=Snakefile
context_key: ['if config["RUN_READ_SORTING"] == False', 'if config["RUN_DMR_ANALYSIS"] or config["RUN_DOWNSTREAM"]']
    (32, 'if config["RUN_READ_SORTING"] == False:')
    (33, '    if config["RUN_DMR_ANALYSIS"] or config["RUN_DOWNSTREAM"]:')
    (34, '        sys.exit(')
    (35, '            "Your conditional parameters are set incorrectly: one step is stopping the workflow and one downstream step is set to True. Please fix this problem before running ARPEGGIO"')
    (36, '        )')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=supermaxiste/ARPEGGIO, file=Snakefile
context_key: ['if config["RUN_DMR_ANALYSIS"] == False', 'if config["RUN_DOWNSTREAM"]']
    (37, 'if config["RUN_DMR_ANALYSIS"] == False:')
    (38, '    if config["RUN_DOWNSTREAM"]:')
    (39, '        sys.exit(')
    (40, '            "Your conditional parameters are set incorrectly: one step is stopping the workflow and one downstream step is set to True. Please fix this problem before running ARPEGGIO"')
    (41, '        )')
    (42, '')
    (43, '## Import metadata file')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=supermaxiste/ARPEGGIO, file=Snakefile
context_key: ['if config["IS_PAIRED"']
    (60, '    if config["IS_PAIRED"]')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=supermaxiste/ARPEGGIO, file=Snakefile
context_key: ['if config["POLYPLOID_ONLY"]']
    (103, 'if config["POLYPLOID_ONLY"]:')
    (104, '    n_samples_A = len(')
    (105, '        samples.name[(samples.origin == "allopolyploid") & (samples.condition == "A")]')
    (106, '    )')
    (107, '    n_samples_B = len(')
    (108, '        samples.name[(samples.origin == "allopolyploid") & (samples.condition == "B")]')
    (109, '    )')
    (110, '    if n_samples_A < 2 or n_samples_B < 2:')
    (111, '        sys.exit(')
    (112, '            "There seems to be fewer than two samples for either of your two conditions, please have at least two samples per condition in your metadata file or make sure the metadata file has the correct formatting (tab-separated columns)"')
    (113, '        )')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=supermaxiste/ARPEGGIO, file=Snakefile
context_key: ['if config["DIPLOID_ONLY"]']
    (114, 'if config["DIPLOID_ONLY"]:')
    (115, '    n_samples_A = len(')
    (116, '        samples.name[')
    (117, '            ((samples.origin == "parent1") | (samples.origin == "parent2"))')
    (118, '            & (samples.condition == "A")')
    (119, '        ]')
    (120, '    )')
    (121, '    n_samples_B = len(')
    (122, '        samples.name[')
    (123, '            ((samples.origin == "parent1") | (samples.origin == "parent2"))')
    (124, '            & (samples.condition == "B")')
    (125, '        ]')
    (126, '    )')
    (127, '    if n_samples_A < 2 or n_samples_B < 2:')
    (128, '        sys.exit(')
    (129, '            "There seems to be fewer than two samples for either of your two conditions, please have at least two samples per condition in your metadata file or make sure the metadata file has the correct formatting (tab-separated columns)"')
    (130, '        )')
    (131, '')
    (132, '####################### Docker setup ##########################################')
    (133, '')
    (134, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=tjbencomo/ngs-pipeline, file=rules/common.smk
context_key: ['else', "if config[\\'pon_vcf\\'] == \\'None\\'"]
    (69, "    if config[\\'pon_vcf\\'] == \\'None\\':")
    (70, '        build_pon = True ')
    (71, '        pon_vcf = "pon/pon.vcf.gz"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=tjbencomo/ngs-pipeline, file=rules/common.smk
context_key: ["if config[\\'alternate_isoforms\\'] == \\'None\\'"]
    (86, "if config[\\'alternate_isoforms\\'] == \\'None\\':")
    (87, "    alternate_isoforms = \\'\\'")
    (88, "    isoforms_param = \\'\\'")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=sinanugur/RNAseq-variant-calling, file=workflow/rules/snakefile_seqbuster_new.smk
context_key: ["if config.get(\\'directory\\') is None"]
    (4, "if config.get(\\'directory\\') is None:")
    (5, '\\tdirectories, files, = glob_wildcards("data/raw/{samplegroup}/{sample}.fastq.gz")')
    (6, '\\t#glob_wildcards("WGS/tests/fastq/{group}/{sample}.fastq.gzadr_R1.fastq")')
    (7, 'else: #a directory name can be provided for a single group run')
    (8, '\\tfiles, = glob_wildcards("data/raw/" + config.get(\\\'directory\\\') + "/{sample}.fastq.gz")')
    (9, "\\tdirectories=[config.get(\\'directory\\')]*len(files)")
    (10, '')
    (11, '')
    (12, '')
    (13, '')
    (14, '')
    (15, '')
    (16, '')
    (17, '')
    (18, 'gene=["hairpin","isomir","mirna"]')
    (19, '')
    (20, '')
    (21, 'file_dict=defaultdict(list)')
    (22, '')
    (23, '#assign files to correct directories')
    (24, 'for i in zip(directories,files):')
    (25, '        file_dict[i[0]].append(i[1])')
    (26, '')
    (27, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=sinanugur/RNAseq-variant-calling, file=workflow/rules/Snakefile.seqbuster.standart.smk
context_key: ["if config.get(\\'directory\\') is None"]
    (4, "if config.get(\\'directory\\') is None:")
    (5, '\\tdirectories, files, = glob_wildcards("data/raw/{samplegroup}/{sample}.fastq.gz")')
    (6, '\\t#glob_wildcards("WGS/tests/fastq/{group}/{sample}.fastq.gzadr_R1.fastq")')
    (7, 'else: #a directory name can be provided for a single group run')
    (8, '\\tfiles, = glob_wildcards("data/raw/" + config.get(\\\'directory\\\') + "/{sample}.fastq.gz")')
    (9, "\\tdirectories=[config.get(\\'directory\\')]*len(files)")
    (10, '')
    (11, '')
    (12, '')
    (13, 'mirbase_directory="/WORKING/databases/miRBase/"')
    (14, '')
    (15, '')
    (16, '')
    (17, '')
    (18, 'gene=["hairpin","isomir","mirna"]')
    (19, '')
    (20, '')
    (21, 'file_dict=defaultdict(list)')
    (22, '')
    (23, '#assign files to correct directories')
    (24, 'for i in zip(directories,files):')
    (25, '        file_dict[i[0]].append(i[1])')
    (26, '')
    (27, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=trofimovamw/GInCovPipe, file=Snakefile
context_key: ['if config["R0"]', 'else', 'rule strip_whitespaces', 'rule samtools_faidx', 'rule replace_dashes', 'rule samtools_dict', 'rule minimap_index_ref', 'rule minimap', 'rule sort_bam', 'rule index_bam', 'rule samtools_idxstats', 'rule run_binning', 'rule theta_estimates', 'rule interpolation', 'if config["R0"]']
    (13, 'if config["R0"]:')
    (14, '\\trule all:')
    (15, '\\t\\tinput:')
    (16, '\\t\\t\\t"results/r0/r0.csv"')
    (17, 'else:')
    (18, '\\trule all:')
    (19, '\\t\\tinput:')
    (20, '\\t\\t\\t"results/interpolation/interpolation.csv"')
    (21, '')
    (22, '')
    (23, 'rule strip_whitespaces:')
    (24, '\\tinput:')
    (25, '\\t\\tconfig["samples"]')
    (26, '\\toutput:')
    (27, '\\t\\texpand("results/raw/{sample}_fixed1.fasta", sample=basefilename)')
    (28, '\\tconda:')
    (29, '\\t\\t"env/env.yml"')
    (30, '\\tlog:')
    (31, '\\t\\texpand("logs/ws_{sample}.log", sample=basefilename)')
    (32, '\\tshell:')
    (33, '\\t\\t"reformat.sh in={input} out={output} underscore ignorejunk overwrite=true 2> {log}"')
    (34, '')
    (35, '')
    (36, 'rule samtools_faidx:')
    (37, '\\tinput:')
    (38, '\\t\\texpand("{reference}", reference=config["consensus"])')
    (39, '\\toutput:')
    (40, '\\t\\texpand("{reference}.fai", reference=config["consensus"])')
    (41, '\\tshell:')
    (42, '\\t\\t"samtools faidx {input}"')
    (43, '')
    (44, 'rule replace_dashes:')
    (45, '\\tinput:')
    (46, '\\t\\t"results/raw/{sample}_fixed1.fasta"')
    (47, '\\toutput:')
    (48, '\\t\\t"results/raw/{sample}_fixed12.fasta"')
    (49, '\\tconda:')
    (50, '\\t\\t"env/env.yml"')
    (51, '\\tlog:')
    (52, '\\t\\t"logs/dashes_{sample}.log"')
    (53, '\\tshell:')
    (54, '\\t\\t"seqkit replace -s -p \\\'-\\\' -r \\\'N\\\' {input} -o {output} 2> {log}"')
    (55, '')
    (56, 'rule samtools_dict:')
    (57, '\\tinput:')
    (58, '\\t\\texpand("{reference}", reference=config["consensus"])')
    (59, '\\toutput:')
    (60, '\\t\\texpand("{reference}.dict", reference=config["consensus"][:-5])')
    (61, '\\tshell:')
    (62, '\\t\\t"samtools dict {input} -o {output}"')
    (63, '')
    (64, 'rule minimap_index_ref:')
    (65, '\\tinput:')
    (66, '\\t\\texpand("{reference}", reference=config["consensus"])')
    (67, '\\toutput:')
    (68, '\\t\\texpand("{reference}.mmi", reference=config["consensus"][:-5])')
    (69, '\\tconda:')
    (70, '\\t\\t"env/env.yml"')
    (71, '\\tshell:')
    (72, '\\t\\t"minimap2 -d {output} {input}"')
    (73, '')
    (74, 'rule minimap:')
    (75, '\\tinput:')
    (76, '\\t\\tref = expand("{reference}.mmi", reference=config["consensus"][:-5]),')
    (77, '\\t\\ts = "results/raw/{sample}_fixed12.fasta"')
    (78, '\\toutput:')
    (79, '\\t\\t"results/bam/{sample}.bam"')
    (80, '\\tconda:')
    (81, '\\t\\t"env/env.yml"')
    (82, '\\tlog:')
    (83, '\\t\\t"logs/map_{sample}.log"')
    (84, '\\tshell:')
    (85, '\\t\\t"minimap2 -a --eqx {input.ref} {input.s} | samtools view -Sb -F 0x900 > {output} 2> {log}"')
    (86, '')
    (87, 'rule sort_bam:')
    (88, '\\tinput:')
    (89, '\\t\\t"results/bam/{sample}.bam"')
    (90, '\\toutput:')
    (91, '\\t\\t"results/bam/{sample}-sorted.bam"')
    (92, '\\tlog:')
    (93, '\\t\\t"logs/sort_{sample}.log"')
    (94, '\\tconda:')
    (95, '\\t\\t"env/env.yml"')
    (96, '\\tshell:')
    (97, '\\t\\t"samtools sort {input} > {output} 2> {log}"')
    (98, '')
    (99, 'rule index_bam:')
    (100, '\\tinput:')
    (101, '\\t\\t"results/bam/{sample}-sorted.bam"')
    (102, '\\toutput:')
    (103, '\\t\\t"results/bam/{sample}-sorted.bam.bai"')
    (104, '\\tconda:')
    (105, '\\t\\t"env/env.yml"')
    (106, '\\tlog:')
    (107, '\\t\\t"logs/index_{sample}.log"')
    (108, '\\tshell:')
    (109, '\\t\\t"samtools index {input} 2> {log}"')
    (110, '')
    (111, 'rule samtools_idxstats:')
    (112, '\\tinput:')
    (113, '\\t\\t"results/bam/{sample}-sorted.bam"')
    (114, '\\toutput:')
    (115, '\\t\\t"results/bam/{sample}-sorted-stats.txt"')
    (116, '\\tconda:')
    (117, '\\t\\t"env/env.yml"')
    (118, '\\tlog:')
    (119, '\\t\\t"logs/idxstats_{sample}.log"')
    (120, '\\tshell:')
    (121, '\\t\\t"samtools idxstats {input} > {output}"')
    (122, '')
    (123, 'rule run_binning:')
    (124, '\\tinput:')
    (125, '\\t\\tbam = expand("results/bam/{sample}-sorted.bam", sample=basefilename),')
    (126, '\\t\\tbai = expand("results/bam/{sample}-sorted.bam.bai", sample=basefilename),')
    (127, '\\t\\tstats = expand("results/bam/{sample}-sorted-stats.txt", sample=basefilename)')
    (128, '\\toutput:')
    (129, '\\t\\tfiles_list = "results/bins/list_of_binnings.tsv",')
    (130, '\\t\\tmeta = "results/meta/meta_dates.tsv"')
    (131, '\\tparams:')
    (132, '\\t\\teq_num = config["number_per_bin"],')
    (133, '\\t\\teq_days = config["days_per_bin"],')
    (134, '\\t\\tbin_dir = "results/bins",')
    (135, '\\t\\treference = config["consensus"]')
    (136, '\\tconda:')
    (137, '\\t\\t"env/env.yml"')
    (138, '\\tscript:')
    (139, '\\t\\t"scripts/binning/run_binning_count.py"')
    (140, '')
    (141, 'rule theta_estimates:')
    (142, '\\tinput:')
    (143, '\\t\\t"results/bins/list_of_binnings.tsv"')
    (144, '\\toutput:')
    (145, '\\t\\t"results/bins_incidence/table_merged_phi_estimates_var_from_size.tsv"')
    (146, '\\tparams:')
    (147, '\\t\\tref = config["consensus"],')
    (148, '\\t\\tcutoff = config["freq_cutoff"],')
    (149, '\\t\\tmin_bin_size = config["min_bin_size"],')
    (150, '\\t\\tmin_days_span = config["min_days_span"],')
    (151, '\\t\\tmax_days_span = config["max_days_span"],')
    (152, '\\t\\tgroup = config["group"]')
    (153, '\\tconda:')
    (154, '\\t\\t"env/env.yml"')
    (155, '\\tscript:')
    (156, '\\t\\t"scripts/metrics/run_fp.py"')
    (157, '')
    (158, 'rule interpolation:')
    (159, '\\tinput:')
    (160, '\\t\\tinfile = "results/bins_incidence/table_merged_phi_estimates_var_from_size.tsv"')
    (161, '\\tparams:')
    (162, '\\t\\trep_cases = config["reported_cases"],')
    (163, '\\t\\tgroup = config["group"]')
    (164, '\\tconda:')
    (165, '\\t\\t"env/env.yml"')
    (166, '\\toutput:')
    (167, '\\t\\tresult = "results/incidence/incidence.csv",')
    (168, '\\t\\t#abs_path = os.path.join(workflow.basedir,"results/splines/out_spline.pdf"),')
    (169, '\\tshell:')
    (170, '\\t\\t"Rscript {workflow.basedir}/scripts/Rscripts/splines/computeInterpolation.R {input.infile} \\\\')
    (171, '\\t\\t{params.group} {output.result} {params.rep_cases}"')
    (172, '')
    (173, 'if config["R0"]:')
    (174, '\\trule r0:')
    (175, '\\t\\tinput:')
    (176, '\\t\\t\\tinfile = "results/incidence/incidence.csv"')
    (177, '\\t\\toutput:')
    (178, '\\t\\t\\toutfile = "results/r0/r0.csv"')
    (179, '\\t\\tconda:')
    (180, '\\t\\t\\t"env/env.yml"')
    (181, '\\t\\tshell:')
    (182, '\\t\\t\\t"Rscript {workflow.basedir}/scripts/Rscripts/splines/computeR0.R {input.infile} \\\\')
    (183, '\\t\\t\\t{output.outfile}"')
    (184, "'")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=kcivkulis/stag-mwc, file=rules/multiqc/multiqc.smk
context_key: ['if config["multiqc_report"]', 'rule multiqc', 'input']
    (3, 'if config["multiqc_report"]:')
    (4, '    citations.add(publications["MultiQC"])')
    (5, '')
    (6, '    mqc_config = config["multiqc"]')
    (7, '    rule multiqc:')
    (8, '        input:')
    (9, '            all_outputs')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=kcivkulis/stag-mwc, file=rules/multiqc/multiqc.smk
context_key: ['if config["multiqc_report"]', 'rule multiqc', 'output']
    (10, '        output:')
    (11, '            report=report(f"{OUTDIR}/multiqc/multiqc_report.html",')
    (12, '                category="Sequencing data quality",')
    (13, '                caption="../../report/multiqc.rst"),')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=kcivkulis/stag-mwc, file=rules/multiqc/multiqc.smk
context_key: ['if config["multiqc_report"]', 'rule multiqc', 'log']
    (14, '        log:')
    (15, '           f"{LOGDIR}/multiqc/multiqc.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=kcivkulis/stag-mwc, file=rules/multiqc/multiqc.smk
context_key: ['if config["multiqc_report"]', 'rule multiqc', 'shadow']
    (16, '        shadow:')
    (17, '            "shallow"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=kcivkulis/stag-mwc, file=rules/multiqc/multiqc.smk
context_key: ['if config["multiqc_report"]', 'rule multiqc', 'conda']
    (18, '        conda:')
    (19, '            "../../envs/stag-mwc.yaml"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=kcivkulis/stag-mwc, file=rules/multiqc/multiqc.smk
context_key: ['if config["multiqc_report"]', 'rule multiqc', 'singularity']
    (20, '        singularity:')
    (21, '            "shub://ctmrbio/stag-mwc:stag-mwc"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=kcivkulis/stag-mwc, file=rules/multiqc/multiqc.smk
context_key: ['if config["multiqc_report"]', 'rule multiqc', 'threads']
    (22, '        threads:')
    (23, '            1')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=kcivkulis/stag-mwc, file=rules/multiqc/multiqc.smk
context_key: ['if config["multiqc_report"]', 'rule multiqc', 'params']
    (24, '        params:')
    (25, '            extra=mqc_config["extra"],')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=kcivkulis/stag-mwc, file=rules/multiqc/multiqc.smk
context_key: ['if config["multiqc_report"]', 'rule multiqc', 'shell']
    (26, '        shell:')
    (27, '            """')
    (28, '            multiqc {OUTDIR} \\\\')
    (29, '                --filename {output.report} \\\\')
    (30, '                --force \\\\')
    (31, '                2> {log}')
    (32, '            """')
    (33, '')
    (34, '    # Appended after the rule definition to avoid circular dependency')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=kcivkulis/stag-mwc, file=rules/multiqc/multiqc.smk
context_key: ['if config["multiqc_report"]']
    (35, '    all_outputs.append(f"{OUTDIR}/multiqc/multiqc_report.html")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=kcivkulis/stag-mwc, file=Snakefile
context_key: ['if config["email"]']
    (119, '    if config["email"]:')
    (120, '        shell("""mail -s "StaG-mwc run failed!" {config[email]} < {log}""")')
    (121, '')
    (122, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=kcivkulis/stag-mwc, file=Snakefile
context_key: ['if config["email"]']
    (142, '    if config["email"]:')
    (143, '        shell("""mail -s "StaG-mwc run completed" {config[email]} < {log}""")')
    (144, '')
    (145, '    if config["report"]:')
    (146, '        from sys import argv')
    (147, '        from datetime import datetime')
    (148, '')
    (149, '        report_datetime = datetime.now().strftime("%Y%m%d-%H%S")')
    (150, '')
    (151, '        citation_filename = f"citations-{report_datetime}.rst"')
    (152, '        with open(citation_filename, "w") as citation_file:')
    (153, '            for citation in sorted(citations):')
    (154, '                citation_file.write("* "+citation+"\\')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=kcivkulis/stag-mwc, file=rules/taxonomic_profiling/kraken2.smk
context_key: ['if config["taxonomic_profile"]["kraken2"]', 'if not db_path.exists()']
    (26, 'if config["taxonomic_profile"]["kraken2"]:')
    (27, '    db_path = Path(config["base_path"]+kraken2_config["db"])')
    (28, '    if not db_path.exists():')
    (29, '        err_message = "No Kraken2 database folder at: \\\'{}\\\'!\\')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=kcivkulis/stag-mwc, file=rules/taxonomic_profiling/kraken2.smk
context_key: ['if config["taxonomic_profile"]["kraken2"] and kraken2_config["bracken"]["kmer_distrib"]', 'if not Path(kraken2_config["bracken"]["kmer_distrib"]).exists()']
    (261, 'if config["taxonomic_profile"]["kraken2"] and kraken2_config["bracken"]["kmer_distrib"]:')
    (262, '    if not Path(kraken2_config["bracken"]["kmer_distrib"]).exists():')
    (263, '        err_message = "No Bracken kmer_distrib database file at: \\\'{}\\\'!\\')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=kcivkulis/stag-mwc, file=rules/functional_profiling/humann2.smk
context_key: ['if config["functional_profile"]["humann2"]']
    (13, 'if config["functional_profile"]["humann2"]:')
    (14, '    if (not all([h_config["nucleotide_db"], h_config["protein_db"]]) ')
    (15, '        or not any([Path(h_config["nucleotide_db"]).is_dir(), Path(h_config["protein_db"]).is_dir()])):')
    (16, '        err_message = "Could not find HUMAnN2 nucleotide and protein databases at: \\\'{}\\\', \\\'{}\\\'!\\')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=kcivkulis/stag-mwc, file=rules/mappers/bbmap.smk
context_key: ['if config["mappers"]["bbmap"]', 'if not Path(db_path/"ref").exists()']
    (12, '    if config["mappers"]["bbmap"]:')
    (13, '        if not Path(db_path/"ref").exists():')
    (14, '            err_message = "BBMap index not found at: \\\'{}\\\'\\')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=kcivkulis/stag-mwc, file=rules/preproc/preprocessing_summary.smk
context_key: ['if config["qc_reads"] and config["host_removal"]']
    (10, 'if config["qc_reads"] and config["host_removal"]:')
    (11, "    # Add final output files from this module to \\'all_outputs\\' from the main")
    (12, '    # Snakefile scope. SAMPLES is also from the main Snakefile scope.')
    (13, '    read_counts = str(OUTDIR/"preprocessing_read_counts.txt")')
    (14, '    read_counts_plot = str(OUTDIR/"preprocessing_read_counts.pdf")')
    (15, '')
    (16, '    all_outputs.append(read_counts)')
    (17, '    all_outputs.append(read_counts_plot)')
    (18, '')
    (19, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=gitbackspacer/rna-seq-kallisto-sleuth-test, file=workflow/Snakefile
context_key: ['if config["enrichment"]["goatools"]["activate"]']
    (15, '    if config["enrichment"]["goatools"]["activate"]:')
    (16, '        wanted_input.extend(')
    (17, '                expand(')
    (18, '                    [')
    (19, '                        "results/tables/go_terms/{model}.genes-mostsigtrans.diffexp.go_term_enrichment.gene_fdr_{gene_fdr}.go_term_fdr_{go_term_fdr}.tsv",')
    (20, '                        "results/plots/go_terms/{model}.genes-mostsigtrans.diffexp.go_term_enrichment_{go_ns}.gene_fdr_{gene_fdr}.go_term_fdr_{go_term_fdr}.pdf"')
    (21, '                    ],')
    (22, '                    model=config["diffexp"]["models"],')
    (23, '                    go_ns=["BP", "CC", "MF"],')
    (24, '                    gene_fdr=str(config["enrichment"]["goatools"]["fdr_genes"]).replace(\\\'.\\\',\\\'-\\\'),')
    (25, '                    go_term_fdr=str(config["enrichment"]["goatools"]["fdr_go_terms"]).replace(\\\'.\\\',\\\'-\\\')')
    (26, '                )')
    (27, '            )')
    (28, '')
    (29, "    # request fgsea if \\'activated\\' in config.yaml")
    (30, '    if config["enrichment"]["fgsea"]["activate"]:')
    (31, '        wanted_input.extend(')
    (32, '                expand(')
    (33, '                    [')
    (34, '                        "results/tables/fgsea/{model}.all-gene-sets.tsv",')
    (35, '                        "results/tables/fgsea/{model}.sig-gene-sets.tsv",')
    (36, '                        "results/plots/fgsea/{model}.table-plot.pdf",')
    (37, '                        "results/plots/fgsea/{model}"')
    (38, '                    ],')
    (39, '                    model=config["diffexp"]["models"],')
    (40, '                    gene_set_fdr=str(config["enrichment"]["fgsea"]["fdr_gene_set"]).replace(\\\'.\\\',\\\'-\\\'),')
    (41, '                    nperm=str(config["enrichment"]["fgsea"]["nperm"])')
    (42, '                )')
    (43, '            )')
    (44, '')
    (45, "    # request spia if \\'activated\\' in config.yaml")
    (46, '    if config["enrichment"]["spia"]["activate"]:')
    (47, '        wanted_input.extend(')
    (48, '                expand(')
    (49, '                    [ "results/tables/pathways/{model}.pathways.tsv" ],')
    (50, '                    model=config["diffexp"]["models"],')
    (51, '                )')
    (52, '            )')
    (53, '')
    (54, '    # workflow output that is always wanted')
    (55, '')
    (56, '    # general sleuth output')
    (57, '    wanted_input.extend(')
    (58, '            expand(')
    (59, '                [')
    (60, '                    "results/plots/mean-var/{model}.mean-variance-plot.pdf",')
    (61, '                    "results/plots/volcano/{model}.volcano-plots.pdf",')
    (62, '                    "results/plots/ma/{model}.ma-plots.pdf",')
    (63, '                    "results/plots/qq/{model}.qq-plots.pdf",')
    (64, '                    "results/tables/diffexp/{model}.transcripts.diffexp.tsv",')
    (65, '                    "results/plots/diffexp-heatmap/{model}.diffexp-heatmap.pdf",')
    (66, '                    "results/tables/tpm-matrix/{model}.tpm-matrix.tsv",')
    (67, '                ],')
    (68, '                model=config["diffexp"]["models"]')
    (69, '            )')
    (70, '        )')
    (71, '        ')
    (72, '    # ihw false discovery rate control')
    (73, '    wanted_input.extend(')
    (74, '            expand(')
    (75, '                [')
    (76, '                    "results/tables/ihw/{model}.{level}.ihw-results.tsv",')
    (77, '                    "results/plots/ihw/{level}/{model}.{level}.plot-dispersion.pdf",')
    (78, '                    "results/plots/ihw/{level}/{model}.{level}.plot-histograms.pdf",')
    (79, '                    "results/plots/ihw/{level}/{model}.{level}.plot-trends.pdf",')
    (80, '                    "results/plots/ihw/{level}/{model}.{level}.plot-decision.pdf",')
    (81, '                    "results/plots/ihw/{level}/{model}.{level}.plot-adj-pvals.pdf"')
    (82, '                ],')
    (83, '                model=config["diffexp"]["models"],')
    (84, '                level=["transcripts", "genes-aggregated", "genes-mostsigtrans"]')
    (85, '            )')
    (86, '        )')
    (87, '')
    (88, '    # sleuth p-value histogram plots')
    (89, '    wanted_input.extend(')
    (90, '            expand("results/plots/diffexp/{model}.{level}.diffexp-pval-hist.pdf",')
    (91, '                model=config["diffexp"]["models"],')
    (92, '                level=["transcripts", "genes-aggregated", "genes-mostsigtrans" ]')
    (93, '            )')
    (94, '        )')
    (95, '')
    (96, '    # technical variance vs. observed variance')
    (97, '    #wanted_input.extend(')
    (98, '    #        expand("results/plots/variance/{model}.transcripts.plot_vars.pdf", model=config["diffexp"]["models"]),')
    (99, '    #    )')
    (100, '')
    (101, '    # PCA plots of kallisto results, each coloured for a different covariate')
    (102, '    wanted_input.extend(')
    (103, '            expand([')
    (104, '                       "results/plots/pc-variance/{covariate}.pc-variance-plot.pdf",')
    (105, '                       "results/plots/loadings/{covariate}.loadings-plot.pdf",')
    (106, '                       "results/plots/pca/{covariate}.pca.pdf"')
    (107, '                   ],')
    (108, '                   covariate=samples.columns[samples.columns != "sample"])')
    (109, '        )')
    (110, '')
    (111, '    # group-density plot')
    (112, '    wanted_input.extend(')
    (113, '             expand(["results/plots/group_density/{model}.group_density.pdf"],')
    (114, '                 model=config["diffexp"]["models"])')
    (115, '        )')
    (116, '')
    (117, '    # scatter plots')
    (118, '    if config["scatter"]["activate"]:')
    (119, '        wanted_input.extend(')
    (120, '                  expand(["results/plots/scatter/{model}.scatter.pdf"],')
    (121, '                      model=config["diffexp"]["models"])')
    (122, '        )')
    (123, '')
    (124, '    # sleuth bootstrap plots')
    (125, '    wanted_input.extend(')
    (126, '            expand("results/plots/bootstrap/{model}",')
    (127, '                model=config["diffexp"]["models"]')
    (128, '            )')
    (129, '        )')
    (130, '')
    (131, '    # fragment length distribution plots')
    (132, '    wanted_input.extend(')
    (133, '            expand("results/plots/fld/{unit.sample}-{unit.unit}.fragment-length-dist.pdf",')
    (134, '                unit=units[["sample", "unit"]].itertuples()')
    (135, '            )')
    (136, '        )')
    (137, '')
    (138, '    return wanted_input')
    (139, '')
    (140, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=DimitriMeistermann/rnaseq_align, file=Snakefile
context_key: ['if config=={}', 'if not os.path.exists(WORKING_DIR+"/log")', 'if not os.path.exists(FASTQ_PATH)', 'else', 'if IS_PAIRED_END', 'if READ_LENGTH<1', 'else', 'if FORWARD_ADAPTATOR == "" and  REVERSE_ADAPTATOR ==""', 'else', 'if IS_PAIRED_END', 'else', 'if STAR_ALIGN_MULTIPLE_FILE', 'rule all', 'rule STAR_INDEX', 'rule CUTADAPT', 'rule FASTQC', 'if PRELOAD_GENOME', 'else', 'if STAR_ALIGN_MULTIPLE_FILE', 'else', 'if PRELOAD_GENOME', 'if DEDUP_UMI', 'rule HTSEQ_COUNT', 'rule COUNTS_TABLE', 'rule MULTIQC']
    (4, 'if config=={}:')
    (5, '\\tprint("Default config file loaded, from " + WORKING_DIR + "/config.json")')
    (6, '\\tconfigfile: WORKING_DIR+"/config.json"')
    (7, '')
    (8, '## creation of the logs subdirectory')
    (9, 'if not os.path.exists(WORKING_DIR+"/log"):')
    (10, '\\tos.mkdir(WORKING_DIR+"/log")')
    (11, '')
    (12, '#put all config variable as variable in the snakefile')
    (13, 'for configVar in config:')
    (14, '\\tif isinstance(config[configVar], str): exec(configVar+"= \\\'"+config[configVar]+"\\\'")')
    (15, '\\telse: exec(configVar+"="+str(config[configVar]))')
    (16, '')
    (17, '')
    (18, '## test of the path provided in the config.json file')
    (19, 'if not os.path.exists(FASTQ_PATH):')
    (20, '\\tprint("The directory " + FASTQ_PATH + " doesn\\\'t exist. Check the field FASTQ_PATH into the config.json file.")')
    (21, '\\tsys.exit(0)')
    (22, 'else:')
    (23, '\\t## If the path ends by /, the / is suppressed')
    (24, '\\tif ( FASTQ_PATH[-1:] == "/" ):')
    (25, '\\t\\tFASTQ_PATH = FASTQ_PATH[:-1]')
    (26, '')
    (27, "INPUT_FASTQS = glob.glob(FASTQ_PATH+\\'/*.fastq.gz\\')")
    (28, '')
    (29, 'SAMPLESsplitted = [os.path.basename(f).split(".") for f in INPUT_FASTQS]')
    (30, 'SAMPLES=[]')
    (31, '')
    (32, '#remove .fastq.gz to get sample names')
    (33, 'for s in SAMPLESsplitted:')
    (34, '\\tSAMPLES.append(".".join(s[0:-2]))')
    (35, '')
    (36, 'if(OUTPUT_PATH[-1] == "/") : OUTPUT_PATH = OUTPUT_PATH[:-1]')
    (37, '')
    (38, '## suppress the .R1. and .R2. elements for paired-end fastq files for the alignement processus in SAMPLES')
    (39, 'if IS_PAIRED_END:')
    (40, '\\tSAMPLES = [itemR2 for itemR2 in SAMPLES if (PAIR_END_FILE_PATTERN+"2") not in itemR2]\\t')
    (41, '\\tSAMPLES = [itemR1.replace((PAIR_END_FILE_PATTERN+"1"),\\\'\\\') for itemR1 in SAMPLES]')
    (42, '')
    (43, '#OVERHANG calculation')
    (44, 'if READ_LENGTH<1:')
    (45, '\\twith os.popen("gunzip -c " + INPUT_FASTQS[0] + " | sed -n \\\'2p\\\'","r") as inputRead:')
    (46, '\\t\\tOVERHANG = len(inputRead.readline()) - 2')
    (47, 'else:')
    (48, '\\tOVERHANG = int(READ_LENGTH) - 1')
    (49, '')
    (50, '#forward/reverse adaptator accounting')
    (51, '#if no adptator removal ("FORWARD_ADAPTATOR" and "REVERSE_ADAPTATOR" == ""), input of STAR is directly "FASTQ_PATH"')
    (52, 'CUTADAPT_PARAMETER="" # -a forward -A reverse for pairedEnd or just -a forward for singleEnd')
    (53, '')
    (54, 'if FORWARD_ADAPTATOR == "" and  REVERSE_ADAPTATOR =="":')
    (55, '\\tSTAR_FASTQ_FOLDER = FASTQ_PATH')
    (56, '\\tUSE_CUTADAPT = False')
    (57, 'else:')
    (58, '\\tSTAR_FASTQ_FOLDER = OUTPUT_PATH + "/FASTQ_CUTADAPT"')
    (59, '\\tUSE_CUTADAPT = True')
    (60, '')
    (61, 'if IS_PAIRED_END:')
    (62, '\\tPAIR_SUFFIX = [PAIR_END_FILE_PATTERN+"1",PAIR_END_FILE_PATTERN+"2"]')
    (63, '\\tif USE_CUTADAPT: CUTADAPT_PARAMETER = "-a " + FORWARD_ADAPTATOR + " -A " + REVERSE_ADAPTATOR')
    (64, 'else:')
    (65, '\\tPAIR_SUFFIX = [""]')
    (66, '\\tif USE_CUTADAPT: CUTADAPT_PARAMETER = "-a " + FORWARD_ADAPTATOR')
    (67, '')
    (68, 'STAR_INDEX_DIR = os.path.dirname(FASTA_REFERENCE)+"/STAR_INDEX"')
    (69, '')
    (70, 'if IS_PAIRED_END:  print("Workflow set on paired end mode")')
    (71, 'else : print("Workflow set on single end mode")')
    (72, 'if USE_CUTADAPT: print("cutadapt will be used on fastq. To disable it, set FORWARD_ADAPTATOR and REVERSE_ADAPTATOR as an empty string in config file")')
    (73, '')
    (74, 'if os.path.isfile(OUTPUT_PATH+"/log/genomeIsLoaded"): os.remove(OUTPUT_PATH+"/log/genomeIsLoaded")')
    (75, '')
    (76, '#for multiple files, create batch of files')
    (77, '')
    (78, 'if STAR_ALIGN_MULTIPLE_FILE:')
    (79, '\\tbatchLim = MAX_SIZE_PER_MULTIPLE_ALIGN * 10**9')
    (80, '\\tbatchNum=1')
    (81, '\\tcurrentSize=0')
    (82, '\\tcurrentBatch="batch"+str(batchNum)')
    (83, '')
    (84, '\\tALIGN_BATCHES={currentBatch:[]}')
    (85, '')
    (86, '\\tfor sample in SAMPLES:')
    (87, '\\t\\tfor pair in PAIR_SUFFIX:')
    (88, '\\t\\t\\tcurrentSize+=os.path.getsize(FASTQ_PATH+"/"+sample+pair+".fastq.gz")')
    (89, '\\t\\tALIGN_BATCHES[currentBatch].append(sample)')
    (90, '\\t\\t#number of opened file in a process can not exess 1024, samtools split open all possible file in one process')
    (91, '\\t\\tif (currentSize > batchLim or len(ALIGN_BATCHES[currentBatch]) > 1000)  and sample != SAMPLES[len(SAMPLES)-1]:')
    (92, '\\t\\t\\tbatchNum+=1')
    (93, '\\t\\t\\tcurrentSize=0')
    (94, '\\t\\t\\tcurrentBatch="batch"+str(batchNum)')
    (95, '\\t\\t\\tALIGN_BATCHES[currentBatch]=[]')
    (96, '')
    (97, '##############')
    (98, 'rule all: ')
    (99, '\\tinput: OUTPUT_PATH+"/results/multiqc_report.html"')
    (100, '')
    (101, 'rule STAR_INDEX:')
    (102, '\\tinput:')
    (103, '\\t\\tgtf = GTF_REFERENCE,')
    (104, '\\t\\tfasta = FASTA_REFERENCE')
    (105, '\\toutput: directory(STAR_INDEX_DIR)')
    (106, '\\tparams:')
    (107, '\\t\\tcpu=STAR_GENOME_THREADS,')
    (108, '\\t\\tram=int(GENOME_INDEX_RAM),')
    (109, '\\tlog:')
    (110, '\\t\\tout=OUTPUT_PATH+"/log/STAR_INDEX.out",')
    (111, '\\t\\terr=OUTPUT_PATH+"/log/STAR_INDEX.err",')
    (112, '\\t\\tstarLog=OUTPUT_PATH+"/log/STAR_INDEX.Log.out"')
    (113, '\\tshell: """')
    (114, '\\tmkdir {output}')
    (115, '\\tSTAR --runThreadN {params.cpu} --runMode genomeGenerate --genomeDir {output} --genomeFastaFiles {input.fasta} \\\\\\\\')
    (116, '\\t--outFileNamePrefix {OUTPUT_PATH}/log/STAR_INDEX. \\\\\\\\')
    (117, '\\t--sjdbGTFfile {input.gtf} --sjdbOverhang {OVERHANG}  --limitGenomeGenerateRAM {params.ram} 1> {log.out} 2> {log.err}')
    (118, '\\t"""')
    (119, '')
    (120, 'rule CUTADAPT:')
    (121, '\\tinput: expand(FASTQ_PATH+"/{{sample}}{pair}.fastq.gz",pair=PAIR_SUFFIX)')
    (122, '\\toutput: expand(OUTPUT_PATH+"/FASTQ_CUTADAPT/{{sample}}{pair}.fastq.gz",pair=PAIR_SUFFIX)')
    (123, '\\tparams:')
    (124, '\\t\\tminLen = CUTADAPT_MIN_READ_LEN,')
    (125, '\\t\\tcpu = THREAD_PER_SAMPLE')
    (126, '\\tlog:')
    (127, '\\t\\terr=OUTPUT_PATH+"/log/CUTADAPT_{sample}.err"')
    (128, '\\tshell: """')
    (129, '\\tcutadapt {CUTADAPT_PARAMETER} -j {params.cpu} --minimum-length {params.minLen}  {input} 2> {log.err} | gzip -c > {output}')
    (130, '\\t"""\\t')
    (131, '')
    (132, 'rule FASTQC:')
    (133, '\\tinput: FASTQ_PATH+"/{sample}{pair}.fastq.gz"')
    (134, '\\toutput: multiext(OUTPUT_PATH+"/fastQC/{sample}{pair}_fastqc",".zip",".html")')
    (135, '\\tparams:')
    (136, '\\t\\toutpath=OUTPUT_PATH+"/fastQC",')
    (137, '\\t\\tcpu = 1')
    (138, '\\tlog:')
    (139, '\\t\\tout=OUTPUT_PATH+"/log/FASTQC_{sample}{pair}.out",')
    (140, '\\t\\terr=OUTPUT_PATH+"/log/FASTQC_{sample}{pair}.err"')
    (141, '\\tshell: """')
    (142, '\\tfastqc -o {params.outpath} {input} 1> {log.out} 2> {log.err}')
    (143, '\\t"""')
    (144, '')
    (145, 'if PRELOAD_GENOME:')
    (146, '\\tSTAR_LOAD_BEHAVIOR = "--genomeLoad LoadAndKeep"')
    (147, '\\tgenomeIsLoadedFile = temp(OUTPUT_PATH+"/log/genomeIsLoaded")')
    (148, '\\trule STAR_LOAD_GENOME:')
    (149, '\\t\\tinput: ')
    (150, '\\t\\t\\tstarIndexDir=STAR_INDEX_DIR')
    (151, '\\t\\toutput:')
    (152, '\\t\\t\\tOUTPUT_PATH+"/log/genomeIsLoaded"')
    (153, '\\t\\tlog:')
    (154, '\\t\\t\\tout=OUTPUT_PATH+"/log/STAR_LOAD_GENOME.out",')
    (155, '\\t\\t\\terr=OUTPUT_PATH+"/log/STAR_LOAD_GENOME.err",')
    (156, '\\t\\t\\tstarLog=OUTPUT_PATH+"/log/STAR_LOAD_GENOME.Log.out",')
    (157, '\\t\\t\\tstarProgressLog=OUTPUT_PATH+"/log/STAR_LOAD_GENOME.progress.out"')
    (158, '\\t\\tparams: cpu=STAR_GENOME_THREADS')
    (159, '\\t\\tshell: """')
    (160, '\\t\\tSTAR --genomeLoad Remove  --genomeDir {input.starIndexDir} --runThreadN {params.cpu} \\\\\\\\')
    (161, '\\t\\t--outFileNamePrefix {OUTPUT_PATH}/log/STAR_LOAD_GENOME. 1> {log.out} 2> {log.err}')
    (162, '\\t\\t')
    (163, '\\t\\tSTAR --genomeLoad LoadAndExit  --runThreadN {params.cpu}  \\\\\\\\')
    (164, '\\t\\t--genomeDir {input.starIndexDir} \\\\\\\\')
    (165, '\\t\\t--outFileNamePrefix {OUTPUT_PATH}/log/STAR_LOAD_GENOME.  1> {log.out} 2> {log.err}')
    (166, '\\t\\t')
    (167, '\\t\\ttouch {output}')
    (168, '\\t\\trm {OUTPUT_PATH}/log/STAR_LOAD_GENOME.Aligned.out.sam')
    (169, '\\t\\t"""')
    (170, 'else:')
    (171, '\\tSTAR_LOAD_BEHAVIOR=""')
    (172, '\\tgenomeIsLoadedFile=[]')
    (173, '')
    (174, 'if STAR_ALIGN_MULTIPLE_FILE:')
    (175, '')
    (176, '\\tdef getFASTQSofAlignBatch(wildcards): ')
    (177, '\\t\\treturn expand(STAR_FASTQ_FOLDER+"/{sample}{pair}.fastq.gz",\\\\')
    (178, '\\t\\tsample=ALIGN_BATCHES[wildcards.alignBatch],pair=PAIR_SUFFIX)')
    (179, '')
    (180, '\\trule BUILD_MANIFEST:')
    (181, '\\t\\tinput:')
    (182, '\\t\\t\\tgetFASTQSofAlignBatch')
    (183, '\\t\\toutput:')
    (184, '\\t\\t\\tOUTPUT_PATH+"/log/star_manifest_{alignBatch}.txt"')
    (185, '\\t\\trun:')
    (186, '\\t\\t\\twith open(str(output),"w") as writer:')
    (187, '\\t\\t\\t\\tfor sample in ALIGN_BATCHES[wildcards.alignBatch]:')
    (188, '\\t\\t\\t\\t\\tbase_name = STAR_FASTQ_FOLDER+"/"+sample')
    (189, '\\t\\t\\t\\t\\tif IS_PAIRED_END:')
    (190, '\\t\\t\\t\\t\\t\\twriter.write(base_name+PAIR_SUFFIX[0]+".fastq.gz\\\\t"+base_name+PAIR_SUFFIX[1]+".fastq.gz\\\\t"+sample+"\\')
    (191, '")')
    (192, '\\t\\t\\t\\t\\telse:')
    (193, '\\t\\t\\t\\t\\t\\twriter.write(base_name+".fastq.gz\\\\t-\\\\t"+sample+"\\')
    (194, '")')
    (195, '')
    (196, '\\trule STAR_ALIGN:')
    (197, '\\t\\tinput: ')
    (198, '\\t\\t\\tstarIndexDir=STAR_INDEX_DIR,')
    (199, '\\t\\t\\tmanifest=OUTPUT_PATH+"/log/star_manifest_{alignBatch}.txt"')
    (200, '\\t\\toutput:')
    (201, '\\t\\t\\ttemp(OUTPUT_PATH+"/log/STAR_ALIGN_{alignBatch}.Aligned.out.bam")')
    (202, '\\t\\tlog:')
    (203, '\\t\\t\\tout=OUTPUT_PATH+"/log/STAR_ALIGN_{alignBatch}.out",')
    (204, '\\t\\t\\terr=OUTPUT_PATH+"/log/STAR_ALIGN_{alignBatch}.err",')
    (205, '\\t\\t\\tstarLog=OUTPUT_PATH+"/log/STAR_ALIGN_{alignBatch}.Log.out",')
    (206, '\\t\\t\\tstarProgressLog=OUTPUT_PATH+"/log/STAR_ALIGN_{alignBatch}.progress.out"')
    (207, '\\t\\tparams: cpu = STAR_GENOME_THREADS')
    (208, '\\t\\tshell: """')
    (209, '\\t\\tSTAR --runThreadN {params.cpu} --genomeDir {input.starIndexDir} --readFilesCommand zcat \\\\\\\\')
    (210, '\\t\\t--readFilesManifest {input.manifest} --outSAMattributes NH HI AS nM RG \\\\\\\\')
    (211, '\\t\\t--outFileNamePrefix {OUTPUT_PATH}/log/STAR_ALIGN_{wildcards.alignBatch}. --outSAMtype BAM Unsorted \\\\\\\\')
    (212, '\\t\\t{STAR_LOAD_BEHAVIOR} 1> {log.out} 2> {log.err}')
    (213, '\\t\\t"""')
    (214, '')
    (215, '\\trule SPLIT_BAM:')
    (216, '\\t\\tinput: OUTPUT_PATH+"/log/STAR_ALIGN_{alignBatch}.Aligned.out.bam"')
    (217, '\\t\\toutput: touch(OUTPUT_PATH+"/log/{alignBatch}_splitIsDone"), ')
    (218, '\\t\\tparams: cpu = THREAD_PER_SAMPLE')
    (219, '\\t\\tshell: """\\t\\t\\t')
    (220, "\\t\\tsamtools split -f \\'{OUTPUT_PATH}/log/%!.bam\\' -@{params.cpu} {input}")
    (221, '\\t\\t"""')
    (222, '')
    (223, '\\trule FAKE_RULE_MULTIPLE_FILE:')
    (224, '\\t\\tinput: expand(OUTPUT_PATH+"/log/{alignBatch}_splitIsDone",alignBatch=ALIGN_BATCHES)')
    (225, '\\t\\toutput: expand(OUTPUT_PATH+"/BAM/{sample}.bam", sample=SAMPLES)')
    (226, '\\t\\trun:')
    (227, '\\t\\t\\tmissingFile=[]')
    (228, '\\t\\t\\tfor alignBatch in ALIGN_BATCHES:')
    (229, '\\t\\t\\t\\tmissingFileInBAM = False')
    (230, '')
    (231, '\\t\\t\\t\\tfor sample in ALIGN_BATCHES[alignBatch]:')
    (232, '\\t\\t\\t\\t\\tbamFile = OUTPUT_PATH+"/log/"+sample+".bam"')
    (233, '\\t\\t\\t\\t\\tif not os.path.exists(bamFile):')
    (234, '\\t\\t\\t\\t\\t\\tmissingFileInBAM=True')
    (235, '\\t\\t\\t\\t\\t\\tmissingFile.append(bamFile)')
    (236, '\\t\\t\\t\\t')
    (237, '\\t\\t\\t\\tif missingFileInBAM: os.remove(OUTPUT_PATH+"/log/"+alignBatch+"_splitIsDone")')
    (238, '\\t\\t\\t')
    (239, '\\t\\t\\tif len(missingFile)>0:')
    (240, '\\t\\t\\t\\texit("BAM splitting step is a failure, the following BAM are missing: "+ " ".join(missingFile))')
    (241, '\\t\\t\\t')
    (242, '\\t\\t\\t#no error')
    (243, '\\t\\t\\tfor sample in SAMPLES:')
    (244, '\\t\\t\\t\\tos.rename(OUTPUT_PATH+"/log/"+sample+".bam", OUTPUT_PATH+"/BAM/"+sample+".bam")')
    (245, '')
    (246, 'else:')
    (247, '\\trule STAR_ALIGN:')
    (248, '\\t\\tinput: ')
    (249, '\\t\\t\\tfastq=expand(STAR_FASTQ_FOLDER+"/{{sample}}{pair}.fastq.gz",pair=PAIR_SUFFIX),')
    (250, '\\t\\t\\tstarIndexDir=STAR_INDEX_DIR,')
    (251, '\\t\\t\\tgenomeIsLoaded=expand("{file}", file=genomeIsLoadedFile) #optional input')
    (252, '\\t\\toutput:')
    (253, '\\t\\t\\tOUTPUT_PATH+"/log/STAR_ALIGN_{sample}.Aligned.out.bam"')
    (254, '\\t\\tlog:')
    (255, '\\t\\t\\tout=OUTPUT_PATH+"/log/STAR_ALIGN_{sample}.out",')
    (256, '\\t\\t\\terr=OUTPUT_PATH+"/log/STAR_ALIGN_{sample}.err",')
    (257, '\\t\\t\\tstarLog=OUTPUT_PATH+"/log/STAR_ALIGN_{sample}.Log.out",')
    (258, '\\t\\t\\tstarProgressLog=OUTPUT_PATH+"/log/STAR_ALIGN_{sample}.progress.out"')
    (259, '\\t\\tparams: cpu = THREAD_PER_SAMPLE')
    (260, '\\t\\tshell: """')
    (261, '\\t\\t')
    (262, '\\t\\tSTAR --runThreadN {params.cpu} --genomeDir {input.starIndexDir} --readFilesCommand zcat --readFilesIn {input.fastq} \\\\\\\\')
    (263, '\\t\\t--outFileNamePrefix {OUTPUT_PATH}/log/STAR_ALIGN_{wildcards.sample}. --outSAMtype BAM Unsorted \\\\\\\\')
    (264, '\\t\\t{STAR_LOAD_BEHAVIOR} 1> {log.out} 2> {log.err}')
    (265, '')
    (266, '\\t\\t"""')
    (267, '\\t')
    (268, '\\trule MOVE_BAM:')
    (269, '\\t\\tinput: OUTPUT_PATH+"/log/STAR_ALIGN_{sample}.Aligned.out.bam"')
    (270, '\\t\\toutput: OUTPUT_PATH+"/BAM/{sample}.bam"')
    (271, '\\t\\tparams: cpu = 1')
    (272, '\\t\\tshell: """')
    (273, '\\t\\t\\tmv {input} {output}')
    (274, '\\t\\t"""')
    (275, '')
    (276, 'if PRELOAD_GENOME:')
    (277, '\\trule STAR_UNLOAD_GENOME:')
    (278, '\\t\\tinput:')
    (279, '\\t\\t\\tbams = expand(OUTPUT_PATH+"/BAM/{sample}.bam", sample=SAMPLES),')
    (280, '\\t\\t\\tgenomeIsLoaded = OUTPUT_PATH+"/log/genomeIsLoaded"')
    (281, '\\t\\tlog:')
    (282, '\\t\\t\\tout=OUTPUT_PATH+"/log/STAR_UNLOAD_GENOME.out",')
    (283, '\\t\\t\\terr=OUTPUT_PATH+"/log/STAR_UNLOAD_GENOME.err",')
    (284, '\\t\\t\\tstarLog=OUTPUT_PATH+"/log/STAR_UNLOAD_GENOME.Log.out",')
    (285, '\\t\\t\\tstarProgressLog=OUTPUT_PATH+"/log/STAR_UNLOAD_GENOME.progress.out"')
    (286, '\\t\\tparams: cpu=STAR_GENOME_THREADS')
    (287, '\\t\\tshell: """')
    (288, '\\t\\tSTAR --genomeLoad Remove  --runThreadN {params.cpu}  --genomeDir {input.starIndexDir} \\\\\\\\')
    (289, '\\t\\t--outFileNamePrefix {OUTPUT_PATH}/log/STAR_UNLOAD_GENOME.  1> {log.out} 2> {log.err}')
    (290, '\\t\\t"""')
    (291, '')
    (292, 'if DEDUP_UMI:')
    (293, '\\trule SORT_BAM:')
    (294, '\\t\\tinput: OUTPUT_PATH+"/BAM/{sample}.bam"')
    (295, '\\t\\toutput: temp(OUTPUT_PATH+"/SORTED_BAM/{sample}.bam")')
    (296, '\\t\\tparams: cpu = THREAD_PER_SAMPLE')
    (297, '\\t\\tshell: """')
    (298, '\\t\\tsamtools sort -@{params.cpu} -o {output} {input} ')
    (299, '\\t\\t"""')
    (300, '')
    (301, '\\trule INDEX_BAM:')
    (302, '\\t\\tinput: OUTPUT_PATH+"/SORTED_BAM/{sample}.bam"')
    (303, '\\t\\toutput: temp(OUTPUT_PATH+"/SORTED_BAM/{sample}.bam.bai")')
    (304, '\\t\\tparams: cpu = THREAD_PER_SAMPLE')
    (305, '\\t\\tshell: """')
    (306, '\\t\\tsamtools index -@{params.cpu} {input}')
    (307, '\\t\\t"""')
    (308, '')
    (309, '\\tBAM_ALIGN_FOLDER = "DEDUP_BAM"')
    (310, '\\trule DEDUP_UMI:')
    (311, '\\t\\tinput:')
    (312, '\\t\\t\\tbam=OUTPUT_PATH+"/SORTED_BAM/{sample}.bam",')
    (313, '\\t\\t\\tbai=OUTPUT_PATH+"/SORTED_BAM/{sample}.bam.bai"')
    (314, '\\t\\toutput: OUTPUT_PATH+"/DEDUP_BAM/{sample}.bam"')
    (315, '\\t\\tlog:')
    (316, '\\t\\t\\tout=OUTPUT_PATH+"/log/DEDUP_UMI_{sample}.out",')
    (317, '\\t\\t\\terr=OUTPUT_PATH+"/log/DEDUP_UMI_{sample}.err"')
    (318, '\\t\\tparams:')
    (319, '\\t\\t\\tpaired="--paired" if IS_PAIRED_END else "",')
    (320, '\\t\\t\\tcpu = THREAD_PER_SAMPLE')
    (321, '\\t\\tshell: """')
    (322, '\\t\\t\\tumi_tools dedup --no-sort-output --stdin={input.bam} k:{params.paired} --log={log.out}  --output-stats={OUTPUT_PATH}/log/DEDUP_UMI_{wildcards.sample} | samtools sort -n -@{params.cpu} -o {output} 2> {log.err}')
    (323, '\\t\\t"""')
    (324, '\\t')
    (325, 'else: BAM_ALIGN_FOLDER = "BAM"')
    (326, '\\t')
    (327, 'rule HTSEQ_COUNT:')
    (328, '\\tinput: OUTPUT_PATH+"/"+BAM_ALIGN_FOLDER+"/{sample}.bam"')
    (329, '\\toutput: OUTPUT_PATH+"/counts/{sample}.counts"')
    (330, '\\tparams:')
    (331, '\\t\\tgtf = GTF_REFERENCE,')
    (332, '\\t\\tfeatureID = FEATURE_ID,')
    (333, '\\t\\tfeatureType = FEATURE_TYPE,')
    (334, '\\t\\tcpu = 1')
    (335, '\\tlog: err=OUTPUT_PATH+"/log/HTSEQ_COUNT_{sample}.err"')
    (336, '\\tshell: """')
    (337, '\\thtseq-count -f bam -t {params.featureType} -i {params.featureID} -s no {input} {params.gtf} 1> {output} 2> {log.err}')
    (338, '\\t"""')
    (339, '\\t')
    (340, 'rule COUNTS_TABLE:')
    (341, '\\tinput: expand(OUTPUT_PATH+"/counts/{sample}.counts",sample=SAMPLES)')
    (342, '\\toutput:')
    (343, '\\t\\ttable = OUTPUT_PATH+"/results/rawCountsTable.tsv",')
    (344, '\\t\\tstat = OUTPUT_PATH+"/results/alignStatTable.tsv"')
    (345, '\\tparams: cpu = 1')
    (346, '\\tlog:')
    (347, '\\t\\tout=OUTPUT_PATH+"/log/COUNTS_TABLE.out",')
    (348, '\\t\\terr=OUTPUT_PATH+"/log/COUNTS_TABLE.err"')
    (349, '\\tshell: "Rscript {WORKING_DIR}/countsTable.R {OUTPUT_PATH}  1> {log.out} 2> {log.err}"')
    (350, '')
    (351, 'rule MULTIQC:')
    (352, '\\tinput:')
    (353, '\\t\\tfastqc=expand(OUTPUT_PATH+"/fastQC/{sample}{pair}_fastqc{ext}", sample=SAMPLES,pair=PAIR_SUFFIX,ext=[".zip",".html"]),')
    (354, '\\t\\ttable = OUTPUT_PATH+"/results/rawCountsTable.tsv",')
    (355, '\\t\\tstat = OUTPUT_PATH+"/results/alignStatTable.tsv",')
    (356, '\\toutput: OUTPUT_PATH+"/results/multiqc_report.html"')
    (357, '\\tparams:')
    (358, '\\t\\toutpath = OUTPUT_PATH + "/results",')
    (359, '\\t\\tcpu = 1')
    (360, '\\tshell: """')
    (361, '\\tmultiqc -f -e general_stats -e tophat -e bowtie2 {OUTPUT_PATH} -o {params.outpath}')
    (362, '\\t"""')
    (363, "'")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SherineAwad/ATAC-Seq, file=Snakefile
context_key: ["if config[\\'PAIRED\\']", 'rule trim', 'input']
    (21, "if config[\\'PAIRED\\']:")
    (22, '    rule trim: ')
    (23, '       input: ')
    (24, '          r1 = "{sample}.r_1.fq.gz",')
    (25, '          r2 = "{sample}.r_2.fq.gz"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SherineAwad/ATAC-Seq, file=Snakefile
context_key: ["if config[\\'PAIRED\\']", 'rule trim', 'output']
    (26, '       output: ')
    (27, '          val1 = "galore/{sample}.r_1_val_1.fq.gz",')
    (28, '          val2 = "galore/{sample}.r_2_val_2.fq.gz"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SherineAwad/ATAC-Seq, file=Snakefile
context_key: ["if config[\\'PAIRED\\']", 'rule trim', 'conda']
    (29, "       conda: \\'env/env-trim.yaml\\'")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SherineAwad/ATAC-Seq, file=Snakefile
context_key: ["if config[\\'PAIRED\\']", 'rule trim', 'log']
    (30, '       log: ')
    (31, '           "{sample}.trim.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SherineAwad/ATAC-Seq, file=Snakefile
context_key: ["if config[\\'PAIRED\\']", 'rule trim', 'shell']
    (32, '       shell: ')
    (33, '         """')
    (34, '         trim_galore --gzip --retain_unpaired --trim1 --fastqc --fastqc_args "--outdir fastqc" -o galore --paired {input.r1} {input.r2}')
    (35, '         """')
    (36, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SherineAwad/ATAC-Seq, file=Snakefile
context_key: ["if config[\\'PAIRED\\']", 'rule tosam', 'input']
    (37, '    rule tosam:')
    (38, '       input:')
    (39, '          r1 = "galore/{sample}.r_1_val_1.fq.gz",')
    (40, '          r2 = "galore/{sample}.r_2_val_2.fq.gz"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SherineAwad/ATAC-Seq, file=Snakefile
context_key: ["if config[\\'PAIRED\\']", 'rule tosam', 'params']
    (41, '       params:')
    (42, "          genome = config[\\'GENOME\\']")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SherineAwad/ATAC-Seq, file=Snakefile
context_key: ["if config[\\'PAIRED\\']", 'rule tosam', 'output']
    (43, '       output:')
    (44, '          "{sample}.sam"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SherineAwad/ATAC-Seq, file=Snakefile
context_key: ["if config[\\'PAIRED\\']", 'rule tosam', 'conda']
    (45, "       conda: \\'env/env-align.yaml\\'")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SherineAwad/ATAC-Seq, file=Snakefile
context_key: ["if config[\\'PAIRED\\']", 'rule tosam', 'log']
    (46, '       log: ')
    (47, '           "{sample}.sam.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SherineAwad/ATAC-Seq, file=Snakefile
context_key: ["if config[\\'PAIRED\\']", 'rule tosam', 'shell']
    (48, '       shell:')
    (49, '           "bowtie2 -x {params} -1 {input.r1} -2 {input.r2} -S {output}"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=dancooke/syntumorsizer, file=workflow/rules/octopus.smk
context_key: ['if config["sex"] == "male"']
    (1, '    if config["sex"] == "male":')
    (2, '        return ["X=1", "Y=1", "chrX=1", "chrY=1"]')
    (3, '    else:')
    (4, '        return ["X=2", "Y=0", "chrX=2", "chrY=0"]')
    (5, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlthafSinghawansaUHN/cfmedipseq_pipeline, file=Snakefile
context_key: ["if config[\\'data\\'][\\'cohorts\\'][c][\\'active\\']"]
    (582, "    if config[\\'data\\'][\\'cohorts\\'][c][\\'active\\']:")
    (583, "        chr_data = get_cohort_config(c)[\\'chromosomes\\']")
    (584, "        chromosome_tuples = [(species, chrom) for species in chr_data for chrom in chr_data[species].split(\\',\\')]")
    (585, '        chromosomes[c] = chromosome_tuples')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Triciasnow/HiFi-sv-snakemake, file=Snakefile
context_key: ["if config[\\'depth\\'] >= 30", 'rule Sniffles_call', 'input']
    (186, "if config[\\'depth\\'] >= 30:")
    (187, '    rule Sniffles_call:')
    (188, '        input:')
    (189, "            ref=expand(\\'{genome}.fa\\',genome=REF),")
    (190, "            pbmm2_bam=\\'{sample}-pbmm2.sort.bam\\',")
    (191, "            ngmlr_bam=\\'{sample}-NGMLR.sort.bam\\'")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Triciasnow/HiFi-sv-snakemake, file=Snakefile
context_key: ["if config[\\'depth\\'] >= 30", 'rule Sniffles_call', 'output']
    (192, '        output:')
    (193, "            pbmm2_MD=\\'{sample}-pbmm2.sort.MD.bam\\',")
    (194, "            vcf_ngmlr=\\'{sample}/Sniffles/{sample}-NGMLR.Sniffles.vcf\\',")
    (195, "            vcf_pbmm2=\\'{sample}/Sniffles/{sample}-pbmm2.Sniffles.vcf\\'")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Triciasnow/HiFi-sv-snakemake, file=Snakefile
context_key: ["if config[\\'depth\\'] >= 30", 'rule Sniffles_call', 'threads']
    (196, '        threads: 2')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Triciasnow/HiFi-sv-snakemake, file=Snakefile
context_key: ["if config[\\'depth\\'] >= 30", 'rule Sniffles_call', 'log']
    (197, '        log:')
    (198, "            log_ngmlr=\\'logs/{sample}-NGMLR.Sniffles.log.txt\\',")
    (199, "            log_pbmm2=\\'logs/{sample}-pbmm2.Sniffles.log.txt\\'")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Triciasnow/HiFi-sv-snakemake, file=Snakefile
context_key: ["if config[\\'depth\\'] >= 30", 'rule Sniffles_call', 'params']
    (200, '        params:')
    (201, "            para=int(int(config[\\'depth\\'])/10)")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Triciasnow/HiFi-sv-snakemake, file=Snakefile
context_key: ["if config[\\'depth\\'] >= 30", 'rule Sniffles_call', 'conda']
    (202, '        conda: "./evn/sniffles.yaml"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Triciasnow/HiFi-sv-snakemake, file=Snakefile
context_key: ["if config[\\'depth\\'] >= 30", 'rule Sniffles_call', 'shell']
    (203, '        shell:')
    (204, "            \\'samtools calmd -u {input.pbmm2_bam} {input.ref} > {output.pbmm2_MD}\\' \\\\")
    (205, "            \\'sniffles --skip_parameter_estimation -s {params.para} --ccs_reads -m {input.ngmlr_bam} -v {output.vcf_ngmlr} 2> {log.log_ngmlr}\\' \\\\")
    (206, "            \\'sniffles --skip_parameter_estimation -s {params.para} --ccs_reads -m {output.pbmm2_MD} -v {output.vcf_pbmm2} 2> {log.log_pbmm2}\\'")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=akcorut/SnakeRNASeq, file=Snakefile
context_key: ['if config["alignment"]["activate"]', 'if config["featurecounts"]["activate"]']
    (40, 'if config["alignment"]["activate"]:')
    (41, '    ')
    (42, '    STAR_PASS1= expand("/scratch/ac32082/02.PeanutRNASeq/01.analysis/peanut_rna_seq_analysis/results/04_alignment/04a_alignment_results/star/pass1/{smp}/Aligned.out.bam", smp=sample_id)')
    (43, '    STAR_PASS1_SJ= expand("/scratch/ac32082/02.PeanutRNASeq/01.analysis/peanut_rna_seq_analysis/results/04_alignment/04a_alignment_results/star/pass1/{smp}/SJ.out.tab", smp=sample_id)')
    (44, '    SPLICE_JUNC= expand("/scratch/ac32082/02.PeanutRNASeq/01.analysis/peanut_rna_seq_analysis/results/04_alignment/04a_alignment_results/star/junctions/SJ.filtered.tab")')
    (45, '    STAR_BAM= expand("/scratch/ac32082/02.PeanutRNASeq/01.analysis/peanut_rna_seq_analysis/results/04_alignment/04a_alignment_results/star/pass2/{smp}/Aligned.out.bam", smp=sample_id)')
    (46, '    STAR_TCP_BAM= expand("/scratch/ac32082/02.PeanutRNASeq/01.analysis/peanut_rna_seq_analysis/results/04_alignment/04a_alignment_results/star/pass2/{smp}/Aligned.toTranscriptome.out.bam", smp=sample_id)')
    (47, '    STAR_SORTED_BAM= expand("/scratch/ac32082/02.PeanutRNASeq/01.analysis/peanut_rna_seq_analysis/results/04_alignment/04a_alignment_results/star/pass2/{smp}/Aligned.sortedByCoord.out.bam", smp=sample_id)')
    (48, '    STAR_GENE_COUNT= expand("/scratch/ac32082/02.PeanutRNASeq/01.analysis/peanut_rna_seq_analysis/results/04_alignment/04a_alignment_results/star/pass2/{smp}/ReadsPerGene.out.tab", smp=sample_id)')
    (49, '    STAR_RSEQC= expand("/scratch/ac32082/02.PeanutRNASeq/01.analysis/peanut_rna_seq_analysis/results/04_alignment/04b_alignment_qc/rseqc/rseqc_multiqc_report.html")')
    (50, '    QUALIMAP_REPORT= expand("/scratch/ac32082/02.PeanutRNASeq/01.analysis/peanut_rna_seq_analysis/results/04_alignment/04b_alignment_qc/qualimap/{smp}/qualimapReport.html", smp=sample_id)')
    (51, '    QUALIMAP_MQC= expand("/scratch/ac32082/02.PeanutRNASeq/01.analysis/peanut_rna_seq_analysis/results/04_alignment/04b_alignment_qc/qualimap/qualimap_multiqc.html")')
    (52, '    ALL_TARGET.extend(STAR_PASS1)')
    (53, '    ALL_TARGET.extend(SPLICE_JUNC)')
    (54, '    ALL_TARGET.extend(STAR_BAM)')
    (55, '    ALL_TARGET.extend(STAR_TCP_BAM)')
    (56, '    ALL_TARGET.extend(STAR_SORTED_BAM)')
    (57, '    ALL_TARGET.extend(STAR_GENE_COUNT)')
    (58, '    ALL_TARGET.extend(STAR_RSEQC)')
    (59, '    ALL_TARGET.extend(QUALIMAP_REPORT)')
    (60, '    ALL_TARGET.extend(QUALIMAP_MQC)')
    (61, '        ')
    (62, '    if config["featurecounts"]["activate"]:')
    (63, '        FCOUNTS_RESULTS= expand("/scratch/ac32082/02.PeanutRNASeq/01.analysis/peanut_rna_seq_analysis/results/feature/featureCounts_results.txt")')
    (64, '        FCOUNTS_MQC= expand("/scratch/ac32082/02.PeanutRNASeq/01.analysis/peanut_rna_seq_analysis/results/feature/feature_multiqc.html")')
    (65, '        ALL_TARGET.extend(FCOUNTS_RESULTS)')
    (66, '        ALL_TARGET.extend(FCOUNTS_MQC)')
    (67, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=akcorut/SnakeRNASeq, file=Snakefile
context_key: ['if config["alignment"]["activate"]', 'if config["rsem"]["activate"]']
    (68, '    if config["rsem"]["activate"]:')
    (69, '        RSEM_INDEX= expand(config["rsem"]["rsemindex"] + ".n2g.idx.fa")')
    (70, '        RSEM_GENES= expand("/scratch/ac32082/02.PeanutRNASeq/01.analysis/peanut_rna_seq_analysis/results/05_quantification/05a_rsem/genes/{smp}.genes.results", smp=sample_id)')
    (71, '        RSEM_MQC= expand("/scratch/ac32082/02.PeanutRNASeq/01.analysis/peanut_rna_seq_analysis/results/05_quantification/05a_rsem/rsem_multiqc.html")')
    (72, '        ALL_TARGET.extend(RSEM_INDEX)')
    (73, '        ALL_TARGET.extend(RSEM_GENES)')
    (74, '        ALL_TARGET.extend(RSEM_MQC)')
    (75, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=akcorut/SnakeRNASeq, file=Snakefile
context_key: ['if config["alignment"]["activate"]', 'if config["htseq"]["activate"]']
    (76, '    if config["htseq"]["activate"]:')
    (77, '        HTSEQ_CNT= expand("/scratch/ac32082/02.PeanutRNASeq/01.analysis/peanut_rna_seq_analysis/results/05_quantification/05b_htseq/{smp}_htseq.cnt", smp=sample_id)')
    (78, '        HTSEQ_MQC= expand("/scratch/ac32082/02.PeanutRNASeq/01.analysis/peanut_rna_seq_analysis/results/05_quantification/05b_htseq/htseq_multiqc.html")')
    (79, '        ALL_TARGET.extend(HTSEQ_CNT)')
    (80, '        ALL_TARGET.extend(HTSEQ_MQC)')
    (81, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=akcorut/SnakeRNASeq, file=Snakefile
context_key: ['if config["alignment_free"]["activate"]', 'if config["salmon"]["activate"]', 'if config["salmon"]["mapping_mode"]']
    (82, 'if config["alignment_free"]["activate"]:')
    (83, '')
    (84, '    if config["salmon"]["activate"]:')
    (85, '')
    (86, '        if config["salmon"]["mapping_mode"]: ')
    (87, '            SALMON_QUASI= expand("/scratch/ac32082/02.PeanutRNASeq/01.analysis/peanut_rna_seq_analysis/results/06_alignment_free/06a_salmon/quant/{smp}", smp=sample_id)')
    (88, '            SALMON__QUASI_MQC= expand("/scratch/ac32082/02.PeanutRNASeq/01.analysis/peanut_rna_seq_analysis/results/06_alignment_free/06a_salmon/salmon_multiqc.html")')
    (89, '            ALL_TARGET.extend(SALMON_QUASI)')
    (90, '            ALL_TARGET.extend(SALMON__QUASI_MQC)')
    (91, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=akcorut/SnakeRNASeq, file=Snakefile
context_key: ['if config["alignment_free"]["activate"]', 'if config["salmon"]["activate"]', 'if config["salmon"]["alignment_mode"]']
    (92, '        if config["salmon"]["alignment_mode"]:')
    (93, '            SALMON_ALIGN= expand("/scratch/ac32082/02.PeanutRNASeq/01.analysis/peanut_rna_seq_analysis/results/salmon_align/quant/{smp}_salmon_quant_align", smp=sample_id)')
    (94, '            SALMON_ALIGN_MQC=  expand("/scratch/ac32082/02.PeanutRNASeq/01.analysis/peanut_rna_seq_analysis/results/salmon_align/salmon_align_multiqc.html")')
    (95, '            ALL_TARGET.extend(SALMON_ALIGN)')
    (96, '            ALL_TARGET.extend(SALMON_ALIGN_MQC)')
    (97, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=akcorut/SnakeRNASeq, file=Snakefile
context_key: ['if config["alignment_free"]["activate"]', 'if config["kallisto"]["activate"]']
    (98, '    if config["kallisto"]["activate"]:')
    (99, '        KALLISTO_QUANT= expand("/scratch/ac32082/02.PeanutRNASeq/01.analysis/peanut_rna_seq_analysis/results/06_alignment_free/06b_kallisto/quant/{smp}", smp=sample_id)')
    (100, '        KALLISTO_MQC= expand("/scratch/ac32082/02.PeanutRNASeq/01.analysis/peanut_rna_seq_analysis/results/06_alignment_free/06b_kallisto/kallisto_multiqc.html")')
    (101, '        ALL_TARGET.extend(KALLISTO_QUANT)')
    (102, '        ALL_TARGET.extend(KALLISTO_MQC)')
    (103, '')
    (104, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=akcorut/SnakeRNASeq, file=rules/06a_salmon.smk
context_key: ['if config["salmon"]["mapping_mode"]', 'rule salmon_quant_mapping', 'input']
    (34, 'if config["salmon"]["mapping_mode"]:')
    (35, '    rule salmon_quant_mapping:')
    (36, '        input:')
    (37, '            r1=GetClean(0),')
    (38, '            r2=GetClean(1),')
    (39, '            index = rules.salmon_index.output')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=akcorut/SnakeRNASeq, file=rules/06a_salmon.smk
context_key: ['if config["salmon"]["mapping_mode"]', 'rule salmon_quant_mapping', 'output']
    (40, '        output:')
    (41, '            directory("/scratch/ac32082/02.PeanutRNASeq/01.analysis/peanut_rna_seq_analysis/results/06_alignment_free/06a_salmon/quant/{smp}"),')
    (42, '            mappings="/scratch/ac32082/02.PeanutRNASeq/01.analysis/peanut_rna_seq_analysis/results/06_alignment_free/06a_salmon/mappings/{smp}_salmon_mappings"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=akcorut/SnakeRNASeq, file=rules/06a_salmon.smk
context_key: ['if config["salmon"]["mapping_mode"]', 'rule salmon_quant_mapping', 'log']
    (43, '        log:')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=akcorut/SnakeRNASeq, file=rules/06a_salmon.smk
context_key: ['if config["salmon"]["mapping_mode"]', 'conda']
    (44, '    \\t\\t"/scratch/ac32082/02.PeanutRNASeq/01.analysis/peanut_rna_seq_analysis/results/06_alignment_free/06a_salmon/logs/{smp}.salmon.log"')
    (45, '        conda:')
    (46, '            "../envs/salmon.yaml"')
    (47, '        threads:24')
    (48, '        shell:')
    (49, '            """')
    (50, '            salmon quant -i {input.index} -l A -1 {input.r1} -2 {input.r2} -o {output} --validateMappings --gcBias --seqBias --writeUnmappedNames --writeMappings={output.mappings} -p {threads} --numBootstraps 100')
    (51, '            """')
    (52, '    ')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=akcorut/SnakeRNASeq, file=rules/06a_salmon.smk
context_key: ['if config["salmon"]["mapping_mode"]', 'rule multiqc_salmon', 'input']
    (53, '    rule multiqc_salmon:')
    (54, '        input:')
    (55, '            expand(rules.salmon_quant_mapping.output, smp=sample_id)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=akcorut/SnakeRNASeq, file=rules/06a_salmon.smk
context_key: ['if config["salmon"]["mapping_mode"]', 'rule multiqc_salmon', 'output']
    (56, '        output:')
    (57, '            "/scratch/ac32082/02.PeanutRNASeq/01.analysis/peanut_rna_seq_analysis/results/06_alignment_free/06a_salmon/salmon_multiqc.html"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=akcorut/SnakeRNASeq, file=rules/06a_salmon.smk
context_key: ['if config["salmon"]["mapping_mode"]', 'rule multiqc_salmon', 'log']
    (58, '        log:')
    (59, '            "/scratch/ac32082/02.PeanutRNASeq/01.analysis/peanut_rna_seq_analysis/results/06_alignment_free/06a_salmon/logs/multiqc.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=akcorut/SnakeRNASeq, file=rules/06a_salmon.smk
context_key: ['if config["salmon"]["mapping_mode"]', 'rule multiqc_salmon', 'wrapper']
    (60, '        wrapper:')
    (61, '            "0.49.0/bio/multiqc"')
    (62, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=akcorut/SnakeRNASeq, file=rules/06a_salmon.smk
context_key: ['if config["salmon"]["alignment_mode"]', 'rule make_transcript', 'input']
    (63, 'if config["salmon"]["alignment_mode"]:')
    (64, '    rule make_transcript:')
    (65, '        input:')
    (66, '            ref= REFERENCE,')
    (67, '            gtf= rules.gff3_to_gtf.output.gtf')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=akcorut/SnakeRNASeq, file=rules/06a_salmon.smk
context_key: ['if config["salmon"]["alignment_mode"]', 'rule make_transcript', 'output']
    (68, '        output:')
    (69, '            "/scratch/ac32082/02.PeanutRNASeq/01.analysis/peanut_rna_seq_analysis/results/salmon_align/transcript/arahy_transcripts.fa"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=akcorut/SnakeRNASeq, file=rules/06a_salmon.smk
context_key: ['if config["salmon"]["alignment_mode"]', 'rule make_transcript', 'conda']
    (70, '        conda:')
    (71, '            "../envs/gffread.yaml"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=akcorut/SnakeRNASeq, file=rules/06a_salmon.smk
context_key: ['if config["salmon"]["alignment_mode"]', 'rule make_transcript', 'shell']
    (72, '        shell:')
    (73, "            \\'\\'\\'")
    (74, '            gffread -w {output} -g {input.ref} {input.gtf}')
    (75, "            \\'\\'\\'")
    (76, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=akcorut/SnakeRNASeq, file=rules/06a_salmon.smk
context_key: ['if config["salmon"]["alignment_mode"]', 'rule salmon_quant_alignment', 'input']
    (77, '    rule salmon_quant_alignment:')
    (78, '        input:')
    (79, '            bam= rules.star_pass2.output.tcp_bam,')
    (80, '            tcp = rules.make_transcript.output,')
    (81, '            gtf= rules.gff3_to_gtf.output.gtf,')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=akcorut/SnakeRNASeq, file=rules/06a_salmon.smk
context_key: ['if config["salmon"]["alignment_mode"]', 'rule salmon_quant_alignment', 'output']
    (82, '        output:')
    (83, '            directory("/scratch/ac32082/02.PeanutRNASeq/01.analysis/peanut_rna_seq_analysis/results/salmon_align/quant/{smp}_salmon_quant_align")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=akcorut/SnakeRNASeq, file=rules/06a_salmon.smk
context_key: ['if config["salmon"]["alignment_mode"]', 'rule salmon_quant_alignment', 'log']
    (84, '        log:')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=akcorut/SnakeRNASeq, file=rules/06a_salmon.smk
context_key: ['if config["salmon"]["alignment_mode"]', 'conda']
    (85, '    \\t\\t"/scratch/ac32082/02.PeanutRNASeq/01.analysis/peanut_rna_seq_analysis/results/salmon_align/logs/{smp}.salmon_align.log"')
    (86, '        conda:')
    (87, '            "../envs/salmon.yaml"')
    (88, '        threads:24')
    (89, '        priority:2')
    (90, '        shell:')
    (91, "            \\'\\'\\'")
    (92, '            salmon quant -t {input.tcp} -l A -a {input.bam} -o {output} --gcBias --seqBias --writeUnmappedNames -p {threads} -g {input.gtf} --numBootstraps 100')
    (93, "            \\'\\'\\'")
    (94, '')
    (95, '')
    (96, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=akcorut/SnakeRNASeq, file=rules/06a_salmon.smk
context_key: ['if config["salmon"]["alignment_mode"]', 'rule multiqc_salmon_align', 'input']
    (97, 'if config["salmon"]["alignment_mode"]:')
    (98, '    rule multiqc_salmon_align:')
    (99, '        input:')
    (100, '            expand(rules.salmon_quant_alignment.output, smp=sample_id)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=akcorut/SnakeRNASeq, file=rules/06a_salmon.smk
context_key: ['if config["salmon"]["alignment_mode"]', 'rule multiqc_salmon_align', 'output']
    (101, '        output:')
    (102, '            "/scratch/ac32082/02.PeanutRNASeq/01.analysis/peanut_rna_seq_analysis/results/salmon_align/salmon_align_multiqc.html"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=akcorut/SnakeRNASeq, file=rules/06a_salmon.smk
context_key: ['if config["salmon"]["alignment_mode"]', 'rule multiqc_salmon_align', 'log']
    (103, '        log:')
    (104, '            "/scratch/ac32082/02.PeanutRNASeq/01.analysis/peanut_rna_seq_analysis/results/salmon_align/logs/multiqc.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=akcorut/SnakeRNASeq, file=rules/06a_salmon.smk
context_key: ['if config["salmon"]["alignment_mode"]', 'rule multiqc_salmon_align', 'wrapper']
    (105, '        wrapper:')
    (106, '            "0.47.0/bio/multiqc"\'')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=greydongilmore/clinical_dicom2bids_smk, file=workflow/Snakefile
context_key: ["if config[\\'fmriprep\\'][\\'run\\']", "if not exists(join(config[\\'out_dir\\'], \\'derivatives\\', \\'fmriprep\\'))"]
    (34, "if config[\\'fmriprep\\'][\\'run\\']:")
    (35, "    include: \\'rules/fmriprep.smk\\'")
    (36, "    if not exists(join(config[\\'out_dir\\'], \\'derivatives\\', \\'fmriprep\\')):")
    (37, "       makedirs(join(config[\\'out_dir\\'], \\'derivatives\\', \\'fmriprep\\'))")
    (38, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=greydongilmore/clinical_dicom2bids_smk, file=workflow/Snakefile
context_key: ["if config[\\'fastsurfer\\'][\\'run\\']"]
    (41, "if config[\\'fastsurfer\\'][\\'run\\']:")
    (42, "    include: \\'rules/fastsurfer.smk\\'")
    (43, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=pburnham50/KallistoPipeline, file=workflow/Snakefile
context_key: ['if config["enrichment"]["goatools"]["activate"]']
    (15, '    if config["enrichment"]["goatools"]["activate"]:')
    (16, '        wanted_input.extend(')
    (17, '                expand(')
    (18, '                    [')
    (19, '                        "results/tables/go_terms/{model}.genes-mostsigtrans.diffexp.go_term_enrichment.gene_fdr_{gene_fdr}.go_term_fdr_{go_term_fdr}.tsv",')
    (20, '                        "results/plots/go_terms/{model}.genes-mostsigtrans.diffexp.go_term_enrichment_{go_ns}.gene_fdr_{gene_fdr}.go_term_fdr_{go_term_fdr}.pdf"')
    (21, '                    ],')
    (22, '                    model=config["diffexp"]["models"],')
    (23, '                    go_ns=["BP", "CC", "MF"],')
    (24, '                    gene_fdr=str(config["enrichment"]["goatools"]["fdr_genes"]).replace(\\\'.\\\',\\\'-\\\'),')
    (25, '                    go_term_fdr=str(config["enrichment"]["goatools"]["fdr_go_terms"]).replace(\\\'.\\\',\\\'-\\\')')
    (26, '                )')
    (27, '            )')
    (28, '')
    (29, "    # request fgsea if \\'activated\\' in config.yaml")
    (30, '    if config["enrichment"]["fgsea"]["activate"]:')
    (31, '        wanted_input.extend(')
    (32, '                expand(')
    (33, '                    [')
    (34, '                        "results/tables/fgsea/{model}.all-gene-sets.tsv",')
    (35, '                        "results/tables/fgsea/{model}.sig-gene-sets.tsv",')
    (36, '                        "results/plots/fgsea/{model}.table-plot.pdf",')
    (37, '                        "results/plots/fgsea/{model}"')
    (38, '                    ],')
    (39, '                    model=config["diffexp"]["models"],')
    (40, '                    gene_set_fdr=str(config["enrichment"]["fgsea"]["fdr_gene_set"]).replace(\\\'.\\\',\\\'-\\\'),')
    (41, '                    nperm=str(config["enrichment"]["fgsea"]["nperm"])')
    (42, '                )')
    (43, '            )')
    (44, '')
    (45, "    # request spia if \\'activated\\' in config.yaml")
    (46, '    if config["enrichment"]["spia"]["activate"]:')
    (47, '        wanted_input.extend(')
    (48, '                expand(')
    (49, '                    [ "results/tables/pathways/{model}.pathways.tsv" ],')
    (50, '                    model=config["diffexp"]["models"],')
    (51, '                )')
    (52, '            )')
    (53, '')
    (54, '    # workflow output that is always wanted')
    (55, '')
    (56, '    # general sleuth output')
    (57, '    wanted_input.extend(')
    (58, '            expand(')
    (59, '                [')
    (60, '                    "results/plots/mean-var/{model}.mean-variance-plot.pdf",')
    (61, '                    "results/plots/volcano/{model}.volcano-plots.pdf",')
    (62, '                    "results/plots/ma/{model}.ma-plots.pdf",')
    (63, '                    "results/plots/qq/{model}.qq-plots.pdf",')
    (64, '                    "results/tables/diffexp/{model}.transcripts.diffexp.tsv",')
    (65, '                    "results/plots/diffexp-heatmap/{model}.diffexp-heatmap.pdf",')
    (66, '                    "results/tables/tpm-matrix/{model}.tpm-matrix.tsv",')
    (67, '                ],')
    (68, '                model=config["diffexp"]["models"]')
    (69, '            )')
    (70, '        )')
    (71, '        ')
    (72, '    # ihw false discovery rate control')
    (73, '    wanted_input.extend(')
    (74, '            expand(')
    (75, '                [')
    (76, '                    "results/tables/ihw/{model}.{level}.ihw-results.tsv",')
    (77, '                    "results/plots/ihw/{level}/{model}.{level}.plot-dispersion.pdf",')
    (78, '                    "results/plots/ihw/{level}/{model}.{level}.plot-histograms.pdf",')
    (79, '                    "results/plots/ihw/{level}/{model}.{level}.plot-trends.pdf",')
    (80, '                    "results/plots/ihw/{level}/{model}.{level}.plot-decision.pdf",')
    (81, '                    "results/plots/ihw/{level}/{model}.{level}.plot-adj-pvals.pdf"')
    (82, '                ],')
    (83, '                model=config["diffexp"]["models"],')
    (84, '                level=["transcripts", "genes-aggregated", "genes-mostsigtrans"]')
    (85, '            )')
    (86, '        )')
    (87, '')
    (88, '    # sleuth p-value histogram plots')
    (89, '    wanted_input.extend(')
    (90, '            expand("results/plots/diffexp/{model}.{level}.diffexp-pval-hist.pdf",')
    (91, '                model=config["diffexp"]["models"],')
    (92, '                level=["transcripts", "genes-aggregated", "genes-mostsigtrans" ]')
    (93, '            )')
    (94, '        )')
    (95, '')
    (96, '    # technical variance vs. observed variance')
    (97, '    #wanted_input.extend(')
    (98, '    #        expand("results/plots/variance/{model}.transcripts.plot_vars.pdf", model=config["diffexp"]["models"]),')
    (99, '    #    )')
    (100, '')
    (101, '    # PCA plots of kallisto results, each coloured for a different covariate')
    (102, '    wanted_input.extend(')
    (103, '            expand([')
    (104, '                       "results/plots/pc-variance/{covariate}.pc-variance-plot.pdf",')
    (105, '                       "results/plots/loadings/{covariate}.loadings-plot.pdf",')
    (106, '                       "results/plots/pca/{covariate}.pca.pdf"')
    (107, '                   ],')
    (108, '                   covariate=samples.columns[samples.columns != "sample"])')
    (109, '        )')
    (110, '')
    (111, '    # group-density plot')
    (112, '    wanted_input.extend(')
    (113, '             expand(["results/plots/group_density/{model}.group_density.pdf"],')
    (114, '                 model=config["diffexp"]["models"])')
    (115, '        )')
    (116, '')
    (117, '    # scatter plots')
    (118, '    if config["scatter"]["activate"]:')
    (119, '        wanted_input.extend(')
    (120, '                  expand(["results/plots/scatter/{model}.scatter.pdf"],')
    (121, '                      model=config["diffexp"]["models"])')
    (122, '        )')
    (123, '')
    (124, '    # sleuth bootstrap plots')
    (125, '    wanted_input.extend(')
    (126, '            expand("results/plots/bootstrap/{model}",')
    (127, '                model=config["diffexp"]["models"]')
    (128, '            )')
    (129, '        )')
    (130, '')
    (131, '    # fragment length distribution plots')
    (132, '    wanted_input.extend(')
    (133, '            expand("results/plots/fld/{unit.sample}-{unit.unit}.fragment-length-dist.pdf",')
    (134, '                unit=units[["sample", "unit"]].itertuples()')
    (135, '            )')
    (136, '        )')
    (137, '')
    (138, '    return wanted_input')
    (139, '')
    (140, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/qc.py
context_key: ['if config["illumina_se"] is None and config["QC_Tests"] is True', 'rule fastqc_raw_pe', 'input']
    (2, 'if config["illumina_se"] is None and config["QC_Tests"] is True:')
    (3, '    rule fastqc_raw_pe:')
    (4, '        input:')
    (5, '            RAW_DIR + "{sample}_{pair}.fq.gz",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/qc.py
context_key: ['if config["illumina_se"] is None and config["QC_Tests"] is True', 'rule fastqc_raw_pe', 'output']
    (6, '        output:')
    (7, '            fastQC_raw + "{sample}.raw.{pair}.fastqc"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/qc.py
context_key: ['if config["illumina_se"] is None and config["QC_Tests"] is True', 'rule fastqc_raw_pe', 'shell']
    (8, '        shell:')
    (9, '            """')
    (10, '            fastqc --outdir {fastQC_raw} {input} > {output}')
    (11, '            """')
    (12, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/qc.py
context_key: ['elif config["illumina_pe"] is None and config["QC_Tests"] is True', 'rule fastqc_raw_se', 'input']
    (13, 'elif config["illumina_pe"] is None and config["QC_Tests"] is True:')
    (14, '    rule fastqc_raw_se:')
    (15, '        input:')
    (16, '            RAW_DIR + "{sample}.se.fq.gz"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/qc.py
context_key: ['elif config["illumina_pe"] is None and config["QC_Tests"] is True', 'rule fastqc_raw_se', 'output']
    (17, '        output:')
    (18, '            fastQC_raw + "{sample}.raw.fastqc"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/qc.py
context_key: ['elif config["illumina_pe"] is None and config["QC_Tests"] is True', 'rule fastqc_raw_se', 'shell']
    (19, '        shell:')
    (20, '            """')
    (21, '            fastqc --outdir {fastQC_raw} {input} > {output}')
    (22, '            """')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/qc.py
context_key: ['if config["illumina_se"] is None', 'rule qc_trimmomatic_pe']
    (32, 'if config["illumina_se"] is None:')
    (33, '    rule qc_trimmomatic_pe:')
    (34, '        """')
    (35, '        Run trimmomatic in paired end mode to eliminate Illumina adaptors and')
    (36, '        remove low quality regions and reads.')
    (37, '        Inputs _1 and _2 are piped through gzip/pigz.')
    (38, '        Outputs _1 and _2 are piped to gzip/pigz (level 9).')
    (39, '        Outputs _3 and _4 are compressed with the builtin compressor from')
    (40, '        Trimmomatic. Further on they are catted and compressed with gzip/pigz')
    (41, '        (level 9).')
    (42, '        Note: The cut -f 1 -d " " is to remove additional fields in the FASTQ')
    (43, '        header. It is done posterior to the trimming since the output comes')
    (44, '        slower than the input is read.')
    (45, '        Number of threads used:')
    (46, '            4 for trimmomatic')
    (47, '            2 for gzip inputs')
    (48, '            2 for gzip outputs')
    (49, '            Total: 8')
    (50, '        """')
    (51, '        input:')
    (52, '            forward = RAW_DIR + "{sample}_1.fq.gz",')
    (53, '            reverse = RAW_DIR + "{sample}_2.fq.gz"')
    (54, '        output:')
    (55, '            forward     = QC_DIR + "{sample}.final.1.fq.gz",')
    (56, '            reverse     = QC_DIR + "{sample}.final.2.fq.gz",')
    (57, '            unpaired_pe    = protected(QC_DIR + "{sample}.final.unpaired.fq.gz")')
    (58, '        params:')
    (59, '            unpaired_1  = QC_DIR + "{sample}_3.fq.gz",')
    (60, '            unpaired_2  = QC_DIR + "{sample}_4.fq.gz",')
    (61, '            adapter     = lambda wildcards: config["illumina_pe"][wildcards.sample]["adapter"],')
    (62, '            phred       = lambda wildcards: config["illumina_pe"][wildcards.sample]["phred"],')
    (63, '            trimmomatic_params = config["Read Trimming"]["trimmomatic_params"]')
    (64, '        log:')
    (65, '            QC_DOC + "trimmomatic_pe_{sample}.log"')
    (66, '        benchmark:')
    (67, '            QC_DOC + "trimmomatic_pe_{sample}.json"')
    (68, '        threads:')
    (69, "            24 # I\\'ve been able to work with pigz and 24 trimmomatic threads.")
    (70, '        shell:')
    (71, '            """')
    (72, '            trimmomatic PE \\\\')
    (73, '                -threads {threads} \\\\')
    (74, '                -{params.phred} \\\\')
    (75, '                {input.forward} {input.reverse} \\\\')
    (76, '                {output.forward} {params.unpaired_1} {output.reverse} {params.unpaired_2} \\\\')
    (77, '                ILLUMINACLIP:{params.adapter}:2:30:10 \\\\')
    (78, '                {params.trimmomatic_params} \\\\')
    (79, '                2> {log}')
    (80, '')
    (81, '                zcat {params.unpaired_1} {params.unpaired_2} |')
    (82, '                cut -f 1 -d " " |')
    (83, '                pigz -9 > {output.unpaired_pe}')
    (84, '')
    (85, '            rm {params.unpaired_1} {params.unpaired_2}')
    (86, '            """')
    (87, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/qc.py
context_key: ['elif config["illumina_pe"] is None', 'rule qc_trimmomatic_se']
    (88, 'elif config["illumina_pe"] is None:')
    (89, '    rule qc_trimmomatic_se:')
    (90, '        """')
    (91, '        Run trimmomatic in paired end mode to eliminate Illumina adaptors and')
    (92, '        remove low quality regions and reads.')
    (93, '        Inputs _1 and _2 are piped through gzip/pigz.')
    (94, '        Outputs _1 and _2 are piped to gzip/pigz (level 9).')
    (95, '        Outputs _3 and _4 are compressed with the builtin compressor from')
    (96, '        Trimmomatic. Further on they are catted and compressed with gzip/pigz')
    (97, '        (level 9).')
    (98, '        Note: The cut -f 1 -d " " is to remove additional fields in the FASTQ')
    (99, '        header. It is done posterior to the trimming since the output comes')
    (100, '        slower than the input is read.')
    (101, '        Number of threads used:')
    (102, '            4 for trimmomatic')
    (103, '            2 for gzip inputs')
    (104, '            2 for gzip outputs')
    (105, '            Total: 8')
    (106, '        """')
    (107, '        input:')
    (108, '            single = RAW_DIR + "{sample}.se.fq.gz"')
    (109, '        output:')
    (110, '            single\\t= QC_DIR + "{sample}.se.final.fq.gz"')
    (111, '        params:')
    (112, '            adapter\\t= lambda wildcards: config["illumina_se"][wildcards.sample]["adapter"],')
    (113, '            phred\\t= lambda wildcards: config["illumina_se"][wildcards.sample]["phred"],')
    (114, '            trimmomatic_params = config["Read Trimming"]["trimmomatic_params"]')
    (115, '        log:')
    (116, '            QC_DOC + "trimmomatic_se_{sample}.log"')
    (117, '        benchmark:')
    (118, '            QC_DOC + "trimmomatic_se_{sample}.json"')
    (119, '        threads:')
    (120, "            24 # I\\'ve been able to work with pigz and 24 trimmomatic threads.")
    (121, '        shell:')
    (122, '            """')
    (123, '            trimmomatic SE \\\\')
    (124, '            \\t-threads {threads} \\\\')
    (125, '            \\t-{params.phred} \\\\')
    (126, '            \\t{input.single} \\\\')
    (127, '            \\t{output.single} \\\\')
    (128, '            \\tILLUMINACLIP:{params.adapter}:2:30:10 \\\\')
    (129, '            \\t{params.trimmomatic_params} \\\\')
    (130, '            \\t2> {log}')
    (131, '            """')
    (132, '')
    (133, '')
    (134, '')
    (135, '############################################################################################################')
    (136, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/qc.py
context_key: ['if config["illumina_se"] is None and config["QC_Tests"] is True', 'rule fastqc_pe', 'input']
    (137, 'if config["illumina_se"] is None and config["QC_Tests"] is True:')
    (138, '    rule fastqc_pe:')
    (139, '        input:')
    (140, '            QC_DIR + "{sample}.final.{pair}.fq.gz"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/qc.py
context_key: ['if config["illumina_se"] is None and config["QC_Tests"] is True', 'rule fastqc_pe', 'output']
    (141, '        output:')
    (142, '            fastQC + "{sample}.{pair}"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/qc.py
context_key: ['if config["illumina_se"] is None and config["QC_Tests"] is True', 'rule fastqc_pe', 'shell']
    (143, '        shell:')
    (144, '            """')
    (145, '            fastqc --outdir {fastQC} {input} > {output}')
    (146, '            """')
    (147, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/qc.py
context_key: ['elif config["illumina_pe"] is None and config["QC_Tests"] is True', 'rule fastqc_se', 'input']
    (148, 'elif config["illumina_pe"] is None and config["QC_Tests"] is True:')
    (149, '    rule fastqc_se:')
    (150, '        input:')
    (151, '            QC_DIR + "{sample}.se.final.fq.gz"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/qc.py
context_key: ['elif config["illumina_pe"] is None and config["QC_Tests"] is True', 'rule fastqc_se', 'output']
    (152, '        output:')
    (153, '            fastQC + "{sample}.se"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/qc.py
context_key: ['elif config["illumina_pe"] is None and config["QC_Tests"] is True', 'rule fastqc_se', 'shell']
    (154, '        shell:')
    (155, '            """')
    (156, '            fastqc --outdir {fastQC} {input} > {output}')
    (157, '            """')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/qc.py
context_key: ['else', 'if config["illumina_se"] is None and config["Flash"] is True', 'rule flash_pe_reads', 'input']
    (163, 'if config["illumina_se"] is None and config["Flash"] is True:')
    (164, '    rule flash_pe_reads:')
    (165, '        input:')
    (166, '            forward = QC_DIR + "{sample}.final.1.fq.gz",')
    (167, '            reverse = QC_DIR + "{sample}.final.2.fq.gz"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/qc.py
context_key: ['else', 'if config["illumina_se"] is None and config["Flash"] is True', 'output']
    (168, '        output:')
    (169, '            name = FLASHED_READS + "{sample}.flashed",')
    (170, '            file_name = FLASHED_READS + "{sample}.flashed.extendedFrags.fastq.gz"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/qc.py
context_key: ['else', 'if config["illumina_se"] is None and config["Flash"] is True', 'params']
    (171, '        params:')
    (172, '            scripts_dir = config["scripts_dir"],')
    (173, '            flash_params = config["FLASH"]["FLASH_params"]')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/qc.py
context_key: ['else', 'if config["illumina_se"] is None and config["Flash"] is True', 'threads']
    (174, '        threads:')
    (175, '            4')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/qc.py
context_key: ['else', 'if config["illumina_se"] is None and config["Flash"] is True', 'shell']
    (176, '        shell:')
    (177, '            "flash {params.flash_params} {input.forward} {input.reverse} -o {output.name} -z"')
    (178, '            #"{params.scripts_dir}/flash_reads.sh {input.forward} {input.reverse} {output.name}"')
    (179, '            "> {output.name} "   ')
    (180, '')
    (181, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/qc.py
context_key: ['elif config["illumina_pe"] is None']
    (182, 'elif config["illumina_pe"] is None:')
    (183, '    pass')
    (184, '')
    (185, '')
    (186, '############################################################################################################')
    (187, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/qc.py
context_key: ['if config["illumina_se"] is None', 'rule qc_results_pe', 'input']
    (188, 'if config["illumina_se"] is None:')
    (189, '    rule qc_results_pe:')
    (190, "        \\'\\'\\'Generate only the resulting files, not the reports\\'\\'\\'")
    (191, '        input:')
    (192, '            pe_files = expand(')
    (193, '                [QC_DIR + "{sample}.final.{pair}.fq.gz", fastQC_raw + "{sample}.raw.{pair}.fastqc", FLASHED_READS + "{sample}.flashed.extendedFrags.fastq.gz", FLASHED_READS + "{sample}.flashed"],')
    (194, '                sample = SAMPLES_PE,')
    (195, '                pair = "1 2".split()')
    (196, '            )')
    (197, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/qc.py
context_key: ['elif config["illumina_pe"] is None', 'rule qc_results_se', 'input']
    (198, 'elif config["illumina_pe"] is None:')
    (199, '    rule qc_results_se:')
    (200, "        \\'\\'\\'Generate only the resulting files, not the reports\\'\\'\\'")
    (201, '        input:')
    (202, '            se_files = expand(')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/qc.py
context_key: ['if config["illumina_se"] is None and config["QC_Tests"] is True', 'rule raw_results_fastqc_pe', 'input']
    (211, 'if config["illumina_se"] is None and config["QC_Tests"] is True:')
    (212, '    rule raw_results_fastqc_pe:')
    (213, '        """Checkpoint to generate all the links for raw data"""')
    (214, '        input:')
    (215, '            expand(')
    (216, '                fastQC_raw + "{sample}.raw.{pair}.fastqc.{extension}", ')
    (217, '                sample = SAMPLES_PE,')
    (218, '                pair = "1 2".split(),')
    (219, '                extension = "zip html".split()')
    (220, '                )')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/qc.py
context_key: ['elif config["illumina_pe"] is None and config["QC_Tests"] is True', 'rule raw_results_fastqc_se', 'input']
    (221, 'elif config["illumina_pe"] is None and config["QC_Tests"] is True:')
    (222, '    rule raw_results_fastqc_se:')
    (223, '        """Checkpoint to generate all the links for raw data"""')
    (224, '        input:')
    (225, '            expand(')
    (226, '                fastQC_raw + "{sample}.raw.fastqc.{extension}",')
    (227, '                sample = SAMPLES_SE,')
    (228, '                extension = "zip html".split()')
    (229, "           )'")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/haplotype.py
context_key: ['elif config["Haplotyper"] is True and config["Validation"] is not None', 'rule haplotype_make_overlapping_vcf_link_pe', 'input']
    (19, 'elif config["Haplotyper"] is True and config["Validation"] is not None:')
    (20, '    rule haplotype_make_overlapping_vcf_link_pe:')
    (21, '        """')
    (22, '        Make symlinks to run rad_haplotyper')
    (23, '        """')
    (24, '        input:')
    (25, '            vcf = FINAL_VARIANTS + "Overlapping_SNPs.vcf"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/haplotype.py
context_key: ['elif config["Haplotyper"] is True and config["Validation"] is not None', 'rule haplotype_make_overlapping_vcf_link_pe', 'output']
    (26, '        output:')
    (27, '            vcf = HAPLOTYPE_DIR + "Overlapping_filtered_snps.recode.vcf"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/haplotype.py
context_key: ['elif config["Haplotyper"] is True and config["Validation"] is not None', 'rule haplotype_make_overlapping_vcf_link_pe', 'threads']
    (28, '        threads:')
    (29, '            1')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/haplotype.py
context_key: ['elif config["Haplotyper"] is True and config["Validation"] is not None', 'rule haplotype_make_overlapping_vcf_link_pe', 'log']
    (30, '        log:')
    (31, '            HAPLOTYPE_DOC + "make_vcf_link.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/haplotype.py
context_key: ['elif config["Haplotyper"] is True and config["Validation"] is not None', 'rule haplotype_make_overlapping_vcf_link_pe', 'benchmark']
    (32, '        benchmark:')
    (33, '            HAPLOTYPE_DOC + "make_vcf_link.json"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/haplotype.py
context_key: ['elif config["Haplotyper"] is True and config["Validation"] is not None', 'rule haplotype_make_overlapping_vcf_link_pe', 'shell']
    (34, '        shell:')
    (35, '            "ln -s $(readlink -f {input.vcf}) {output.vcf} 2> {log} "')
    (36, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/haplotype.py
context_key: ['else', 'if config["Haplotyper"] is True and config["Validation"] is None', 'rule haplotype_make_bam_links_pe', 'input']
    (42, 'if config["Haplotyper"] is True and config["Validation"] is None:')
    (43, '    rule haplotype_make_bam_links_pe:')
    (44, '        """')
    (45, '        Make symlinks to run rad_haplotyper')
    (46, '        """')
    (47, '        input:')
    (48, '            vcf = HAPLOTYPE_DIR + "filtered_snps.recode.vcf",')
    (49, '            bam = MAP_DIR + "{sample}.sorted.bam",')
    (50, '            bai = MAP_DIR + "{sample}.sorted.bam.bai"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/haplotype.py
context_key: ['else', 'if config["Haplotyper"] is True and config["Validation"] is None', 'output']
    (51, '        output:')
    (52, '            bam = HAPLOTYPE_DIR + "{sample}.bam",')
    (53, '            bai = HAPLOTYPE_DIR + "{sample}.bam.bai"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/haplotype.py
context_key: ['else', 'if config["Haplotyper"] is True and config["Validation"] is None', 'threads']
    (54, '        threads:')
    (55, '            1')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/haplotype.py
context_key: ['else', 'if config["Haplotyper"] is True and config["Validation"] is None', 'log']
    (56, '        log:')
    (57, '            HAPLOTYPE_DOC + "make_bam_links.{sample}.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/haplotype.py
context_key: ['else', 'if config["Haplotyper"] is True and config["Validation"] is None', 'benchmark']
    (58, '        benchmark:')
    (59, '            HAPLOTYPE_DOC + "make_bam_links.{sample}.json"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/haplotype.py
context_key: ['else', 'if config["Haplotyper"] is True and config["Validation"] is None', 'shell']
    (60, '        shell:')
    (61, '            "ln -s $(readlink -f {input.bam}) {output.bam} 2> {log}; "')
    (62, '            "ln -s $(readlink -f {input.bai}) {output.bai} 2> {log}; "')
    (63, '')
    (64, '')
    (65, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/haplotype.py
context_key: ['else', 'if config["illumina_se"] is None and config["Haplotyper"] is True and config["Validation"] is None', 'rule haplotype_make_popmap_pe', 'input']
    (94, 'if config["illumina_se"] is None and config["Haplotyper"] is True and config["Validation"] is None:')
    (95, '    rule haplotype_make_popmap_pe:')
    (96, '        """')
    (97, '        Make popmap to run rad_haplotyper')
    (98, '        """')
    (99, '        input:')
    (100, '            vcf = HAPLOTYPE_DIR + "filtered_snps.recode.vcf",')
    (101, '            bam = expand(HAPLOTYPE_DIR + "{sample}.bam",')
    (102, '                         sample = SAMPLES_PE)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/haplotype.py
context_key: ['else', 'if config["illumina_se"] is None and config["Haplotyper"] is True and config["Validation"] is None', 'output']
    (103, '        output:')
    (104, '            popmap = HAPLOTYPE_DIR + "popmap"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/haplotype.py
context_key: ['else', 'if config["illumina_se"] is None and config["Haplotyper"] is True and config["Validation"] is None', 'threads']
    (105, '        threads:')
    (106, '            1')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/haplotype.py
context_key: ['else', 'if config["illumina_se"] is None and config["Haplotyper"] is True and config["Validation"] is None', 'params']
    (107, '        params:')
    (108, '            hap_dir = HAPLOTYPE_DIR')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/haplotype.py
context_key: ['else', 'if config["illumina_se"] is None and config["Haplotyper"] is True and config["Validation"] is None', 'log']
    (109, '        log:')
    (110, '            HAPLOTYPE_DOC + "make_popmap.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/haplotype.py
context_key: ['else', 'if config["illumina_se"] is None and config["Haplotyper"] is True and config["Validation"] is None', 'benchmark']
    (111, '        benchmark:')
    (112, '            HAPLOTYPE_DOC + "make_popmap.json"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/haplotype.py
context_key: ['else', 'if config["illumina_se"] is None and config["Haplotyper"] is True and config["Validation"] is None', 'shell']
    (113, '        shell:')
    (114, '            "ls {params.hap_dir}/*.bam | sed \\\'s/.bam//\\\' | awk \\\'{{print $1, 1}}\\\' > {output.popmap} "')
    (115, '')
    (116, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/haplotype.py
context_key: ['elif config["illumina_pe"] is None and config["Haplotyper"] is True and config["Validation"] is None', 'rule haplotype_make_popmap_se', 'input']
    (117, 'elif config["illumina_pe"] is None and config["Haplotyper"] is True and config["Validation"] is None:')
    (118, '    rule haplotype_make_popmap_se:')
    (119, '        """')
    (120, '        Make popmap to run rad_haplotyper')
    (121, '        """')
    (122, '        input:')
    (123, '            vcf = HAPLOTYPE_DIR + "filtered_snps.recode.vcf",')
    (124, '            bam = expand(HAPLOTYPE_DIR + "{sample}.bam",')
    (125, '                         sample = SAMPLES_SE)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/haplotype.py
context_key: ['elif config["illumina_pe"] is None and config["Haplotyper"] is True and config["Validation"] is None', 'rule haplotype_make_popmap_se', 'output']
    (126, '        output:')
    (127, '            popmap = HAPLOTYPE_DIR + "popmap"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/haplotype.py
context_key: ['elif config["illumina_pe"] is None and config["Haplotyper"] is True and config["Validation"] is None', 'rule haplotype_make_popmap_se', 'threads']
    (128, '        threads:')
    (129, '            1')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/haplotype.py
context_key: ['elif config["illumina_pe"] is None and config["Haplotyper"] is True and config["Validation"] is None', 'rule haplotype_make_popmap_se', 'params']
    (130, '        params:')
    (131, '            hap_dir = HAPLOTYPE_DIR')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/haplotype.py
context_key: ['elif config["illumina_pe"] is None and config["Haplotyper"] is True and config["Validation"] is None', 'rule haplotype_make_popmap_se', 'log']
    (132, '        log:')
    (133, '            HAPLOTYPE_DOC + "make_popmap.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/haplotype.py
context_key: ['elif config["illumina_pe"] is None and config["Haplotyper"] is True and config["Validation"] is None', 'rule haplotype_make_popmap_se', 'benchmark']
    (134, '        benchmark:')
    (135, '            HAPLOTYPE_DOC + "make_popmap.json"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/haplotype.py
context_key: ['elif config["illumina_pe"] is None and config["Haplotyper"] is True and config["Validation"] is None', 'rule haplotype_make_popmap_se', 'shell']
    (136, '        shell:')
    (137, '            "ls {params.hap_dir}/*.bam | sed \\\'s/.bam//\\\' | awk \\\'{{print $1, 1}}\\\' > {output.popmap} "')
    (138, '')
    (139, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/haplotype.py
context_key: ['elif config["illumina_se"] is None and config["Haplotyper"] is True and config["Validation"] is not None', 'rule haplotype_make_popmap_overlapping_SNPs_pe', 'input']
    (140, 'elif config["illumina_se"] is None and config["Haplotyper"] is True and config["Validation"] is not None:')
    (141, '    rule haplotype_make_popmap_overlapping_SNPs_pe:')
    (142, '        """')
    (143, '        Make popmap to run rad_haplotyper')
    (144, '        """')
    (145, '        input:')
    (146, '            vcf = HAPLOTYPE_DIR + "Overlapping_filtered_snps.recode.vcf",')
    (147, '            bam = expand(HAPLOTYPE_DIR + "{sample}.bam",')
    (148, '                         sample = SAMPLES_PE)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/haplotype.py
context_key: ['elif config["illumina_se"] is None and config["Haplotyper"] is True and config["Validation"] is not None', 'rule haplotype_make_popmap_overlapping_SNPs_pe', 'output']
    (149, '        output:')
    (150, '            popmap = HAPLOTYPE_DIR + "popmap"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/haplotype.py
context_key: ['elif config["illumina_se"] is None and config["Haplotyper"] is True and config["Validation"] is not None', 'rule haplotype_make_popmap_overlapping_SNPs_pe', 'threads']
    (151, '        threads:')
    (152, '            1')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/haplotype.py
context_key: ['elif config["illumina_se"] is None and config["Haplotyper"] is True and config["Validation"] is not None', 'rule haplotype_make_popmap_overlapping_SNPs_pe', 'params']
    (153, '        params:')
    (154, '            hap_dir = HAPLOTYPE_DIR')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/haplotype.py
context_key: ['elif config["illumina_se"] is None and config["Haplotyper"] is True and config["Validation"] is not None', 'rule haplotype_make_popmap_overlapping_SNPs_pe', 'log']
    (155, '        log:')
    (156, '            HAPLOTYPE_DOC + "make_popmap.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/haplotype.py
context_key: ['elif config["illumina_se"] is None and config["Haplotyper"] is True and config["Validation"] is not None', 'rule haplotype_make_popmap_overlapping_SNPs_pe', 'benchmark']
    (157, '        benchmark:')
    (158, '            HAPLOTYPE_DOC + "make_popmap.json"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/haplotype.py
context_key: ['elif config["illumina_se"] is None and config["Haplotyper"] is True and config["Validation"] is not None', 'rule haplotype_make_popmap_overlapping_SNPs_pe', 'shell']
    (159, '        shell:')
    (160, '            "ls {params.hap_dir}/*.bam | sed \\\'s/.bam//\\\' | awk \\\'{{print $1, 1}}\\\' > {output.popmap} "')
    (161, '')
    (162, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/haplotype.py
context_key: ['elif config["illumina_pe"] is None and config["Haplotyper"] is True and config["Validation"] is not None', 'rule haplotype_make_popmap_overlapping_SNPs_se', 'input']
    (163, 'elif config["illumina_pe"] is None and config["Haplotyper"] is True and config["Validation"] is not None:')
    (164, '    rule haplotype_make_popmap_overlapping_SNPs_se:')
    (165, '        """')
    (166, '        Make popmap to run rad_haplotyper')
    (167, '        """')
    (168, '        input:')
    (169, '            vcf = HAPLOTYPE_DIR + "Overlapping_filtered_snps.recode.vcf",')
    (170, '            bam = expand(HAPLOTYPE_DIR + "{sample}.bam",')
    (171, '                         sample = SAMPLES_SE)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/haplotype.py
context_key: ['elif config["illumina_pe"] is None and config["Haplotyper"] is True and config["Validation"] is not None', 'rule haplotype_make_popmap_overlapping_SNPs_se', 'output']
    (172, '        output:')
    (173, '            popmap = HAPLOTYPE_DIR + "popmap"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/haplotype.py
context_key: ['elif config["illumina_pe"] is None and config["Haplotyper"] is True and config["Validation"] is not None', 'rule haplotype_make_popmap_overlapping_SNPs_se', 'threads']
    (174, '        threads:')
    (175, '            1')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/haplotype.py
context_key: ['elif config["illumina_pe"] is None and config["Haplotyper"] is True and config["Validation"] is not None', 'rule haplotype_make_popmap_overlapping_SNPs_se', 'params']
    (176, '        params:')
    (177, '            hap_dir = HAPLOTYPE_DIR')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/haplotype.py
context_key: ['elif config["illumina_pe"] is None and config["Haplotyper"] is True and config["Validation"] is not None', 'rule haplotype_make_popmap_overlapping_SNPs_se', 'log']
    (178, '        log:')
    (179, '            HAPLOTYPE_DOC + "make_popmap.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/haplotype.py
context_key: ['elif config["illumina_pe"] is None and config["Haplotyper"] is True and config["Validation"] is not None', 'rule haplotype_make_popmap_overlapping_SNPs_se', 'benchmark']
    (180, '        benchmark:')
    (181, '            HAPLOTYPE_DOC + "make_popmap.json"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/haplotype.py
context_key: ['elif config["illumina_pe"] is None and config["Haplotyper"] is True and config["Validation"] is not None', 'rule haplotype_make_popmap_overlapping_SNPs_se', 'shell']
    (182, '        shell:')
    (183, '            "ls {params.hap_dir}/*.bam | sed \\\'s/.bam//\\\' | awk \\\'{{print $1, 1}}\\\' > {output.popmap} "')
    (184, '')
    (185, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/variant_calling.py
context_key: ['if config["illumina_se"] is None and config["Flash"] is False', 'rule variant_call_subset_bam_pe', 'input']
    (47, 'if config["illumina_se"] is None and config["Flash"] is False:')
    (48, '    rule variant_call_subset_bam_pe:')
    (49, '        """')
    (50, '        Generate a BAM file for each of the genome partitions')
    (51, '        """')
    (52, '        input:')
    (53, '            bam = MAP_DIR + "merged_properly_paired.bam",')
    (54, '            bai = MAP_DIR + "merged_properly_paired.bam.bai",')
    (55, '            bed = VARIANT_CALL_DIR + "genome.{index}.bed"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/variant_calling.py
context_key: ['if config["illumina_se"] is None and config["Flash"] is False', 'rule variant_call_subset_bam_pe', 'output']
    (56, '        output:')
    (57, '            bam = VARIANT_CALL_DIR + "merged.{index}.bam",')
    (58, '            bai = VARIANT_CALL_DIR + "merged.{index}.bam.bai"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/variant_calling.py
context_key: ['if config["illumina_se"] is None and config["Flash"] is False', 'rule variant_call_subset_bam_pe', 'params']
    (59, '        params:')
    (60, '            scripts_dir = config["scripts_dir"]')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/variant_calling.py
context_key: ['if config["illumina_se"] is None and config["Flash"] is False', 'rule variant_call_subset_bam_pe', 'threads']
    (61, '        threads:')
    (62, '            2')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/variant_calling.py
context_key: ['if config["illumina_se"] is None and config["Flash"] is False', 'rule variant_call_subset_bam_pe', 'log']
    (63, '        log:')
    (64, '            VARIANT_CALL_DOC + "variant_call_make_bam.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/variant_calling.py
context_key: ['if config["illumina_se"] is None and config["Flash"] is False', 'rule variant_call_subset_bam_pe', 'benchmark']
    (65, '        benchmark:')
    (66, '            VARIANT_CALL_DOC + "variant_call_make_bam.json"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/variant_calling.py
context_key: ['if config["illumina_se"] is None and config["Flash"] is False', 'rule variant_call_subset_bam_pe', 'shell']
    (67, '        shell:')
    (68, '            "samtools view -L {input.bed} -b {input.bam} "')
    (69, '            "> {output.bam} "')
    (70, '            "2> {log} && "')
    (71, '            "samtools index {output.bam}"')
    (72, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/variant_calling.py
context_key: ['elif config["illumina_se"] is None and config["Flash"] is True', 'rule variant_call_flashed_bam_pe', 'input']
    (73, 'elif config["illumina_se"] is None and config["Flash"] is True:')
    (74, '    rule variant_call_flashed_bam_pe:')
    (75, '        """')
    (76, '        Generate a BAM file for each of the genome partitions')
    (77, '        """')
    (78, '        input:')
    (79, '            bam = MAP_DIR + "merged.bam",')
    (80, '            bai = MAP_DIR + "merged.bam.bai",')
    (81, '            bed = VARIANT_CALL_DIR + "genome.{index}.bed"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/variant_calling.py
context_key: ['elif config["illumina_se"] is None and config["Flash"] is True', 'rule variant_call_flashed_bam_pe', 'output']
    (82, '        output:')
    (83, '            bam = VARIANT_CALL_DIR + "merged.{index}.bam",')
    (84, '            bai = VARIANT_CALL_DIR + "merged.{index}.bam.bai"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/variant_calling.py
context_key: ['elif config["illumina_se"] is None and config["Flash"] is True', 'rule variant_call_flashed_bam_pe', 'params']
    (85, '        params:')
    (86, '            scripts_dir = config["scripts_dir"]')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/variant_calling.py
context_key: ['elif config["illumina_se"] is None and config["Flash"] is True', 'rule variant_call_flashed_bam_pe', 'threads']
    (87, '        threads:')
    (88, '            2')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/variant_calling.py
context_key: ['elif config["illumina_se"] is None and config["Flash"] is True', 'rule variant_call_flashed_bam_pe', 'log']
    (89, '        log:')
    (90, '            VARIANT_CALL_DOC + "variant_call_make_bam.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/variant_calling.py
context_key: ['elif config["illumina_se"] is None and config["Flash"] is True', 'rule variant_call_flashed_bam_pe', 'benchmark']
    (91, '        benchmark:')
    (92, '            VARIANT_CALL_DOC + "variant_call_make_bam.json"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/variant_calling.py
context_key: ['elif config["illumina_se"] is None and config["Flash"] is True', 'rule variant_call_flashed_bam_pe', 'shell']
    (93, '        shell:')
    (94, '            "samtools view -L {input.bed} -b {input.bam} "')
    (95, '            "> {output.bam} "')
    (96, '            "2> {log} && "')
    (97, '            "samtools index {output.bam}"')
    (98, '')
    (99, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/variant_calling.py
context_key: ['elif config["illumina_pe"] is None', 'rule variant_call_subset_bam_se', 'input']
    (100, 'elif config["illumina_pe"] is None:')
    (101, '    rule variant_call_subset_bam_se:')
    (102, '        """')
    (103, '        Generate a BAM file for each of the genome partitions')
    (104, '        """')
    (105, '        input:')
    (106, '            bam = MAP_DIR + "merged.bam",')
    (107, '            bai = MAP_DIR + "merged.bam.bai",')
    (108, '            bed = VARIANT_CALL_DIR + "genome.{index}.bed"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/variant_calling.py
context_key: ['elif config["illumina_pe"] is None', 'rule variant_call_subset_bam_se', 'output']
    (109, '        output:')
    (110, '            bam = VARIANT_CALL_DIR + "merged.{index}.bam",')
    (111, '            bai = VARIANT_CALL_DIR + "merged.{index}.bam.bai"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/variant_calling.py
context_key: ['elif config["illumina_pe"] is None', 'rule variant_call_subset_bam_se', 'params']
    (112, '        params:')
    (113, '            scripts_dir = config["scripts_dir"]')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/variant_calling.py
context_key: ['elif config["illumina_pe"] is None', 'rule variant_call_subset_bam_se', 'threads']
    (114, '        threads:')
    (115, '            2')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/variant_calling.py
context_key: ['elif config["illumina_pe"] is None', 'rule variant_call_subset_bam_se', 'log']
    (116, '        log:')
    (117, '            VARIANT_CALL_DOC + "variant_call_make_bam.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/variant_calling.py
context_key: ['elif config["illumina_pe"] is None', 'rule variant_call_subset_bam_se', 'benchmark']
    (118, '        benchmark:')
    (119, '            VARIANT_CALL_DOC + "variant_call_make_bam.json"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/variant_calling.py
context_key: ['elif config["illumina_pe"] is None', 'rule variant_call_subset_bam_se', 'shell']
    (120, '        shell:')
    (121, '            "samtools view -L {input.bed} -b {input.bam} "')
    (122, '            "> {output.bam} "')
    (123, '            "2> {log} && "')
    (124, '            "samtools index {output.bam}"')
    (125, '')
    (126, '#########################################################################################################')
    (127, '')
    (128, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/variant_calling.py
context_key: ['if config["illumina_se"] is None and config["Validation"] is not None', 'rule variant_validation_vcf', 'input']
    (252, 'if config["illumina_se"] is None and config["Validation"] is not None:')
    (253, '    rule variant_validation_vcf:')
    (254, '        """')
    (255, '        Use a previous variant dataset to compare, extract and store common high-value SNPs between the two datasets')
    (256, '        """')
    (257, '        input:')
    (258, '            FILTERED_VARIANTS = FINAL_VARIANTS + "filtered_snps.recode.vcf",')
    (259, '            INPUT_VCF_FILE = config["Validation"]')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/variant_calling.py
context_key: ['if config["illumina_se"] is None and config["Validation"] is not None', 'rule variant_validation_vcf', 'output']
    (260, '        output:')
    (261, '            FINAL_VARIANTS + "Overlapping_SNPs"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/variant_calling.py
context_key: ['if config["illumina_se"] is None and config["Validation"] is not None', 'rule variant_validation_vcf', 'log']
    (262, '        log:')
    (263, '            VARIANT_CALL_DOC + "variant_validation.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/variant_calling.py
context_key: ['if config["illumina_se"] is None and config["Validation"] is not None', 'rule variant_validation_vcf', 'benchmark']
    (264, '        benchmark:')
    (265, '            VARIANT_CALL_DOC + "variant_validation.json"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/variant_calling.py
context_key: ['if config["illumina_se"] is None and config["Validation"] is not None', 'rule variant_validation_vcf', 'shell']
    (266, '        shell:')
    (267, '            """')
    (268, '            vcftools --vcf {input.FILTERED_VARIANTS} --diff {input.INPUT_VCF_FILE} --diff-site -c > {output}')
    (269, '            """')
    (270, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/variant_calling.py
context_key: ['if config["illumina_se"] is None and config["Validation"] is not None', 'rule intersect_vcf', 'input']
    (276, 'if config["illumina_se"] is None and config["Validation"] is not None:')
    (277, '    rule intersect_vcf:')
    (278, '        input:')
    (279, '            FILTERED_VARIANTS = FINAL_VARIANTS + "filtered_snps.recode.vcf",')
    (280, '            INPUT_VCF_FILE = config["Validation"]')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/variant_calling.py
context_key: ['if config["illumina_se"] is None and config["Validation"] is not None', 'rule intersect_vcf', 'output']
    (281, '        output:')
    (282, '            FINAL_VARIANTS + "Overlapping_SNPs.vcf"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/variant_calling.py
context_key: ['if config["illumina_se"] is None and config["Validation"] is not None', 'rule intersect_vcf', 'log']
    (283, '        log:')
    (284, '            VARIANT_CALL_DOC + "bedtools_intersect.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/variant_calling.py
context_key: ['if config["illumina_se"] is None and config["Validation"] is not None', 'rule intersect_vcf', 'benchmark']
    (285, '        benchmark:')
    (286, '            VARIANT_CALL_DOC + "bedtools_intersect.json"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/variant_calling.py
context_key: ['if config["illumina_se"] is None and config["Validation"] is not None', 'rule intersect_vcf', 'shell']
    (287, '        shell:')
    (288, '            """')
    (289, '            bedtools intersect -a {input.FILTERED_VARIANTS} -b {input.INPUT_VCF_FILE} -header > {output}')
    (290, '            """')
    (291, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['if config["illumina_se"] is None and config["Flash"] is False', 'rule map_bwa_sample_pe', 'input']
    (22, 'if config["illumina_se"] is None and config["Flash"] is False:')
    (23, '   rule map_bwa_sample_pe:')
    (24, '        input:')
    (25, '            reference = RAW_DIR + "genome.fasta",')
    (26, '            index = RAW_DIR + "genome.fasta.bwt",')
    (27, '            forward = QC_DIR + "{sample}.final.1.fq.gz",')
    (28, '            reverse = QC_DIR + "{sample}.final.2.fq.gz"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['if config["illumina_se"] is None and config["Flash"] is False', 'rule map_bwa_sample_pe', 'output']
    (29, '        output:')
    (30, '            temp(MAP_DIR + "{sample}.unsorted.bam")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['if config["illumina_se"] is None and config["Flash"] is False', 'rule map_bwa_sample_pe', 'params']
    (31, '        params:')
    (32, '            rg="@RG\\\\tID:{sample}\\\\tSM:{sample}\\\\tPL:Illumina",')
    (33, '            bwa_params = config["BWA-Mapping"]["BWA_mem_params"],')
    (34, '            samtools_params = config["Samtools_mapping_params"]["samtools_view_params"]')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['if config["illumina_se"] is None and config["Flash"] is False', 'rule map_bwa_sample_pe', 'log']
    (35, '        log:')
    (36, '            MAP_DOC + "bwa_{sample}_pe.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['if config["illumina_se"] is None and config["Flash"] is False', 'rule map_bwa_sample_pe', 'benchmark']
    (37, '        benchmark:')
    (38, '            MAP_DOC + "bwa_{sample}_pe.json"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['if config["illumina_se"] is None and config["Flash"] is False', 'rule map_bwa_sample_pe', 'shell']
    (39, '        shell:')
    (40, '            "(bwa mem -R \\\'{params.rg}\\\' {params.bwa_params} {input.reference} {input.forward} {input.reverse} | "')
    (41, '            "samtools view {params.samtools_params} - "')
    (42, '            "> {output}) "')
    (43, '            "2> {log}"')
    (44, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['elif config["illumina_se"] is None and config["Flash"] is True', 'rule map_bwa_sample_pe_flashed', 'input']
    (45, 'elif config["illumina_se"] is None and config["Flash"] is True:')
    (46, '   rule map_bwa_sample_pe_flashed:')
    (47, '        input:')
    (48, '            reference = RAW_DIR + "genome.fasta",')
    (49, '            index = RAW_DIR + "genome.fasta.bwt",')
    (50, '            Flashed_read = FLASHED_READS + "{sample}.flashed.extendedFrags.fastq.gz"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['elif config["illumina_se"] is None and config["Flash"] is True', 'rule map_bwa_sample_pe_flashed', 'output']
    (51, '        output:')
    (52, '            temp(MAP_DIR + "{sample}.unsorted.bam")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['elif config["illumina_se"] is None and config["Flash"] is True', 'rule map_bwa_sample_pe_flashed', 'params']
    (53, '        params:')
    (54, '            rg="@RG\\\\tID:{sample}\\\\tSM:{sample}\\\\tPL:Illumina",')
    (55, '            bwa_params = config["BWA-Mapping"]["BWA_mem_params"],')
    (56, '            samtools_params = config["Samtools_mapping_params"]["samtools_view_params"]')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['elif config["illumina_se"] is None and config["Flash"] is True', 'rule map_bwa_sample_pe_flashed', 'log']
    (57, '        log:')
    (58, '            MAP_DOC + "bwa_{sample}.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['elif config["illumina_se"] is None and config["Flash"] is True', 'rule map_bwa_sample_pe_flashed', 'benchmark']
    (59, '        benchmark:')
    (60, '            MAP_DOC + "bwa_{sample}.json"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['elif config["illumina_se"] is None and config["Flash"] is True', 'rule map_bwa_sample_pe_flashed', 'shell']
    (61, '        shell:')
    (62, '            "(bwa mem -R \\\'{params.rg}\\\' {params.bwa_params} {input.reference} {input.Flashed_read} | "')
    (63, '            "samtools view {params.samtools_params} - "')
    (64, '            "> {output}) "')
    (65, '            "2> {log}"')
    (66, '')
    (67, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['elif config["illumina_pe"] is None', 'rule map_bwa_sample_se', 'input']
    (68, 'elif config["illumina_pe"] is None:')
    (69, '    rule map_bwa_sample_se:')
    (70, '        input:')
    (71, '            reference = RAW_DIR + "genome.fasta",')
    (72, '            index = RAW_DIR + "genome.fasta.bwt",')
    (73, '            single = QC_DIR + "{sample}.se.final.fq.gz"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['elif config["illumina_pe"] is None', 'rule map_bwa_sample_se', 'output']
    (74, '        output:')
    (75, '            temp(MAP_DIR + "{sample}.unsorted.bam")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['elif config["illumina_pe"] is None', 'rule map_bwa_sample_se', 'params']
    (76, '        params:')
    (77, '            rg="@RG\\\\tID:{sample}\\\\tSM:{sample}\\\\tPL:Illumina",')
    (78, '            bwa_params = config["BWA-Mapping"]["BWA_mem_params"],')
    (79, '            samtools_params = config["Samtools_mapping_params"]["samtools_view_params"]')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['elif config["illumina_pe"] is None', 'rule map_bwa_sample_se', 'log']
    (80, '        log:')
    (81, '            MAP_DOC + "bwa_{sample}.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['elif config["illumina_pe"] is None', 'rule map_bwa_sample_se', 'benchmark']
    (82, '        benchmark:')
    (83, '            MAP_DOC + "bwa_{sample}.json"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['elif config["illumina_pe"] is None', 'rule map_bwa_sample_se', 'shell']
    (84, '        shell:')
    (85, '            "(bwa mem -R \\\'{params.rg}\\\' {params.bwa_params} {input.reference} {input.single} | "')
    (86, '            "samtools view {params.samtools_params} - "')
    (87, '            "> {output}) "')
    (88, '            "2> {log}"')
    (89, '')
    (90, '#########################################################################################################')
    (91, '')
    (92, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['if config["illumina_se"] is None', 'rule map_MultiQC_Samtools_sample_pe', 'input']
    (235, 'if config["illumina_se"] is None:')
    (236, '    rule map_MultiQC_Samtools_sample_pe:')
    (237, '        input:')
    (238, '            idxstats = expand(FINAL_DOCS_IDXSTATS + "{sample}.idxstats", sample = SAMPLES_PE),')
    (239, '            flagstat = expand(FINAL_DOCS_FLAGSTAT + "{sample}.flagstat", sample = SAMPLES_PE)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['if config["illumina_se"] is None', 'rule map_MultiQC_Samtools_sample_pe', 'output']
    (240, '        output:')
    (241, '            MultiQC_idxstats = FINAL_DOCS_MULTIQC_IDXSTATS,')
    (242, '            MultiQC_flagstat = FINAL_DOCS_MULTIQC_FLAGSTAT')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['if config["illumina_se"] is None', 'rule map_MultiQC_Samtools_sample_pe', 'shell']
    (243, '        shell:')
    (244, '            """')
    (245, '            multiqc -m samtools {input.idxstats} -o {output.MultiQC_idxstats}')
    (246, '            multiqc -m samtools {input.flagstat} -o {output.MultiQC_flagstat}')
    (247, '            """')
    (248, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['elif config["illumina_pe"] is None', 'rule map_MultiQC_Samtools_se', 'input']
    (249, 'elif config["illumina_pe"] is None:')
    (250, '    rule map_MultiQC_Samtools_se:')
    (251, '        input:')
    (252, '            idxstats = expand(FINAL_DOCS_IDXSTATS + "{sample}.idxstats", sample = SAMPLES_SE),')
    (253, '            flagstat = expand(FINAL_DOCS_FLAGSTAT + "{sample}.flagstat", sample = SAMPLES_SE)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['elif config["illumina_pe"] is None', 'rule map_MultiQC_Samtools_se', 'output']
    (254, '        output:')
    (255, '            MultiQC_idxstats = FINAL_DOCS_MULTIQC_IDXSTATS,')
    (256, '            MultiQC_flagstat = FINAL_DOCS_MULTIQC_FLAGSTAT')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['elif config["illumina_pe"] is None', 'rule map_MultiQC_Samtools_se', 'shell']
    (257, '        shell:')
    (258, '            """')
    (259, '            multiqc -m samtools {input.idxstats} -o {output.MultiQC_idxstats}')
    (260, '            multiqc -m samtools {input.flagstat} -o {output.MultiQC_flagstat}')
    (261, '            """')
    (262, '')
    (263, '#########################################################################################################')
    (264, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['if config["illumina_se"] is None and config["QC_Tests"] is True', 'rule map_MultiQC_Qualimap_sample_pe', 'input']
    (265, 'if config["illumina_se"] is None and config["QC_Tests"] is True:')
    (266, '    rule map_MultiQC_Qualimap_sample_pe:')
    (267, '        input:')
    (268, '            QUALIMAP = expand(FINAL_DOCS_QUALIMAP + "{sample}.qualimap", sample = SAMPLES_PE)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['if config["illumina_se"] is None and config["QC_Tests"] is True', 'rule map_MultiQC_Qualimap_sample_pe', 'output']
    (269, '        output:')
    (270, '            MULTIQC_QUALIMAP = FINAL_DOCS_MULTIQC_QUALIMAP')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['if config["illumina_se"] is None and config["QC_Tests"] is True', 'rule map_MultiQC_Qualimap_sample_pe', 'shell']
    (271, '        shell:')
    (272, '            """')
    (273, '            multiqc -m qualimap {input.QUALIMAP} -o {output.MULTIQC_QUALIMAP}')
    (274, '            """')
    (275, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['elif config["illumina_pe"] is None and config["QC_Tests"] is True', 'rule map_MultiQC_Qualimap_sample_se', 'input']
    (276, 'elif config["illumina_pe"] is None and config["QC_Tests"] is True:')
    (277, '    rule map_MultiQC_Qualimap_sample_se:')
    (278, '        input:')
    (279, '            QUALIMAP = expand(FINAL_DOCS_QUALIMAP + "{sample}.qualimap", sample = SAMPLES_SE)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['elif config["illumina_pe"] is None and config["QC_Tests"] is True', 'rule map_MultiQC_Qualimap_sample_se', 'output']
    (280, '        output:')
    (281, '            MULTIQC_QUALIMAP = FINAL_DOCS_MULTIQC_QUALIMAP')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['elif config["illumina_pe"] is None and config["QC_Tests"] is True', 'rule map_MultiQC_Qualimap_sample_se', 'shell']
    (282, '        shell:')
    (283, '            """')
    (284, '            multiqc -m qualimap {input.QUALIMAP} -o {output.MULTIQC_QUALIMAP}')
    (285, '            """')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['else', 'if config["illumina_se"] is None', 'rule map_merge_bam_pe', 'input']
    (291, 'if config["illumina_se"] is None:')
    (292, '    rule map_merge_bam_pe:')
    (293, '        input:')
    (294, '            bam = expand(MAP_DIR + "{sample}.sorted.bam",')
    (295, '                         sample = SAMPLES_PE),')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['else', 'if config["illumina_se"] is None', 'rule map_merge_bam_pe']
    (296, '            bai = expand(MAP_DIR + "{sample}.sorted.bam.bai",')
    (297, '                         sample = SAMPLES_PE)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['else', 'if config["illumina_se"] is None', 'output']
    (298, '        output:')
    (299, '            BAM_1 = MAP_DIR + "merged.bam",')
    (300, '            BAM_2 = BAM_FILES + "merged.bam",')
    (301, '            BAI_1 = BAM_FILES + "merged.bam.bai",')
    (302, '            BAI_2 = MAP_DIR + "merged.bam.bai",')
    (303, '            MD5_1 = MAP_DIR + "mergedMD5.txt",')
    (304, '            MD5_2 = BAM_FILES + "mergedMD5.txt"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['else', 'if config["illumina_se"] is None', 'log']
    (305, '        log:')
    (306, '            MAP_DOC + "merge_bam_pe.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['else', 'if config["illumina_se"] is None', 'benchmark']
    (307, '        benchmark:')
    (308, '            MAP_DOC + "merge_bam_pe.json"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['else', 'if config["illumina_se"] is None', 'shell']
    (309, '        shell:')
    (310, '            """')
    (311, '            samtools merge {output.BAM_1} {input.bam} > {log} 2>&1')
    (312, '            cp {output.BAM_1} {output.BAM_2}')
    (313, '            md5sum {output.BAM_1} > {output.MD5_1}')
    (314, '            md5sum {output.BAM_1} > {output.MD5_2}')
    (315, '            samtools index {output.BAM_1} {output.BAI_1}')
    (316, '            cp {output.BAI_1} {output.BAI_2}')
    (317, '            """')
    (318, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['elif config["illumina_pe"] is None', 'rule map_merge_bam_se', 'input']
    (319, 'elif config["illumina_pe"] is None:')
    (320, '    rule map_merge_bam_se:')
    (321, '        input:')
    (322, '            bam = expand(MAP_DIR + "{sample}.sorted.bam",')
    (323, '                         sample = SAMPLES_SE),')
    (324, '            bai = expand(MAP_DIR + "{sample}.sorted.bam.bai",')
    (325, '                         sample = SAMPLES_SE)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['elif config["illumina_pe"] is None', 'rule map_merge_bam_se', 'output']
    (326, '        output:')
    (327, '            BAM_1 = MAP_DIR + "merged.bam",')
    (328, '            BAM_2 = BAM_FILES + "merged.bam",')
    (329, '            BAI_1 = BAM_FILES + "merged.bam.bai",')
    (330, '            BAI_2 = MAP_DIR + "merged.bam.bai",')
    (331, '            MD5_1 = MAP_DIR + "mergedMD5.txt",')
    (332, '            MD5_2 = BAM_FILES + "mergedMD5.txt"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['elif config["illumina_pe"] is None', 'rule map_merge_bam_se', 'log']
    (333, '        log:')
    (334, '            MAP_DOC + "merge_bam_se.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['elif config["illumina_pe"] is None', 'rule map_merge_bam_se', 'benchmark']
    (335, '        benchmark:')
    (336, '            MAP_DOC + "merge_bam_se.json"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['elif config["illumina_pe"] is None', 'rule map_merge_bam_se', 'shell']
    (337, '        shell:')
    (338, '            """')
    (339, '            samtools merge {output.BAM_1} {input.bam} > {log} 2>&1')
    (340, '            cp {output.BAM_1} {output.BAM_2}')
    (341, '            md5sum {output.BAM_1} > {output.MD5_1}')
    (342, '            md5sum {output.BAM_1} > {output.MD5_2}')
    (343, '            samtools index {output.BAM_1} {output.BAI_1}')
    (344, '            cp {output.BAI_1} {output.BAI_2}')
    (345, '            """')
    (346, '')
    (347, '#########################################################################################################')
    (348, '')
    (349, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['if config["illumina_se"] is None and config["Flash"] is False', 'rule map_samtools_properly_paired_pe', 'input']
    (350, 'if config["illumina_se"] is None and config["Flash"] is False:')
    (351, '    rule map_samtools_properly_paired_pe:')
    (352, '        input:')
    (353, '            MAP_DIR + "merged.bam"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['if config["illumina_se"] is None and config["Flash"] is False', 'rule map_samtools_properly_paired_pe', 'output']
    (354, '        output:')
    (355, '            BAM_1 = MAP_DIR + "merged_properly_paired.bam",')
    (356, '            BAM_2 = BAM_FILES + "merged_properly_paired.bam"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['if config["illumina_se"] is None and config["Flash"] is False', 'rule map_samtools_properly_paired_pe', 'params']
    (357, '        params:')
    (358, '            samtools_params = config["Samtools_mapping_params"]["samtools_view_params"],')
    (359, '            samtools_filtering_params = config["Samtools_read_filtering"]["samtools_view_filtering"]')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['if config["illumina_se"] is None and config["Flash"] is False', 'rule map_samtools_properly_paired_pe', 'log']
    (360, '        log:')
    (361, '            MAP_DOC + "properly_paired_merged.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['if config["illumina_se"] is None and config["Flash"] is False', 'rule map_samtools_properly_paired_pe', 'benchmark']
    (362, '        benchmark:')
    (363, '            MAP_DOC + "properly_paired_merged.json"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['if config["illumina_se"] is None and config["Flash"] is False', 'rule map_samtools_properly_paired_pe', 'shell']
    (364, '        shell:')
    (365, '            """')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['elif config["illumina_se"] is None and config["Flash"] is True']
    (370, 'elif config["illumina_se"] is None and config["Flash"] is True:')
    (371, '    pass')
    (372, '')
    (373, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['elif config["illumina_pe"] is None']
    (374, 'elif config["illumina_pe"] is None:')
    (375, '    pass')
    (376, '')
    (377, '')
    (378, '#########################################################################################################')
    (379, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['if config["illumina_se"] is None', 'rule properly_paired_index_pe', 'input']
    (380, 'if config["illumina_se"] is None:')
    (381, '    rule properly_paired_index_pe:')
    (382, '        input:')
    (383, '            MAP_DIR + "merged_properly_paired.bam"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['if config["illumina_se"] is None', 'rule properly_paired_index_pe', 'output']
    (384, '        output:')
    (385, '            BAI_1 = MAP_DIR + "merged_properly_paired.bam.bai",')
    (386, '            BAI_2 = BAM_FILES + "merged_properly_paired.bam.bai"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['if config["illumina_se"] is None', 'rule properly_paired_index_pe', 'log']
    (387, '        log:')
    (388, '            MAP_DOC + "index_merged_properly_paired.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['if config["illumina_se"] is None', 'rule properly_paired_index_pe', 'benchmark']
    (389, '        benchmark:')
    (390, '            MAP_DOC + "index_merged_properly_paired.json"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['if config["illumina_se"] is None', 'rule properly_paired_index_pe', 'shell']
    (391, '        shell:')
    (392, '            """')
    (393, '            samtools index {input} {output.BAI_1}')
    (394, '            cp {output.BAI_1} {output.BAI_2}')
    (395, '            """')
    (396, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['elif config["illumina_se"] is None and config["Flash"] is True']
    (397, 'elif config["illumina_se"] is None and config["Flash"] is True:')
    (398, '    pass')
    (399, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['elif config["illumina_pe"] is None']
    (400, 'elif config["illumina_pe"] is None:')
    (401, '    pass')
    (402, '')
    (403, '#########################################################################################################')
    (404, '')
    (405, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['if config["illumina_se"] is None', 'rule map', 'input']
    (406, 'if config["illumina_se"] is None:')
    (407, '    rule map:')
    (408, '        input:')
    (409, '            MAP_DIR + "merged.bam.bai",')
    (410, '            expand([FINAL_DOCS_IDXSTATS + "{sample}.idxstats", FINAL_DOCS_FLAGSTAT + "{sample}.flagstat", FINAL_DOCS_GENERALSTATS + "{sample}.generalStats"],')
    (411, '                sample = SAMPLES_PE)')
    (412, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['elif config["illumina_pe"] is None', 'rule map', 'input']
    (413, 'elif config["illumina_pe"] is None:')
    (414, '    rule map:')
    (415, '        input:')
    (416, '            MAP_DIR + "merged.bam.bai",')
    (417, '            expand([FINAL_DOCS_IDXSTATS + "{sample}.idxstats", FINAL_DOCS_FLAGSTAT + "{sample}.flagstat", FINAL_DOCS_GENERALSTATS + "{sample}.generalStats"],')
    (418, "                sample = SAMPLES_SE)'")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/variant_calling.py
context_key: ['if config["illumina_se"] is None and config["Flash"] is False', 'rule variant_call_subset_bam_pe', 'input']
    (47, 'if config["illumina_se"] is None and config["Flash"] is False:')
    (48, '    rule variant_call_subset_bam_pe:')
    (49, '        """')
    (50, '        Generate a BAM file for each of the genome partitions')
    (51, '        """')
    (52, '        input:')
    (53, '            bam = MAP_DIR + "merged_properly_paired.bam",')
    (54, '            bai = MAP_DIR + "merged_properly_paired.bam.bai",')
    (55, '            bed = VARIANT_CALL_DIR + "genome.{index}.bed"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/variant_calling.py
context_key: ['if config["illumina_se"] is None and config["Flash"] is False', 'rule variant_call_subset_bam_pe', 'output']
    (56, '        output:')
    (57, '            bam = VARIANT_CALL_DIR + "merged.{index}.bam",')
    (58, '            bai = VARIANT_CALL_DIR + "merged.{index}.bam.bai"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/variant_calling.py
context_key: ['if config["illumina_se"] is None and config["Flash"] is False', 'rule variant_call_subset_bam_pe', 'params']
    (59, '        params:')
    (60, '            scripts_dir = config["scripts_dir"]')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/variant_calling.py
context_key: ['if config["illumina_se"] is None and config["Flash"] is False', 'rule variant_call_subset_bam_pe', 'threads']
    (61, '        threads:')
    (62, '            2')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/variant_calling.py
context_key: ['if config["illumina_se"] is None and config["Flash"] is False', 'rule variant_call_subset_bam_pe', 'log']
    (63, '        log:')
    (64, '            VARIANT_CALL_DOC + "variant_call_make_bam.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/variant_calling.py
context_key: ['if config["illumina_se"] is None and config["Flash"] is False', 'rule variant_call_subset_bam_pe', 'benchmark']
    (65, '        benchmark:')
    (66, '            VARIANT_CALL_DOC + "variant_call_make_bam.json"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/variant_calling.py
context_key: ['if config["illumina_se"] is None and config["Flash"] is False', 'rule variant_call_subset_bam_pe', 'shell']
    (67, '        shell:')
    (68, '            "samtools view -L {input.bed} -b {input.bam} "')
    (69, '            "> {output.bam} "')
    (70, '            "2> {log} && "')
    (71, '            "samtools index {output.bam}"')
    (72, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/variant_calling.py
context_key: ['elif config["illumina_se"] is None and config["Flash"] is True', 'rule variant_call_flashed_bam_pe', 'input']
    (73, 'elif config["illumina_se"] is None and config["Flash"] is True:')
    (74, '    rule variant_call_flashed_bam_pe:')
    (75, '        """')
    (76, '        Generate a BAM file for each of the genome partitions')
    (77, '        """')
    (78, '        input:')
    (79, '            bam = MAP_DIR + "merged.bam",')
    (80, '            bai = MAP_DIR + "merged.bam.bai",')
    (81, '            bed = VARIANT_CALL_DIR + "genome.{index}.bed"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/variant_calling.py
context_key: ['elif config["illumina_se"] is None and config["Flash"] is True', 'rule variant_call_flashed_bam_pe', 'output']
    (82, '        output:')
    (83, '            bam = VARIANT_CALL_DIR + "merged.{index}.bam",')
    (84, '            bai = VARIANT_CALL_DIR + "merged.{index}.bam.bai"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/variant_calling.py
context_key: ['elif config["illumina_se"] is None and config["Flash"] is True', 'rule variant_call_flashed_bam_pe', 'params']
    (85, '        params:')
    (86, '            scripts_dir = config["scripts_dir"]')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/variant_calling.py
context_key: ['elif config["illumina_se"] is None and config["Flash"] is True', 'rule variant_call_flashed_bam_pe', 'threads']
    (87, '        threads:')
    (88, '            2')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/variant_calling.py
context_key: ['elif config["illumina_se"] is None and config["Flash"] is True', 'rule variant_call_flashed_bam_pe', 'log']
    (89, '        log:')
    (90, '            VARIANT_CALL_DOC + "variant_call_make_bam.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/variant_calling.py
context_key: ['elif config["illumina_se"] is None and config["Flash"] is True', 'rule variant_call_flashed_bam_pe', 'benchmark']
    (91, '        benchmark:')
    (92, '            VARIANT_CALL_DOC + "variant_call_make_bam.json"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/variant_calling.py
context_key: ['elif config["illumina_se"] is None and config["Flash"] is True', 'rule variant_call_flashed_bam_pe', 'shell']
    (93, '        shell:')
    (94, '            "samtools view -L {input.bed} -b {input.bam} "')
    (95, '            "> {output.bam} "')
    (96, '            "2> {log} && "')
    (97, '            "samtools index {output.bam}"')
    (98, '')
    (99, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/variant_calling.py
context_key: ['elif config["illumina_pe"] is None', 'rule variant_call_subset_bam_se', 'input']
    (100, 'elif config["illumina_pe"] is None:')
    (101, '    rule variant_call_subset_bam_se:')
    (102, '        """')
    (103, '        Generate a BAM file for each of the genome partitions')
    (104, '        """')
    (105, '        input:')
    (106, '            bam = MAP_DIR + "merged.bam",')
    (107, '            bai = MAP_DIR + "merged.bam.bai",')
    (108, '            bed = VARIANT_CALL_DIR + "genome.{index}.bed"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/variant_calling.py
context_key: ['elif config["illumina_pe"] is None', 'rule variant_call_subset_bam_se', 'output']
    (109, '        output:')
    (110, '            bam = VARIANT_CALL_DIR + "merged.{index}.bam",')
    (111, '            bai = VARIANT_CALL_DIR + "merged.{index}.bam.bai"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/variant_calling.py
context_key: ['elif config["illumina_pe"] is None', 'rule variant_call_subset_bam_se', 'params']
    (112, '        params:')
    (113, '            scripts_dir = config["scripts_dir"]')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/variant_calling.py
context_key: ['elif config["illumina_pe"] is None', 'rule variant_call_subset_bam_se', 'threads']
    (114, '        threads:')
    (115, '            2')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/variant_calling.py
context_key: ['elif config["illumina_pe"] is None', 'rule variant_call_subset_bam_se', 'log']
    (116, '        log:')
    (117, '            VARIANT_CALL_DOC + "variant_call_make_bam.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/variant_calling.py
context_key: ['elif config["illumina_pe"] is None', 'rule variant_call_subset_bam_se', 'benchmark']
    (118, '        benchmark:')
    (119, '            VARIANT_CALL_DOC + "variant_call_make_bam.json"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/variant_calling.py
context_key: ['elif config["illumina_pe"] is None', 'rule variant_call_subset_bam_se', 'shell']
    (120, '        shell:')
    (121, '            "samtools view -L {input.bed} -b {input.bam} "')
    (122, '            "> {output.bam} "')
    (123, '            "2> {log} && "')
    (124, '            "samtools index {output.bam}"')
    (125, '')
    (126, '#########################################################################################################')
    (127, '')
    (128, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/variant_calling.py
context_key: ['if config["illumina_se"] is None and config["Validation"] is not None', 'rule variant_validation_vcf', 'input']
    (252, 'if config["illumina_se"] is None and config["Validation"] is not None:')
    (253, '    rule variant_validation_vcf:')
    (254, '        """')
    (255, '        Use a previous variant dataset to compare, extract and store common high-value SNPs between the two datasets')
    (256, '        """')
    (257, '        input:')
    (258, '            FILTERED_VARIANTS = FINAL_VARIANTS + "filtered_snps.recode.vcf",')
    (259, '            INPUT_VCF_FILE = config["Validation"]')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/variant_calling.py
context_key: ['if config["illumina_se"] is None and config["Validation"] is not None', 'rule variant_validation_vcf', 'output']
    (260, '        output:')
    (261, '            FINAL_VARIANTS + "Overlapping_SNPs"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/variant_calling.py
context_key: ['if config["illumina_se"] is None and config["Validation"] is not None', 'rule variant_validation_vcf', 'log']
    (262, '        log:')
    (263, '            VARIANT_CALL_DOC + "variant_validation.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/variant_calling.py
context_key: ['if config["illumina_se"] is None and config["Validation"] is not None', 'rule variant_validation_vcf', 'benchmark']
    (264, '        benchmark:')
    (265, '            VARIANT_CALL_DOC + "variant_validation.json"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/variant_calling.py
context_key: ['if config["illumina_se"] is None and config["Validation"] is not None', 'rule variant_validation_vcf', 'shell']
    (266, '        shell:')
    (267, '            """')
    (268, '            vcftools --vcf {input.FILTERED_VARIANTS} --diff {input.INPUT_VCF_FILE} --diff-site -c > {output}')
    (269, '            """')
    (270, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/variant_calling.py
context_key: ['if config["illumina_se"] is None and config["Validation"] is not None', 'rule intersect_vcf', 'input']
    (276, 'if config["illumina_se"] is None and config["Validation"] is not None:')
    (277, '    rule intersect_vcf:')
    (278, '        input:')
    (279, '            FILTERED_VARIANTS = FINAL_VARIANTS + "filtered_snps.recode.vcf",')
    (280, '            INPUT_VCF_FILE = config["Validation"]')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/variant_calling.py
context_key: ['if config["illumina_se"] is None and config["Validation"] is not None', 'rule intersect_vcf', 'output']
    (281, '        output:')
    (282, '            FINAL_VARIANTS + "Overlapping_SNPs.vcf"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/variant_calling.py
context_key: ['if config["illumina_se"] is None and config["Validation"] is not None', 'rule intersect_vcf', 'log']
    (283, '        log:')
    (284, '            VARIANT_CALL_DOC + "bedtools_intersect.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/variant_calling.py
context_key: ['if config["illumina_se"] is None and config["Validation"] is not None', 'rule intersect_vcf', 'benchmark']
    (285, '        benchmark:')
    (286, '            VARIANT_CALL_DOC + "bedtools_intersect.json"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/variant_calling.py
context_key: ['if config["illumina_se"] is None and config["Validation"] is not None', 'rule intersect_vcf', 'shell']
    (287, '        shell:')
    (288, '            """')
    (289, '            bedtools intersect -a {input.FILTERED_VARIANTS} -b {input.INPUT_VCF_FILE} -header > {output}')
    (290, '            """')
    (291, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/BAM_to_SAM.py
context_key: ['elif config["illumina_pe"] is None and config["Haplotyper"] is True', 'rule map_BAM_to_SAM_se', 'input']
    (12, 'elif config["illumina_pe"] is None and config["Haplotyper"] is True:')
    (13, '    rule map_BAM_to_SAM_se:')
    (14, '        input:')
    (15, '            MAP_DIR + "{sample}.sorted.bam"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/BAM_to_SAM.py
context_key: ['elif config["illumina_pe"] is None and config["Haplotyper"] is True', 'rule map_BAM_to_SAM_se', 'output']
    (16, '        output:')
    (17, '            MAP_SAM + "{sample}.sorted.sam"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/BAM_to_SAM.py
context_key: ['elif config["illumina_pe"] is None and config["Haplotyper"] is True', 'rule map_BAM_to_SAM_se', 'shell']
    (18, '        shell:')
    (19, '            "samtools view -h -o {output} {input}"')
    (20, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/BAM_to_SAM.py
context_key: ['else', 'if config["illumina_se"] is None and config["Haplotyper"] is True', 'rule make_label', 'input', 'output']
    (26, 'if config["illumina_se"] is None and config["Haplotyper"] is True:')
    (27, '    rule make_label:')
    (28, '        input:')
    (29, '        \\texpand(MAP_SAM + "{sample}.sorted.sam", sample = SAMPLES_PE)')
    (30, '        output:')
    (31, '            MICROHAPLOT + "labels.txt"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/BAM_to_SAM.py
context_key: ['else', 'if config["illumina_se"] is None and config["Haplotyper"] is True', 'params']
    (32, '        params:')
    (33, '            scripts_dir = config["scripts_dir"]')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/BAM_to_SAM.py
context_key: ['else', 'if config["illumina_se"] is None and config["Haplotyper"] is True', 'shell']
    (34, '        shell:')
    (35, '            "{params.scripts_dir}/Make_labels.sh {output}"')
    (36, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/BAM_to_SAM.py
context_key: ['elif config["illumina_pe"] is None and config["Haplotyper"] is True', 'rule make_label', 'input']
    (37, 'elif config["illumina_pe"] is None and config["Haplotyper"] is True:')
    (38, '    rule make_label:')
    (39, '        input:')
    (40, '            expand(MAP_SAM + "{sample}.sorted.sam", sample = SAMPLES_SE)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/BAM_to_SAM.py
context_key: ['elif config["illumina_pe"] is None and config["Haplotyper"] is True', 'rule make_label', 'output']
    (41, '        output:')
    (42, '            MICROHAPLOT + "labels.txt"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/BAM_to_SAM.py
context_key: ['elif config["illumina_pe"] is None and config["Haplotyper"] is True', 'rule make_label', 'params']
    (43, '        params:')
    (44, '            scripts_dir = config["scripts_dir"]')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/BAM_to_SAM.py
context_key: ['elif config["illumina_pe"] is None and config["Haplotyper"] is True', 'rule make_label', 'shell']
    (45, '        shell:')
    (46, '            "{params.scripts_dir}/Make_labels.sh {output}"')
    (47, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/BAM_to_SAM.py
context_key: ['else', 'if config["Haplotyper"] is True', 'rule make_SAM_link', 'input']
    (53, 'if config["Haplotyper"] is True:')
    (54, '    rule make_SAM_link:')
    (55, '        """')
    (56, '        Make symlinks to run "microhaplot"')
    (57, '        """')
    (58, '        input:')
    (59, '            MAP_SAM + "{sample}.sorted.sam"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/BAM_to_SAM.py
context_key: ['else', 'if config["Haplotyper"] is True', 'output']
    (60, '        output:')
    (61, '            MICROHAPLOT + "{sample}.sorted.sam"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/BAM_to_SAM.py
context_key: ['else', 'if config["Haplotyper"] is True', 'log']
    (62, '        log:')
    (63, '            HAPLOTYPE_DOC + "make_SAM_link.{sample}.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/BAM_to_SAM.py
context_key: ['else', 'if config["Haplotyper"] is True', 'threads']
    (64, '        threads:')
    (65, '            1')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/BAM_to_SAM.py
context_key: ['else', 'if config["Haplotyper"] is True', 'shell']
    (66, '        shell:')
    (67, '            "ln -s $(readlink -f {input}) {output} 2> {log} "')
    (68, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/BAM_to_SAM.py
context_key: ['if config["Haplotyper"] is True and config["Validation"] is None', 'rule make_VCF_link', 'input']
    (76, 'if config["Haplotyper"] is True and config["Validation"] is None:')
    (77, '    rule make_VCF_link:')
    (78, '        """')
    (79, '        Make symlinks to run "microhaplot"')
    (80, '        """')
    (81, '        input:')
    (82, '            vcf = FINAL_VARIANTS + "filtered_snps.recode.vcf"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/BAM_to_SAM.py
context_key: ['if config["Haplotyper"] is True and config["Validation"] is None', 'rule make_VCF_link', 'output']
    (83, '        output:')
    (84, '            vcf = MICROHAPLOT + "snps.vcf"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/BAM_to_SAM.py
context_key: ['if config["Haplotyper"] is True and config["Validation"] is None', 'rule make_VCF_link', 'log']
    (85, '        log:')
    (86, '            HAPLOTYPE_DOC + "make_VCF_link.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/BAM_to_SAM.py
context_key: ['if config["Haplotyper"] is True and config["Validation"] is None', 'rule make_VCF_link', 'threads']
    (87, '        threads:')
    (88, '            1')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/BAM_to_SAM.py
context_key: ['if config["Haplotyper"] is True and config["Validation"] is None', 'rule make_VCF_link', 'shell']
    (89, '        shell:')
    (90, '            "ln -s $(readlink -f {input.vcf}) {output.vcf} 2> {log} "')
    (91, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/BAM_to_SAM.py
context_key: ['elif config["Haplotyper"] is True and config["Validation"] is not None', 'rule make_VCF_link', 'input']
    (92, 'elif config["Haplotyper"] is True and config["Validation"] is not None:')
    (93, '    rule make_VCF_link:')
    (94, '        """')
    (95, '        Make symlinks to run "microhaplot"')
    (96, '        """')
    (97, '        input:')
    (98, '            vcf = FINAL_VARIANTS + "Overlapping_SNPs.vcf"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/BAM_to_SAM.py
context_key: ['elif config["Haplotyper"] is True and config["Validation"] is not None', 'rule make_VCF_link', 'output']
    (99, '        output:')
    (100, '            vcf = MICROHAPLOT + "snps.vcf"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/BAM_to_SAM.py
context_key: ['elif config["Haplotyper"] is True and config["Validation"] is not None', 'rule make_VCF_link', 'log']
    (101, '        log:')
    (102, '            HAPLOTYPE_DOC + "make_VCF_link.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/BAM_to_SAM.py
context_key: ['elif config["Haplotyper"] is True and config["Validation"] is not None', 'rule make_VCF_link', 'threads']
    (103, '        threads:')
    (104, '            1')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/BAM_to_SAM.py
context_key: ['elif config["Haplotyper"] is True and config["Validation"] is not None', 'rule make_VCF_link', 'shell']
    (105, '        shell:')
    (106, '            "ln -s $(readlink -f {input.vcf}) {output.vcf} 2> {log} "')
    (107, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/BAM_to_SAM.py
context_key: ['elif config["illumina_pe"] is None and config["Haplotyper"] is True', 'rule map_BAM_to_SAM_se', 'input']
    (12, 'elif config["illumina_pe"] is None and config["Haplotyper"] is True:')
    (13, '    rule map_BAM_to_SAM_se:')
    (14, '        input:')
    (15, '            MAP_DIR + "{sample}.sorted.bam"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/BAM_to_SAM.py
context_key: ['elif config["illumina_pe"] is None and config["Haplotyper"] is True', 'rule map_BAM_to_SAM_se', 'output']
    (16, '        output:')
    (17, '            MAP_SAM + "{sample}.sorted.sam"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/BAM_to_SAM.py
context_key: ['elif config["illumina_pe"] is None and config["Haplotyper"] is True', 'rule map_BAM_to_SAM_se', 'shell']
    (18, '        shell:')
    (19, '            "samtools view -h -o {output} {input}"')
    (20, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/BAM_to_SAM.py
context_key: ['else', 'if config["illumina_se"] is None and config["Haplotyper"] is True', 'rule make_label', 'input', 'output']
    (26, 'if config["illumina_se"] is None and config["Haplotyper"] is True:')
    (27, '    rule make_label:')
    (28, '        input:')
    (29, '        \\texpand(MAP_SAM + "{sample}.sorted.sam", sample = SAMPLES_PE)')
    (30, '        output:')
    (31, '            MICROHAPLOT + "labels.txt"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/BAM_to_SAM.py
context_key: ['else', 'if config["illumina_se"] is None and config["Haplotyper"] is True', 'params']
    (32, '        params:')
    (33, '            scripts_dir = config["scripts_dir"]')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/BAM_to_SAM.py
context_key: ['else', 'if config["illumina_se"] is None and config["Haplotyper"] is True', 'shell']
    (34, '        shell:')
    (35, '            "{params.scripts_dir}/Make_labels.sh {output}"')
    (36, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/BAM_to_SAM.py
context_key: ['elif config["illumina_pe"] is None and config["Haplotyper"] is True', 'rule make_label', 'input']
    (37, 'elif config["illumina_pe"] is None and config["Haplotyper"] is True:')
    (38, '    rule make_label:')
    (39, '        input:')
    (40, '            expand(MAP_SAM + "{sample}.sorted.sam", sample = SAMPLES_SE)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/BAM_to_SAM.py
context_key: ['elif config["illumina_pe"] is None and config["Haplotyper"] is True', 'rule make_label', 'output']
    (41, '        output:')
    (42, '            MICROHAPLOT + "labels.txt"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/BAM_to_SAM.py
context_key: ['elif config["illumina_pe"] is None and config["Haplotyper"] is True', 'rule make_label', 'params']
    (43, '        params:')
    (44, '            scripts_dir = config["scripts_dir"]')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/BAM_to_SAM.py
context_key: ['elif config["illumina_pe"] is None and config["Haplotyper"] is True', 'rule make_label', 'shell']
    (45, '        shell:')
    (46, '            "{params.scripts_dir}/Make_labels.sh {output}"')
    (47, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/BAM_to_SAM.py
context_key: ['else', 'if config["Haplotyper"] is True', 'rule make_SAM_link', 'input']
    (53, 'if config["Haplotyper"] is True:')
    (54, '    rule make_SAM_link:')
    (55, '        """')
    (56, '        Make symlinks to run "microhaplot"')
    (57, '        """')
    (58, '        input:')
    (59, '            MAP_SAM + "{sample}.sorted.sam"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/BAM_to_SAM.py
context_key: ['else', 'if config["Haplotyper"] is True', 'output']
    (60, '        output:')
    (61, '            MICROHAPLOT + "{sample}.sorted.sam"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/BAM_to_SAM.py
context_key: ['else', 'if config["Haplotyper"] is True', 'log']
    (62, '        log:')
    (63, '            HAPLOTYPE_DOC + "make_SAM_link.{sample}.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/BAM_to_SAM.py
context_key: ['else', 'if config["Haplotyper"] is True', 'threads']
    (64, '        threads:')
    (65, '            1')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/BAM_to_SAM.py
context_key: ['else', 'if config["Haplotyper"] is True', 'shell']
    (66, '        shell:')
    (67, '            "ln -s $(readlink -f {input}) {output} 2> {log} "')
    (68, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/BAM_to_SAM.py
context_key: ['if config["Haplotyper"] is True and config["Validation"] is None', 'rule make_VCF_link', 'input']
    (76, 'if config["Haplotyper"] is True and config["Validation"] is None:')
    (77, '    rule make_VCF_link:')
    (78, '        """')
    (79, '        Make symlinks to run "microhaplot"')
    (80, '        """')
    (81, '        input:')
    (82, '            vcf = FINAL_VARIANTS + "filtered_snps.recode.vcf"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/BAM_to_SAM.py
context_key: ['if config["Haplotyper"] is True and config["Validation"] is None', 'rule make_VCF_link', 'output']
    (83, '        output:')
    (84, '            vcf = MICROHAPLOT + "snps.vcf"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/BAM_to_SAM.py
context_key: ['if config["Haplotyper"] is True and config["Validation"] is None', 'rule make_VCF_link', 'log']
    (85, '        log:')
    (86, '            HAPLOTYPE_DOC + "make_VCF_link.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/BAM_to_SAM.py
context_key: ['if config["Haplotyper"] is True and config["Validation"] is None', 'rule make_VCF_link', 'threads']
    (87, '        threads:')
    (88, '            1')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/BAM_to_SAM.py
context_key: ['if config["Haplotyper"] is True and config["Validation"] is None', 'rule make_VCF_link', 'shell']
    (89, '        shell:')
    (90, '            "ln -s $(readlink -f {input.vcf}) {output.vcf} 2> {log} "')
    (91, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/BAM_to_SAM.py
context_key: ['elif config["Haplotyper"] is True and config["Validation"] is not None', 'rule make_VCF_link', 'input']
    (92, 'elif config["Haplotyper"] is True and config["Validation"] is not None:')
    (93, '    rule make_VCF_link:')
    (94, '        """')
    (95, '        Make symlinks to run "microhaplot"')
    (96, '        """')
    (97, '        input:')
    (98, '            vcf = FINAL_VARIANTS + "Overlapping_SNPs.vcf"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/BAM_to_SAM.py
context_key: ['elif config["Haplotyper"] is True and config["Validation"] is not None', 'rule make_VCF_link', 'output']
    (99, '        output:')
    (100, '            vcf = MICROHAPLOT + "snps.vcf"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/BAM_to_SAM.py
context_key: ['elif config["Haplotyper"] is True and config["Validation"] is not None', 'rule make_VCF_link', 'log']
    (101, '        log:')
    (102, '            HAPLOTYPE_DOC + "make_VCF_link.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/BAM_to_SAM.py
context_key: ['elif config["Haplotyper"] is True and config["Validation"] is not None', 'rule make_VCF_link', 'threads']
    (103, '        threads:')
    (104, '            1')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/BAM_to_SAM.py
context_key: ['elif config["Haplotyper"] is True and config["Validation"] is not None', 'rule make_VCF_link', 'shell']
    (105, '        shell:')
    (106, '            "ln -s $(readlink -f {input.vcf}) {output.vcf} 2> {log} "')
    (107, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=Snakefile
context_key: ['if config["illumina_pe"] is None', 'elif config["illumina_se"] is None', 'if config["illumina_se"] is None', 'elif config["illumina_pe"] is None', 'if config["illumina_se"] is None', 'elif config["illumina_pe"] is None', 'if SAMPLES_SE == []']
    (24, 'if config["illumina_pe"] is None:')
    (25, '\\tSAMPLES_SE_RAW = config["illumina_se"] if config["illumina_se"] is not None else []')
    (26, 'elif config["illumina_se"] is None:')
    (27, '\\tSAMPLES_PE_RAW = config["illumina_pe"] if config["illumina_pe"] is not None else []')
    (28, '')
    (29, '')
    (30, '')
    (31, 'if config["illumina_se"] is None:')
    (32, '\\tSAMPLES_PE = [x for x in SAMPLES_PE_RAW]')
    (33, 'elif config["illumina_pe"] is None:')
    (34, '\\tSAMPLES_SE = [x for x in SAMPLES_SE_RAW]')
    (35, '')
    (36, '')
    (37, '')
    (38, 'if config["illumina_se"] is None:')
    (39, '\\tif SAMPLES_PE == []:')
    (40, '\\t\\tsys.exit("Paired-end reads cannot be found")')
    (41, '\\telse:')
    (42, '\\t\\tpass')
    (43, 'elif config["illumina_pe"] is None:')
    (44, '    if SAMPLES_SE == []:')
    (45, '        sys.exit("Single-end reads cannot be found")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=Snakefile
context_key: ['if config["illumina_pe"] is None', 'else']
    (46, '    else:')
    (47, '        pass')
    (48, '')
    (49, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=Snakefile
context_key: ['if config["illumina_se"] is None and config["QC_Tests"] is True and config["Haplotyper"] is False and config["Validation"] is None and config["Flash"] is False', 'elif config["illumina_se"] is None and config["QC_Tests"] is False and config["Haplotyper"] is False and config["Validation"] is None and config["Flash"] is False', 'elif config["illumina_pe"] is None and config["QC_Tests"] is True and config["Haplotyper"] is False and config["Validation"] is None', 'elif config["illumina_pe"] is None and config["QC_Tests"] is False and config["Haplotyper"] is False and config["Validation"] is None', 'elif config["illumina_se"] is None and config["QC_Tests"] is True and config["Haplotyper"] is True and config["Validation"] is None and config["Flash"] is False', 'elif config["illumina_se"] is None and config["QC_Tests"] is False and config["Haplotyper"] is True and config["Validation"] is None and config["Flash"] is False', 'elif config["illumina_pe"] is None and config["QC_Tests"] is True and config["Haplotyper"] is True and config["Validation"] is None', 'elif config["illumina_pe"] is None and config["QC_Tests"] is False and config["Haplotyper"] is True and config["Validation"] is None', 'elif config["illumina_se"] is None and config["QC_Tests"] is True and config["Haplotyper"] is True and config["Validation"] is not None and config["Flash"] is False', 'elif config["illumina_se"] is None and config["QC_Tests"] is False and config["Haplotyper"] is True and config["Validation"] is not None and config["Flash"] is False', 'elif config["illumina_pe"] is None and config["QC_Tests"] is True and config["Haplotyper"] is True and config["Validation"] is not None', 'elif config["illumina_pe"] is None and config["QC_Tests"] is False and config["Haplotyper"] is True and config["Validation"] is not None', 'elif config["illumina_se"] is None and config["QC_Tests"] is True and config["Haplotyper"] is False and config["Validation"] is not None and config["Flash"] is False', 'elif config["illumina_se"] is None and config["QC_Tests"] is False and config["Haplotyper"] is False and config["Validation"] is not None and config["Flash"] is False', 'elif config["illumina_pe"] is None and config["QC_Tests"] is True and config["Haplotyper"] is False and config["Validation"] is not None', 'elif config["illumina_pe"] is None and config["QC_Tests"] is False and config["Haplotyper"] is False and config["Validation"] is not None', 'elif config["illumina_se"] is None and config["QC_Tests"] is True and config["Haplotyper"] is False and config["Validation"] is None and config["Flash"] is True', 'elif config["illumina_se"] is None and config["QC_Tests"] is False and config["Haplotyper"] is False and config["Validation"] is None and config["Flash"] is True', 'elif config["illumina_se"] is None and config["QC_Tests"] is True and config["Haplotyper"] is True and config["Validation"] is None and config["Flash"] is True', 'elif config["illumina_se"] is None and config["QC_Tests"] is False and config["Haplotyper"] is True and config["Validation"] is None and config["Flash"] is True', 'elif config["illumina_se"] is None and config["QC_Tests"] is True and config["Haplotyper"] is True and config["Validation"] is not None and config["Flash"] is True', 'elif config["illumina_se"] is None and config["QC_Tests"] is False and config["Haplotyper"] is True and config["Validation"] is not None and config["Flash"] is True', 'elif config["illumina_se"] is None and config["QC_Tests"] is True and config["Haplotyper"] is False and config["Validation"] is not None and config["Flash"] is True', 'elif config["illumina_se"] is None and config["QC_Tests"] is False and config["Haplotyper"] is False and config["Validation"] is not None and config["Flash"] is True']
    (67, 'if config["illumina_se"] is None and config["QC_Tests"] is True and config["Haplotyper"] is False and config["Validation"] is None and config["Flash"] is False:')
    (68, '\\trule all:')
    (69, '\\t\\tinput:')
    (70, '\\t\\t  \\texpand([FINAL_DOCS_IDXSTATS + "{sample}.idxstats", FINAL_VARIANTS + "Hardy_Weinberg_values", FINAL_DOCS_MULTIQC_IDXSTATS, FINAL_DOCS_MULTIQC_FLAGSTAT, FINAL_DOCS_MULTIQC_QUALIMAP, FINAL_DOCS_GENERALSTATS + "{sample}.generalStats", FINAL_DOCS_FLAGSTAT + "{sample}.flagstat", fastQC_raw + "{sample}.raw.{pair}.fastqc", fastQC + "{sample}.{pair}"],')
    (71, '\\t\\t    \\tsample = SAMPLES_PE, pair = "1 2".split())')
    (72, '\\t\\t  ')
    (73, '')
    (74, 'elif config["illumina_se"] is None and config["QC_Tests"] is False and config["Haplotyper"] is False and config["Validation"] is None and config["Flash"] is False:')
    (75, '\\trule all:')
    (76, '\\t\\tinput:')
    (77, '\\t\\t\\texpand([FINAL_DOCS_IDXSTATS + "{sample}.idxstats", FINAL_VARIANTS + "Hardy_Weinberg_values", FINAL_DOCS_MULTIQC_IDXSTATS, FINAL_DOCS_MULTIQC_FLAGSTAT, FINAL_DOCS_GENERALSTATS + "{sample}.generalStats", FINAL_DOCS_FLAGSTAT + "{sample}.flagstat"],')
    (78, '\\t\\t\\t\\tsample = SAMPLES_PE, pair = "1 2".split())')
    (79, '')
    (80, 'elif config["illumina_pe"] is None and config["QC_Tests"] is True and config["Haplotyper"] is False and config["Validation"] is None:')
    (81, '\\trule all:')
    (82, '\\t\\tinput:')
    (83, '\\t\\t\\texpand([FINAL_DOCS_IDXSTATS + "{sample}.idxstats", FINAL_VARIANTS + "Hardy_Weinberg_values", FINAL_DOCS_MULTIQC_IDXSTATS, FINAL_DOCS_MULTIQC_FLAGSTAT, FINAL_DOCS_MULTIQC_QUALIMAP, FINAL_DOCS_GENERALSTATS + "{sample}.generalStats", FINAL_DOCS_FLAGSTAT + "{sample}.flagstat", fastQC_raw + "{sample}.raw.fastqc", fastQC + "{sample}.se"],')
    (84, '\\t\\t  \\t\\tsample = SAMPLES_SE)')
    (85, '')
    (86, 'elif config["illumina_pe"] is None and config["QC_Tests"] is False and config["Haplotyper"] is False and config["Validation"] is None:')
    (87, '\\trule all:')
    (88, '\\t\\tinput:')
    (89, '\\t\\t\\texpand([FINAL_DOCS_IDXSTATS + "{sample}.idxstats", FINAL_VARIANTS + "Hardy_Weinberg_values", FINAL_DOCS_MULTIQC_IDXSTATS, FINAL_DOCS_MULTIQC_FLAGSTAT, FINAL_DOCS_FLAGSTAT + "{sample}.flagstat", FINAL_DOCS_GENERALSTATS + "{sample}.generalStats"],')
    (90, '\\t\\t\\t\\tsample = SAMPLES_SE)')
    (91, '')
    (92, '')
    (93, '#########################################################################################################')
    (94, '')
    (95, '')
    (96, 'elif config["illumina_se"] is None and config["QC_Tests"] is True and config["Haplotyper"] is True and config["Validation"] is None and config["Flash"] is False:')
    (97, '\\trule all:')
    (98, '\\t\\tinput:')
    (99, '\\t\\t  HAPLOTYPE_DIR + "haplotypes.done",')
    (100, '\\t\\t  expand([MICROHAPLOT + "filtered_snps.recode.vcf", MICROHAPLOT + "{sample}.sorted.sam", MICROHAPLOT + "labels.txt", MAP_SAM + "{sample}.sorted.sam", FINAL_DOCS_IDXSTATS + "{sample}.idxstats", FINAL_VARIANTS + "Hardy_Weinberg_values", FINAL_DOCS_MULTIQC_IDXSTATS, FINAL_DOCS_MULTIQC_FLAGSTAT, FINAL_DOCS_MULTIQC_QUALIMAP, FINAL_DOCS_GENERALSTATS + "{sample}.generalStats", FINAL_DOCS_FLAGSTAT + "{sample}.flagstat", fastQC_raw + "{sample}.raw.{pair}.fastqc", fastQC + "{sample}.{pair}"],')
    (101, '\\t\\t    sample = SAMPLES_PE, pair = "1 2".split())')
    (102, '')
    (103, 'elif config["illumina_se"] is None and config["QC_Tests"] is False and config["Haplotyper"] is True and config["Validation"] is None and config["Flash"] is False:')
    (104, '\\trule all:')
    (105, '\\t\\tinput:')
    (106, '\\t\\t  HAPLOTYPE_DIR + "haplotypes.done",')
    (107, '\\t\\t  expand([MICROHAPLOT + "filtered_snps.recode.vcf", MICROHAPLOT + "{sample}.sorted.sam", MICROHAPLOT + "labels.txt", MAP_SAM + "{sample}.sorted.sam", FINAL_DOCS_IDXSTATS + "{sample}.idxstats", FINAL_VARIANTS + "Hardy_Weinberg_values", FINAL_DOCS_MULTIQC_IDXSTATS, FINAL_DOCS_MULTIQC_FLAGSTAT, FINAL_DOCS_GENERALSTATS + "{sample}.generalStats", FINAL_DOCS_FLAGSTAT + "{sample}.flagstat"],')
    (108, '\\t\\t\\tsample = SAMPLES_PE, pair = "1 2".split())')
    (109, '')
    (110, 'elif config["illumina_pe"] is None and config["QC_Tests"] is True and config["Haplotyper"] is True and config["Validation"] is None:')
    (111, '\\trule all:')
    (112, '\\t\\tinput:')
    (113, '\\t\\t\\tHAPLOTYPE_DIR + "haplotypes.done",')
    (114, '\\t\\t\\texpand([MICROHAPLOT + "filtered_snps.recode.vcf", MICROHAPLOT + "{sample}.sorted.sam", MICROHAPLOT + "labels.txt", MAP_SAM + "{sample}.sorted.sam", FINAL_DOCS_IDXSTATS + "{sample}.idxstats", FINAL_VARIANTS + "Hardy_Weinberg_values", FINAL_DOCS_MULTIQC_IDXSTATS, FINAL_DOCS_MULTIQC_FLAGSTAT, FINAL_DOCS_MULTIQC_QUALIMAP, FINAL_DOCS_GENERALSTATS + "{sample}.generalStats", FINAL_DOCS_FLAGSTAT + "{sample}.flagstat", fastQC_raw + "{sample}.raw.fastqc",fastQC + "{sample}.se"],')
    (115, '\\t\\t  \\t\\tsample = SAMPLES_SE)')
    (116, '')
    (117, 'elif config["illumina_pe"] is None and config["QC_Tests"] is False and config["Haplotyper"] is True and config["Validation"] is None:')
    (118, '\\trule all:')
    (119, '\\t\\tinput:')
    (120, '\\t\\t\\tHAPLOTYPE_DIR + "haplotypes.done",')
    (121, '\\t\\t\\texpand([MICROHAPLOT + "filtered_snps.recode.vcf", MICROHAPLOT + "{sample}.sorted.sam", MICROHAPLOT + "labels.txt", MAP_SAM + "{sample}.sorted.sam", FINAL_DOCS_IDXSTATS + "{sample}.idxstats", FINAL_VARIANTS + "Hardy_Weinberg_values", FINAL_DOCS_MULTIQC_IDXSTATS, FINAL_DOCS_MULTIQC_FLAGSTAT, FINAL_DOCS_GENERALSTATS + "{sample}.generalStats", FINAL_DOCS_FLAGSTAT + "{sample}.flagstat"],')
    (122, '\\t\\t\\t\\tsample = SAMPLES_SE)')
    (123, '')
    (124, '')
    (125, '#########################################################################################################')
    (126, '')
    (127, 'elif config["illumina_se"] is None and config["QC_Tests"] is True and config["Haplotyper"] is True and config["Validation"] is not None and config["Flash"] is False:')
    (128, '\\trule all:')
    (129, '\\t\\tinput:')
    (130, '\\t\\t  HAPLOTYPE_DIR + "haplotypes.done",')
    (131, '\\t\\t  expand([MICROHAPLOT + "Overlapping_filtered_snps.recode.vcf", MICROHAPLOT + "{sample}.sorted.sam", MICROHAPLOT + "labels.txt", MAP_SAM + "{sample}.sorted.sam", FINAL_DOCS_IDXSTATS + "{sample}.idxstats", FINAL_VARIANTS + "Hardy_Weinberg_values", FINAL_DOCS_MULTIQC_IDXSTATS, FINAL_DOCS_MULTIQC_FLAGSTAT, FINAL_DOCS_MULTIQC_QUALIMAP, FINAL_DOCS_GENERALSTATS + "{sample}.generalStats", FINAL_DOCS_FLAGSTAT + "{sample}.flagstat", fastQC_raw + "{sample}.raw.{pair}.fastqc", fastQC + "{sample}.{pair}", FINAL_VARIANTS + "Overlapping_SNPs_pe", FINAL_VARIANTS + "Overlapping_SNPs_pe.vcf"],')
    (132, '\\t\\t    sample = SAMPLES_PE, pair = "1 2".split())')
    (133, '')
    (134, 'elif config["illumina_se"] is None and config["QC_Tests"] is False and config["Haplotyper"] is True and config["Validation"] is not None and config["Flash"] is False:')
    (135, '\\trule all:')
    (136, '\\t\\tinput:')
    (137, '\\t\\t  HAPLOTYPE_DIR + "haplotypes.done",')
    (138, '\\t\\t  expand([MICROHAPLOT + "Overlapping_filtered_snps.recode.vcf", MICROHAPLOT + "{sample}.sorted.sam", MICROHAPLOT + "labels.txt", MAP_SAM + "{sample}.sorted.sam", FINAL_DOCS_IDXSTATS + "{sample}.idxstats", FINAL_VARIANTS + "Hardy_Weinberg_values", FINAL_DOCS_MULTIQC_IDXSTATS, FINAL_DOCS_MULTIQC_FLAGSTAT, FINAL_DOCS_GENERALSTATS + "{sample}.generalStats", FINAL_DOCS_FLAGSTAT + "{sample}.flagstat", FINAL_VARIANTS + "Overlapping_SNPs_pe", FINAL_VARIANTS + "Overlapping_SNPs_pe.vcf"],')
    (139, '\\t\\t  \\tsample = SAMPLES_PE, pair = "1 2".split())')
    (140, '')
    (141, 'elif config["illumina_pe"] is None and config["QC_Tests"] is True and config["Haplotyper"] is True and config["Validation"] is not None:')
    (142, '\\trule all:')
    (143, '\\t\\tinput:')
    (144, '\\t\\t\\tHAPLOTYPE_DIR + "haplotypes.done",')
    (145, '\\t\\t\\texpand([MICROHAPLOT + "Overlapping_filtered_snps.recode.vcf", MICROHAPLOT + "{sample}.sorted.sam", MICROHAPLOT + "labels.txt", MAP_SAM + "{sample}.sorted.sam", FINAL_DOCS_IDXSTATS + "{sample}.idxstats", FINAL_VARIANTS + "Hardy_Weinberg_values", FINAL_DOCS_MULTIQC_IDXSTATS, FINAL_DOCS_MULTIQC_FLAGSTAT, FINAL_DOCS_MULTIQC_QUALIMAP, FINAL_DOCS_GENERALSTATS + "{sample}.generalStats", FINAL_DOCS_FLAGSTAT + "{sample}.flagstat", fastQC_raw + "{sample}.raw.fastqc", fastQC + "{sample}.se", FINAL_VARIANTS + "Overlapping_SNPs_se", FINAL_VARIANTS + "Overlapping_SNPs_se.vcf"],')
    (146, '\\t\\t\\t\\tsample = SAMPLES_SE)')
    (147, '')
    (148, 'elif config["illumina_pe"] is None and config["QC_Tests"] is False and config["Haplotyper"] is True and config["Validation"] is not None:')
    (149, '\\trule all:')
    (150, '\\t\\tinput:')
    (151, '\\t\\t\\tHAPLOTYPE_DIR + "haplotypes.done",')
    (152, '\\t\\t\\texpand([MICROHAPLOT + "Overlapping_filtered_snps.recode.vcf", MICROHAPLOT + "{sample}.sorted.sam", MICROHAPLOT + "labels.txt", MAP_SAM + "{sample}.sorted.sam", FINAL_DOCS_IDXSTATS + "{sample}.idxstats", FINAL_VARIANTS + "Hardy_Weinberg_values", FINAL_DOCS_MULTIQC_IDXSTATS, FINAL_DOCS_MULTIQC_FLAGSTAT, FINAL_DOCS_GENERALSTATS + "{sample}.generalStats", FINAL_DOCS_FLAGSTAT + "{sample}.flagstat",  FINAL_VARIANTS + "Overlapping_SNPs_se", FINAL_VARIANTS + "Overlapping_SNPs_se.vcf"],')
    (153, '\\t\\t\\t\\tsample = SAMPLES_SE)')
    (154, '')
    (155, '#########################################################################################################')
    (156, '')
    (157, '')
    (158, 'elif config["illumina_se"] is None and config["QC_Tests"] is True and config["Haplotyper"] is False and config["Validation"] is not None and config["Flash"] is False:')
    (159, '\\trule all:')
    (160, '\\t\\tinput:')
    (161, '\\t\\t  \\texpand([FINAL_DOCS_IDXSTATS + "{sample}.idxstats", FINAL_VARIANTS + "Hardy_Weinberg_values", FINAL_DOCS_MULTIQC_IDXSTATS, FINAL_DOCS_MULTIQC_FLAGSTAT, FINAL_DOCS_MULTIQC_QUALIMAP, FINAL_DOCS_GENERALSTATS + "{sample}.generalStats", FINAL_DOCS_FLAGSTAT + "{sample}.flagstat", fastQC_raw + "{sample}.raw.{pair}.fastqc", fastQC + "{sample}.{pair}", FINAL_VARIANTS + "Overlapping_SNPs_pe", FINAL_VARIANTS + "Overlapping_SNPs_pe.vcf"],')
    (162, '\\t\\t    \\tsample = SAMPLES_PE, pair = "1 2".split())')
    (163, '')
    (164, 'elif config["illumina_se"] is None and config["QC_Tests"] is False and config["Haplotyper"] is False and config["Validation"] is not None and config["Flash"] is False:')
    (165, '\\trule all:')
    (166, '\\t\\tinput:')
    (167, '\\t\\t\\texpand([FINAL_DOCS_IDXSTATS + "{sample}.idxstats", FINAL_VARIANTS + "Hardy_Weinberg_values", FINAL_DOCS_MULTIQC_IDXSTATS, FINAL_DOCS_MULTIQC_FLAGSTAT, FINAL_DOCS_GENERALSTATS + "{sample}.generalStats", FINAL_DOCS_FLAGSTAT + "{sample}.flagstat", FINAL_VARIANTS + "Overlapping_SNPs_pe", FINAL_VARIANTS + "Overlapping_SNPs_pe.vcf", FINAL_VARIANTS + "Overlapping_SNPs_pe.vcf"],')
    (168, '\\t\\t\\t\\tsample = SAMPLES_PE, pair = "1 2".split())')
    (169, '')
    (170, 'elif config["illumina_pe"] is None and config["QC_Tests"] is True and config["Haplotyper"] is False and config["Validation"] is not None:')
    (171, '\\trule all:')
    (172, '\\t\\tinput:')
    (173, '\\t\\t\\texpand([FINAL_DOCS_IDXSTATS + "{sample}.idxstats", FINAL_VARIANTS + "Hardy_Weinberg_values", FINAL_DOCS_MULTIQC_IDXSTATS, FINAL_DOCS_MULTIQC_FLAGSTAT, FINAL_DOCS_MULTIQC_QUALIMAP, FINAL_DOCS_GENERALSTATS + "{sample}.generalStats", FINAL_DOCS_FLAGSTAT + "{sample}.flagstat", fastQC_raw + "{sample}.raw.fastqc", fastQC + "{sample}.se", FINAL_VARIANTS + "Overlapping_SNPs_se", FINAL_VARIANTS + "Overlapping_SNPs_se.vcf"],')
    (174, '\\t\\t  \\t\\tsample = SAMPLES_SE)')
    (175, '')
    (176, 'elif config["illumina_pe"] is None and config["QC_Tests"] is False and config["Haplotyper"] is False and config["Validation"] is not None:')
    (177, '\\trule all:')
    (178, '\\t\\tinput:')
    (179, '\\t\\t\\texpand([FINAL_DOCS_IDXSTATS + "{sample}.idxstats", FINAL_VARIANTS + "Hardy_Weinberg_values", FINAL_DOCS_MULTIQC_IDXSTATS, FINAL_DOCS_MULTIQC_FLAGSTAT, FINAL_DOCS_FLAGSTAT + "{sample}.flagstat", FINAL_DOCS_GENERALSTATS + "{sample}.generalStats", FINAL_VARIANTS + "Overlapping_SNPs_se", FINAL_VARIANTS + "Overlapping_SNPs_se.vcf"],')
    (180, '\\t\\t\\t\\tsample = SAMPLES_SE)')
    (181, '')
    (182, '#########################################################################################################')
    (183, '')
    (184, '')
    (185, 'elif config["illumina_se"] is None and config["QC_Tests"] is True and config["Haplotyper"] is False and config["Validation"] is None and config["Flash"] is True:')
    (186, '\\trule all:')
    (187, '\\t\\tinput:')
    (188, '\\t\\t  \\texpand([FLASHED_READS + "{sample}.flashed.extendedFrags.fastq.gz", FLASHED_READS + "{sample}.flashed", FINAL_DOCS_IDXSTATS + "{sample}.idxstats", FINAL_VARIANTS + "Hardy_Weinberg_values", FINAL_DOCS_MULTIQC_IDXSTATS, FINAL_DOCS_MULTIQC_FLAGSTAT, FINAL_DOCS_MULTIQC_QUALIMAP, FINAL_DOCS_GENERALSTATS + "{sample}.generalStats", FINAL_DOCS_FLAGSTAT + "{sample}.flagstat", fastQC_raw + "{sample}.raw.{pair}.fastqc", fastQC + "{sample}.{pair}"],')
    (189, '\\t\\t    \\tsample = SAMPLES_PE, pair = "1 2".split())')
    (190, '\\t\\t  ')
    (191, '')
    (192, 'elif config["illumina_se"] is None and config["QC_Tests"] is False and config["Haplotyper"] is False and config["Validation"] is None and config["Flash"] is True:')
    (193, '\\trule all:')
    (194, '\\t\\tinput:')
    (195, '\\t\\t\\texpand([FLASHED_READS + "{sample}.flashed.extendedFrags.fastq.gz", FLASHED_READS + "{sample}.flashed", FINAL_DOCS_IDXSTATS + "{sample}.idxstats", FINAL_VARIANTS + "Hardy_Weinberg_values", FINAL_DOCS_MULTIQC_IDXSTATS, FINAL_DOCS_MULTIQC_FLAGSTAT, FINAL_DOCS_GENERALSTATS + "{sample}.generalStats", FINAL_DOCS_FLAGSTAT + "{sample}.flagstat"],')
    (196, '\\t\\t\\t\\tsample = SAMPLES_PE, pair = "1 2".split())')
    (197, '')
    (198, 'elif config["illumina_se"] is None and config["QC_Tests"] is True and config["Haplotyper"] is True and config["Validation"] is None and config["Flash"] is True:')
    (199, '\\trule all:')
    (200, '\\t\\tinput:')
    (201, '\\t\\t  HAPLOTYPE_DIR + "haplotypes.done",')
    (202, '\\t\\t  expand([MICROHAPLOT + "filtered_snps.recode.vcf", MICROHAPLOT + "{sample}.sorted.sam", MICROHAPLOT + "labels.txt", MICROHAPLOT + "labels.txt", MAP_SAM + "{sample}.sorted.sam", FLASHED_READS + "{sample}.flashed.extendedFrags.fastq.gz", FLASHED_READS + "{sample}.flashed", FINAL_DOCS_IDXSTATS + "{sample}.idxstats", FINAL_VARIANTS + "Hardy_Weinberg_values", FINAL_DOCS_MULTIQC_IDXSTATS, FINAL_DOCS_MULTIQC_FLAGSTAT, FINAL_DOCS_MULTIQC_QUALIMAP, FINAL_DOCS_GENERALSTATS + "{sample}.generalStats", FINAL_DOCS_FLAGSTAT + "{sample}.flagstat", fastQC_raw + "{sample}.raw.{pair}.fastqc", fastQC + "{sample}.{pair}"],')
    (203, '\\t\\t    sample = SAMPLES_PE, pair = "1 2".split())')
    (204, '')
    (205, 'elif config["illumina_se"] is None and config["QC_Tests"] is False and config["Haplotyper"] is True and config["Validation"] is None and config["Flash"] is True:')
    (206, '\\trule all:')
    (207, '\\t\\tinput:')
    (208, '\\t\\t  HAPLOTYPE_DIR + "haplotypes.done",')
    (209, '\\t\\t  expand([MICROHAPLOT + "filtered_snps.recode.vcf", MICROHAPLOT + "{sample}.sorted.sam", MICROHAPLOT + "labels.txt", MAP_SAM + "{sample}.sorted.sam", FLASHED_READS + "{sample}.flashed.extendedFrags.fastq.gz", FLASHED_READS + "{sample}.flashed", FINAL_DOCS_IDXSTATS + "{sample}.idxstats", FINAL_VARIANTS + "Hardy_Weinberg_values", FINAL_DOCS_MULTIQC_IDXSTATS, FINAL_DOCS_MULTIQC_FLAGSTAT, FINAL_DOCS_GENERALSTATS + "{sample}.generalStats", FINAL_DOCS_FLAGSTAT + "{sample}.flagstat"],')
    (210, '\\t\\t\\tsample = SAMPLES_PE, pair = "1 2".split())')
    (211, '')
    (212, 'elif config["illumina_se"] is None and config["QC_Tests"] is True and config["Haplotyper"] is True and config["Validation"] is not None and config["Flash"] is True:')
    (213, '\\trule all:')
    (214, '\\t\\tinput:')
    (215, '\\t\\t  HAPLOTYPE_DIR + "haplotypes.done",')
    (216, '\\t\\t  expand([MICROHAPLOT + "Overlapping_filtered_snps.recode.vcf", MICROHAPLOT + "{sample}.sorted.sam", MICROHAPLOT + "labels.txt", MAP_SAM + "{sample}.sorted.sam", FLASHED_READS + "{sample}.flashed.extendedFrags.fastq.gz", FLASHED_READS + "{sample}.flashed", FINAL_DOCS_IDXSTATS + "{sample}.idxstats", FINAL_VARIANTS + "Hardy_Weinberg_values", FINAL_DOCS_MULTIQC_IDXSTATS, FINAL_DOCS_MULTIQC_FLAGSTAT, FINAL_DOCS_MULTIQC_QUALIMAP, FINAL_DOCS_GENERALSTATS + "{sample}.generalStats", FINAL_DOCS_FLAGSTAT + "{sample}.flagstat", fastQC_raw + "{sample}.raw.{pair}.fastqc", fastQC + "{sample}.{pair}", FINAL_VARIANTS + "Overlapping_SNPs_pe", FINAL_VARIANTS + "Overlapping_SNPs_pe.vcf"],')
    (217, '\\t\\t    sample = SAMPLES_PE, pair = "1 2".split())')
    (218, '')
    (219, 'elif config["illumina_se"] is None and config["QC_Tests"] is False and config["Haplotyper"] is True and config["Validation"] is not None and config["Flash"] is True:')
    (220, '\\trule all:')
    (221, '\\t\\tinput:')
    (222, '\\t\\t  HAPLOTYPE_DIR + "haplotypes.done",')
    (223, '\\t\\t  expand([MICROHAPLOT + "Overlapping_filtered_snps.recode.vcf", MICROHAPLOT + "{sample}.sorted.sam", MICROHAPLOT + "labels.txt", MAP_SAM + "{sample}.sorted.sam", FLASHED_READS + "{sample}.flashed.extendedFrags.fastq.gz", FLASHED_READS + "{sample}.flashed", FINAL_DOCS_IDXSTATS + "{sample}.idxstats", FINAL_VARIANTS + "Hardy_Weinberg_values", FINAL_DOCS_MULTIQC_IDXSTATS, FINAL_DOCS_MULTIQC_FLAGSTAT, FINAL_DOCS_GENERALSTATS + "{sample}.generalStats", FINAL_DOCS_FLAGSTAT + "{sample}.flagstat", FINAL_VARIANTS + "Overlapping_SNPs_pe", FINAL_VARIANTS + "Overlapping_SNPs_pe.vcf"],')
    (224, '\\t\\t  \\tsample = SAMPLES_PE, pair = "1 2".split())')
    (225, '')
    (226, 'elif config["illumina_se"] is None and config["QC_Tests"] is True and config["Haplotyper"] is False and config["Validation"] is not None and config["Flash"] is True:')
    (227, '\\trule all:')
    (228, '\\t\\tinput:')
    (229, '\\t\\t  \\texpand([ FLASHED_READS + "{sample}.flashed.extendedFrags.fastq.gz", FLASHED_READS + "{sample}.flashed", FINAL_DOCS_IDXSTATS + "{sample}.idxstats", FINAL_VARIANTS + "Hardy_Weinberg_values", FINAL_DOCS_MULTIQC_IDXSTATS, FINAL_DOCS_MULTIQC_FLAGSTAT, FINAL_DOCS_MULTIQC_QUALIMAP, FINAL_DOCS_GENERALSTATS + "{sample}.generalStats", FINAL_DOCS_FLAGSTAT + "{sample}.flagstat", fastQC_raw + "{sample}.raw.{pair}.fastqc", fastQC + "{sample}.{pair}", FINAL_VARIANTS + "Overlapping_SNPs_pe", FINAL_VARIANTS + "Overlapping_SNPs_pe.vcf"],')
    (230, '\\t\\t    \\tsample = SAMPLES_PE, pair = "1 2".split())')
    (231, '')
    (232, 'elif config["illumina_se"] is None and config["QC_Tests"] is False and config["Haplotyper"] is False and config["Validation"] is not None and config["Flash"] is True:')
    (233, '\\trule all:')
    (234, '\\t\\tinput:')
    (235, '\\t\\t\\texpand([ FLASHED_READS + "{sample}.flashed.extendedFrags.fastq.gz", FLASHED_READS + "{sample}.flashed", FINAL_DOCS_IDXSTATS + "{sample}.idxstats", FINAL_VARIANTS + "Hardy_Weinberg_values", FINAL_DOCS_MULTIQC_IDXSTATS, FINAL_DOCS_MULTIQC_FLAGSTAT, FINAL_DOCS_GENERALSTATS + "{sample}.generalStats", FINAL_DOCS_FLAGSTAT + "{sample}.flagstat", FINAL_VARIANTS + "Overlapping_SNPs_pe", FINAL_VARIANTS + "Overlapping_SNPs_pe.vcf", FINAL_VARIANTS + "Overlapping_SNPs_pe.vcf"],')
    (236, '\\t\\t\\t\\tsample = SAMPLES_PE, pair = "1 2".split())')
    (237, "'")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/qc.py
context_key: ['if config["illumina_se"] is None and config["QC_Tests"] is True', 'rule fastqc_raw_pe', 'input']
    (2, 'if config["illumina_se"] is None and config["QC_Tests"] is True:')
    (3, '    rule fastqc_raw_pe:')
    (4, '        input:')
    (5, '            RAW_DIR + "{sample}_{pair}.fq.gz",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/qc.py
context_key: ['if config["illumina_se"] is None and config["QC_Tests"] is True', 'rule fastqc_raw_pe', 'output']
    (6, '        output:')
    (7, '            fastQC_raw + "{sample}.raw.{pair}.fastqc"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/qc.py
context_key: ['if config["illumina_se"] is None and config["QC_Tests"] is True', 'rule fastqc_raw_pe', 'shell']
    (8, '        shell:')
    (9, '            """')
    (10, '            fastqc --outdir {fastQC_raw} {input} > {output}')
    (11, '            """')
    (12, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/qc.py
context_key: ['elif config["illumina_pe"] is None and config["QC_Tests"] is True', 'rule fastqc_raw_se', 'input']
    (13, 'elif config["illumina_pe"] is None and config["QC_Tests"] is True:')
    (14, '    rule fastqc_raw_se:')
    (15, '        input:')
    (16, '            RAW_DIR + "{sample}.se.fq.gz"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/qc.py
context_key: ['elif config["illumina_pe"] is None and config["QC_Tests"] is True', 'rule fastqc_raw_se', 'output']
    (17, '        output:')
    (18, '            fastQC_raw + "{sample}.raw.fastqc"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/qc.py
context_key: ['elif config["illumina_pe"] is None and config["QC_Tests"] is True', 'rule fastqc_raw_se', 'shell']
    (19, '        shell:')
    (20, '            """')
    (21, '            fastqc --outdir {fastQC_raw} {input} > {output}')
    (22, '            """')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/qc.py
context_key: ['if config["illumina_se"] is None', 'rule qc_trimmomatic_pe']
    (32, 'if config["illumina_se"] is None:')
    (33, '    rule qc_trimmomatic_pe:')
    (34, '        """')
    (35, '        Run trimmomatic in paired end mode to eliminate Illumina adaptors and')
    (36, '        remove low quality regions and reads.')
    (37, '        Inputs _1 and _2 are piped through gzip/pigz.')
    (38, '        Outputs _1 and _2 are piped to gzip/pigz (level 9).')
    (39, '        Outputs _3 and _4 are compressed with the builtin compressor from')
    (40, '        Trimmomatic. Further on they are catted and compressed with gzip/pigz')
    (41, '        (level 9).')
    (42, '        Note: The cut -f 1 -d " " is to remove additional fields in the FASTQ')
    (43, '        header. It is done posterior to the trimming since the output comes')
    (44, '        slower than the input is read.')
    (45, '        Number of threads used:')
    (46, '            4 for trimmomatic')
    (47, '            2 for gzip inputs')
    (48, '            2 for gzip outputs')
    (49, '            Total: 8')
    (50, '        """')
    (51, '        input:')
    (52, '            forward = RAW_DIR + "{sample}_1.fq.gz",')
    (53, '            reverse = RAW_DIR + "{sample}_2.fq.gz"')
    (54, '        output:')
    (55, '            forward     = QC_DIR + "{sample}.final.1.fq.gz",')
    (56, '            reverse     = QC_DIR + "{sample}.final.2.fq.gz",')
    (57, '            unpaired_pe    = protected(QC_DIR + "{sample}.final.unpaired.fq.gz")')
    (58, '        params:')
    (59, '            unpaired_1  = QC_DIR + "{sample}_3.fq.gz",')
    (60, '            unpaired_2  = QC_DIR + "{sample}_4.fq.gz",')
    (61, '            adapter     = lambda wildcards: config["illumina_pe"][wildcards.sample]["adapter"],')
    (62, '            phred       = lambda wildcards: config["illumina_pe"][wildcards.sample]["phred"],')
    (63, '            trimmomatic_params = config["Read Trimming"]["trimmomatic_params"]')
    (64, '        log:')
    (65, '            QC_DOC + "trimmomatic_pe_{sample}.log"')
    (66, '        benchmark:')
    (67, '            QC_DOC + "trimmomatic_pe_{sample}.json"')
    (68, '        threads:')
    (69, "            24 # I\\'ve been able to work with pigz and 24 trimmomatic threads.")
    (70, '        shell:')
    (71, '            """')
    (72, '            trimmomatic PE \\\\')
    (73, '                -threads {threads} \\\\')
    (74, '                -{params.phred} \\\\')
    (75, '                {input.forward} {input.reverse} \\\\')
    (76, '                {output.forward} {params.unpaired_1} {output.reverse} {params.unpaired_2} \\\\')
    (77, '                ILLUMINACLIP:{params.adapter}:2:30:10 \\\\')
    (78, '                {params.trimmomatic_params} \\\\')
    (79, '                2> {log}')
    (80, '')
    (81, '                zcat {params.unpaired_1} {params.unpaired_2} |')
    (82, '                cut -f 1 -d " " |')
    (83, '                pigz -9 > {output.unpaired_pe}')
    (84, '')
    (85, '            rm {params.unpaired_1} {params.unpaired_2}')
    (86, '            """')
    (87, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/qc.py
context_key: ['elif config["illumina_pe"] is None', 'rule qc_trimmomatic_se']
    (88, 'elif config["illumina_pe"] is None:')
    (89, '    rule qc_trimmomatic_se:')
    (90, '        """')
    (91, '        Run trimmomatic in paired end mode to eliminate Illumina adaptors and')
    (92, '        remove low quality regions and reads.')
    (93, '        Inputs _1 and _2 are piped through gzip/pigz.')
    (94, '        Outputs _1 and _2 are piped to gzip/pigz (level 9).')
    (95, '        Outputs _3 and _4 are compressed with the builtin compressor from')
    (96, '        Trimmomatic. Further on they are catted and compressed with gzip/pigz')
    (97, '        (level 9).')
    (98, '        Note: The cut -f 1 -d " " is to remove additional fields in the FASTQ')
    (99, '        header. It is done posterior to the trimming since the output comes')
    (100, '        slower than the input is read.')
    (101, '        Number of threads used:')
    (102, '            4 for trimmomatic')
    (103, '            2 for gzip inputs')
    (104, '            2 for gzip outputs')
    (105, '            Total: 8')
    (106, '        """')
    (107, '        input:')
    (108, '            single = RAW_DIR + "{sample}.se.fq.gz"')
    (109, '        output:')
    (110, '            single\\t= QC_DIR + "{sample}.se.final.fq.gz"')
    (111, '        params:')
    (112, '            adapter\\t= lambda wildcards: config["illumina_se"][wildcards.sample]["adapter"],')
    (113, '            phred\\t= lambda wildcards: config["illumina_se"][wildcards.sample]["phred"],')
    (114, '            trimmomatic_params = config["Read Trimming"]["trimmomatic_params"]')
    (115, '        log:')
    (116, '            QC_DOC + "trimmomatic_se_{sample}.log"')
    (117, '        benchmark:')
    (118, '            QC_DOC + "trimmomatic_se_{sample}.json"')
    (119, '        threads:')
    (120, "            24 # I\\'ve been able to work with pigz and 24 trimmomatic threads.")
    (121, '        shell:')
    (122, '            """')
    (123, '            trimmomatic SE \\\\')
    (124, '            \\t-threads {threads} \\\\')
    (125, '            \\t-{params.phred} \\\\')
    (126, '            \\t{input.single} \\\\')
    (127, '            \\t{output.single} \\\\')
    (128, '            \\tILLUMINACLIP:{params.adapter}:2:30:10 \\\\')
    (129, '            \\t{params.trimmomatic_params} \\\\')
    (130, '            \\t2> {log}')
    (131, '            """')
    (132, '')
    (133, '')
    (134, '')
    (135, '############################################################################################################')
    (136, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/qc.py
context_key: ['if config["illumina_se"] is None and config["QC_Tests"] is True', 'rule fastqc_pe', 'input']
    (137, 'if config["illumina_se"] is None and config["QC_Tests"] is True:')
    (138, '    rule fastqc_pe:')
    (139, '        input:')
    (140, '            QC_DIR + "{sample}.final.{pair}.fq.gz"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/qc.py
context_key: ['if config["illumina_se"] is None and config["QC_Tests"] is True', 'rule fastqc_pe', 'output']
    (141, '        output:')
    (142, '            fastQC + "{sample}.{pair}"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/qc.py
context_key: ['if config["illumina_se"] is None and config["QC_Tests"] is True', 'rule fastqc_pe', 'shell']
    (143, '        shell:')
    (144, '            """')
    (145, '            fastqc --outdir {fastQC} {input} > {output}')
    (146, '            """')
    (147, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/qc.py
context_key: ['elif config["illumina_pe"] is None and config["QC_Tests"] is True', 'rule fastqc_se', 'input']
    (148, 'elif config["illumina_pe"] is None and config["QC_Tests"] is True:')
    (149, '    rule fastqc_se:')
    (150, '        input:')
    (151, '            QC_DIR + "{sample}.se.final.fq.gz"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/qc.py
context_key: ['elif config["illumina_pe"] is None and config["QC_Tests"] is True', 'rule fastqc_se', 'output']
    (152, '        output:')
    (153, '            fastQC + "{sample}.se"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/qc.py
context_key: ['elif config["illumina_pe"] is None and config["QC_Tests"] is True', 'rule fastqc_se', 'shell']
    (154, '        shell:')
    (155, '            """')
    (156, '            fastqc --outdir {fastQC} {input} > {output}')
    (157, '            """')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/qc.py
context_key: ['else', 'if config["illumina_se"] is None and config["Flash"] is True', 'rule flash_pe_reads', 'input']
    (163, 'if config["illumina_se"] is None and config["Flash"] is True:')
    (164, '    rule flash_pe_reads:')
    (165, '        input:')
    (166, '            forward = QC_DIR + "{sample}.final.1.fq.gz",')
    (167, '            reverse = QC_DIR + "{sample}.final.2.fq.gz"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/qc.py
context_key: ['else', 'if config["illumina_se"] is None and config["Flash"] is True', 'output']
    (168, '        output:')
    (169, '            name = FLASHED_READS + "{sample}.flashed",')
    (170, '            file_name = FLASHED_READS + "{sample}.flashed.extendedFrags.fastq.gz"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/qc.py
context_key: ['else', 'if config["illumina_se"] is None and config["Flash"] is True', 'params']
    (171, '        params:')
    (172, '            scripts_dir = config["scripts_dir"],')
    (173, '            flash_params = config["FLASH"]["FLASH_params"]')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/qc.py
context_key: ['else', 'if config["illumina_se"] is None and config["Flash"] is True', 'threads']
    (174, '        threads:')
    (175, '            4')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/qc.py
context_key: ['else', 'if config["illumina_se"] is None and config["Flash"] is True', 'shell']
    (176, '        shell:')
    (177, '            "flash {params.flash_params} {input.forward} {input.reverse} -o {output.name} -z"')
    (178, '            #"{params.scripts_dir}/flash_reads.sh {input.forward} {input.reverse} {output.name}"')
    (179, '            "> {output.name} "   ')
    (180, '')
    (181, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/qc.py
context_key: ['elif config["illumina_pe"] is None']
    (182, 'elif config["illumina_pe"] is None:')
    (183, '    pass')
    (184, '')
    (185, '')
    (186, '############################################################################################################')
    (187, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/qc.py
context_key: ['if config["illumina_se"] is None', 'rule qc_results_pe', 'input']
    (188, 'if config["illumina_se"] is None:')
    (189, '    rule qc_results_pe:')
    (190, "        \\'\\'\\'Generate only the resulting files, not the reports\\'\\'\\'")
    (191, '        input:')
    (192, '            pe_files = expand(')
    (193, '                [QC_DIR + "{sample}.final.{pair}.fq.gz", fastQC_raw + "{sample}.raw.{pair}.fastqc", FLASHED_READS + "{sample}.flashed.extendedFrags.fastq.gz", FLASHED_READS + "{sample}.flashed"],')
    (194, '                sample = SAMPLES_PE,')
    (195, '                pair = "1 2".split()')
    (196, '            )')
    (197, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/qc.py
context_key: ['elif config["illumina_pe"] is None', 'rule qc_results_se', 'input']
    (198, 'elif config["illumina_pe"] is None:')
    (199, '    rule qc_results_se:')
    (200, "        \\'\\'\\'Generate only the resulting files, not the reports\\'\\'\\'")
    (201, '        input:')
    (202, '            se_files = expand(')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/qc.py
context_key: ['if config["illumina_se"] is None and config["QC_Tests"] is True', 'rule raw_results_fastqc_pe', 'input']
    (211, 'if config["illumina_se"] is None and config["QC_Tests"] is True:')
    (212, '    rule raw_results_fastqc_pe:')
    (213, '        """Checkpoint to generate all the links for raw data"""')
    (214, '        input:')
    (215, '            expand(')
    (216, '                fastQC_raw + "{sample}.raw.{pair}.fastqc.{extension}", ')
    (217, '                sample = SAMPLES_PE,')
    (218, '                pair = "1 2".split(),')
    (219, '                extension = "zip html".split()')
    (220, '                )')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/qc.py
context_key: ['elif config["illumina_pe"] is None and config["QC_Tests"] is True', 'rule raw_results_fastqc_se', 'input']
    (221, 'elif config["illumina_pe"] is None and config["QC_Tests"] is True:')
    (222, '    rule raw_results_fastqc_se:')
    (223, '        """Checkpoint to generate all the links for raw data"""')
    (224, '        input:')
    (225, '            expand(')
    (226, '                fastQC_raw + "{sample}.raw.fastqc.{extension}",')
    (227, '                sample = SAMPLES_SE,')
    (228, '                extension = "zip html".split()')
    (229, "           )'")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['if config["illumina_se"] is None and config["Flash"] is False', 'rule map_bwa_sample_pe', 'input']
    (22, 'if config["illumina_se"] is None and config["Flash"] is False:')
    (23, '   rule map_bwa_sample_pe:')
    (24, '        input:')
    (25, '            reference = RAW_DIR + "genome.fasta",')
    (26, '            index = RAW_DIR + "genome.fasta.bwt",')
    (27, '            forward = QC_DIR + "{sample}.final.1.fq.gz",')
    (28, '            reverse = QC_DIR + "{sample}.final.2.fq.gz"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['if config["illumina_se"] is None and config["Flash"] is False', 'rule map_bwa_sample_pe', 'output']
    (29, '        output:')
    (30, '            temp(MAP_DIR + "{sample}.unsorted.bam")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['if config["illumina_se"] is None and config["Flash"] is False', 'rule map_bwa_sample_pe', 'params']
    (31, '        params:')
    (32, '            rg="@RG\\\\tID:{sample}\\\\tSM:{sample}\\\\tPL:Illumina",')
    (33, '            bwa_params = config["BWA-Mapping"]["BWA_mem_params"],')
    (34, '            samtools_params = config["Samtools_mapping_params"]["samtools_view_params"]')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['if config["illumina_se"] is None and config["Flash"] is False', 'rule map_bwa_sample_pe', 'log']
    (35, '        log:')
    (36, '            MAP_DOC + "bwa_{sample}_pe.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['if config["illumina_se"] is None and config["Flash"] is False', 'rule map_bwa_sample_pe', 'benchmark']
    (37, '        benchmark:')
    (38, '            MAP_DOC + "bwa_{sample}_pe.json"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['if config["illumina_se"] is None and config["Flash"] is False', 'rule map_bwa_sample_pe', 'shell']
    (39, '        shell:')
    (40, '            "(bwa mem -R \\\'{params.rg}\\\' {params.bwa_params} {input.reference} {input.forward} {input.reverse} | "')
    (41, '            "samtools view {params.samtools_params} - "')
    (42, '            "> {output}) "')
    (43, '            "2> {log}"')
    (44, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['elif config["illumina_se"] is None and config["Flash"] is True', 'rule map_bwa_sample_pe_flashed', 'input']
    (45, 'elif config["illumina_se"] is None and config["Flash"] is True:')
    (46, '   rule map_bwa_sample_pe_flashed:')
    (47, '        input:')
    (48, '            reference = RAW_DIR + "genome.fasta",')
    (49, '            index = RAW_DIR + "genome.fasta.bwt",')
    (50, '            Flashed_read = FLASHED_READS + "{sample}.flashed.extendedFrags.fastq.gz"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['elif config["illumina_se"] is None and config["Flash"] is True', 'rule map_bwa_sample_pe_flashed', 'output']
    (51, '        output:')
    (52, '            temp(MAP_DIR + "{sample}.unsorted.bam")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['elif config["illumina_se"] is None and config["Flash"] is True', 'rule map_bwa_sample_pe_flashed', 'params']
    (53, '        params:')
    (54, '            rg="@RG\\\\tID:{sample}\\\\tSM:{sample}\\\\tPL:Illumina",')
    (55, '            bwa_params = config["BWA-Mapping"]["BWA_mem_params"],')
    (56, '            samtools_params = config["Samtools_mapping_params"]["samtools_view_params"]')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['elif config["illumina_se"] is None and config["Flash"] is True', 'rule map_bwa_sample_pe_flashed', 'log']
    (57, '        log:')
    (58, '            MAP_DOC + "bwa_{sample}.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['elif config["illumina_se"] is None and config["Flash"] is True', 'rule map_bwa_sample_pe_flashed', 'benchmark']
    (59, '        benchmark:')
    (60, '            MAP_DOC + "bwa_{sample}.json"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['elif config["illumina_se"] is None and config["Flash"] is True', 'rule map_bwa_sample_pe_flashed', 'shell']
    (61, '        shell:')
    (62, '            "(bwa mem -R \\\'{params.rg}\\\' {params.bwa_params} {input.reference} {input.Flashed_read} | "')
    (63, '            "samtools view {params.samtools_params} - "')
    (64, '            "> {output}) "')
    (65, '            "2> {log}"')
    (66, '')
    (67, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['elif config["illumina_pe"] is None', 'rule map_bwa_sample_se', 'input']
    (68, 'elif config["illumina_pe"] is None:')
    (69, '    rule map_bwa_sample_se:')
    (70, '        input:')
    (71, '            reference = RAW_DIR + "genome.fasta",')
    (72, '            index = RAW_DIR + "genome.fasta.bwt",')
    (73, '            single = QC_DIR + "{sample}.se.final.fq.gz"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['elif config["illumina_pe"] is None', 'rule map_bwa_sample_se', 'output']
    (74, '        output:')
    (75, '            temp(MAP_DIR + "{sample}.unsorted.bam")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['elif config["illumina_pe"] is None', 'rule map_bwa_sample_se', 'params']
    (76, '        params:')
    (77, '            rg="@RG\\\\tID:{sample}\\\\tSM:{sample}\\\\tPL:Illumina",')
    (78, '            bwa_params = config["BWA-Mapping"]["BWA_mem_params"],')
    (79, '            samtools_params = config["Samtools_mapping_params"]["samtools_view_params"]')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['elif config["illumina_pe"] is None', 'rule map_bwa_sample_se', 'log']
    (80, '        log:')
    (81, '            MAP_DOC + "bwa_{sample}.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['elif config["illumina_pe"] is None', 'rule map_bwa_sample_se', 'benchmark']
    (82, '        benchmark:')
    (83, '            MAP_DOC + "bwa_{sample}.json"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['elif config["illumina_pe"] is None', 'rule map_bwa_sample_se', 'shell']
    (84, '        shell:')
    (85, '            "(bwa mem -R \\\'{params.rg}\\\' {params.bwa_params} {input.reference} {input.single} | "')
    (86, '            "samtools view {params.samtools_params} - "')
    (87, '            "> {output}) "')
    (88, '            "2> {log}"')
    (89, '')
    (90, '#########################################################################################################')
    (91, '')
    (92, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['if config["illumina_se"] is None', 'rule map_MultiQC_Samtools_sample_pe', 'input']
    (235, 'if config["illumina_se"] is None:')
    (236, '    rule map_MultiQC_Samtools_sample_pe:')
    (237, '        input:')
    (238, '            idxstats = expand(FINAL_DOCS_IDXSTATS + "{sample}.idxstats", sample = SAMPLES_PE),')
    (239, '            flagstat = expand(FINAL_DOCS_FLAGSTAT + "{sample}.flagstat", sample = SAMPLES_PE)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['if config["illumina_se"] is None', 'rule map_MultiQC_Samtools_sample_pe', 'output']
    (240, '        output:')
    (241, '            MultiQC_idxstats = FINAL_DOCS_MULTIQC_IDXSTATS,')
    (242, '            MultiQC_flagstat = FINAL_DOCS_MULTIQC_FLAGSTAT')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['if config["illumina_se"] is None', 'rule map_MultiQC_Samtools_sample_pe', 'shell']
    (243, '        shell:')
    (244, '            """')
    (245, '            multiqc -m samtools {input.idxstats} -o {output.MultiQC_idxstats}')
    (246, '            multiqc -m samtools {input.flagstat} -o {output.MultiQC_flagstat}')
    (247, '            """')
    (248, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['elif config["illumina_pe"] is None', 'rule map_MultiQC_Samtools_se', 'input']
    (249, 'elif config["illumina_pe"] is None:')
    (250, '    rule map_MultiQC_Samtools_se:')
    (251, '        input:')
    (252, '            idxstats = expand(FINAL_DOCS_IDXSTATS + "{sample}.idxstats", sample = SAMPLES_SE),')
    (253, '            flagstat = expand(FINAL_DOCS_FLAGSTAT + "{sample}.flagstat", sample = SAMPLES_SE)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['elif config["illumina_pe"] is None', 'rule map_MultiQC_Samtools_se', 'output']
    (254, '        output:')
    (255, '            MultiQC_idxstats = FINAL_DOCS_MULTIQC_IDXSTATS,')
    (256, '            MultiQC_flagstat = FINAL_DOCS_MULTIQC_FLAGSTAT')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['elif config["illumina_pe"] is None', 'rule map_MultiQC_Samtools_se', 'shell']
    (257, '        shell:')
    (258, '            """')
    (259, '            multiqc -m samtools {input.idxstats} -o {output.MultiQC_idxstats}')
    (260, '            multiqc -m samtools {input.flagstat} -o {output.MultiQC_flagstat}')
    (261, '            """')
    (262, '')
    (263, '#########################################################################################################')
    (264, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['if config["illumina_se"] is None and config["QC_Tests"] is True', 'rule map_MultiQC_Qualimap_sample_pe', 'input']
    (265, 'if config["illumina_se"] is None and config["QC_Tests"] is True:')
    (266, '    rule map_MultiQC_Qualimap_sample_pe:')
    (267, '        input:')
    (268, '            QUALIMAP = expand(FINAL_DOCS_QUALIMAP + "{sample}.qualimap", sample = SAMPLES_PE)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['if config["illumina_se"] is None and config["QC_Tests"] is True', 'rule map_MultiQC_Qualimap_sample_pe', 'output']
    (269, '        output:')
    (270, '            MULTIQC_QUALIMAP = FINAL_DOCS_MULTIQC_QUALIMAP')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['if config["illumina_se"] is None and config["QC_Tests"] is True', 'rule map_MultiQC_Qualimap_sample_pe', 'shell']
    (271, '        shell:')
    (272, '            """')
    (273, '            multiqc -m qualimap {input.QUALIMAP} -o {output.MULTIQC_QUALIMAP}')
    (274, '            """')
    (275, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['elif config["illumina_pe"] is None and config["QC_Tests"] is True', 'rule map_MultiQC_Qualimap_sample_se', 'input']
    (276, 'elif config["illumina_pe"] is None and config["QC_Tests"] is True:')
    (277, '    rule map_MultiQC_Qualimap_sample_se:')
    (278, '        input:')
    (279, '            QUALIMAP = expand(FINAL_DOCS_QUALIMAP + "{sample}.qualimap", sample = SAMPLES_SE)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['elif config["illumina_pe"] is None and config["QC_Tests"] is True', 'rule map_MultiQC_Qualimap_sample_se', 'output']
    (280, '        output:')
    (281, '            MULTIQC_QUALIMAP = FINAL_DOCS_MULTIQC_QUALIMAP')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['elif config["illumina_pe"] is None and config["QC_Tests"] is True', 'rule map_MultiQC_Qualimap_sample_se', 'shell']
    (282, '        shell:')
    (283, '            """')
    (284, '            multiqc -m qualimap {input.QUALIMAP} -o {output.MULTIQC_QUALIMAP}')
    (285, '            """')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['else', 'if config["illumina_se"] is None', 'rule map_merge_bam_pe', 'input']
    (291, 'if config["illumina_se"] is None:')
    (292, '    rule map_merge_bam_pe:')
    (293, '        input:')
    (294, '            bam = expand(MAP_DIR + "{sample}.sorted.bam",')
    (295, '                         sample = SAMPLES_PE),')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['else', 'if config["illumina_se"] is None', 'rule map_merge_bam_pe']
    (296, '            bai = expand(MAP_DIR + "{sample}.sorted.bam.bai",')
    (297, '                         sample = SAMPLES_PE)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['else', 'if config["illumina_se"] is None', 'output']
    (298, '        output:')
    (299, '            BAM_1 = MAP_DIR + "merged.bam",')
    (300, '            BAM_2 = BAM_FILES + "merged.bam",')
    (301, '            BAI_1 = BAM_FILES + "merged.bam.bai",')
    (302, '            BAI_2 = MAP_DIR + "merged.bam.bai",')
    (303, '            MD5_1 = MAP_DIR + "mergedMD5.txt",')
    (304, '            MD5_2 = BAM_FILES + "mergedMD5.txt"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['else', 'if config["illumina_se"] is None', 'log']
    (305, '        log:')
    (306, '            MAP_DOC + "merge_bam_pe.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['else', 'if config["illumina_se"] is None', 'benchmark']
    (307, '        benchmark:')
    (308, '            MAP_DOC + "merge_bam_pe.json"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['else', 'if config["illumina_se"] is None', 'shell']
    (309, '        shell:')
    (310, '            """')
    (311, '            samtools merge {output.BAM_1} {input.bam} > {log} 2>&1')
    (312, '            cp {output.BAM_1} {output.BAM_2}')
    (313, '            md5sum {output.BAM_1} > {output.MD5_1}')
    (314, '            md5sum {output.BAM_1} > {output.MD5_2}')
    (315, '            samtools index {output.BAM_1} {output.BAI_1}')
    (316, '            cp {output.BAI_1} {output.BAI_2}')
    (317, '            """')
    (318, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['elif config["illumina_pe"] is None', 'rule map_merge_bam_se', 'input']
    (319, 'elif config["illumina_pe"] is None:')
    (320, '    rule map_merge_bam_se:')
    (321, '        input:')
    (322, '            bam = expand(MAP_DIR + "{sample}.sorted.bam",')
    (323, '                         sample = SAMPLES_SE),')
    (324, '            bai = expand(MAP_DIR + "{sample}.sorted.bam.bai",')
    (325, '                         sample = SAMPLES_SE)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['elif config["illumina_pe"] is None', 'rule map_merge_bam_se', 'output']
    (326, '        output:')
    (327, '            BAM_1 = MAP_DIR + "merged.bam",')
    (328, '            BAM_2 = BAM_FILES + "merged.bam",')
    (329, '            BAI_1 = BAM_FILES + "merged.bam.bai",')
    (330, '            BAI_2 = MAP_DIR + "merged.bam.bai",')
    (331, '            MD5_1 = MAP_DIR + "mergedMD5.txt",')
    (332, '            MD5_2 = BAM_FILES + "mergedMD5.txt"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['elif config["illumina_pe"] is None', 'rule map_merge_bam_se', 'log']
    (333, '        log:')
    (334, '            MAP_DOC + "merge_bam_se.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['elif config["illumina_pe"] is None', 'rule map_merge_bam_se', 'benchmark']
    (335, '        benchmark:')
    (336, '            MAP_DOC + "merge_bam_se.json"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['elif config["illumina_pe"] is None', 'rule map_merge_bam_se', 'shell']
    (337, '        shell:')
    (338, '            """')
    (339, '            samtools merge {output.BAM_1} {input.bam} > {log} 2>&1')
    (340, '            cp {output.BAM_1} {output.BAM_2}')
    (341, '            md5sum {output.BAM_1} > {output.MD5_1}')
    (342, '            md5sum {output.BAM_1} > {output.MD5_2}')
    (343, '            samtools index {output.BAM_1} {output.BAI_1}')
    (344, '            cp {output.BAI_1} {output.BAI_2}')
    (345, '            """')
    (346, '')
    (347, '#########################################################################################################')
    (348, '')
    (349, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['if config["illumina_se"] is None and config["Flash"] is False', 'rule map_samtools_properly_paired_pe', 'input']
    (350, 'if config["illumina_se"] is None and config["Flash"] is False:')
    (351, '    rule map_samtools_properly_paired_pe:')
    (352, '        input:')
    (353, '            MAP_DIR + "merged.bam"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['if config["illumina_se"] is None and config["Flash"] is False', 'rule map_samtools_properly_paired_pe', 'output']
    (354, '        output:')
    (355, '            BAM_1 = MAP_DIR + "merged_properly_paired.bam",')
    (356, '            BAM_2 = BAM_FILES + "merged_properly_paired.bam"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['if config["illumina_se"] is None and config["Flash"] is False', 'rule map_samtools_properly_paired_pe', 'params']
    (357, '        params:')
    (358, '            samtools_params = config["Samtools_mapping_params"]["samtools_view_params"],')
    (359, '            samtools_filtering_params = config["Samtools_read_filtering"]["samtools_view_filtering"]')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['if config["illumina_se"] is None and config["Flash"] is False', 'rule map_samtools_properly_paired_pe', 'log']
    (360, '        log:')
    (361, '            MAP_DOC + "properly_paired_merged.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['if config["illumina_se"] is None and config["Flash"] is False', 'rule map_samtools_properly_paired_pe', 'benchmark']
    (362, '        benchmark:')
    (363, '            MAP_DOC + "properly_paired_merged.json"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['if config["illumina_se"] is None and config["Flash"] is False', 'rule map_samtools_properly_paired_pe', 'shell']
    (364, '        shell:')
    (365, '            """')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['elif config["illumina_se"] is None and config["Flash"] is True']
    (370, 'elif config["illumina_se"] is None and config["Flash"] is True:')
    (371, '    pass')
    (372, '')
    (373, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['elif config["illumina_pe"] is None']
    (374, 'elif config["illumina_pe"] is None:')
    (375, '    pass')
    (376, '')
    (377, '')
    (378, '#########################################################################################################')
    (379, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['if config["illumina_se"] is None', 'rule properly_paired_index_pe', 'input']
    (380, 'if config["illumina_se"] is None:')
    (381, '    rule properly_paired_index_pe:')
    (382, '        input:')
    (383, '            MAP_DIR + "merged_properly_paired.bam"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['if config["illumina_se"] is None', 'rule properly_paired_index_pe', 'output']
    (384, '        output:')
    (385, '            BAI_1 = MAP_DIR + "merged_properly_paired.bam.bai",')
    (386, '            BAI_2 = BAM_FILES + "merged_properly_paired.bam.bai"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['if config["illumina_se"] is None', 'rule properly_paired_index_pe', 'log']
    (387, '        log:')
    (388, '            MAP_DOC + "index_merged_properly_paired.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['if config["illumina_se"] is None', 'rule properly_paired_index_pe', 'benchmark']
    (389, '        benchmark:')
    (390, '            MAP_DOC + "index_merged_properly_paired.json"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['if config["illumina_se"] is None', 'rule properly_paired_index_pe', 'shell']
    (391, '        shell:')
    (392, '            """')
    (393, '            samtools index {input} {output.BAI_1}')
    (394, '            cp {output.BAI_1} {output.BAI_2}')
    (395, '            """')
    (396, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['elif config["illumina_se"] is None and config["Flash"] is True']
    (397, 'elif config["illumina_se"] is None and config["Flash"] is True:')
    (398, '    pass')
    (399, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['elif config["illumina_pe"] is None']
    (400, 'elif config["illumina_pe"] is None:')
    (401, '    pass')
    (402, '')
    (403, '#########################################################################################################')
    (404, '')
    (405, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['if config["illumina_se"] is None', 'rule map', 'input']
    (406, 'if config["illumina_se"] is None:')
    (407, '    rule map:')
    (408, '        input:')
    (409, '            MAP_DIR + "merged.bam.bai",')
    (410, '            expand([FINAL_DOCS_IDXSTATS + "{sample}.idxstats", FINAL_DOCS_FLAGSTAT + "{sample}.flagstat", FINAL_DOCS_GENERALSTATS + "{sample}.generalStats"],')
    (411, '                sample = SAMPLES_PE)')
    (412, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/map.py
context_key: ['elif config["illumina_pe"] is None', 'rule map', 'input']
    (413, 'elif config["illumina_pe"] is None:')
    (414, '    rule map:')
    (415, '        input:')
    (416, '            MAP_DIR + "merged.bam.bai",')
    (417, '            expand([FINAL_DOCS_IDXSTATS + "{sample}.idxstats", FINAL_DOCS_FLAGSTAT + "{sample}.flagstat", FINAL_DOCS_GENERALSTATS + "{sample}.generalStats"],')
    (418, "                sample = SAMPLES_SE)'")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/haplotype.py
context_key: ['elif config["Haplotyper"] is True and config["Validation"] is not None', 'rule haplotype_make_overlapping_vcf_link_pe', 'input']
    (19, 'elif config["Haplotyper"] is True and config["Validation"] is not None:')
    (20, '    rule haplotype_make_overlapping_vcf_link_pe:')
    (21, '        """')
    (22, '        Make symlinks to run rad_haplotyper')
    (23, '        """')
    (24, '        input:')
    (25, '            vcf = FINAL_VARIANTS + "Overlapping_SNPs.vcf"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/haplotype.py
context_key: ['elif config["Haplotyper"] is True and config["Validation"] is not None', 'rule haplotype_make_overlapping_vcf_link_pe', 'output']
    (26, '        output:')
    (27, '            vcf = HAPLOTYPE_DIR + "Overlapping_filtered_snps.recode.vcf"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/haplotype.py
context_key: ['elif config["Haplotyper"] is True and config["Validation"] is not None', 'rule haplotype_make_overlapping_vcf_link_pe', 'threads']
    (28, '        threads:')
    (29, '            1')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/haplotype.py
context_key: ['elif config["Haplotyper"] is True and config["Validation"] is not None', 'rule haplotype_make_overlapping_vcf_link_pe', 'log']
    (30, '        log:')
    (31, '            HAPLOTYPE_DOC + "make_vcf_link.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/haplotype.py
context_key: ['elif config["Haplotyper"] is True and config["Validation"] is not None', 'rule haplotype_make_overlapping_vcf_link_pe', 'benchmark']
    (32, '        benchmark:')
    (33, '            HAPLOTYPE_DOC + "make_vcf_link.json"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/haplotype.py
context_key: ['elif config["Haplotyper"] is True and config["Validation"] is not None', 'rule haplotype_make_overlapping_vcf_link_pe', 'shell']
    (34, '        shell:')
    (35, '            "ln -s $(readlink -f {input.vcf}) {output.vcf} 2> {log} "')
    (36, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/haplotype.py
context_key: ['else', 'if config["Haplotyper"] is True and config["Validation"] is None', 'rule haplotype_make_bam_links_pe', 'input']
    (42, 'if config["Haplotyper"] is True and config["Validation"] is None:')
    (43, '    rule haplotype_make_bam_links_pe:')
    (44, '        """')
    (45, '        Make symlinks to run rad_haplotyper')
    (46, '        """')
    (47, '        input:')
    (48, '            vcf = HAPLOTYPE_DIR + "filtered_snps.recode.vcf",')
    (49, '            bam = MAP_DIR + "{sample}.sorted.bam",')
    (50, '            bai = MAP_DIR + "{sample}.sorted.bam.bai"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/haplotype.py
context_key: ['else', 'if config["Haplotyper"] is True and config["Validation"] is None', 'output']
    (51, '        output:')
    (52, '            bam = HAPLOTYPE_DIR + "{sample}.bam",')
    (53, '            bai = HAPLOTYPE_DIR + "{sample}.bam.bai"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/haplotype.py
context_key: ['else', 'if config["Haplotyper"] is True and config["Validation"] is None', 'threads']
    (54, '        threads:')
    (55, '            1')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/haplotype.py
context_key: ['else', 'if config["Haplotyper"] is True and config["Validation"] is None', 'log']
    (56, '        log:')
    (57, '            HAPLOTYPE_DOC + "make_bam_links.{sample}.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/haplotype.py
context_key: ['else', 'if config["Haplotyper"] is True and config["Validation"] is None', 'benchmark']
    (58, '        benchmark:')
    (59, '            HAPLOTYPE_DOC + "make_bam_links.{sample}.json"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/haplotype.py
context_key: ['else', 'if config["Haplotyper"] is True and config["Validation"] is None', 'shell']
    (60, '        shell:')
    (61, '            "ln -s $(readlink -f {input.bam}) {output.bam} 2> {log}; "')
    (62, '            "ln -s $(readlink -f {input.bai}) {output.bai} 2> {log}; "')
    (63, '')
    (64, '')
    (65, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/haplotype.py
context_key: ['else', 'if config["illumina_se"] is None and config["Haplotyper"] is True and config["Validation"] is None', 'rule haplotype_make_popmap_pe', 'input']
    (94, 'if config["illumina_se"] is None and config["Haplotyper"] is True and config["Validation"] is None:')
    (95, '    rule haplotype_make_popmap_pe:')
    (96, '        """')
    (97, '        Make popmap to run rad_haplotyper')
    (98, '        """')
    (99, '        input:')
    (100, '            vcf = HAPLOTYPE_DIR + "filtered_snps.recode.vcf",')
    (101, '            bam = expand(HAPLOTYPE_DIR + "{sample}.bam",')
    (102, '                         sample = SAMPLES_PE)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/haplotype.py
context_key: ['else', 'if config["illumina_se"] is None and config["Haplotyper"] is True and config["Validation"] is None', 'output']
    (103, '        output:')
    (104, '            popmap = HAPLOTYPE_DIR + "popmap"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/haplotype.py
context_key: ['else', 'if config["illumina_se"] is None and config["Haplotyper"] is True and config["Validation"] is None', 'threads']
    (105, '        threads:')
    (106, '            1')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/haplotype.py
context_key: ['else', 'if config["illumina_se"] is None and config["Haplotyper"] is True and config["Validation"] is None', 'params']
    (107, '        params:')
    (108, '            hap_dir = HAPLOTYPE_DIR')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/haplotype.py
context_key: ['else', 'if config["illumina_se"] is None and config["Haplotyper"] is True and config["Validation"] is None', 'log']
    (109, '        log:')
    (110, '            HAPLOTYPE_DOC + "make_popmap.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/haplotype.py
context_key: ['else', 'if config["illumina_se"] is None and config["Haplotyper"] is True and config["Validation"] is None', 'benchmark']
    (111, '        benchmark:')
    (112, '            HAPLOTYPE_DOC + "make_popmap.json"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/haplotype.py
context_key: ['else', 'if config["illumina_se"] is None and config["Haplotyper"] is True and config["Validation"] is None', 'shell']
    (113, '        shell:')
    (114, '            "ls {params.hap_dir}/*.bam | sed \\\'s/.bam//\\\' | awk \\\'{{print $1, 1}}\\\' > {output.popmap} "')
    (115, '')
    (116, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/haplotype.py
context_key: ['elif config["illumina_pe"] is None and config["Haplotyper"] is True and config["Validation"] is None', 'rule haplotype_make_popmap_se', 'input']
    (117, 'elif config["illumina_pe"] is None and config["Haplotyper"] is True and config["Validation"] is None:')
    (118, '    rule haplotype_make_popmap_se:')
    (119, '        """')
    (120, '        Make popmap to run rad_haplotyper')
    (121, '        """')
    (122, '        input:')
    (123, '            vcf = HAPLOTYPE_DIR + "filtered_snps.recode.vcf",')
    (124, '            bam = expand(HAPLOTYPE_DIR + "{sample}.bam",')
    (125, '                         sample = SAMPLES_SE)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/haplotype.py
context_key: ['elif config["illumina_pe"] is None and config["Haplotyper"] is True and config["Validation"] is None', 'rule haplotype_make_popmap_se', 'output']
    (126, '        output:')
    (127, '            popmap = HAPLOTYPE_DIR + "popmap"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/haplotype.py
context_key: ['elif config["illumina_pe"] is None and config["Haplotyper"] is True and config["Validation"] is None', 'rule haplotype_make_popmap_se', 'threads']
    (128, '        threads:')
    (129, '            1')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/haplotype.py
context_key: ['elif config["illumina_pe"] is None and config["Haplotyper"] is True and config["Validation"] is None', 'rule haplotype_make_popmap_se', 'params']
    (130, '        params:')
    (131, '            hap_dir = HAPLOTYPE_DIR')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/haplotype.py
context_key: ['elif config["illumina_pe"] is None and config["Haplotyper"] is True and config["Validation"] is None', 'rule haplotype_make_popmap_se', 'log']
    (132, '        log:')
    (133, '            HAPLOTYPE_DOC + "make_popmap.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/haplotype.py
context_key: ['elif config["illumina_pe"] is None and config["Haplotyper"] is True and config["Validation"] is None', 'rule haplotype_make_popmap_se', 'benchmark']
    (134, '        benchmark:')
    (135, '            HAPLOTYPE_DOC + "make_popmap.json"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/haplotype.py
context_key: ['elif config["illumina_pe"] is None and config["Haplotyper"] is True and config["Validation"] is None', 'rule haplotype_make_popmap_se', 'shell']
    (136, '        shell:')
    (137, '            "ls {params.hap_dir}/*.bam | sed \\\'s/.bam//\\\' | awk \\\'{{print $1, 1}}\\\' > {output.popmap} "')
    (138, '')
    (139, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/haplotype.py
context_key: ['elif config["illumina_se"] is None and config["Haplotyper"] is True and config["Validation"] is not None', 'rule haplotype_make_popmap_overlapping_SNPs_pe', 'input']
    (140, 'elif config["illumina_se"] is None and config["Haplotyper"] is True and config["Validation"] is not None:')
    (141, '    rule haplotype_make_popmap_overlapping_SNPs_pe:')
    (142, '        """')
    (143, '        Make popmap to run rad_haplotyper')
    (144, '        """')
    (145, '        input:')
    (146, '            vcf = HAPLOTYPE_DIR + "Overlapping_filtered_snps.recode.vcf",')
    (147, '            bam = expand(HAPLOTYPE_DIR + "{sample}.bam",')
    (148, '                         sample = SAMPLES_PE)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/haplotype.py
context_key: ['elif config["illumina_se"] is None and config["Haplotyper"] is True and config["Validation"] is not None', 'rule haplotype_make_popmap_overlapping_SNPs_pe', 'output']
    (149, '        output:')
    (150, '            popmap = HAPLOTYPE_DIR + "popmap"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/haplotype.py
context_key: ['elif config["illumina_se"] is None and config["Haplotyper"] is True and config["Validation"] is not None', 'rule haplotype_make_popmap_overlapping_SNPs_pe', 'threads']
    (151, '        threads:')
    (152, '            1')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/haplotype.py
context_key: ['elif config["illumina_se"] is None and config["Haplotyper"] is True and config["Validation"] is not None', 'rule haplotype_make_popmap_overlapping_SNPs_pe', 'params']
    (153, '        params:')
    (154, '            hap_dir = HAPLOTYPE_DIR')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/haplotype.py
context_key: ['elif config["illumina_se"] is None and config["Haplotyper"] is True and config["Validation"] is not None', 'rule haplotype_make_popmap_overlapping_SNPs_pe', 'log']
    (155, '        log:')
    (156, '            HAPLOTYPE_DOC + "make_popmap.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/haplotype.py
context_key: ['elif config["illumina_se"] is None and config["Haplotyper"] is True and config["Validation"] is not None', 'rule haplotype_make_popmap_overlapping_SNPs_pe', 'benchmark']
    (157, '        benchmark:')
    (158, '            HAPLOTYPE_DOC + "make_popmap.json"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/haplotype.py
context_key: ['elif config["illumina_se"] is None and config["Haplotyper"] is True and config["Validation"] is not None', 'rule haplotype_make_popmap_overlapping_SNPs_pe', 'shell']
    (159, '        shell:')
    (160, '            "ls {params.hap_dir}/*.bam | sed \\\'s/.bam//\\\' | awk \\\'{{print $1, 1}}\\\' > {output.popmap} "')
    (161, '')
    (162, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/haplotype.py
context_key: ['elif config["illumina_pe"] is None and config["Haplotyper"] is True and config["Validation"] is not None', 'rule haplotype_make_popmap_overlapping_SNPs_se', 'input']
    (163, 'elif config["illumina_pe"] is None and config["Haplotyper"] is True and config["Validation"] is not None:')
    (164, '    rule haplotype_make_popmap_overlapping_SNPs_se:')
    (165, '        """')
    (166, '        Make popmap to run rad_haplotyper')
    (167, '        """')
    (168, '        input:')
    (169, '            vcf = HAPLOTYPE_DIR + "Overlapping_filtered_snps.recode.vcf",')
    (170, '            bam = expand(HAPLOTYPE_DIR + "{sample}.bam",')
    (171, '                         sample = SAMPLES_SE)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/haplotype.py
context_key: ['elif config["illumina_pe"] is None and config["Haplotyper"] is True and config["Validation"] is not None', 'rule haplotype_make_popmap_overlapping_SNPs_se', 'output']
    (172, '        output:')
    (173, '            popmap = HAPLOTYPE_DIR + "popmap"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/haplotype.py
context_key: ['elif config["illumina_pe"] is None and config["Haplotyper"] is True and config["Validation"] is not None', 'rule haplotype_make_popmap_overlapping_SNPs_se', 'threads']
    (174, '        threads:')
    (175, '            1')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/haplotype.py
context_key: ['elif config["illumina_pe"] is None and config["Haplotyper"] is True and config["Validation"] is not None', 'rule haplotype_make_popmap_overlapping_SNPs_se', 'params']
    (176, '        params:')
    (177, '            hap_dir = HAPLOTYPE_DIR')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/haplotype.py
context_key: ['elif config["illumina_pe"] is None and config["Haplotyper"] is True and config["Validation"] is not None', 'rule haplotype_make_popmap_overlapping_SNPs_se', 'log']
    (178, '        log:')
    (179, '            HAPLOTYPE_DOC + "make_popmap.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/haplotype.py
context_key: ['elif config["illumina_pe"] is None and config["Haplotyper"] is True and config["Validation"] is not None', 'rule haplotype_make_popmap_overlapping_SNPs_se', 'benchmark']
    (180, '        benchmark:')
    (181, '            HAPLOTYPE_DOC + "make_popmap.json"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skyriakidis/Snakemake_haps, file=bin/snakefiles/haplotype.py
context_key: ['elif config["illumina_pe"] is None and config["Haplotyper"] is True and config["Validation"] is not None', 'rule haplotype_make_popmap_overlapping_SNPs_se', 'shell']
    (182, '        shell:')
    (183, '            "ls {params.hap_dir}/*.bam | sed \\\'s/.bam//\\\' | awk \\\'{{print $1, 1}}\\\' > {output.popmap} "')
    (184, '')
    (185, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=solida-core/niasmic, file=Snakefile
context_key: ['if config.get("pe")=="no"', 'if config.get("fastq_numb")==2', 'include']
    (49, 'if config.get("pe")=="no":')
    (50, '    if config.get("fastq_numb")==2:')
    (51, '        include:')
    (52, '            include_prefix + "/umi_bclconvert_se.smk"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=solida-core/niasmic, file=Snakefile
context_key: ['if config.get("pe")=="no"', 'else', 'include']
    (53, '    else:')
    (54, '        include:')
    (55, '            include_prefix + "/umi_se.smk"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=solida-core/niasmic, file=Snakefile
context_key: ['if config.get("pe")=="no"', 'include']
    (56, '    include:')
    (57, '        include_prefix + "/trimming_se.smk"')
    (58, '    include:')
    (59, '        include_prefix + "/alignment_se.smk"')
    (60, '')
    (61, '')
    (62, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=solida-core/niasmic, file=Snakefile
context_key: ['else', 'if config.get("fastq_numb")==2', 'include']
    (70, '    if config.get("fastq_numb")==2:')
    (71, '        include:')
    (72, '            include_prefix + "/umi_bclconvert.smk"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=pmenzel/ont-assembly-snake, file=Snakefile
context_key: ["if config.get(\\'filtlong_min_read_length\\',False)"]
    (6, "if config.get(\\'filtlong_min_read_length\\',False):")
    (7, "  filtlong_min_read_length = config[\\'filtlong_min_read_length\\']")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=pmenzel/ont-assembly-snake, file=Snakefile
context_key: ["if config.get(\\'medaka_model\\',False)"]
    (17, "if config.get(\\'medaka_model\\',False):")
    (18, "  medaka_model = config[\\'medaka_model\\']")
    (19, '  print("Medaka model = " + medaka_model)')
    (20, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=pmenzel/ont-assembly-snake, file=Snakefile
context_key: ["if config.get(\\'map_medaka_model\\',False)"]
    (22, "if config.get(\\'map_medaka_model\\',False):")
    (23, "  medaka_model_file = config[\\'map_medaka_model\\']")
    (24, "  table = pd.read_csv(medaka_model_file, sep=\\'\\\\t\\', lineterminator=\\'\\")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=LUMC/HAMLET, file=Snakefile
context_key: ['if config.get("fusioncatcher_data")']
    (147, 'if config.get("fusioncatcher_data"):')
    (148, '    OUTPUTS["fusioncatcher_txt"] = fusion.module_output.optional.fusion_catcher')
    (149, '    OUTPUTS["fusions_txt"] = fusion.module_output.optional.intersect')
    (150, '    OUTPUTS["isect_txt"] = fusion.module_output.optional.subset_predictions')
    (151, '')
    (152, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=tjgibson/NGS-workflow-RNAseq, file=workflow/rules/filter.smk
context_key: ['if config["filter_chroms"]', 'else', 'rule samtools_index_filtered', 'input']
    (11, 'if config["filter_chroms"]:')
    (12, '\\trule filter_multireads:')
    (13, '\\t\\tinput:')
    (14, '\\t\\t\\t"results/aligned_reads/sorted/{sample}.bam"')
    (15, '\\t\\toutput:')
    (16, '\\t\\t\\ttemp("results/aligned_reads/unireads/{sample}.bam")')
    (17, '\\t\\tlog:')
    (18, '\\t\\t\\t"logs/filter_multireads/{sample}.log"')
    (19, '\\t\\tparams:')
    (20, '\\t\\t\\textra=config["params"]["filter_multireads"] ')
    (21, '\\t\\tthreads: 8')
    (22, '\\t\\twrapper:')
    (23, '\\t\\t\\t"v1.1.0/bio/sambamba/view"')
    (24, '\\t')
    (25, '\\trule samtools_index_unireads:')
    (26, '\\t\\tinput:')
    (27, '\\t\\t\\t"results/aligned_reads/unireads/{sample}.bam"')
    (28, '\\t\\toutput:')
    (29, '\\t\\t\\ttemp("results/aligned_reads/unireads/{sample}.bam.bai")')
    (30, '\\t\\tlog:')
    (31, '\\t\\t\\t"logs/samtools_index/{sample}.log"')
    (32, '\\t\\tparams:')
    (33, '\\t\\t\\t"" # optional params string')
    (34, '\\t\\tthreads:  # Samtools takes additional threads through its option -@')
    (35, '\\t\\t\\t4     # This value - 1 will be sent to -@')
    (36, '\\t\\twrapper:')
    (37, '\\t\\t\\t"v1.1.0/bio/samtools/index"')
    (38, '\\t')
    (39, '\\trule samtools_idxstats_unireads:')
    (40, '\\t\\tinput:')
    (41, '\\t\\t\\tbam="results/aligned_reads/unireads/{sample}.bam",')
    (42, '\\t\\t\\tidx="results/aligned_reads/unireads/{sample}.bam.bai"')
    (43, '\\t\\toutput:')
    (44, '\\t\\t\\t"results/aligned_reads/stats/{sample}_unireads.idxstats"')
    (45, '\\t\\tlog:')
    (46, '\\t\\t\\t"logs/samtools/idxstats/{sample}.log"')
    (47, '\\t\\twrapper:')
    (48, '\\t\\t\\t"v1.1.0/bio/samtools/idxstats"')
    (49, '\\t')
    (50, '\\trule filter_chroms:')
    (51, '\\t\\tinput:')
    (52, '\\t\\t\\tbam="results/aligned_reads/unireads/{sample}.bam",')
    (53, '\\t\\t\\tkeep_chroms="resources/keep_chroms.bed"')
    (54, '\\t\\toutput:')
    (55, '\\t\\t\\t"results/aligned_reads/filtered/{sample}.bam"')
    (56, '\\t\\tlog:')
    (57, '\\t\\t\\t"logs/filter_chroms/{sample}.log"')
    (58, '\\t\\tconda:')
    (59, '\\t\\t\\t"../envs/samtools.yaml"')
    (60, '\\t\\tshell:')
    (61, '\\t\\t\\t"samtools view -bh -L {input.keep_chroms} --output-fmt BAM -o {output} {input.bam} 2>> {log}"')
    (62, 'else:')
    (63, '\\trule filter_multireads:')
    (64, '\\t\\tinput:')
    (65, '\\t\\t\\t"results/aligned_reads/sorted/{sample}.bam"')
    (66, '\\t\\toutput:')
    (67, '\\t\\t\\t"results/aligned_reads/filtered/{sample}.bam"')
    (68, '\\t\\tlog:')
    (69, '\\t\\t\\t"logs/filter_multireads/{sample}.log"')
    (70, '\\t\\tparams:')
    (71, '\\t\\t\\textra=config["params"]["filter_multireads"] ')
    (72, '\\t\\tthreads: 8')
    (73, '\\t\\twrapper:')
    (74, '\\t\\t\\t"v1.1.0/bio/sambamba/view"')
    (75, '\\t\\t')
    (76, '')
    (77, 'rule samtools_index_filtered:')
    (78, '    input:')
    (79, '        "results/aligned_reads/filtered/{sample}.bam"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=tjgibson/NGS-workflow-RNAseq, file=workflow/rules/filter.smk
context_key: ['if config["filter_chroms"]', 'output']
    (80, '    output:')
    (81, '        "results/aligned_reads/filtered/{sample}.bam.bai"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=tjgibson/NGS-workflow-RNAseq, file=workflow/rules/filter.smk
context_key: ['if config["filter_chroms"]', 'log']
    (82, '    log:')
    (83, '        "logs/samtools_index/{sample}.log"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=tjgibson/NGS-workflow-RNAseq, file=workflow/rules/filter.smk
context_key: ['if config["filter_chroms"]', 'params']
    (84, '    params:')
    (85, '        "" # optional params string')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=tjgibson/NGS-workflow-RNAseq, file=workflow/rules/filter.smk
context_key: ['if config["filter_chroms"]', 'threads']
    (86, '    threads:  # Samtools takes additional threads through its option -@')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=tjgibson/NGS-workflow-RNAseq, file=workflow/rules/filter.smk
context_key: ['if config["filter_chroms"]']
    (87, '        4     # This value - 1 will be sent to -@')
    (88, '    wrapper:')
    (89, '        "v1.1.0/bio/samtools/index"')
    (90, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=tjgibson/NGS-workflow-RNAseq, file=workflow/rules/diff_exp.smk
context_key: ['if config["run_diff_exp"]']
    (19, 'if config["run_diff_exp"]:')
    (20, '\\trule DEseq2:')
    (21, '\\t\\tinput:')
    (22, '\\t\\t\\t"results/count_tables/{experiment}.featureCounts"')
    (23, '\\t\\toutput:')
    (24, '\\t\\t\\t"results/DEseq2/{experiment}.dds"')
    (25, '\\t\\tparams:')
    (26, '\\t\\t\\tsamples=config["samples"],')
    (27, '\\t\\t\\tmodel=config["diff_exp"]["model"],')
    (28, '\\t\\t\\tcount_threshold=config["diff_exp"]["count_threshold"],')
    (29, '\\t\\tconda:')
    (30, '\\t\\t\\t"../envs/DEseq2.yaml",')
    (31, '\\t\\tlog:')
    (32, '\\t\\t\\t"logs/DEseq2/{experiment}.log",')
    (33, '\\t\\tscript:')
    (34, '\\t\\t\\t"../scripts/DEseq2.R"')
    (35, '')
    (36, '\\trule DEseq2_results:')
    (37, '\\t\\tinput:')
    (38, '\\t\\t\\tdds="results/DEseq2/{experiment}.dds",')
    (39, '\\t\\t\\tannotation=rules.get_genome_annotation.output')
    (40, '\\t\\toutput:')
    (41, '\\t\\t\\t"results/DEseq2/{experiment}_{contrast}_results.tsv"')
    (42, '\\t\\tparams:')
    (43, '\\t\\t\\t contrast=get_contrast,')
    (44, '\\t\\t\\t padj_cutoff=config["diff_exp"]["padj_cutoff"],')
    (45, '\\t\\t\\t FC_cutoff=config["diff_exp"]["log2FC_cutoff"],')
    (46, '\\t\\tconda:')
    (47, '\\t\\t\\t"../envs/DEseq2.yaml",')
    (48, '\\t\\tlog:')
    (49, '\\t\\t\\t"logs/DEseq2_results/{experiment}_{contrast}.log",')
    (50, '\\t\\tscript:')
    (51, '\\t\\t\\t"../scripts/DEseq2_results.R"\'')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=BleekerLab/freebayes_snp_calling, file=Snakefile
context_key: ['if config["remove_workdir"]', 'rule all', 'message']
    (90, '        message:"all done! Cleaning working directory"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=BleekerLab/freebayes_snp_calling, file=Snakefile
context_key: ['if config["remove_workdir"]', 'rule all', 'shell']
    (91, '        shell:')
    (92, '            "rm -r {TEMP_DIR}"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=mozilla/firefox-translations-training, file=Snakefile
context_key: ["if config[\\'gpus\\']"]
    (124, "if config[\\'gpus\\']:")
    (125, '    envs += f\\\' CUDA_VISIBLE_DEVICES="{gpus}" \\\'')
    (126, '')
    (127, '### workflow options')
    (128, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=euronion/trace, file=rules/gegis.smk
context_key: ['if config["GlobalEnergyGIS"].get("init_gegis", False) is True', 'rule set_GEGIS_base_dir', 'output']
    (7, 'if config["GlobalEnergyGIS"].get("init_gegis", False) is True:')
    (8, '')
    (9, '    rule set_GEGIS_base_dir:')
    (10, '        output:')
    (11, '            directory(config["GlobalEnergyGIS"]["base_dir"]),')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=euronion/trace, file=rules/gegis.smk
context_key: ['if config["GlobalEnergyGIS"].get("init_gegis", False) is True', 'rule set_GEGIS_base_dir', 'threads']
    (12, '        threads: 1')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=euronion/trace, file=rules/gegis.smk
context_key: ['if config["GlobalEnergyGIS"].get("init_gegis", False) is True', 'rule set_GEGIS_base_dir', 'script']
    (13, '        script:')
    (14, '            "../actions/set_GEGIS_base_dir.jl"')
    (15, '')
    (16, '# Download auxiliary datasets for GEGIS')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=euronion/trace, file=rules/gegis.smk
context_key: ['if config["GlobalEnergyGIS"].get("init_gegis", False) is True', 'rule download_GEGIS_dataset', 'output']
    (17, '    rule download_GEGIS_dataset:')
    (18, '        output:')
    (19, '            Path(config["GlobalEnergyGIS"]["base_dir"]) / "protected.jld",  # not full list, only dependencies for rules below (proxy all others)')
    (20, '            Path(config["GlobalEnergyGIS"]["base_dir"]) / "gadm.tif",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=euronion/trace, file=rules/gegis.smk
context_key: ['if config["GlobalEnergyGIS"].get("init_gegis", False) is True', 'rule download_GEGIS_dataset', 'script']
    (21, '        script:')
    (22, '            "../actions/download_GEGIS_datasets.jl"')
    (23, '')
    (24, '# Download ERA5 data for wind/solar/synthetic demand for GEGIS')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=euronion/trace, file=rules/gegis.smk
context_key: ['if config["GlobalEnergyGIS"].get("init_gegis", False) is True', 'rule download_GEGIS_era5', 'output']
    (25, '    rule download_GEGIS_era5:')
    (26, '        output:')
    (27, '            Path(config["GlobalEnergyGIS"]["base_dir"]) / "era5wind{year}.h5",')
    (28, '            Path(config["GlobalEnergyGIS"]["base_dir"]) / "era5solar{year}.h5",')
    (29, '            Path(config["GlobalEnergyGIS"]["base_dir"]) / "era5temp{year}.h5",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=euronion/trace, file=rules/gegis.smk
context_key: ['if config["GlobalEnergyGIS"].get("init_gegis", False) is True', 'rule download_GEGIS_era5', 'script']
    (30, '        script:')
    (31, '            "../actions/download_GEGIS_era5.jl"')
    (32, '# Create region for GlobalEnergyGIS containing')
    (33, '')
    (34, '')
    (35, '')
    (36, '# one or more areas defined by GADM (Database of Global Administrative Areas)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=marcoralab/imputePipeline, file=workflow/Snakefile
context_key: ["if config[\\'chr_callrate\\']"]
    (157, "if config[\\'chr_callrate\\']:")
    (158, "    include: \\'rules/chr_callrate.smk\\'")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=marcoralab/imputePipeline, file=workflow/Snakefile
context_key: ["elif config[\\'chunk_callrate\\']"]
    (159, "elif config[\\'chunk_callrate\\']:")
    (160, "    include: \\'rules/chunk_callrate.smk\\'")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

