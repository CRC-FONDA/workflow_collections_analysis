repo=rmFlynn/snakemake_example, file=workflow/rules/binning.smk
context_key: ['rule check_dups_fasta', 'run', "if not config[\\'backend\\'][\\'check_fasta_for_dups\\']"]
    (58, "        if not config[\\'backend\\'][\\'check_fasta_for_dups\\']:")
    (59, "            msg=\\'Duplicate test waved\\'")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=rmFlynn/snakemake_example, file=workflow/rules/binning.smk
context_key: ['rule check_dups_fasta', 'run', 'else', "if fastas_dup_check(input.reads, \\'@\\')"]
    (61, "            if fastas_dup_check(input.reads, \\'@\\'):")
    (62, "                msg=\\'There are no duplicates\\'")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=mrvollger/sd-divergence, file=workflow/rules/trackhub.smk
context_key: ['rule make_trackdb', 'run', 'if sm == "all" and h == 2']
    (112, '                if sm == "all" and h == 2:')
    (113, '                    continue')
    (114, '                out.write(')
    (115, '                    track.format(')
    (116, '                        sm=sm, h=h, strong_color=strong_color, weak_color=weak_color')
    (117, '                    )')
    (118, '                )')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=KonstantinBurkin/cbai, file=workflow/rules/calling.smk
context_key: ['rule call_variants', 'input', 'else [']
    (23, '            else []')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=CVUA-RRW/FooDMe, file=workflow/rules/blast.smk
context_key: ['rule blast_otus', 'input', 'else "{sample}/denoising/{sample}_ASVs.fasta"']
    (119, '        else "{sample}/denoising/{sample}_ASVs.fasta",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=CVUA-RRW/FooDMe, file=workflow/rules/blast.smk
context_key: ['rule blast_stats', 'input', 'else "{sample}/denoising/{sample}_ASVs.fasta"']
    (204, '        else "{sample}/denoising/{sample}_ASVs.fasta",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=snakemake-workflows/cyrcular-calling, file=workflow/rules/map.smk
context_key: ['rule merge_fastqs', 'params', 'if (any(map(lambda f']
    (48, '        if (any(map(lambda f: f.endswith(".gz"), get_fastqs(wc))))')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=snakemake-workflows/cyrcular-calling, file=workflow/rules/map.smk
context_key: ['rule merge_fastqs', 'params', 'else "cat"']
    (49, '        else "cat",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/mosaicatcher-pipeline, file=workflow/rules/external_data.smk
context_key: ['rule download_hg19_reference', 'run', 'if not os.path.exists(directory)']
    (32, '        if not os.path.exists(directory):')
    (33, '            os.makedirs(directory)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/mosaicatcher-pipeline, file=workflow/rules/external_data.smk
context_key: ['rule download_hg38_reference', 'run', 'if not os.path.exists(directory)']
    (50, '        if not os.path.exists(directory):')
    (51, '            os.makedirs(directory)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/mosaicatcher-pipeline, file=workflow/rules/external_data.smk
context_key: ['rule download_T2T_reference', 'run', 'if not os.path.exists(directory)']
    (68, '        if not os.path.exists(directory):')
    (69, '            os.makedirs(directory)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/mosaicatcher-pipeline, file=workflow/rules/external_data.smk
context_key: ['rule download_T2T_tarball', 'run', 'if not os.path.exists(directory)']
    (86, '        if not os.path.exists(directory):')
    (87, '            os.makedirs(directory)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=wharvey31/denovo_sv_validation, file=workflow/rules/msa.smk
context_key: ['rule rename', 'run', 'if line[0] == ">"']
    (33, '                    if line[0] == ">":')
    (34, '                        outfile.write(f">{wildcards.sample}_{wildcards.hap}\\')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=wharvey31/denovo_sv_validation, file=workflow/rules/msa.smk
context_key: ['rule process_align', 'run', 'if hap not in record_dict']
    (75, '                    if hap not in record_dict:')
    (76, '                        record_dict[hap] = pd.DataFrame.from_dict(')
    (77, '                            {')
    (78, '                                "chr": [wildcards.ids],')
    (79, '                                "start": [m.start()],')
    (80, '                                "end": [m.end()],')
    (81, '                                "hap": [hap],')
    (82, '                            }')
    (83, '                        )')
    (84, '                    else:')
    (85, '                        record_dict[hap] = record_dict[hap].append(')
    (86, '                            pd.DataFrame.from_dict(')
    (87, '                                {')
    (88, '                                    "chr": [wildcards.ids],')
    (89, '                                    "start": [m.start()],')
    (90, '                                    "end": [m.end()],')
    (91, '                                    "hap": [hap],')
    (92, '                                }')
    (93, '                            )')
    (94, '                        )')
    (95, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=wharvey31/denovo_sv_validation, file=workflow/rules/msa.smk
context_key: ['rule check_hap', 'run', 'if i == 0']
    (132, '            if i == 0:')
    (133, '                par_bed = BedTool.from_dataframe(')
    (134, '                    df_parents.loc[df_parents["hap"] == sample]')
    (135, '                )')
    (136, '            else:')
    (137, '                par_bed = par_bed.intersect(')
    (138, '                    BedTool.from_dataframe(df_parents.loc[df_parents["hap"] == sample])')
    (139, '                )')
    (140, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=wharvey31/denovo_sv_validation, file=workflow/rules/msa.smk
context_key: ['rule check_hap', 'run', 'if len(shared_ovl) > 0']
    (147, '        if len(shared_ovl) > 0:')
    (148, '            shared_ovl["ovl"] = shared_ovl["END"] - shared_ovl["POS"]')
    (149, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=wharvey31/denovo_sv_validation, file=workflow/rules/msa.smk
context_key: ['rule combine_ids', 'run', 'if x not in sv_df["sample"].value']
    (187, '                if x not in sv_df["sample"].values')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=wharvey31/denovo_sv_validation, file=workflow/rules/msa.smk
context_key: ['rule combine_ids', 'run', 'if len(dn_sample) == 1']
    (189, '            if len(dn_sample) == 1:')
    (190, '                val_call = "VALID"')
    (191, '                val_sample = dn_sample[0]')
    (192, '            else:')
    (193, '                val_call = "NOTVALID"')
    (194, '                val_sample = ""')
    (195, '            out_df = out_df.append(')
    (196, '                pd.DataFrame.from_dict(')
    (197, '                    {')
    (198, '                        f"MSA_VAL_SAMPLE_{wildcards.val_type}": [val_sample],')
    (199, '                        f"MSA_VAL_{wildcards.val_type}": [val_call],')
    (200, '                        "ID": [svid],')
    (201, '                    }')
    (202, '                )')
    (203, '            )')
    (204, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=wharvey31/denovo_sv_validation, file=workflow/rules/subseq.smk
context_key: ['rule subseq_table_setdef_bed', 'run', 'if wildcards.set_def not in SET_DEF']
    (20, '        if wildcards.set_def not in SET_DEF:')
    (21, '            raise RuntimeError(')
    (22, '                "Set definition not found in SET_DEF: " + wildcards.set_def')
    (23, '            )')
    (24, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=wharvey31/denovo_sv_validation, file=workflow/rules/subseq.smk
context_key: ['rule subseq_table_setdef_bed', 'run', 'if "bed" in input.keys() and bool']
    (28, '        if "bed" in input.keys() and bool(')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=wharvey31/denovo_sv_validation, file=workflow/rules/subseq.smk
context_key: ['rule subseq_table_setdef_bed', 'run', 'if svlen_min is not None']
    (44, '            if svlen_min is not None:')
    (45, '                df = df.loc[df["SVLEN"] >= svlen_min]')
    (46, '')
    (47, '            if svlen_max is not None:')
    (48, '                df = df.loc[df["SVLEN"] < svlen_max]')
    (49, '')
    (50, '            # Add sample and caller')
    (51, '            df["SAMPLE"] = wildcards.sample')
    (52, '            df["CALLER"] = "POTENTIAL_DENOVO"')
    (53, '')
    (54, '            # Annotate window (replace POS and END with the window coordinates)')
    (55, '            df["WIN_FLANK"] = win_size')
    (56, '')
    (57, '            # Define windows, replace POS and END')
    (58, '            df["ORG_POS"] = df["POS"]')
    (59, '            df["ORG_END"] = df["END"]')
    (60, '')
    (61, '            if df.shape[0] > 0:')
    (62, '                df["POS"] = df.apply(')
    (63, '                    lambda row: np.max([row["POS"] - row["WIN_FLANK"], 0]), axis=1')
    (64, '                )')
    (65, '                df["END"] = df.apply(')
    (66, '                    lambda row: np.min(')
    (67, '                        [row["END"] + row["WIN_FLANK"], df_fai[row["#CHROM"]]]')
    (68, '                    ),')
    (69, '                    axis=1,')
    (70, '                )')
    (71, '')
    (72, '            df["WIN_L"] = df["ORG_POS"] - df["POS"]')
    (73, '            df["WIN_R"] = df["END"] - df["ORG_END"]')
    (74, '')
    (75, '            df["WINDOW_SIZE"] = df["WIN_L"] + df["WIN_R"]')
    (76, '')
    (77, '            del (df["ORG_POS"], df["ORG_END"])')
    (78, '')
    (79, '            if df.shape[0] > 0:')
    (80, '                df["WINDOW"] = df.apply(')
    (81, '                    lambda row: "{#CHROM}:{POS}-{END}".format(**row), axis=1')
    (82, '                )')
    (83, '            else:')
    (84, '                df["WINDOW"] = []')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=wharvey31/denovo_sv_validation, file=workflow/rules/subseq.smk
context_key: ['rule subseq_tab_window_single', 'run', 'if aln_input_exists']
    (159, '        if aln_input_exists:')
    (160, '            # Alignment file exists, get stats')
    (161, '')
    (162, '            stat_list = [')
    (163, '                summary_func(get_len_list(window, input.aln, "subseqfa"))')
    (164, '                for window in region_bed["WINDOW"]')
    (165, '            ]')
    (166, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=wharvey31/denovo_sv_validation, file=workflow/rules/subseq.smk
context_key: ['rule subseq_tab_window_single', 'run', 'if len(stat_list) > 0']
    (173, '        if len(stat_list) > 0:')
    (174, '            # Merge summary records')
    (175, '            df = pd.DataFrame(pd.concat(stat_list, axis=1)).T.reset_index(drop=True)')
    (176, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=wharvey31/denovo_sv_validation, file=workflow/rules/subseq.smk
context_key: ['rule subseq_tab_window_single', 'run', 'if field in df.column']
    (187, '            if field in df.columns')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=wharvey31/denovo_sv_validation, file=workflow/rules/subseq.smk
context_key: ['rule subseq_val', 'run', 'if wildcards.vartype == "sv"']
    (248, '        if wildcards.vartype == "sv":')
    (249, '            strategy = "size50_2_4"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=wharvey31/denovo_sv_validation, file=workflow/rules/callable.smk
context_key: ['rule combine_callable', 'run', 'if i == 0']
    (28, '            if i == 0:')
    (29, '                df = pd.read_csv(file, sep="\\\\t")')
    (30, '            else:')
    (31, '                df = df.merge(pd.read_csv(file, sep="\\\\t"))')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=snakemake-workflows/dna-seq-gatk-variant-calling, file=workflow/rules/calling.smk
context_key: ['rule call_variants', 'input', 'else [']
    (23, '            else []')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=snakemake-workflows/dna-seq-gatk-variant-calling, file=workflow/rules/filtering.smk
context_key: ['rule merge_calls', 'input', 'else "hardfiltered"']
    (48, '            else "hardfiltered",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=snakemake-workflows/dna-seq-varlociraptor, file=workflow/rules/calling.smk
context_key: ['rule varlociraptor_call', 'params', 'if not config["calling"].get("infer_genotypes"']
    (77, '        if not config["calling"].get("infer_genotypes")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=snakemake-workflows/dna-seq-varlociraptor, file=workflow/rules/calling.smk
context_key: ['rule varlociraptor_call', 'params', 'else "| varlociraptor genotype >"']
    (78, '        else "| varlociraptor genotype >",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=snakemake-workflows/dna-seq-varlociraptor, file=workflow/rules/regions.smk
context_key: ['rule filter_group_regions', 'input', 'if "target_regions" in confi']
    (70, '        if "target_regions" in config')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=snakemake-workflows/dna-seq-varlociraptor, file=workflow/rules/regions.smk
context_key: ['rule filter_group_regions', 'input', 'else []']
    (71, '        else [],')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=snakemake-workflows/dna-seq-varlociraptor, file=workflow/rules/mapping.smk
context_key: ['rule mark_duplicates', 'input', 'if units.loc[wc.sample, "umis"].isnull().any(']
    (34, '        if units.loc[wc.sample, "umis"].isnull().any()')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=snakemake-workflows/dna-seq-varlociraptor, file=workflow/rules/mapping.smk
context_key: ['rule mark_duplicates', 'input', 'else "results/mapped/{sample}.annotated.bam"']
    (35, '        else "results/mapped/{sample}.annotated.bam",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=mrvollger/fastCN-smk, file=workflow/rules/quickmer.smk
context_key: ['rule copy_ref', 'run', 'if input.ref.endswith(".gz")']
    (13, '        if input.ref.endswith(".gz"):')
    (14, '            shell("gunzip -c {input.ref} > {output.ref_keep}")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=sneuensc/mapache, file=workflow/rules/sample.smk
context_key: ['rule get_final_bam', 'run', 'if is_external_sample(wildcards.sm, wildcards.genome)']
    (138, '        if is_external_sample(wildcards.sm, wildcards.genome):')
    (139, '            shell("ln -srf {input} {output}")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=sneuensc/mapache, file=workflow/rules/stats.smk
context_key: ['rule merge_stats_per_fastq', 'input', 'if run_adapter_remova']
    (257, '        if run_adapter_removal')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=sneuensc/mapache, file=workflow/rules/stats.smk
context_key: ['rule merge_stats_per_fastq', 'input', 'else "{folder}/04_stats/01_sparse_stats/01_fastq/00_reads/01_files_orig/{sm}/{lb}/{id}_fastqc.zip"']
    (258, '        else "{folder}/04_stats/01_sparse_stats/01_fastq/00_reads/01_files_orig/{sm}/{lb}/{id}_fastqc.zip",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=sneuensc/mapache, file=workflow/rules/stats.smk
context_key: ['rule multiqc', 'input', 'if run_adapter_remova']
    (774, '            if run_adapter_removal')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=sneuensc/mapache, file=workflow/rules/stats.smk
context_key: ['rule multiqc', 'input', 'if run_adapter_remova']
    (781, '            if run_adapter_removal')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=sneuensc/mapache, file=workflow/rules/stats.smk
context_key: ['rule multiqc', 'input', 'if str2bool(recursive_get(["stats", "qualimap"], False)']
    (818, '            if str2bool(recursive_get(["stats", "qualimap"], False))')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/examples.smk
context_key: ['rule download_hg19_reference', 'run', 'if not os.path.exists(directory)']
    (21, '        if not os.path.exists(directory):')
    (22, '            os.makedirs(directory)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/examples.smk
context_key: ['rule download_hg38_reference', 'run', 'if not os.path.exists(directory)']
    (39, '        if not os.path.exists(directory):')
    (40, '            os.makedirs(directory)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=friendsofstrandseq/ashleys-qc-pipeline, file=workflow/rules/examples.smk
context_key: ['rule download_T2T_reference', 'run', 'if not os.path.exists(directory)']
    (57, '        if not os.path.exists(directory):')
    (58, '            os.makedirs(directory)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=zavolanlab/polyAsite_workflow, file=Snakefile
context_key: ['rule raw_3pSites_cnt', 'run', 'if F[5] == "+"']
    (1291, '                if F[5] == "+":')
    (1292, '                    plus += 1')
    (1293, '                    plus_reads += float(F[4])')
    (1294, '                else:')
    (1295, '                    minus += 1')
    (1296, '                    minus_reads += float(F[4])')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=zavolanlab/polyAsite_workflow, file=Snakefile
context_key: ['rule IP_3pSites_cnt', 'run', 'if F[3] == "IP"', 'if F[5] == "+"']
    (1432, '                if F[3] == "IP":')
    (1433, '                    if F[5] == "+":')
    (1434, '                        plus += 1')
    (1435, '                        plus_reads += float(F[4])')
    (1436, '                    else:')
    (1437, '                        minus += 1')
    (1438, '                        minus_reads += float(F[4])')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=zavolanlab/polyAsite_workflow, file=Snakefile
context_key: ['rule delete_noReadSupport_rows', 'run', 'if line.startswith("#")']
    (1696, '                if line.startswith("#"):')
    (1697, '                    out_file.write(line)')
    (1698, '                    continue')
    (1699, '                line_list = line.rstrip().split("\\\\t")')
    (1700, '                read_sum = sum( [1 for i in line_list[3:-2] if float(i) > 0] )')
    (1701, '                if read_sum > 0:')
    (1702, '                    # this site has still read support')
    (1703, '                    out_file.write(line)')
    (1704, '')
    (1705, '#-------------------------------------------------------------------------------')
    (1706, '# For each SAMPLE')
    (1707, "# get background-corrected number of 3\\' sites")
    (1708, '# get number of sites with PAS')
    (1709, '#-------------------------------------------------------------------------------')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=zavolanlab/polyAsite_workflow, file=Snakefile
context_key: ['rule get_noBG_3pSites_per_sample', 'run', 'if line.startswith("#")', 'if params.sample in line']
    (1737, '                if line.startswith("#"):')
    (1738, '                    if params.sample in line:')
    (1739, '                        F = line.rstrip().split(";")')
    (1740, '                    \\tcol = int(F[0].lstrip("#"))')
    (1741, '                else:')
    (1742, '                    if col == 0:')
    (1743, '                        print("Column for sample could not be identified!")')
    (1744, '                        print(params.sample)')
    (1745, '                        exit()')
    (1746, '                    else:')
    (1747, '                        line_list = line.rstrip().split("\\\\t")')
    (1748, '                        if line_list[col] != "0":')
    (1749, '                            sites += 1')
    (1750, '                            reads += int(line_list[col])')
    (1751, '                            if line_list[-2] != "NA":')
    (1752, '                                pas += 1')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=zavolanlab/polyAsite_workflow, file=Snakefile
context_key: ['rule get_final_clusters_stats', 'run', 'if not "NA" in line']
    (2143, '                if not "NA" in line:')
    (2144, '                    p += 1')
    (2145, '                # For each cluster get annotation')
    (2146, "                a = line.split(\\'\\\\t\\')[9]")
    (2147, '                annos[a] += 1')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Finn-Lab/MAG_Snakemake_wf, file=modules/coas.Snakefile
context_key: ['rule readcounts_coas', 'run', 'if os.path.exists(outfile)']
    (90, '        if os.path.exists(outfile):')
    (91, '            os.remove(outfile)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Finn-Lab/MAG_Snakemake_wf, file=modules/cmseq.Snakefile
context_key: ['rule append_cmseq', 'run', 'if os.path.exists(str(output))']
    (191, '        if os.path.exists(str(output)):')
    (192, '            os.remove(str(output))')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Finn-Lab/MAG_Snakemake_wf, file=modules/cmseq.Snakefile
context_key: ['rule append_cmseq', 'run', 'if len(lines) > 1']
    (200, '                if len(lines) > 1:')
    (201, '                    lines_sub = lines[1].strip()')
    (202, '                    L = filename + "\\\\t" + lines_sub + "\\')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Finn-Lab/MAG_Snakemake_wf, file=modules/cmseq.Snakefile
context_key: ['rule append_cmseq_coas', 'run', 'if os.path.exists(str(output))']
    (217, '        if os.path.exists(str(output)):')
    (218, '            os.remove(str(output))')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Finn-Lab/MAG_Snakemake_wf, file=modules/cmseq.Snakefile
context_key: ['rule append_cmseq_coas', 'run', 'if len(lines) > 1']
    (226, '                if len(lines) > 1:')
    (227, '                    lines_sub = lines[1].strip()')
    (228, '                    L = filename + "\\\\t" + lines_sub + "\\')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Finn-Lab/MAG_Snakemake_wf, file=modules/preprocessing.Snakefile
context_key: ['rule readcount_fq', 'run', 'if os.path.exists(outfile)']
    (199, '        if os.path.exists(outfile):')
    (200, '            os.remove(outfile)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NBISweden/fungal-trans, file=source/rules/filter.smk
context_key: ['rule union_filtered_reads', 'run', 'if remaining != 0']
    (547, '        if remaining != 0:')
    (548, '            sys.exit("WARNING: Could not get all reads for {output.R1}\\')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NBISweden/fungal-trans, file=source/rules/annotate_co.smk
context_key: ['rule taxonomy_featurecount_co', 'run', 'if len(orfs) == 0']
    (131, '        if len(orfs) == 0:')
    (132, '            shell("touch {output}")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NBISweden/fungal-trans, file=source/rules/annotate_co.smk
context_key: ['rule eggnog_tax_annotations', 'run', 'if len(orfs) == 0']
    (295, '        if len(orfs) == 0:')
    (296, '            shell("touch {output}")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NBISweden/fungal-trans, file=source/rules/annotate_co.smk
context_key: ['rule dbcan_tax_annotations', 'run', 'if len(orfs) == 0']
    (493, '        if len(orfs) == 0:')
    (494, '            shell("touch {output}")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NBISweden/fungal-trans, file=source/rules/map.smk
context_key: ['rule multiqc_map_report', 'run', 'if line[0']
    (160, '                    if line[0:6]=="Status":')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=gruber-sciencelab/MAPP, file=Snakefile
context_key: ['rule MAPP_collect_summary', 'params', 'else \\']
    (95, '            else \\\\')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Monia234/NCI-GEMSCAN, file=workflow/rules/Snakefile_DeepVariant
context_key: ['rule DV_create_cohort_manifest', 'params', 'if by_chro']
    (104, '            if by_chrom')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Monia234/NCI-GEMSCAN, file=workflow/rules/Snakefile_DeepVariant
context_key: ['rule DV_create_cohort_manifest', 'params', 'else outputDir + "deepVariant/called/gvcfs/']
    (105, '            else outputDir + "deepVariant/called/gvcfs/"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Monia234/NCI-GEMSCAN, file=workflow/rules/Snakefile_DeepVariant
context_key: ['rule DV_GLmerge_gvcfs', 'input', 'if by_chro']
    (136, '            if by_chrom')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Monia234/NCI-GEMSCAN, file=workflow/rules/Snakefile_DeepVariant
context_key: ['rule DV_GLmerge_gvcfs', 'input', 'else expand("deepVariant/called_by_sample/{sample}.g.vcf.gz", sample=sampleList']
    (137, '            else expand("deepVariant/called_by_sample/{sample}.g.vcf.gz", sample=sampleList)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Monia234/NCI-GEMSCAN, file=workflow/rules/Snakefile_DeepVariant
context_key: ['rule DV_GLmerge_gvcfs', 'input', 'if by_chro']
    (141, '            if by_chrom')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Monia234/NCI-GEMSCAN, file=workflow/rules/Snakefile_DeepVariant
context_key: ['rule DV_GLmerge_gvcfs', 'input', 'else "deepVariant/called/gvcfs/manifest.txt']
    (142, '            else "deepVariant/called/gvcfs/manifest.txt"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Monia234/NCI-GEMSCAN, file=workflow/rules/Snakefile_DeepVariant
context_key: ['rule DV_run_deepvariant', 'output', 'if by_chro']
    (200, '            if by_chrom')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Monia234/NCI-GEMSCAN, file=workflow/rules/Snakefile_DeepVariant
context_key: ['rule DV_run_deepvariant', 'output', 'else "deepVariant/called_by_sample/{sample}.vcf.gz']
    (201, '            else "deepVariant/called_by_sample/{sample}.vcf.gz"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Monia234/NCI-GEMSCAN, file=workflow/rules/Snakefile_DeepVariant
context_key: ['rule DV_run_deepvariant', 'output', 'if by_chro']
    (205, '            if by_chrom')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Monia234/NCI-GEMSCAN, file=workflow/rules/Snakefile_DeepVariant
context_key: ['rule DV_run_deepvariant', 'output', 'else "deepVariant/called_by_sample/{sample}.vcf.gz.tbi']
    (206, '            else "deepVariant/called_by_sample/{sample}.vcf.gz.tbi"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Monia234/NCI-GEMSCAN, file=workflow/rules/Snakefile_DeepVariant
context_key: ['rule DV_run_deepvariant', 'output', 'if by_chro']
    (210, '            if by_chrom')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Monia234/NCI-GEMSCAN, file=workflow/rules/Snakefile_DeepVariant
context_key: ['rule DV_run_deepvariant', 'output', 'else "deepVariant/called_by_sample/{sample}.g.vcf.gz']
    (211, '            else "deepVariant/called_by_sample/{sample}.g.vcf.gz"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Monia234/NCI-GEMSCAN, file=workflow/rules/Snakefile_DeepVariant
context_key: ['rule DV_run_deepvariant', 'output', 'if by_chro']
    (215, '            if by_chrom')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Monia234/NCI-GEMSCAN, file=workflow/rules/Snakefile_DeepVariant
context_key: ['rule DV_run_deepvariant', 'output', 'else "deepVariant/called_by_sample/{sample}.g.vcf.gz.tbi']
    (216, '            else "deepVariant/called_by_sample/{sample}.g.vcf.gz.tbi"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Monia234/NCI-GEMSCAN, file=workflow/rules/Snakefile_Strelka2
context_key: ['rule strelka2_AddSampleName', 'input', 'if by_chro']
    (20, '            if by_chrom')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Monia234/NCI-GEMSCAN, file=workflow/rules/Snakefile_Strelka2
context_key: ['rule strelka2_AddSampleName', 'input', 'else "strelka2/calledBySample/{sample}/results/variants/genome.S1.vcf.gz']
    (21, '            else "strelka2/calledBySample/{sample}/results/variants/genome.S1.vcf.gz"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Monia234/NCI-GEMSCAN, file=workflow/rules/Snakefile_Strelka2
context_key: ['rule strelka2_AddSampleName', 'input', 'if by_chro']
    (25, '            if by_chrom')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Monia234/NCI-GEMSCAN, file=workflow/rules/Snakefile_Strelka2
context_key: ['rule strelka2_AddSampleName', 'input', 'else "strelka2/calledBySample/{sample}/results/variants/genome.S1.vcf.gz.tbi']
    (26, '            else "strelka2/calledBySample/{sample}/results/variants/genome.S1.vcf.gz.tbi"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Monia234/NCI-GEMSCAN, file=workflow/rules/Snakefile_Strelka2
context_key: ['rule strelka2_AddSampleName', 'output', 'if by_chro']
    (31, '            if by_chrom')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Monia234/NCI-GEMSCAN, file=workflow/rules/Snakefile_Strelka2
context_key: ['rule strelka2_AddSampleName', 'output', 'else "strelka2/called/genome.{sample}.vcf.gz']
    (32, '            else "strelka2/called/genome.{sample}.vcf.gz"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Monia234/NCI-GEMSCAN, file=workflow/rules/Snakefile_Strelka2
context_key: ['rule strelka2_AddSampleName', 'output', 'if by_chro']
    (36, '            if by_chrom')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Monia234/NCI-GEMSCAN, file=workflow/rules/Snakefile_Strelka2
context_key: ['rule strelka2_AddSampleName', 'output', 'else "strelka2/called/genome.{sample}.vcf.gz.tbi']
    (37, '            else "strelka2/called/genome.{sample}.vcf.gz.tbi"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Monia234/NCI-GEMSCAN, file=workflow/rules/Snakefile_Strelka2
context_key: ['rule strelka2_callVariant', 'output', 'if by_chro']
    (73, '            if by_chrom')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Monia234/NCI-GEMSCAN, file=workflow/rules/Snakefile_Strelka2
context_key: ['rule strelka2_callVariant', 'output', 'else "strelka2/calledBySample/{sample}/results/variants/genome.S1.vcf.gz']
    (74, '            else "strelka2/calledBySample/{sample}/results/variants/genome.S1.vcf.gz"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Monia234/NCI-GEMSCAN, file=workflow/rules/Snakefile_Strelka2
context_key: ['rule strelka2_callVariant', 'output', 'if by_chro']
    (78, '            if by_chrom')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Monia234/NCI-GEMSCAN, file=workflow/rules/Snakefile_Strelka2
context_key: ['rule strelka2_callVariant', 'output', 'else "strelka2/calledBySample/{sample}/results/variants/genome.S1.vcf.gz.tbi']
    (79, '            else "strelka2/calledBySample/{sample}/results/variants/genome.S1.vcf.gz.tbi"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Monia234/NCI-GEMSCAN, file=workflow/rules/Snakefile_Strelka2
context_key: ['rule strelka2_callVariant', 'output', 'if by_chro']
    (83, '            if by_chrom')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Monia234/NCI-GEMSCAN, file=workflow/rules/Snakefile_Strelka2
context_key: ['rule strelka2_callVariant', 'output', 'else "strelka2/calledBySample/{sample}/results/variants/variants.vcf.gz']
    (84, '            else "strelka2/calledBySample/{sample}/results/variants/variants.vcf.gz"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Monia234/NCI-GEMSCAN, file=workflow/rules/Snakefile_Strelka2
context_key: ['rule strelka2_callVariant', 'output', 'if by_chro']
    (88, '            if by_chrom')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Monia234/NCI-GEMSCAN, file=workflow/rules/Snakefile_Strelka2
context_key: ['rule strelka2_callVariant', 'output', 'else "strelka2/calledBySample/{sample}/results/variants/variants.vcf.gz.tbi']
    (89, '            else "strelka2/calledBySample/{sample}/results/variants/variants.vcf.gz.tbi"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Monia234/NCI-GEMSCAN, file=workflow/rules/Snakefile_Strelka2
context_key: ['rule strelka2_callVariant', 'params', 'if by_chro']
    (94, '            if by_chrom')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Monia234/NCI-GEMSCAN, file=workflow/rules/Snakefile_Strelka2
context_key: ['rule strelka2_callVariant', 'params', 'else outputDir + "strelka2/calledBySample/{sample}']
    (95, '            else outputDir + "strelka2/calledBySample/{sample}"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Monia234/NCI-GEMSCAN, file=workflow/rules/Snakefile_Strelka2
context_key: ['rule Strelka2_GLmerge_gvcfs', 'input', 'if by_chro']
    (180, '            if by_chrom')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Monia234/NCI-GEMSCAN, file=workflow/rules/Snakefile_Strelka2
context_key: ['rule Strelka2_GLmerge_gvcfs', 'input', 'else expand("strelka2/called/genome.{sample}.vcf.gz", sample=sampleList']
    (181, '            else expand("strelka2/called/genome.{sample}.vcf.gz", sample=sampleList)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Monia234/NCI-GEMSCAN, file=workflow/rules/Snakefile_Strelka2
context_key: ['rule Strelka2_GLmerge_gvcfs', 'input', 'if by_chro']
    (185, '            if by_chrom')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Monia234/NCI-GEMSCAN, file=workflow/rules/Snakefile_Strelka2
context_key: ['rule Strelka2_GLmerge_gvcfs', 'input', 'else "strelka2/called/gvcfs/manifest.txt']
    (186, '            else "strelka2/called/gvcfs/manifest.txt"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Monia234/NCI-GEMSCAN, file=workflow/rules/Snakefile_Strelka2
context_key: ['rule Strelka2_GLmerge_gvcfs', 'params', 'else "Strelka2_GLmerge_gvcfs/']
    (197, '            else "Strelka2_GLmerge_gvcfs/"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Monia234/NCI-GEMSCAN, file=workflow/rules/Snakefile_Strelka2
context_key: ['rule strelka2_create_cohort_manifest', 'params', 'if by_chro']
    (249, '            if by_chrom')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Monia234/NCI-GEMSCAN, file=workflow/rules/Snakefile_Strelka2
context_key: ['rule strelka2_create_cohort_manifest', 'params', 'else outputDir + "strelka2/called/manifests/']
    (250, '            else outputDir + "strelka2/called/manifests/"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=JEstabrook/decoupler_workflow, file=Snakefile
context_key: ["if not os.path.exists(os.path.join(os.getcwd(),\\'logs\\',rule))"]
    (26, "    if not os.path.exists(os.path.join(os.getcwd(),\\'logs\\',rule)):")
    (27, "        log_out = os.path.join(os.getcwd(), \\'logs\\', rule)")
    (28, '        os.makedirs(log_out)')
    (29, '        print(log_out)')
    (30, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NBISweden/nbis-meta, file=workflow/rules/binning.smk
context_key: ['rule aggregate_gtdbtk', 'run', 'if os.path.exists(summary)']
    (542, '                if os.path.exists(summary):')
    (543, '                    summaries.append(summary)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NIH-HPC/snakemake-class, file=Snakefile
context_key: ['rule gtf2bed12', 'run', "if line.startswith(\\'#\\')"]
    (180, "            if line.startswith(\\'#\\'):")
    (181, '                continue')
    (182, "            chrom, _, feat, s, e, score, strand, _, attr = line.split(\\'\\\\t\\')")
    (183, "            if feat not in (\\'transcript\\', \\'exon\\'):")
    (184, '                continue')
    (185, '            s = int(s) - 1')
    (186, '            e = int(e)')
    (187, '            assert s < e')
    (188, '            tid = None')
    (189, "            for a in attr.split(\\';\\'):")
    (190, "                if a.strip().startswith(\\'transcript_id\\'):")
    (191, '                    tid = a.split(\\\'"\\\')[1]')
    (192, '                    break')
    (193, '            if tid is None:')
    (194, '                raise ValueError')
    (195, "            if feat == \\'transcript\\':")
    (196, '                i += 1')
    (197, "                transcripts[tid] = {\\'c\\': chrom, \\'s\\':s, \\'e\\':e, ")
    (198, "                        \\'strand\\': strand, \\'exons\\':[], \\'tid\\': tid, \\'i\\': i}")
    (199, '            else:')
    (200, "                transcripts[tid][\\'exons\\'].append((s, e))")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NIH-HPC/snakemake-class, file=Snakefile
context_key: ['rule make_transcript_gene_map', 'run', "if line.startswith(\\'#\\')"]
    (217, "            if line.startswith(\\'#\\'):")
    (218, '                continue')
    (219, "            chrom, _, feat, s, e, score, strand, _, attr = line.split(\\'\\\\t\\')")
    (220, "            if feat != \\'transcript\\':")
    (221, '                continue')
    (222, '            tid = None')
    (223, '            gid = None')
    (224, "            for a in attr.split(\\';\\'):")
    (225, "                if a.strip().startswith(\\'transcript_id\\'):")
    (226, '                    tid = a.split(\\\'"\\\')[1]')
    (227, "                if a.strip().startswith(\\'gene_id\\'):")
    (228, '                    gid = a.split(\\\'"\\\')[1]')
    (229, '            if tid is None or gid is None:')
    (230, '                raise ValueError')
    (231, '            transcripts.append((tid, gid))')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=CCBR/CCBR_circRNA_DAQ, file=workflow/rules/preprocessing.smk
context_key: ['rule cutadapt', 'if [ ! -d {params.outdir} ];then mkdir {params.outdir};f']
    (27, 'if [ ! -d {params.outdir} ];then mkdir {params.outdir};fi')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=CCBR/CCBR_circRNA_DAQ, file=workflow/rules/preprocessing.smk
context_key: ['rule cutadapt', 'if [ "{params.peorse}" == "PE" ];the']
    (28, 'if [ "{params.peorse}" == "PE" ];then')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=taylorreiter/2021-bsub, file=Snakefile
context_key: ['rule cat_libraries_R1', 'run', 'if merge_nb > 1']
    (98, '            if merge_nb > 1:')
    (99, '                cmd = "cat " + " ".join(to_merge) + " > " + "inputs/cat/" + library + "_1.fastq.gz"')
    (100, '            else:')
    (101, '                cmd = "ln --relative --force -s " + " ".join(to_merge) + " inputs/cat/" + library + "_1.fastq.gz"')
    (102, '            os.system(cmd)')
    (103, '    ')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=taylorreiter/2021-bsub, file=Snakefile
context_key: ['rule cat_libraries_R2', 'run', 'if merge_nb > 1']
    (121, '            if merge_nb > 1:')
    (122, '                cmd = "cat " + " ".join(to_merge) + " > " + "inputs/cat/" + library + "_2.fastq.gz"')
    (123, '            else:')
    (124, '                cmd = "ln --relative --force -s " + " ".join(to_merge) + " inputs/cat/" + library + "_2.fastq.gz"')
    (125, '            os.system(cmd)')
    (126, '    ')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Roett/ImcSegmentationSnakemake, file=workflow/Snakefile
context_key: ['rule modify_measurement_pipeline', 'run', 'if line.rstrip()']
    (536, '                        if line.rstrip())')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Roett/ImcSegmentationSnakemake, file=workflow/Snakefile
context_key: ['rule download_example_data', 'run', 'if ~fn.exists()']
    (614, '            if ~fn.exists():')
    (615, '                shutil.move(fn_cache[0], fn)')
    (616, '')
    (617, '### Varia')
    (618, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=yztxwd/snakemake-pipeline-general, file=rules/filter.smk
context_key: ['rule samtools_view', 'params', 'else config["samtools_view"]["pe"])']
    (36, '            else config["samtools_view"]["pe"]))')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=yztxwd/snakemake-pipeline-general, file=rules/filter.smk
context_key: ['rule mapq_filter', 'params', 'else config["filter"]["pe"])']
    (55, '            else config["filter"]["pe"]) ')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=qbicsoftware-archive/rnaseq, file=Snakefile
context_key: ['rule checksums', 'run', 'if glob.glob(data("*.sha256sum"))']
    (112, '        if glob.glob(data("*.sha256sum")):')
    (113, '            shell("cd %s; "')
    (114, '                  "sha256sum -c *.sha256sum && "')
    (115, '                  "touch %s" % (data(\\\'.\\\'), out))')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=qbicsoftware-archive/rnaseq, file=Snakefile
context_key: ['rule PreFilterReads', 'run', "if all(\\'"]
    (140, "                if all(\\':Y:\\' not in part for part in line.split(\\' \\')[1:]):")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=qbicsoftware-archive/rnaseq, file=Snakefile
context_key: ['rule PreFilterReads', 'run', 'if num_filtered / num_all > .1']
    (148, '        if num_filtered / num_all > .1:')
    (149, '            raise ValueError("More than 10% of reads were filtered in "')
    (150, '                "PreFilterReads. This probably indicates a bug.")')
    (151, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=qbicsoftware-archive/rnaseq, file=Snakefile
context_key: ['rule Overrepresented', 'run', 'if line.startswith(">>Overrepresented")']
    (180, '            if line.startswith(">>Overrepresented"):')
    (181, '                sw = True')
    (182, '            if not line.startswith(">>END_MODULE") and sw:')
    (183, '                out.write(line)')
    (184, '            else:')
    (185, '                sw = False')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=qbicsoftware-archive/rnaseq, file=Snakefile
context_key: ['rule OverrepTxtFasta', 'run', 'if not (line.startswith("#") or line.startswith(">>"))']
    (196, '            if not (line.startswith("#") or line.startswith(">>")):')
    (197, '                 tokens1 = line.split("\\\\t")')
    (198, '                 print(tokens1)')
    (199, '                 fseq = tokens1[0]')
    (200, "                 fheader = \\'>\\' + tokens1[3]")
    (201, "                 out.write(fheader)#+\\'\\")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=qbicsoftware-archive/rnaseq, file=Snakefile
context_key: ['rule CutAdapt', 'run', 'if skip']
    (227, '        if skip:')
    (228, '            os.symlink(os.path.abspath(str(input[1])), str(output))')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=williamjeong2/snakemake_DNA-seq, file=rules/calling.smk
context_key: ['rule call_variants', 'input', 'else [']
    (23, '            else []')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=williamjeong2/snakemake_DNA-seq, file=rules/filtering.smk
context_key: ['rule merge_calls', 'input', 'else "hardfiltered"']
    (48, '            else "hardfiltered",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=ravimore8386/gatk, file=rules/filtering.smk
context_key: ['rule merge_calls', 'input', 'else "hardfiltered"']
    (58, '                              else "hardfiltered")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=aomlomics/tourmaline, file=Snakefile
context_key: ['rule summarize_metadata', 'run', 'if col in df.columns', 'if vc.index.shape == (0,)']
    (314, '            if col in df.columns:')
    (315, '                vc = df[col].value_counts()')
    (316, '                if vc.index.shape == (0,):')
    (317, "                    df2.loc[col, 0] = \\'(no values in column)\\'")
    (318, "                    df2.loc[col, 1] = \\'--\\'")
    (319, '                else:')
    (320, '                    df2.loc[col, 0] = vc.index[0]')
    (321, '                    df2.loc[col, 1] = vc.values[0]')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=aomlomics/tourmaline, file=Snakefile
context_key: ['rule summarize_metadata', 'run', 'if col in df.columns', 'else']
    (322, '            else:')
    (323, "                df2.loc[col, 0] = \\'(column not provided)\\'")
    (324, "                df2.loc[col, 1] = \\'--\\'")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=MetaSUB-CAMP/camp_binning, file=workflow/Snakefile
context_key: ['rule make_config', 'run', 'if s not in dct']
    (224, '            if s not in dct:')
    (225, '                dct[s] = {}')
    (226, '            dct[s][d] = join(*info[:-1] + [s])')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=CVUA-RRW/BaRCoD, file=workflow/rules/reports.smk
context_key: ['rule seq_size_table', 'run', 'if params.trim']
    (290, '        if params.trim:')
    (291, "            dfout = dfoutraw.rename(columns={\\'length\\': \\'db_length\\'})")
    (292, '            dftrim = pd.read_csv(input.trim, sep = \\\'\\\\t\\\', names = ["seqid", "length"])')
    (293, "            dfout = dfout.join(dftrim.set_index(\\'seqid\\'),")
    (294, "                               on = \\'seqid\\', how = \\'inner\\').rename(columns = {\\'length\\' : \\'trim_length\\'})")
    (295, "            dfout = dfout[[\\'seqid\\', \\'taxid\\', \\'name\\', \\'db_length\\', \\'trim_length\\']]")
    (296, "            dfout.to_csv(output[0], sep = \\'\\\\t\\', index = False)")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=ezherman/find-defence-systems, file=workflow/rules/systems_by_sample.smk
context_key: ['rule systems_by_sample', 'run', 'if df.empty']
    (11, '        if df.empty:')
    (12, '            df.to_csv(output.csv_out)')
    (13, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=ezherman/find-defence-systems, file=workflow/rules/subsystems_by_sample.smk
context_key: ['rule subsystems_by_sample', 'run', 'if os.stat(input.padloc).st_size > 0']
    (12, '        if os.stat(input.padloc).st_size > 0:')
    (13, '')
    (14, '            # import dataframes')
    (15, '            padloc = pd.read_csv(input.padloc)')
    (16, '            defense_finder = pd.read_table(input.dfinder)')
    (17, '')
    (18, '            # wrangle dataframes')
    (19, '            padloc = create_subsystem_table(padloc, "padloc")')
    (20, '            defense_finder = create_subsystem_table(defense_finder, "defense_finder")')
    (21, '')
    (22, '            # merge dataframes and export')
    (23, '            merge_subsystem_tables(defense_finder, padloc).to_csv(output.csv)')
    (24, '')
    (25, '        # if padloc did not find hits')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=ezherman/find-defence-systems, file=workflow/rules/subsystems_by_sample.smk
context_key: ['rule subsystems_by_sample', 'run', 'if os.stat(input.padloc).st_size == 0']
    (26, '        if os.stat(input.padloc).st_size == 0:')
    (27, '')
    (28, '            # import and wrangle')
    (29, '            defense_finder = pd.read_table(input.dfinder)')
    (30, '            defense_finder = create_subsystem_table(defense_finder, "defense_finder")')
    (31, '')
    (32, '            # export')
    (33, '            merge_subsystem_tables(defense_finder).to_csv(output.csv)')
    (34, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=jmeppley/np_read_clustering, file=rules/Snakefile.polish
context_key: ['rule compare_genes', 'run', 'if len(lengths) > 0']
    (58, '            if len(lengths) > 0:')
    (59, '                lengths = numpy.array(lengths)')
    (60, '                data.append(dict(mean=numpy.round(lengths.mean(),1),')
    (61, '                                 max=lengths.max(),')
    (62, '                                 min=lengths.min(),')
    (63, '                                 median=numpy.median(lengths),')
    (64, '                                 num=len(lengths),')
    (65, '                                 total=lengths.sum()')
    (66, '                                ))')
    (67, '            else:')
    (68, '                data.append({k:0 for k in')
    (69, "                [\\'mean\\',\\'max\\',\\'min\\',\\'median\\',\\'num\\',\\'total\\']})")
    (70, '            names.append(name)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=jmeppley/np_read_clustering, file=rules/Snakefile.minimap
context_key: ['rule window_abc', 'run', 'if os.path.getsize(str(input)) > 0']
    (54, '            if os.path.getsize(str(input)) > 0:')
    (55, '                for query, hit, mfrac in \\\\')
    (56, "                        pandas.read_csv(str(input), sep=\\'\\\\t\\') \\\\")
    (57, "                        .query(f\\'(hit != query) and \\' \\\\")
    (58, "                               f\\'(mlen >= {MM_COV_FRAC} * ((qlen + hlen) / 2))\\') \\\\")
    (59, "                        [[\\'query\\',\\'hit\\',\\'mfrac\\']].values:")
    (60, '')
    (61, '                    # MCL wants explicit bi directional scores')
    (62, '                    #  but minima only reports hits in one direction`')
    (63, '                    out_handle.write(f"{query}\\\\t{hit}\\\\t{mfrac:0.2f}\\')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=jmeppley/np_read_clustering, file=rules/Snakefile.finish
context_key: ['rule remove_fragments', 'params', "if w.ext.startswith(\\'f\\') \\"]
    (62, "                           if w.ext.startswith(\\'f\\') \\\\")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=jmeppley/np_read_clustering, file=rules/Snakefile.finish
context_key: ['rule remove_fragments', 'params', 'else "screen_table.py']
    (63, '                           else "screen_table.py"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Zhanmengtao/ImcSegmentationSnakemake, file=workflow/Snakefile
context_key: ['rule modify_measurement_pipeline', 'run', 'if line.rstrip()']
    (536, '                        if line.rstrip())')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Zhanmengtao/ImcSegmentationSnakemake, file=workflow/Snakefile
context_key: ['rule download_example_data', 'run', 'if ~fn.exists()']
    (614, '            if ~fn.exists():')
    (615, '                shutil.move(fn_cache[0], fn)')
    (616, '')
    (617, '### Varia')
    (618, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Adrianzo/dna-seq-variant-calling, file=rules/filtering.smk
context_key: ['rule merge_calls', 'input', 'else "hardfiltered"']
    (58, '                              else "hardfiltered")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=ttumkaya/snakemake_variant_calling, file=rules/calling.smk
context_key: ['rule call_variants', 'input', 'else [']
    (23, '            else []')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=wenliangz/wgs-variant-calling, file=rules/filtering.smk
context_key: ['rule merge_calls', 'input', 'else "hardfiltered"']
    (58, '                              else "hardfiltered")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=sheucke/dna-seq-gatk-variant-calling, file=rules/filtering.smk
context_key: ['rule merge_calls', 'input', 'else "hardfiltered"']
    (58, '                              else "hardfiltered")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=williamjeong2/snakemake_RNA-seq, file=Snakefile
context_key: ['rule fastp', 'run', 'if sample_is_single_end(params.sampleName)']
    (109, '        if sample_is_single_end(params.sampleName):')
    (110, '            shell("fastp --thread {threads} --html {output.html} \\\\')
    (111, '            --qualified_quality_phred {params.qualified_quality_phred} \\\\')
    (112, '            --in1 {input} --out1 {output.fq1} 2> {log}; \\\\')
    (113, '            touch {output.fq2}")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=williamjeong2/snakemake_RNA-seq, file=Snakefile
context_key: ['rule fastqc', 'run', 'if sample_is_single_end(params.sampleName)']
    (348, '       if sample_is_single_end(params.sampleName):')
    (349, '           shell("fastqc -t {threads} {input[0]} --outdir={params.path}")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=williamjeong2/snakemake_RNA-seq, file=Snakefile_toCount
context_key: ['rule fastp', 'run', 'if sample_is_single_end(params.sampleName)']
    (106, '        if sample_is_single_end(params.sampleName):')
    (107, '            shell("fastp --thread {threads} --html {output.html} \\\\')
    (108, '            --qualified_quality_phred {params.qualified_quality_phred} \\\\')
    (109, '            --in1 {input} --out1 {output.fq1} 2> {log}; \\\\')
    (110, '            touch {output.fq2}")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=eriqande/dna-seq-gatk-variant-calling, file=rules/calling.smk
context_key: ['rule call_variants', 'input', 'else [']
    (23, '            else []')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=allytrope/variant-analysis, file=workflow/rules/variant_calling.smk
context_key: ['rule consolidate', 'if [ -d {params.db} ]; \\']
    (308, '        if [ -d {params.db} ]; \\\\')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=allytrope/variant-analysis, file=workflow/rules/variant_calling.smk
context_key: ['rule consolidate', 'else WORKSPACE_FLAG="genomicsdb-workspace-path"; \\']
    (310, '        else WORKSPACE_FLAG="genomicsdb-workspace-path"; \\\\')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['else', 'rule count_samples_final', 'input', 'else "{PROJECT}/runs/{run}/{sample}_data/seqs_fw_rev_filtered.fasta']
    (1324, '            else "{PROJECT}/runs/{run}/{sample}_data/seqs_fw_rev_filtered.fasta"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['else', 'rule combine_filtered_samples', 'input', 'else  "{PROJECT}/runs/{run}/{sample}_data/seqs_fw_rev_filtered.fasta",PROJECT=config["PROJECT"],sample=config["LIBRARY"], run=run']
    (1355, '            else  "{PROJECT}/runs/{run}/{sample}_data/seqs_fw_rev_filtered.fasta",PROJECT=config["PROJECT"],sample=config["LIBRARY"], run=run)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['rule pick_representatives', 'input', 'if (config["derep"]["dereplicate"] == "T"  and config["pickOTU"]["m"] != "usearch" and config["pickOTU"]["m"] != "swarm"']
    (1452, '        if (config["derep"]["dereplicate"] == "T"  and config["pickOTU"]["m"] != "usearch" and config["pickOTU"]["m"] != "swarm")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['rule pick_representatives', 'input', 'else "{PROJECT}/runs/{run}/otu/seqs_fw_rev_combined_otus.txt"']
    (1454, '        else "{PROJECT}/runs/{run}/otu/seqs_fw_rev_combined_otus.txt",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['else', 'rule report_all_asv', 'input', 'else "{PROJECT}/runs/{run}/asv/taxonomy_dada2/representative_seq_set_noSingletons.fasta"']
    (1931, '            else "{PROJECT}/runs/{run}/asv/taxonomy_dada2/representative_seq_set_noSingletons.fasta",')
    (1932, ' #           if config["alignRep"]["align"] == "T"')
    (1933, ' #           else "{PROJECT}/runs/{run}/asv/dada2_representatives.fasta"')
    (1934, ' #           e="{PROJECT}/runs/{run}/asv/dada2_representatives.fasta",')
    (1935, ' #           if config["ANALYSIS_TYPE"] == "ASV"')
    (1936, ' #           else')
    (1937, ' #           "{PROJECT}/runs/{run}/otu/taxonomy_"+config["assignTaxonomy"]["tool"]+"/representative_seq_set_noSingletons.fasta",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlejandroAb/CASCABEL, file=Snakefile
context_key: ['rule report', 'script', 'else "Scripts/report_asv.py']
    (1984, '        else "Scripts/report_asv.py"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=oma219/khoice, file=workflow/rules/exp_type_6.smk
context_key: ['rule build_complex_ops_files_for_exp6', 'run', 'if data_file.endswith(".fna.gz")']
    (132, '            if data_file.endswith(".fna.gz"):')
    (133, '                base_name = data_file.split(".fna.gz")[0]')
    (134, '                kmc_input_files.append(f"exp6_genome_sets/rest_of_set/k_{wildcards.k}/dataset_{wildcards.num}/{base_name}.transformed")')
    (135, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=oma219/khoice, file=workflow/rules/exp_type_2.smk
context_key: ['rule build_complex_ops_within_files_for_exp2', 'run', 'if data_file.endswith(".fna.gz")']
    (266, '            if data_file.endswith(".fna.gz"):')
    (267, '                base_name = data_file.split(".fna.gz")[0]')
    (268, '                kmc_input_files.append(f"genome_sets_type_2/rest_of_set/k_{wildcards.k}/dataset_{wildcards.num}/{base_name}.transformed")')
    (269, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=oma219/khoice, file=workflow/rules/exp_type_2.smk
context_key: ['rule build_complex_ops_across_files_for_exp2', 'run', 'if i != wildcards.pivot_num']
    (295, '                if i != wildcards.pivot_num:')
    (296, '                    kmc_input_files.append(f"within_databases_type_2/rest_of_set/k_{wildcards.k}/dataset_{i}/dataset_{i}.transformed.combined.transformed")')
    (297, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Masteryuanli/snaktest, file=workflow/Snakefile
context_key: ['rule modify_measurement_pipeline', 'run', 'if line.rstrip()']
    (536, '                        if line.rstrip())')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Masteryuanli/snaktest, file=workflow/Snakefile
context_key: ['rule download_example_data', 'run', 'if ~fn.exists()']
    (614, '            if ~fn.exists():')
    (615, '                shutil.move(fn_cache[0], fn)')
    (616, '')
    (617, '### Varia')
    (618, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=hobrien/DiezmannLabManduca, file=Snakefile
context_key: ['rule download_ref', 'run', "if os.path.basename(o) == \\'ms_ogs.gff\\'"]
    (25, "            if os.path.basename(o) == \\'ms_ogs.gff\\':")
    (26, '                ro = rev_lookup[os.path.basename(o)]')
    (27, '                shell("wget -P Reference {ro}")')
    (28, "            elif os.path.basename(o) == \\'ms_scaffolds.fa\\':")
    (29, "                ro = rev_lookup[os.path.basename(\\'.\\'.join([o, \\'gz\\']))]")
    (30, '                shell("wget -P Reference {ro}")')
    (31, '                ro = os.path.basename(ro)')
    (32, '                shell("gunzip Reference/{ro}")')
    (33, '                shell("perl -pi -e \\\'s/gi.*gb\\\\|(\\\\w+\\\\.\\\\d)\\\\|/$1/\\\' Reference/ms_scaffolds.fa")')
    (34, '            else:    ')
    (35, "                ro = rev_lookup[os.path.basename(\\'.\\'.join([o, \\'gz\\']))]")
    (36, '                shell("wget -P Reference {ro}")')
    (37, '                ro = os.path.basename(ro)')
    (38, '                shell("gunzip Reference/{ro}")')
    (39, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=susheelbhanu/16S_DADA2, file=workflow/rules/asv.smk
context_key: ['rule krona_text', 'run', 'if counts.loc[sid, asv] > 0']
    (127, '                    if counts.loc[sid, asv] > 0:')
    (128, '                        assert asv in tax.index')
    (129, '                        c = counts.loc[sid, asv] # count')
    (130, '                        t = "\\\\t".join(tax.loc[asv].fillna(value="NA")) # taxonomy')
    (131, '                        t = re.sub("^NA(\\\\tNA)+$", "Unknown", t) # replace completely unknown taxonomy')
    (132, '                        t = re.sub("(\\\\tNA)+$", "", t) # remove trailing NAs')
    (133, '                        ofile.write("%d\\\\t%s\\')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SaGeTOPK/sage-topk-experiments, file=Snakefile
context_key: ['rule format_run_topk_query', 'run', 'if "query" not in df']
    (94, '        if "query" not in df:')
    (95, '            df["query"] = wildcards.query')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SaGeTOPK/sage-topk-experiments, file=Snakefile
context_key: ['rule format_run_topk_query', 'run', 'if "run" not in df']
    (96, '        if "run" not in df:')
    (97, '            df["run"] = wildcards.run')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SaGeTOPK/sage-topk-experiments, file=Snakefile
context_key: ['rule format_run_topk_query', 'run', 'if "limit" not in df']
    (98, '        if "limit" not in df:')
    (99, '            df["limit"] = wildcards.limit')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SaGeTOPK/sage-topk-experiments, file=Snakefile
context_key: ['rule format_run_topk_query', 'run', 'if "quota" not in df']
    (100, '        if "quota" not in df:')
    (101, '            df["quota"] = wildcards.quota')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SaGeTOPK/sage-topk-experiments, file=Snakefile
context_key: ['rule format_run_topk_query', 'run', 'if "approach" not in df']
    (102, '        if "approach" not in df:')
    (103, '            df["approach"] = wildcards.approach')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SaGeTOPK/sage-topk-experiments, file=Snakefile
context_key: ['rule format_run_topk_query', 'run', 'if "workload" not in df']
    (104, '        if "workload" not in df:')
    (105, '            df["workload"] = wildcards.workload')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SaGeTOPK/sage-topk-experiments, file=Snakefile
context_key: ['rule format_run_topk_query', 'run', 'if "xp" not in df']
    (106, '        if "xp" not in df:')
    (107, '            df["xp"] = wildcards.xp')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SaGeTOPK/sage-topk-experiments, file=Snakefile
context_key: ['rule format_check_topk_query', 'run', 'if "query" not in df']
    (153, '        if "query" not in df:')
    (154, '            df["query"] = wildcards.query')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SaGeTOPK/sage-topk-experiments, file=Snakefile
context_key: ['rule format_check_topk_query', 'run', 'if "limit" not in df']
    (155, '        if "limit" not in df:')
    (156, '            df["limit"] = wildcards.limit')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SaGeTOPK/sage-topk-experiments, file=Snakefile
context_key: ['rule format_check_topk_query', 'run', 'if "approach" not in df']
    (157, '        if "approach" not in df:')
    (158, '            df["approach"] = wildcards.approach')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SaGeTOPK/sage-topk-experiments, file=Snakefile
context_key: ['rule format_check_topk_query', 'run', 'if "workload" not in df']
    (159, '        if "workload" not in df:')
    (160, '            df["workload"] = wildcards.workload')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=SaGeTOPK/sage-topk-experiments, file=Snakefile
context_key: ['rule format_check_topk_query', 'run', 'if "xp" not in df']
    (161, '        if "xp" not in df:')
    (162, '            df["xp"] = wildcards.xp')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=lculibrk/Ploidetect-pipeline, file=Snakefile
context_key: ['rule ploidetect', 'input', 'if not workflow.use_singularit']
    (525, '            if not workflow.use_singularity')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=lculibrk/Ploidetect-pipeline, file=Snakefile
context_key: ['rule ploidetect', 'input', 'else __file_']
    (528, '            else __file__')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=bitextor/bitextor, file=bitextor/rules/dic_doc_seg_align.smk
context_key: ['rule create_hunalign_dic_format', 'run', 'if langs[0] == SRC_LANG and langs[1] == TRG_LANG']
    (291, '                if langs[0] == SRC_LANG and langs[1] == TRG_LANG:')
    (292, '                    inverse = True')
    (293, '                else:')
    (294, '                    inverse = False')
    (295, '                for inline in inr:')
    (296, '                    columns = inline.strip().split("\\\\t")')
    (297, '                    if inverse:')
    (298, '                        outw.write(f"{columns[1]} @ {columns[0]}\\')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=bitextor/bitextor, file=bitextor/Snakefile
context_key: ['if translatationDirection is different from lang1->lang2, in this rule the columns are switche']
    (1428, '        if translatationDirection is different from lang1->lang2, in this rule the columns are switched')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=bitextor/bitextor, file=bitextor/Snakefile
context_key: ['rule pre_filter', 'run', 'if "bifixer_hash" in header', 'if "bifixer_score" in header']
    (1708, '        if "bifixer_hash" in header:')
    (1709, '            i = header.index("bifixer_hash") + 1')
    (1710, '            j = ""')
    (1711, '')
    (1712, '            if "bifixer_score" in header:')
    (1713, '                # We sort using bifixer score as second criteria and not bicleaner score')
    (1714, '                #  because in the case of duplicated we prefer bifixer, which uses')
    (1715, '                #  rules and indicates which aligned content is more "correct".')
    (1716, "                j = header.index(\\'bifixer_score\\') + 1")
    (1717, '                j = f"-k{j},{j}nr "')
    (1718, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=bitextor/bitextor, file=bitextor/Snakefile
context_key: ['rule pre_filter', 'run', 'if "bifixer_hash" in header']
    (1719, '            sort_flags = f"-k{i},{i} {j}" + sort_flags')
    (1720, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=bitextor/bitextor, file=bitextor/rules/dic_generation.smk
context_key: ['rule dic_generation_lex_dic', 'run', 'if value > 0.1', 'if item[0] in svocabulary and item[1] in tvocabulary']
    (241, '            if value > 0.1:')
    (242, '                if item[0] in svocabulary and item[1] in tvocabulary:')
    (243, '                    dice2f.write("{0} {1} {2}\\')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=iwohlers/2020_mt_analyses, file=Snakefile
context_key: ['rule get populations_and_individual_ids', 'run', 'if line[0] == "#"']
    (501, '                if line[0] == "#":')
    (502, '                    continue')
    (503, '                s = line.split("/")')
    (504, '                population = s[8]')
    (505, '                individual = s[9]')
    (506, '                f_out.write(population+"\\\\t"+individual+"\\')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=iwohlers/2020_mt_analyses, file=Snakefile
context_key: ['rule pop_ind_file_1000g', 'run', 'if line[']
    (620, '                if line[:3] == "url":')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=ocisse/dna-seq-gatk-variant-calling, file=rules/filtering.smk
context_key: ['rule merge_calls', 'input', 'else "hardfiltered"']
    (58, '                              else "hardfiltered")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=broadinstitute/depmap-crispr-vs-rnai, file=ensemble_prediction.snake
context_key: ['rule sparkle_ensemble_params', 'run', 'if model_def["Relation"]']
    (103, '            if model_def["Relation"]:')
    (104, '                all_data = all_data.union(set([model_def["Relation"]]))')
    (105, '        # Write task info')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=1dayac/Novel-X, file=Snakefile
context_key: ['rule assemble_unmapped_reads', 'run', 'if DATA == "other"']
    (53, '        if DATA == "other":')
    (54, '            shell("{SPADES} -t {THREADS} -k {VELVET_K} -1 temp_reads/{wildcards.sample}_R1.fastq -2 temp_reads/{wildcards.sample}_R2.fastq --only-assembler -o spades_{wildcards.sample}")')
    (55, '            shell("cp spades_{wildcards.sample}/scaffolds.fasta fasta/{wildcards.sample}.fasta")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=1dayac/Novel-X, file=Snakefile
context_key: ['rule filter_contaminants', 'run', "if BLAST_DB != \\'None\\'"]
    (89, "        if BLAST_DB != \\'None\\':")
    (90, '            shell("mkdir -p blast")')
    (91, '            shell("{BLASTN} -task megablast -query {input.filtered_fasta} -db {BLAST_DB} -num_threads {THREADS} > blast/{wildcards.sample}.megablast")')
    (92, '            shell("{GIT_ROOT}/cleanmega blast/{wildcards.sample}.megablast blast/{wildcards.sample}.cleanmega")')
    (93, '            shell("{GIT_ROOT}/find_contaminations.py blast/{wildcards.sample}.cleanmega blast/{wildcards.sample}.contaminants")')
    (94, '            shell("python {GIT_ROOT}/remove_contaminations.py blast/{wildcards.sample}.contaminants {input.filtered_fasta} {output.filtered_fasta}")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=kevinrue/snakemake_rnaseq_hisat2, file=workflow/rules/ref.smk
context_key: ['rule download_genome', 'run', 'if bool(re.search(r".gz$", str(input)))']
    (12, '        if bool(re.search(r".gz$", str(input))):')
    (13, '            shell("gzip -d resources/genome.fa.gz > {log} 2>&1")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=kevinrue/snakemake_rnaseq_hisat2, file=workflow/rules/ref.smk
context_key: ['rule download_gene_annotations', 'run', 'if bool(re.search(r".gtf$", str(input)))']
    (46, '        if bool(re.search(r".gtf$", str(input))):')
    (47, '            shell("gzip resources/genes.gtf.gz > {log} 2>&1")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=lqsae/vcf-tools, file=rules/filtering.smk
context_key: ['rule merge_calls', 'input', 'else "hardfiltered"']
    (58, '                              else "hardfiltered")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=maniakk2000/Cbai, file=rules/calling.smk
context_key: ['rule call_variants', 'input', 'else [']
    (23, '            else []')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=lauren-mak/camp_binning, file=workflow/Snakefile
context_key: ['rule make_config', 'run', 'if s not in dct']
    (224, '            if s not in dct:')
    (225, '                dct[s] = {}')
    (226, '            dct[s][d] = join(*info[:-1] + [s])')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=MaleloAS/Alice_MS, file=Snakefile
context_key: ['rule cutadapt', 'run', 'if len(input.fastq) == 2']
    (116, '        if len(input.fastq) == 2:')
    (117, '            shell(r"""')
    (118, '            cutadapt --quality-cutoff 15 --minimum-length 10 --cores 4 \\\\')
    (119, '                -a AGATCGGAAGAGC -A AGATCGGAAGAGC -o {output.fastq_r1} -p {output.fastq_r2} {input.fastq} > {output.report}')
    (120, '            """)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=MaleloAS/Alice_MS, file=Snakefile
context_key: ['rule hisat2_align', 'run', 'if len(input.n_fastq) == 2']
    (356, '        if len(input.n_fastq) == 2:')
    (357, '            shell(r"""')
    (358, '            hisat2 -p 7 --summary-file {output.log} --new-summary --max-intronlen 5000 \\\\')
    (359, '                -x {input.fasta} -1 {input.fastq_r1} -2 {input.fastq_r2} \\\\')
    (360, '            | samtools sort -@ 4 > {output.bam}')
    (361, '')
    (362, '            samtools index {output.bam}')
    (363, '            """)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=ebi-gene-expression-group/wf-bulk-indexing, file=Snakefile
context_key: ['rule stage_files_for_species', 'run', 'if dest.endswith("go") or dest.endswith("interpro")']
    (263, '            if dest.endswith("go") or dest.endswith("interpro"):')
    (264, '                call = f"rsync {rsync_options} --include=*.tsv  --exclude=* {dir}/* {dest}"')
    (265, '            elif not glob.glob(f"{dir}/{params.species}.*.tsv") and not glob.glob(f"{dir}/*/{params.species}.*.tsv"):')
    (266, '                print(f"Skipping {dir} for {params.species}")')
    (267, '                continue')
    (268, "            elif dest.endswith(\\'annotations\\') or dest.endswith(\\'array_designs\\'):")
    (269, '                # some directories which are not "go" will not have anything for our species')
    (270, '                call = f"rsync {rsync_options} {dir}/**/{params.species}.*.tsv {dest}"')
    (271, "            elif dest.endswith(\\'reactome\\') or dest.endswith(\\'mirbase\\'):")
    (272, '                call = f"rsync {rsync_options} {dir}/{params.species}.*.tsv {dest}"')
    (273, '')
    (274, '')
    (275, '            print(f"Calling {call}")')
    (276, '            command = f"""')
    (277, '                      exec &> "{log}"')
    (278, '                      mkdir -p {dest}')
    (279, '                      {call}')
    (280, '                      """')
    (281, '            shell(command)')
    (282, '            print(f"{dir} staged")')
    (283, '')
    (284, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=alexmsalmeida/magscreen, file=Snakefile
context_key: ['rule mags_filter', 'run', 'if not os.path.exists(output[0])']
    (57, '        if not os.path.exists(output[0]):')
    (58, '            os.makedirs(output[0])')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=alexmsalmeida/magscreen, file=Snakefile
context_key: ['rule extract_unknown', 'run', 'if not os.path.exists(output[0])']
    (114, '        if not os.path.exists(output[0]):')
    (115, '            os.makedirs(output[0])')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=alexmsalmeida/magscreen, file=Snakefile
context_key: ['rule extract_unknown', 'run', 'if af < 30 or ani < 95']
    (122, '                if af < 30 or ani < 95:')
    (123, '                    os.symlink(os.path.abspath(INPUT_DIR+"/"+cols[0]+".fa"), output[0]+"/"+cols[0]+".fa")')
    (124, '')
    (125, '# cluster unknown mags')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=alexmsalmeida/magscreen, file=Snakefile
context_key: ['rule new_species', 'run', 'if not os.path.exists(params.new_dir)']
    (188, '        if not os.path.exists(params.new_dir):')
    (189, '            os.makedirs(params.new_dir)')
    (190, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=alexmsalmeida/magscreen, file=Snakefile
context_key: ['rule new_species', 'run', 'if cluster not in clusters']
    (198, '                if cluster not in clusters:')
    (199, '                    clusters[cluster] = 0')
    (200, '                else:')
    (201, '                    clusters[cluster] += 1')
    (202, '                if genome+".fa" == cols[0]:')
    (203, '                    cluster_selected = cluster')
    (204, '            if clusters[cluster_selected] > 1:')
    (205, '                drep_passed = "Yes"')
    (206, '            else:')
    (207, '                drep_passed = "No"')
    (208, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=alexmsalmeida/magscreen, file=Snakefile
context_key: ['rule new_species', 'run', 'if genome+".fa" == cols[0]', 'if float(cols[1]) >= 90']
    (213, '                if genome+".fa" == cols[0]:')
    (214, '                    if float(cols[1]) >= 90:')
    (215, '                        checkm_passed = "Yes"')
    (216, '                    else:')
    (217, '                        checkm_passed = "No"')
    (218, '       ')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=alexmsalmeida/magscreen, file=Snakefile
context_key: ['rule new_species', 'run', 'if genome == cols[0]', 'if float(cols[7]) <= 0.45 or float(cols[8]) <= 0.05 or float(cols[11]) <= 0.5']
    (223, '                if genome == cols[0]:')
    (224, '                    if float(cols[7]) <= 0.45 or float(cols[8]) <= 0.05 or float(cols[11]) <= 0.5:')
    (225, '                        gunc_passed = "Yes"')
    (226, '                    else:')
    (227, '                        gunc_passed = "No"')
    (228, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=alexmsalmeida/magscreen, file=Snakefile
context_key: ['rule new_species', 'run', 'if drep_passed == "Yes" or checkm_passed == "Yes" or gunc_passed == "Yes"']
    (229, '        if drep_passed == "Yes" or checkm_passed == "Yes" or gunc_passed == "Yes":')
    (230, '            os.symlink(os.path.abspath(input.drep+"/dereplicated_genomes/"+genome+".fa"), params.new_dir+"/"+genome+".fa")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=osvaldoreisss/miseq_bac_assembly_annot_workflow, file=workflow/rules/assembly.smk
context_key: ['rule check_best_assembly', 'run', "if assembly == \\'spades\\'"]
    (91, "        if assembly == \\'spades\\':")
    (92, "            copy(f\\'{input.spades}\\', f\\'{output[0]}\\') ")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=osvaldoreisss/miseq_bac_assembly_annot_workflow, file=workflow/rules/assembly.smk
context_key: ['rule check_best_assembly', 'run', "elif assembly == \\'skesa\\'"]
    (93, "        elif assembly == \\'skesa\\':")
    (94, "            copy(f\\'{input.skesa}\\', f\\'{output[0]}\\') ")
    (95, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=jhamman/chains, file=metsim.snakefile
context_key: ['rule config_metsim', 'run', "if wildcards.dsm in config[\\'DOWNSCALING\\']"]
    (82, "        if wildcards.dsm in config[\\'DOWNSCALING\\']:")
    (83, "            in_vars = config[\\'DOWNSCALING\\'][wildcards.dsm][\\'variables\\']")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=jhamman/chains, file=prms.snakefile
context_key: ['rule config_prms', 'run', "if wildcards.scen in [\\'hist\\', \\'obs_hist\\']"]
    (85, "        if wildcards.scen in [\\'hist\\', \\'obs_hist\\']:")
    (86, "            options[\\'use_init_state_file\\'] = 0")
    (87, "            options[\\'input_state\\'] = NULL_STATE")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=jhamman/chains, file=prms.snakefile
context_key: ['rule post_process_prms', 'run', "if \\'missing_value\\' in ds[\\'time\\'].attrs"]
    (134, "        if \\'missing_value\\' in ds[\\'time\\'].attrs:")
    (135, "            del ds[\\'time\\'].attrs[\\'missing_value\\']")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=jhamman/chains, file=prms.snakefile
context_key: ['rule post_process_prms', 'run', "if da.attrs[\\'units\\'] == \\'in/d\\'"]
    (143, "            if da.attrs[\\'units\\'] == \\'in/d\\':")
    (144, '                da = da * MM_PER_IN')
    (145, "                da.attrs[\\'units\\'] = \\'mm d-1\\'")
    (146, "            elif da.attrs[\\'units\\'] == \\'in\\':")
    (147, '                da = da * MM_PER_IN')
    (148, "                da.attrs[\\'units\\'] = \\'mm\\'")
    (149, '            else:')
    (150, "                print(\\'unknown unit conversion\\')")
    (151, '            ds_grid[v] = da')
    (152, '')
    (153, '        # save daily file')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=jhamman/chains, file=downscaling.snakefile
context_key: ['rule downscaling', 'run', "if \\'hist\\' in wildcards.scen"]
    (196, "        if \\'hist\\' in wildcards.scen:")
    (197, '            start_year = int(start_year) - 1')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=jhamman/chains, file=downscaling.snakefile
context_key: ['rule downscaling', 'run', "if wildcards.dsm in config[\\'DOWNSCALING\\']"]
    (199, "        if wildcards.dsm in config[\\'DOWNSCALING\\']:")
    (200, "            rename = config[\\'DOWNSCALING\\'][wildcards.dsm][\\'variables\\']")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=jhamman/chains, file=vic.snakefile
context_key: ['rule config_vic', 'run', "if wildcards.scen in [\\'hist\\', \\'obs_hist\\']"]
    (56, "        if wildcards.scen in [\\'hist\\', \\'obs_hist\\']:")
    (57, "            options[\\'init_state\\'] = \\'\\'")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=jhamman/chains, file=vic.snakefile
context_key: ['rule run_vic', 'run', "if \\'prerun_cmd\\' is not None"]
    (89, "        if \\'prerun_cmd\\' is not None:")
    (90, '            shell(prerun_cmd)')
    (91, '        # TODO: replace 12 {threads}')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=MGXlab/phap, file=workflow/rules/crispropendb.smk
context_key: ['rule process_crispropendb', 'run', 'if "Sorry" in line[1]']
    (43, '                if "Sorry" in line[1]:')
    (44, '                    fout.write(f"{line[0]}\\\\tNone\\\\t0\\')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=bhaddow/pmindia-crawler, file=Snakefile.nmt
context_key: ['rule filter_dev', 'run', 'if len(l0[']
    (90, '        if len(l0[:-1].split()) > 50 or len(l1[:-1].split()) > 50:')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=bhaddow/pmindia-crawler, file=Snakefile
context_key: ['rule release_hunalign', 'run', 'if line in lines']
    (94, '        if line in lines:')
    (95, '          continue')
    (96, '        lines.add(line)')
    (97, '        print (line, file=ofh, end="")')
    (98, '')
    (99, '  #shell:')
    (100, '    #"mkdir -p `dirname {output}`;  LC_ALL=C sort {input} | uniq | shuf >  {output}" ')
    (101, '')
    (102, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=bhaddow/pmindia-crawler, file=Snakefile
context_key: ['rule intersect_align', 'run', 'if line in lines']
    (136, '        if line in lines:')
    (137, '          continue')
    (138, '        lines.add(line)')
    (139, '        if line in hunaligns:')
    (140, '          print(line, file=ifh, end="")')
    (141, '        else:')
    (142, '          print(line, file=ofh, end="")')
    (143, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=bhaddow/pmindia-crawler, file=Snakefile
context_key: ['rule intersect_align', 'run', 'if line in lines']
    (147, '        if line in lines:')
    (148, '          continue')
    (149, '        lines.add(line)')
    (150, '        if not line in vecaligns:')
    (151, '          print(line, file=ofh, end="")')
    (152, '')
    (153, '    #with open(output["intersect"], "w") as ifh:')
    (154, '    #  for pair in vecalign_pairs.intersection(hunalign_pairs):')
    (155, '    #    print("\\\\t".join(pair), file=ifh)')
    (156, '    #with open(output["onlyvec"], "w") as ofh:')
    (157, '    #  for pair in vecalign_pairs.difference(hunalign_pairs):')
    (158, '    #    print("\\\\t".join(pair), file=ofh)')
    (159, '    #with open(output["onlyhun"], "w") as ofh:')
    (160, '    #  for pair in hunalign_pairs.difference(vecalign_pairs):')
    (161, '    #    print("\\\\t".join(pair), file=ofh)')
    (162, '')
    (163, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=dilworthlab/CnT_pipeline_snakemake, file=Snakefile
context_key: ['rule Peaks_SEACR', 'run', 'if len(input.Control) >= 1']
    (533, '        if len(input.Control) >= 1:')
    (534, '            for IgG in input.Control:')
    (535, '                for Targetfile in input.Target:')
    (536, '                    Name = (os.path.basename(Targetfile).split(".")[0]).replace("_Norm", "")')
    (537, '                    shell ( "bash {params.SEACRLoc} {Targetfile} {IgG} non stringent Analysis_Results/Peaks/{Name} &>> {log} " )')
    (538, '                    shell ( "bash {params.SEACRLoc} {Targetfile} {IgG} non relaxed Analysis_Results/Peaks/{Name} &>> {log} " )')
    (539, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=tanaes/snakemake_assemble, file=bin/snakefiles/report
context_key: ['if rule in cluster_json']
    (111, '        if rule in cluster_json:')
    (112, "            benchmark_df.loc[benchmark_df[\\'rule\\'] == rule,\\'n_cpus\\'] = cluster_json[rule][\\'n\\']")
    (113, "            benchmark_df.loc[benchmark_df[\\'rule\\'] == rule,\\'mem\\'] = cluster_json[rule][\\'mem\\']")
    (114, '        else:')
    (115, "            benchmark_df.loc[benchmark_df[\\'rule\\'] == rule,\\'n_cpus\\'] = cluster_json[\\'__default__\\'][\\'n\\']")
    (116, "            benchmark_df.loc[benchmark_df[\\'rule\\'] == rule,\\'mem\\'] = cluster_json[\\'__default__\\'][\\'mem\\']")
    (117, '')
    (118, "    benchmark_df[\\'cpu_s\\'] = benchmark_df[\\'s\\'] * benchmark_df[\\'n_cpus\\']")
    (119, "    benchmark_df[\\'cpu_h\\'] = benchmark_df[\\'s\\'] * benchmark_df[\\'n_cpus\\'] / 3600")
    (120, '    ')
    (121, '    benchmark_tidy = pd.melt(benchmark_df,')
    (122, "               id_vars=[\\'benchmark_file\\', \\'rule\\', \\'module\\', \\'sample\\', \\'abund_sample\\', \\'sample_seqs\\', \\'abund_seqs\\', \\'n_cpus\\', \\'mem\\'])")
    (123, '    ')
    (124, '    # convert value column to numeric')
    (125, "    benchmark_tidy[\\'value\\'] = pd.to_numeric(benchmark_tidy[\\'value\\'])")
    (126, '')
    (127, '')
    (128, '    return(benchmark_df, benchmark_tidy)')
    (129, '')
    (130, '')
    (131, '# plotting functions')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=tanaes/snakemake_assemble, file=bin/snakefiles/report
context_key: ['rule report_benchmark_summary', 'run', 'if not os.path.exists(figdir)']
    (274, '        if not os.path.exists(figdir):')
    (275, '            os.makedirs(figdir)')
    (276, '')
    (277, '        # read in the read stats per sample')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=tanaes/snakemake_assemble, file=bin/snakefiles/qc
context_key: ['rule qc_filter', 'run', 'if params.filter_db is None']
    (62, '        if params.filter_db is None:')
    (63, '            f_fp = os.path.abspath(input.forward)')
    (64, '            r_fp = os.path.abspath(input.reverse)')
    (65, '            shell("""')
    (66, '                    ln -s {f_fp} {output.forward}')
    (67, '                    ln -s {r_fp} {output.reverse}')
    (68, '')
    (69, "                    echo \\'No DB provided; sample not filtered.\\' > {log.bowtie}")
    (70, "                    echo \\'No DB provided; sample not filtered.\\' > {log.other}")
    (71, '                  """)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=tanaes/snakemake_assemble, file=bin/snakefiles/qc
context_key: ['rule qc_filter', 'run', 'if params.filter_db is None']
    (62, '        if params.filter_db is None:')
    (63, '            f_fp = os.path.abspath(input.forward)')
    (64, '            r_fp = os.path.abspath(input.reverse)')
    (65, '            shell("""')
    (66, '                    ln -s {f_fp} {output.forward}')
    (67, '                    ln -s {r_fp} {output.reverse}')
    (68, '')
    (69, "                    echo \\'No DB provided; sample not filtered.\\' > {log.bowtie}")
    (70, "                    echo \\'No DB provided; sample not filtered.\\' > {log.other}")
    (71, '                  """)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=tanaes/snakemake_assemble, file=bin/snakefiles/report
context_key: ['if rule in cluster_json']
    (111, '        if rule in cluster_json:')
    (112, "            benchmark_df.loc[benchmark_df[\\'rule\\'] == rule,\\'n_cpus\\'] = cluster_json[rule][\\'n\\']")
    (113, "            benchmark_df.loc[benchmark_df[\\'rule\\'] == rule,\\'mem\\'] = cluster_json[rule][\\'mem\\']")
    (114, '        else:')
    (115, "            benchmark_df.loc[benchmark_df[\\'rule\\'] == rule,\\'n_cpus\\'] = cluster_json[\\'__default__\\'][\\'n\\']")
    (116, "            benchmark_df.loc[benchmark_df[\\'rule\\'] == rule,\\'mem\\'] = cluster_json[\\'__default__\\'][\\'mem\\']")
    (117, '')
    (118, "    benchmark_df[\\'cpu_s\\'] = benchmark_df[\\'s\\'] * benchmark_df[\\'n_cpus\\']")
    (119, "    benchmark_df[\\'cpu_h\\'] = benchmark_df[\\'s\\'] * benchmark_df[\\'n_cpus\\'] / 3600")
    (120, '    ')
    (121, '    benchmark_tidy = pd.melt(benchmark_df,')
    (122, "               id_vars=[\\'benchmark_file\\', \\'rule\\', \\'module\\', \\'sample\\', \\'abund_sample\\', \\'sample_seqs\\', \\'abund_seqs\\', \\'n_cpus\\', \\'mem\\'])")
    (123, '    ')
    (124, '    # convert value column to numeric')
    (125, "    benchmark_tidy[\\'value\\'] = pd.to_numeric(benchmark_tidy[\\'value\\'])")
    (126, '')
    (127, '')
    (128, '    return(benchmark_df, benchmark_tidy)')
    (129, '')
    (130, '')
    (131, '# plotting functions')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=tanaes/snakemake_assemble, file=bin/snakefiles/report
context_key: ['rule report_benchmark_summary', 'run', 'if not os.path.exists(figdir)']
    (274, '        if not os.path.exists(figdir):')
    (275, '            os.makedirs(figdir)')
    (276, '')
    (277, '        # read in the read stats per sample')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=1709mrd/1_school_dna-seq-gatk-variant-calling, file=rules/calling.smk
context_key: ['rule call_variants', 'input', 'else [']
    (23, '            else []')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=bitextor/bitextor-neural, file=bitextor/Snakefile
context_key: ['rule filter', 'run', 'if input[0][-3']
    (782, '        if input[0][-3:] == ".gz":')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=bitextor/bitextor-neural, file=bitextor/Snakefile
context_key: ['rule filter', 'run', 'if BICLEANER']
    (785, '        if BICLEANER:')
    (786, '            cmd += (')
    (787, '                f""" | {PROFILING} python3 {WORKFLOW}/bitextor_filterbicleaner.py --threshold {BICLEANER_THRESHOLD} """')
    (788, '            )')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=bitextor/bitextor-neural, file=bitextor/Snakefile
context_key: ['rule filter', 'run', 'if ELRC']
    (789, '        if ELRC:')
    (790, '            cmd += f""" | {PROFILING} python3 {WORKFLOW}/bitextor_elrc_filtering.py -c "{BEFORE_ELRC_FIELDS}" -s """')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=bitextor/bitextor-neural, file=workflow/Snakefile
context_key: ['rule filter', 'run', 'if input[0][-3']
    (701, '        if input[0][-3:] == ".gz":')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=bitextor/bitextor-neural, file=workflow/Snakefile
context_key: ['rule filter', 'run', 'if BICLEANER']
    (704, '        if BICLEANER:')
    (705, '            cmd += (')
    (706, '                f""" | {PROFILING} python3 {WORKFLOW}/bitextor_filterbicleaner.py --threshold {BICLEANER_THRESHOLD} """')
    (707, '            )')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=bitextor/bitextor-neural, file=workflow/Snakefile
context_key: ['rule filter', 'run', 'if ELRC']
    (708, '        if ELRC:')
    (709, '            cmd += f""" | {PROFILING} python3 {WORKFLOW}/bitextor_elrc_filtering.py -c "{BEFORE_ELRC_FIELDS}" -s """')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=EvoHull/Tapirs, file=workflow/rules/kraken2.smk
context_key: ['rule kraken2', 'run', 'if len([1 for line in open(input.reads)]) > 0']
    (15, '        if len([1 for line in open(input.reads)]) > 0:')
    (16, '            shell("kraken2 --db {config[kraken2_db]} {input.reads} \\\\')
    (17, '            --threads {config[kraken2_threads]} \\\\')
    (18, '            --confidence {config[kraken2_confidence]} \\\\')
    (19, '            --report {output.reports} \\\\')
    (20, '            --output {output.outputs}")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=DarwinAwardWinner/CD4-csaw, file=rulegraph.Snakefile
context_key: ['rule dag_svg', 'run', 'if is_target_rule(params.target_path)', 'if len(rule.output)']
    (43, '        if is_target_rule(params.target_path):')
    (44, '            rule = get_rule(params.target_path)')
    (45, '            if len(rule.output):')
    (46, '                real_targets = rule.output')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=DarwinAwardWinner/CD4-csaw, file=rulegraph.Snakefile
context_key: ['rule dag_svg', 'run', 'if is_target_rule(params.target_path)', 'else']
    (47, '            else:')
    (48, '                real_targets = rule.input')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=DarwinAwardWinner/CD4-csaw, file=rulegraph.Snakefile
context_key: ['rule rulegraph_svg', 'run', 'if is_target_rule(params.target_path)', 'if len(rule.output)']
    (61, '        if is_target_rule(params.target_path):')
    (62, '            rule = get_rule(params.target_path)')
    (63, '            if len(rule.output):')
    (64, '                real_targets = rule.output')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=DarwinAwardWinner/CD4-csaw, file=rulegraph.Snakefile
context_key: ['rule rulegraph_svg', 'run', 'if is_target_rule(params.target_path)', 'else']
    (65, '            else:')
    (66, '                real_targets = rule.input')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=steveped/GRAVI, file=workflow/rules/pairwise_comparisons.smk
context_key: ['rule compile_pairwise_comparisons_html', 'if [[ {params.git} == "True" ]]; the']
    (102, '        if [[ {params.git} == "True" ]]; then')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=steveped/GRAVI, file=workflow/rules/pairwise_comparisons.smk
context_key: ['rule compile_pairwise_comparisons_html', 'if [[ "$TRIES" == 0 ]]; the']
    (106, '                if [[ "$TRIES" == 0 ]]; then')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=nioo-knaw/PhyloFunDB, file=Snakefile
context_key: ['rule final', 'else expand("results/{gene}.treefile \\']
    (8, '                   else expand("results/{gene}.treefile \\\\')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=nioo-knaw/PhyloFunDB, file=Snakefile
context_key: ['rule download_ncbi', 'if [[ {config[update]} == True ]]; the']
    (24, '           if [[ {config[update]} == True ]]; then')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=nioo-knaw/PhyloFunDB, file=Snakefile
context_key: ['rule download_taxonomy', 'if [[ {config[update]} == True ]]; the']
    (55, '           if [[ {config[update]} == True ]]; then')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=frankier/freqknowfit, file=workflow/Snakefile
context_key: ['rule fit_model', 'run', 'if MODELS[wildcards.model] == "R"']
    (83, '        if MODELS[wildcards.model] == "R":')
    (84, '            prog = "Rscript " + params.r_script')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=jereiard/msto, file=rules/calling.smk
context_key: ['rule call_variants', 'input', 'else [']
    (23, '            else []')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=cbg-ethz/SARS-CoV-2_Analysis, file=workflow/rules/data_retrieval.smk
context_key: ['rule download_fastq', 'run', 'if counter > 0']
    (58, '            if counter > 0:')
    (59, '                # turns out that fasterq-dump crashes for some accessions')
    (60, '                # when using more than 1 thread')
    (61, '                threads = 1')
    (62, '')
    (63, '            try:')
    (64, '                shell(')
    (65, '                    "fasterq-dump"')
    (66, '                    " --threads {threads}"')
    (67, '                    " -p"  # --progress')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=cbg-ethz/SARS-CoV-2_Analysis, file=workflow/rules/data_retrieval.smk
context_key: ['rule download_fastq', 'run', 'if len(available_files) in (1, 2, 3)']
    (79, '            if len(available_files) in (1, 2, 3):')
    (80, '                # downloaded SE, PE, varying read number per spot')
    (81, '                break')
    (82, '')
    (83, '            # no files were downloaded, retry...')
    (84, '            shell(\\\'echo "Download failed, restarting" >> {log.errfile}\\\')')
    (85, '            counter += 1')
    (86, '')
    (87, '            if counter > params.restart_times:')
    (88, '                raise RuntimeError(f"Download failed {counter} times")')
    (89, '')
    (90, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=cbg-ethz/SARS-CoV-2_Analysis, file=workflow/rules/data_retrieval.smk
context_key: ['rule compute_additional_properties', 'run', 'if read.infer_read_length() is not Non']
    (614, '                    if read.infer_read_length() is not None')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=cbg-ethz/SARS-CoV-2_Analysis, file=workflow/rules/data_retrieval.smk
context_key: ['rule distill_data_frame', 'run', 'if isinstance(col, str)']
    (755, '                if isinstance(col, str):')
    (756, '                    res = res.combine_first(df_all[col])')
    (757, '                else:')
    (758, '                    res = res.combine_first(col(df_all))')
    (759, '                print(" > ", col, res.isna().sum())')
    (760, '')
    (761, '            if na_values is not None:')
    (762, '                res = res.replace({v: pd.NA for v in na_values})')
    (763, '')
    (764, '            print(res.value_counts(dropna=False))')
    (765, '            print()')
    (766, '            return res')
    (767, '')
    (768, '')
    (769, '        # engineer additional features')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=alexmsalmeida/amr-profiler, file=Snakefile
context_key: ['rule summarize', 'run', 'if not os.path.exists(params.sum_dir)']
    (96, '        if not os.path.exists(params.sum_dir):')
    (97, '            os.makedirs(params.sum_dir)')
    (98, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=LCrossman/ribosomal_snakemake, file=Snakefile
context_key: ['rule check_for_cleannames', 'run', "if \\'yes\\' in params.required"]
    (57, "           if \\'yes\\' in params.required:")
    (58, '               shell("touch \\\'cleannames.txt\\\'")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=LCrossman/ribosomal_snakemake, file=Snakefile
context_key: ['rule check_for_cleannames', 'run', 'else', "if \\'cleannames.txt\\' in input.files"]
    (60, "               if \\'cleannames.txt\\' in input.files:")
    (61, '                   pass')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=LCrossman/ribosomal_snakemake, file=Snakefile
context_key: ['rule convert_nucl_protein', 'run', "if \\'yes\\' in params.required"]
    (80, "           if \\'yes\\' in params.required:")
    (81, '                   outfile2 = open("cleannames.txt", \\\'w\\\')')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=LCrossman/ribosomal_snakemake, file=Snakefile
context_key: ['rule convert_nucl_protein', 'run', "if \\'yes\\' in params.required"]
    (84, "                   if \\'yes\\' in params.required:")
    (85, '                       outfile2.write(Path(file).name+"\\')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=LCrossman/ribosomal_snakemake, file=Snakefile
context_key: ['rule create_mapover', 'run', "if \\'yes\\' in params.required"]
    (104, "            if \\'yes\\' in params.required:\\t  ")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=LCrossman/ribosomal_snakemake, file=Snakefile
context_key: ['rule create_tree', 'run', "if params.tree_type == \\'iqtree\\'", "if params.protein_dna == \\'dna\\'"]
    (190, "          if params.tree_type == \\'iqtree\\':")
    (191, "               if params.protein_dna == \\'dna\\':")
    (192, '                   shell("(iqtree -s {input} -m GTR -bb 1000 -alrt 1000 -nt {threads} > {output}) 2>>log")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=LCrossman/ribosomal_snakemake, file=Snakefile
context_key: ['rule create_tree', 'run', "if params.tree_type == \\'iqtree\\'", 'else']
    (193, '               else:')
    (194, '                   shell("(iqtree -s {input} -m LG -bb 1000 -alrt 1000 -nt {threads} > {output}) 2>>log")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=LCrossman/ribosomal_snakemake, file=workflow/rules/download_snake.smk
context_key: ['rule gather_gbff', 'run', "if \\'yes\\' in params.required"]
    (24, "           if \\'yes\\' in params.required:")
    (25, '               files = glob.glob("**/*gbff.gz", recursive=True)')
    (26, '               outfile = open("logs/newroot.txt", \\\'w\\\')')
    (27, '               path=os.getcwd()')
    (28, '               for file in files:')
    (29, '                   print(Path(file).name)')
    (30, '                   shutil.copy(file, path)')
    (31, '                   outfile.write(Path(file).name+"\\')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=LCrossman/ribosomal_snakemake, file=workflow/rules/download_snake.smk
context_key: ['rule gunzip_zipfiles', 'run', "if \\'yes\\' in params.required"]
    (45, "            if \\'yes\\' in params.required:")
    (46, '                shell("gunzip *gbff.gz"),')
    (47, '                shell("touch \\\'logs/gunzip_complete.txt\\\'")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=LCrossman/ribosomal_snakemake, file=workflow/rules/blast_missing_seqs.smk
context_key: ['rule collect_hits', 'run', 'if len(input.infiles) > 0']
    (48, '         if len(input.infiles) > 0:')
    (49, '             for inp in input.infiles:')
    (50, '                 print("input is", inp)')
    (51, '                 shell(f"python workflow/scripts/collect_from_diamond_blast.py {inp} {params.protein_dna}")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=LCrossman/ribosomal_snakemake, file=workflow/Snakefile
context_key: ['rule check_for_cleannames', 'run', "if \\'yes\\' in params.required"]
    (57, "           if \\'yes\\' in params.required:")
    (58, '               shell("touch \\\'cleannames.txt\\\'")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=LCrossman/ribosomal_snakemake, file=workflow/Snakefile
context_key: ['rule check_for_cleannames', 'run', 'else', "if \\'cleannames.txt\\' in input.files"]
    (60, "               if \\'cleannames.txt\\' in input.files:")
    (61, '                   pass')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=LCrossman/ribosomal_snakemake, file=workflow/Snakefile
context_key: ['rule convert_nucl_protein', 'run', "if \\'yes\\' in params.required"]
    (80, "           if \\'yes\\' in params.required:")
    (81, '                   outfile2 = open("cleannames.txt", \\\'w\\\')')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=LCrossman/ribosomal_snakemake, file=workflow/Snakefile
context_key: ['rule convert_nucl_protein', 'run', "if \\'yes\\' in params.required"]
    (84, "                   if \\'yes\\' in params.required:")
    (85, '                       outfile2.write(Path(file).name+"\\')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=LCrossman/ribosomal_snakemake, file=workflow/Snakefile
context_key: ['rule create_mapover', 'run', "if \\'yes\\' in params.required"]
    (104, "            if \\'yes\\' in params.required:\\t  ")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=LCrossman/ribosomal_snakemake, file=workflow/Snakefile
context_key: ['rule create_tree', 'run', "if params.tree_type == \\'iqtree\\'", "if params.protein_dna == \\'dna\\'"]
    (190, "          if params.tree_type == \\'iqtree\\':")
    (191, "               if params.protein_dna == \\'dna\\':")
    (192, '                   shell("(iqtree -s {input} -m GTR -bb 1000 -alrt 1000 -nt {threads} > {output}) 2>>log")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=LCrossman/ribosomal_snakemake, file=workflow/Snakefile
context_key: ['rule create_tree', 'run', "if params.tree_type == \\'iqtree\\'", 'else']
    (193, '               else:')
    (194, '                   shell("(iqtree -s {input} -m LG -bb 1000 -alrt 1000 -nt {threads} > {output}) 2>>log")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=1709mrd/school_dna-seq-gatk-variant-calling, file=rules/calling.smk
context_key: ['rule call_variants', 'input', 'else [']
    (23, '            else []')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=lyijin/bismsmark, file=workflow/Snakefile
context_key: ['rule trim_reads', 'run', "if params.library_type == \\'swift\\'"]
    (167, "        if params.library_type == \\'swift\\':")
    (168, '            # the --clip_xx and --three_prime_clip_xx values are set based on')
    (169, '            # https://github.com/FelixKrueger/Bismark/tree/master/Docs')
    (170, "            shell(\\'trim_galore --paired {input.R1} {input.R2} --output_dir 01_trimmed_reads/\\'")
    (171, "                  \\' --clip_r1 10 --clip_r2 15 --three_prime_clip_r1 10 --three_prime_clip_r2 10\\'")
    (172, "                  \\' --cores {threads} > {log.out} 2> {log.err}\\')")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=lyijin/bismsmark, file=workflow/Snakefile
context_key: ['rule trim_reads', 'run', "elif params.library_type in [\\'emseq\\', \\'bsseq\\']"]
    (173, "        elif params.library_type in [\\'emseq\\', \\'bsseq\\']:")
    (174, "            shell(\\'trim_galore --paired {input.R1} {input.R2} --output_dir 01_trimmed_reads/\\'")
    (175, "                  \\' --cores {threads} > {log.out} 2> {log.err}\\')")
    (176, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=lyijin/bismsmark, file=workflow/Snakefile
context_key: ['rule extract_methylation_levels', 'run', "if params.library_type == \\'swift\\'"]
    (241, "        if params.library_type == \\'swift\\':")
    (242, "            shell(\\'bismark_methylation_extractor {input} --bedGraph\\'")
    (243, "                  \\' --output 04_meth_extract_{wildcards.genome}\\'")
    (244, "                  \\' --parallel {threads} --scaffolds --gzip\\'")
    (245, "                  \\' > {log.out} 2> {log.err}\\')")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=lyijin/bismsmark, file=workflow/Snakefile
context_key: ['rule extract_methylation_levels', 'run', "elif params.library_type in [\\'emseq\\', \\'bsseq\\']"]
    (246, "        elif params.library_type in [\\'emseq\\', \\'bsseq\\']:")
    (247, '            # the --ignore_r2 values are set based on')
    (248, '            # https://github.com/FelixKrueger/Bismark/tree/master/Docs')
    (249, "            shell(\\'bismark_methylation_extractor {input} --bedGraph --ignore_r2 2\\'")
    (250, "                  \\' --output 04_meth_extract_{wildcards.genome}\\'")
    (251, "                  \\' --parallel {threads} --scaffolds --gzip\\'")
    (252, "                  \\' > {log.out} 2> {log.err}\\')")
    (253, '        ')
    (254, '        # remove unneeded huge files at the end of command')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Mira0507/snakemake_alignment, file=Snakefile
context_key: ['rule featurecounts', 'run', 'if len(params.ends) == 2']
    (177, '        if len(params.ends) == 2:   # if paired-end')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=cnobles/iGUIDE, file=rules/process.rules
context_key: ['rule assimilate_sites', 'run', 'if (config["UMItags"])']
    (81, '    if (config["UMItags"]):')
    (82, '        call_str=call_str + "-u {params.umitagDir} "')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=cnobles/iGUIDE, file=rules/process.rules
context_key: ['rule assimilate_sites', 'run', 'if (config["recoverMultihits"])']
    (83, '    if (config["recoverMultihits"]):')
    (84, '        call_str=call_str + "-m {params.multiDir} "')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=cnobles/iGUIDE, file=rules/process.rules
context_key: ['rule iguide_evaluation', 'run', 'if (config["suppFile"])']
    (103, '    if (config["suppFile"]):')
    (104, '      call_str=call_str + " -s " + str(SUPPINFO_PATH)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=hivlab/sarscov2-variation, file=workflow/Snakefile
context_key: ['rule multiqc', 'input', 'if fastq_screen_d']
    (395, '            if fastq_screen_db')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=hivlab/sarscov2-variation, file=workflow/Snakefile
context_key: ['rule multiqc', 'input', 'else "results/{sample}/{run}_fastqc.zip"']
    (396, '            else "results/{sample}/{run}_fastqc.zip",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=iqbal-lab-org/viridian_simulations_workflow, file=Snakefile
context_key: ['rule split_sequences', 'run', 'if not os.path.exists(output[0])']
    (75, '        if not os.path.exists(output[0]):')
    (76, '            os.mkdir(output[0])')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=iqbal-lab-org/viridian_simulations_workflow, file=Snakefile
context_key: ['rule mask_assemblies', 'run', 'if not os.path.exists(os.path.dirname(output[0]))']
    (120, '        if not os.path.exists(os.path.dirname(output[0])):')
    (121, '            os.mkdir(os.path.dirname(output[0]))')
    (122, '        # mask bases outside of the amplicon scheme')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=iqbal-lab-org/viridian_simulations_workflow, file=Snakefile
context_key: ['rule mask_assemblies', 'run', 'if not params.mask_assemblies']
    (136, '        if not params.mask_assemblies:')
    (137, '            pass')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=iqbal-lab-org/viridian_simulations_workflow, file=Snakefile
context_key: ['rule mask_assemblies', 'run', 'else', 'if "primer_SNP" in sample_stats[all_amplicons[amplicon]]["errors"] \\']
    (141, '                if "primer_SNP" in sample_stats[all_amplicons[amplicon]]["errors"] \\\\')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=iqbal-lab-org/viridian_simulations_workflow, file=Snakefile
context_key: ['rule mask_assemblies', 'run', 'else', 'if not amplicon == 0']
    (145, '                    if not amplicon == 0:')
    (146, '                        mask_start = sample_stats[all_amplicons[amplicon-1]]["amplicon_end"]')
    (147, '                        #mask_start = sample_stats[all_amplicons[amplicon]]["amplicon_start"]')
    (148, '                    else:')
    (149, '                        mask_start = sample_stats[all_amplicons[amplicon]]["amplicon_start"]')
    (150, '                    mask_end = sample_stats[all_amplicons[amplicon+1]]["amplicon_start"]')
    (151, '                    #mask_end = sample_stats[all_amplicons[amplicon]]["amplicon_end"]')
    (152, '                    # replace the masked sequence with Ns')
    (153, '                    sample_sequence[mask_start:mask_end] = list("N"*(mask_end-mask_start))')
    (154, '        # write out the masked simulated sequence')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=iqbal-lab-org/viridian_simulations_workflow, file=Snakefile
context_key: ['rule cat_art_reads', 'run', 'if not os.path.exists(os.path.dirname(output[0]))']
    (368, '        if not os.path.exists(os.path.dirname(output[0])):')
    (369, '            os.mkdir(os.path.dirname(output[0]))')
    (370, '        # cat ART reads')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=iqbal-lab-org/viridian_simulations_workflow, file=Snakefile
context_key: ['rule cat_badread_reads', 'run', 'if not os.path.exists(os.path.dirname(output[0]))']
    (395, '        if not os.path.exists(os.path.dirname(output[0])):')
    (396, '            os.mkdir(os.path.dirname(output[0]))')
    (397, '        # concat reads')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=apoire27/BodennmillerPipeline, file=workflow/Snakefile
context_key: ['rule modify_measurement_pipeline', 'run', 'if line.rstrip()']
    (536, '                        if line.rstrip())')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=apoire27/BodennmillerPipeline, file=workflow/Snakefile
context_key: ['rule download_example_data', 'run', 'if ~fn.exists()']
    (614, '            if ~fn.exists():')
    (615, '                shutil.move(fn_cache[0], fn)')
    (616, '')
    (617, '### Varia')
    (618, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=1709mrd/New_school_dna-seq-gatk-variant-calling, file=rules/calling.smk
context_key: ['rule call_variants', 'input', 'else [']
    (23, '            else []')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=nanoporetech/Pore-C-Snakemake, file=rules/reads.smk
context_key: ['rule import_fast5s', 'run', 'if path_is_absolute']
    (32, '        if path_is_absolute:')
    (33, '            shell("cp -rs {params.fname} {output}")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=nanoporetech/Pore-C-Snakemake, file=rules/reads.smk
context_key: ['rule adjust_pass_fail', 'run', 'if "filename_fast5" in seq_sum.columns']
    (75, '        if "filename_fast5" in seq_sum.columns:')
    (76, '            fast5_column = "filename_fast5"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=nanoporetech/Pore-C-Snakemake, file=rules/reads.smk
context_key: ['rule adjust_pass_fail', 'run', 'elif "filename" in seq_sum.columns']
    (77, '        elif "filename" in seq_sum.columns:')
    (78, '            fast5_column = "filename"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=nanoporetech/Pore-C-Snakemake, file=rules/reads.smk
context_key: ['rule adjust_pass_fail', 'run', 'if any(tag in example_fn for tag in ["_pass_", "_fail_", "_skip_"])']
    (83, '        if any(tag in example_fn for tag in ["_pass_", "_fail_", "_skip_"]):')
    (84, '            print("Pass/fail files already uniquely named; No adjustments needed")')
    (85, '            shell("cp {input.summary} {output.modified_summary}")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=nanoporetech/Pore-C-Snakemake, file=rules/reads.smk
context_key: ['rule adjust_pass_fail', 'run', 'elif fast5_are_not_split(input.fast5)']
    (86, '        elif fast5_are_not_split(input.fast5):')
    (87, '            print("Fast5 files were not split into pass/fail folders; " + "No adjustments needed")')
    (88, '            shell("cp {input.summary} {output.modified_summary}")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skchronicles/RNA-seek, file=workflow/rules/single-end.smk
context_key: ['rule kraken_se', 'if [ ! -d "{params.tmpdir}" ]; then mkdir -p "{params.tmpdir}"; f']
    (223, '    if [ ! -d "{params.tmpdir}" ]; then mkdir -p "{params.tmpdir}"; fi')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skchronicles/RNA-seek, file=workflow/rules/single-end.smk
context_key: ['else', 'rule star1p', 'if [ ! -d "{params.tmpdir}" ]; then mkdir -p "{params.tmpdir}"; f']
    (479, '        if [ ! -d "{params.tmpdir}" ]; then mkdir -p "{params.tmpdir}"; fi')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skchronicles/RNA-seek, file=workflow/rules/single-end.smk
context_key: ['else', 'rule star2p', 'if [ ! -d "{params.tmpdir}" ]; then mkdir -p "{params.tmpdir}"; f']
    (592, '        if [ ! -d "{params.tmpdir}" ]; then mkdir -p "{params.tmpdir}"; fi')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skchronicles/RNA-seek, file=workflow/rules/single-end.smk
context_key: ['rule rsem', 'if [ ! -d "{params.tmpdir}" ]; then mkdir -p "{params.tmpdir}"; f']
    (664, '    if [ ! -d "{params.tmpdir}" ]; then mkdir -p "{params.tmpdir}"; fi')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skchronicles/RNA-seek, file=workflow/rules/single-end.smk
context_key: ['rule bam2bw_rnaseq_se', 'if [ `echo "$strandinfo < 0.25"|bc` -eq 1 ]; the']
    (709, '    if [ `echo "$strandinfo < 0.25"|bc` -eq 1 ]; then')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skchronicles/RNA-seek, file=workflow/rules/common.smk
context_key: ['rule picard', 'if [ ! -d "{params.tmpdir}" ]; then mkdir -p "{params.tmpdir}"; f']
    (66, '    if [ ! -d "{params.tmpdir}" ]; then mkdir -p "{params.tmpdir}"; fi')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skchronicles/RNA-seek, file=workflow/rules/common.smk
context_key: ['rule stats', 'if [ ! -d "{params.tmpdir}" ]; then mkdir -p "{params.tmpdir}"; f']
    (171, '    if [ ! -d "{params.tmpdir}" ]; then mkdir -p "{params.tmpdir}"; fi')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skchronicles/RNA-seek, file=workflow/rules/paired-end.smk
context_key: ['rule kraken_pe', 'if [ ! -d "{params.tmpdir}" ]; then mkdir -p "{params.tmpdir}"; f']
    (243, '    if [ ! -d "{params.tmpdir}" ]; then mkdir -p "{params.tmpdir}"; fi')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skchronicles/RNA-seek, file=workflow/rules/paired-end.smk
context_key: ['else', 'rule star1p', 'if [ ! -d "{params.tmpdir}" ]; then mkdir -p "{params.tmpdir}"; f']
    (423, '        if [ ! -d "{params.tmpdir}" ]; then mkdir -p "{params.tmpdir}"; fi')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skchronicles/RNA-seek, file=workflow/rules/paired-end.smk
context_key: ['else', 'rule star2p', 'if [ ! -d "{params.tmpdir}" ]; then mkdir -p "{params.tmpdir}"; f']
    (544, '        if [ ! -d "{params.tmpdir}" ]; then mkdir -p "{params.tmpdir}"; fi')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skchronicles/RNA-seek, file=workflow/rules/paired-end.smk
context_key: ['rule rsem', 'if [ ! -d "{params.tmpdir}" ]; then mkdir -p "{params.tmpdir}"; f']
    (740, '    if [ ! -d "{params.tmpdir}" ]; then mkdir -p "{params.tmpdir}"; fi')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=skchronicles/RNA-seek, file=workflow/rules/paired-end.smk
context_key: ['rule bam2bw_rnaseq_pe', 'if [ `echo "$strandinfo < 0.25"|bc` -eq 1 ];the']
    (809, '    if [ `echo "$strandinfo < 0.25"|bc` -eq 1 ];then')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=zavolanlab/tandem-pas, file=Snakefile
context_key: ['rule select_terminal_exon_pas', 'run', 'try', 'if int(total_exons) == int(ex_nr)']
    (150, '                    if int(total_exons) == int(ex_nr):')
    (151, '                        ofile.write(line)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=felixleopoldo/benchpress, file=workflow/rules/evaluation.smk
context_key: ['rule graph_plots', 'run', 'if True']
    (761, '        if True:')
    (762, '            shell("mkdir -p results/output/graph_plots/graphvizcompare")')
    (763, '            for i,f in enumerate(input.graphvizcompare):')
    (764, '                shell("cp "+f+" results/output/graph_plots/graphvizcompare/compare_" +str(i+1) +".pdf")')
    (765, '')
    (766, '            shell("mkdir -p results/output/graph_plots/adjmat_diffplots")')
    (767, '            for i,f in enumerate(input.adjmat_diffplots):')
    (768, '                shell("cp "+f+" results/output/graph_plots/adjmat_diffplots/diffplot_" +str(i+1) +".png")')
    (769, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=desireetillo/CTCF_CutAndRun21, file=Snakefile
context_key: ['rule trim_CutAndRun', 'if [ ! -e /lscratch/$SLURM_JOBID ]; then mkdir /lscratch/$SLURM_JOBID ;f']
    (94, '        if [ ! -e /lscratch/$SLURM_JOBID ]; then mkdir /lscratch/$SLURM_JOBID ;fi')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=desireetillo/CTCF_CutAndRun21, file=Snakefile
context_key: ['rule seacr_peakcall', 'if [ ! -e /lscratch/$SLURM_JOBID ]; then mkdir /lscratch/$SLURM_JOBID; fi']
    (357, '        if [ ! -e /lscratch/$SLURM_JOBID ]; then mkdir /lscratch/$SLURM_JOBID; fi ')
    (358, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=desireetillo/CTCF_CutAndRun21, file=Snakefile
context_key: ['rule seacr_peakcall_120', 'if [ ! -e /lscratch/$SLURM_JOBID ]; then mkdir /lscratch/$SLURM_JOBID; fi']
    (403, '        if [ ! -e /lscratch/$SLURM_JOBID ]; then mkdir /lscratch/$SLURM_JOBID; fi ')
    (404, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=iwohlers/2022_autoimmune_review, file=Snakefile
context_key: ['rule get_disease_specific_associations', 'run', 'if mapped_trait.split("/")[-1] == wildcards.efo_id or line[']
    (77, '                 if mapped_trait.split("/")[-1] == wildcards.efo_id or line[:10] == "DATE ADDED":')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=iwohlers/2022_autoimmune_review, file=Snakefile
context_key: ['rule get_disease_specific_study_lists', 'run', 'if mapped_trait.split("/")[-1] == wildcards.efo_id or line[']
    (145, '                 if mapped_trait.split("/")[-1] == wildcards.efo_id or line[:10] == "DATE ADDED":')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=iwohlers/2022_autoimmune_review, file=Snakefile
context_key: ['rule get_disease_specific_autoimmune_pgs_list', 'run', 'if mapped_trait == wildcards.efo_id or line[']
    (188, '                 if mapped_trait == wildcards.efo_id or line[:15] == "Polygenic Score":')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=psnavais/VR-StartingGrant-2022, file=workflow/Snakefile
context_key: ['rule all', 'if kin_temp.iloc[i, 0] in kin_temp.iloc[0']
    (41, '                if kin_temp.iloc[i, 0] in kin_temp.iloc[0:i, 1].values:')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=jpcsmith/qcsd-experiments, file=workflow/rules/ml-eval-conn.smk
context_key: ['rule ml_eval_conn__simulated_dataset', 'input', 'else "results/ml-eval-conn/defence~undefended/dataset/']
    (87, '            else "results/ml-eval-conn/defence~undefended/dataset/"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=pughlab/cfMeDIP-seq-analysis-pipeline, file=Snakefile
context_key: ['rule all_insertsize', 'run', "if line.startswith(\\'## HISTOGRAM\\')"]
    (617, "                    if line.startswith(\\'## HISTOGRAM\\'):")
    (618, '                        break')
    (619, '                if first_file:')
    (620, "                    outfile.write(\\'file\\\\t\\' + next(infile))")
    (621, '                    first_file = False')
    (622, '                else:')
    (623, '                    next(infile)')
    (624, '                for line in infile:')
    (625, "                    outfile.write(path.split(\\'/\\')[-1] + \\'\\\\t\\' + line)")
    (626, '')
    (627, '# ----------------------------------------------------------------------------- #')
    (628, '#  Fit cfMeDIP-seq coverage stats to infer absolute methylation using MedReMix  #')
    (629, '# ----------------------------------------------------------------------------- #')
    (630, '')
    (631, '# This is the currently used negative binomial GLM approach to fitting')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Albinam1/day5, file=rules/calling.smk
context_key: ['rule call_variants', 'input', 'else [']
    (23, '            else []')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=dieterich-lab/single-cell-nanopore, file=Snakefile
context_key: ['if rule in cluster_config and "threads" in cluster_config[rule]']
    (40, '    if rule in cluster_config and "threads" in cluster_config[rule]:')
    (41, '        return cluster_config[rule]["threads"]')
    (42, '    return int(default)')
    (43, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=leylabmpi/CoreGenomePrimers, file=bin/cgp/primers/Snakefile
context_key: ['rule primers_concat_info', 'run', 'if ii == 0', 'if i == 0']
    (227, '                        if ii == 0:')
    (228, '                            if i == 0:')
    (229, "                                line = \\'\\\\t\\'.join([\\'gene_type\\', \\'cluster_id\\', line])")
    (230, '                            else:')
    (231, '                                continue')
    (232, '                        else:')
    (233, "                            line = \\'\\\\t\\'.join([str(gene_type), str(cluster_id), line])")
    (234, '                        outF.write(line)')
    (235, '                ')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=leylabmpi/CoreGenomePrimers, file=bin/cgp/primers/Snakefile
context_key: ['rule clusters_concat_info', 'run', 'if len([x for x in inF]) > 1']
    (296, '                if len([x for x in inF]) > 1:')
    (297, '                    files.append(y)')
    (298, '        # loading cluster info')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=leylabmpi/CoreGenomePrimers, file=bin/cgp/primers/Snakefile
context_key: ['rule clusters_concat_info', 'run', 'if ii == 0', 'if i == 0']
    (308, '                        if ii == 0:')
    (309, '                            if i == 0:')
    (310, "                                line = \\'\\\\t\\'.join([\\'gene_type\\', \\'cluster_id\\', line])")
    (311, '                            else:')
    (312, '                                continue')
    (313, '                        else:')
    (314, "                            line = \\'\\\\t\\'.join([gene_type, str(cluster_id), line])")
    (315, "                        outF.write(line + \\'\\")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=leylabmpi/CoreGenomePrimers, file=bin/cgp/nontarget/cds/Snakefile
context_key: ['rule clusters_cds_concat_reps_fasta', 'run', "if line.startswith(\\'>\\')"]
    (29, "                        if line.startswith(\\'>\\'):")
    (30, "                            line = line.rstrip() + \\'_{}\\")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=troy-layouni/CellSegTest, file=workflow/Snakefile
context_key: ['rule modify_measurement_pipeline', 'run', 'if line.rstrip()']
    (536, '                        if line.rstrip())')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=troy-layouni/CellSegTest, file=workflow/Snakefile
context_key: ['rule download_example_data', 'run', 'if ~fn.exists()']
    (614, '            if ~fn.exists():')
    (615, '                shutil.move(fn_cache[0], fn)')
    (616, '')
    (617, '### Varia')
    (618, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Monia234/admixMap, file=workflow/Snakefile
context_key: ['if rule in plink_rules']
    (84, '        if rule in plink_rules:')
    (85, '            if config[\\\'run_settings\\\'][\\\'scheduler\\\'] == \\\'slurm\\\': plink_run_specs[rule] = f"--memory {int(int(clusterfile[rule][\\\'mem\\\'].replace(\\\'G\\\',\\\'000\\\'))*0.9)} --threads {clusterfile[rule][\\\'ntasks\\\']}" #0.9 multiplication is because plink can be greedy with memory and use more than requested.')
    (86, '            elif config[\\\'run_settings\\\'][\\\'scheduler\\\'] == \\\'pbs\\\':  plink_run_specs[rule] = f"--memory {clusterfile[rule][\\\'mem\\\'].replace(\\\'b\\\',\\\'\\\').replace(\\\'m\\\',\\\'\\\').replace(\\\'g\\\',\\\'000\\\')} --threads 1" #Deprecated')
    (87, '')
    (88, '')
    (89, '#### DEFINE FUNCTIONS #####')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Monia234/admixMap, file=workflow/Snakefile
context_key: ['rule calc_test_coverage', 'run', 'if os.path.exists(f"sHWE/{BASE}_sHWE-DS{int(x.strip(\\\'.bim\\\').replace(\\\'DS\\\', \\\'\\\').split(\\\'_\\\')[-1])}.rmv.bim")] #Create file list of all successful runs of sHWE (the .rmv.bim file will be present if sHWE completed successfully']
    (315, '                     if os.path.exists(f"sHWE/{BASE}_sHWE-DS{int(x.strip(\\\'.bim\\\').replace(\\\'DS\\\', \\\'\\\').split(\\\'_\\\')[-1])}.rmv.bim")] #Create file list of all successful runs of sHWE (the .rmv.bim file will be present if sHWE completed successfully)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Monia234/admixMap, file=workflow/Snakefile
context_key: ['rule fine_map', 'run', "if not os.path.exists(\\'fine-mapping\\')"]
    (563, "        if not os.path.exists(\\'fine-mapping\\'): os.mkdir(\\'fine-mapping\\')")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=roshnipatel/LocalAncestry, file=Snakefile
context_key: ['rule merge_rfmix_output', 'input', 'if wildcards.chr not in ACROCENTRIC else \\']
    (287, '            if wildcards.chr not in ACROCENTRIC else \\\\')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=roshnipatel/LocalAncestry, file=Snakefile
context_key: ['rule merge_rfmix_output', 'input', 'if wildcards.chr not in ACROCENTRIC else \\']
    (291, '            if wildcards.chr not in ACROCENTRIC else \\\\')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=roshnipatel/LocalAncestry, file=Snakefile
context_key: ['rule merge_rfmix_output', 'input', 'if wildcards.chr not in ACROCENTRIC else \\']
    (295, '            if wildcards.chr not in ACROCENTRIC else \\\\')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=roshnipatel/LocalAncestry, file=Snakefile
context_key: ['rule merge_phasing', 'input', 'if wildcards.chr not in ACROCENTRIC else \\']
    (457, '            if wildcards.chr not in ACROCENTRIC else \\\\')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=bhklab/MERIDA_snakemake_pipeline, file=Snakefile
context_key: ['rule build_merida_input_files', 'run', 'if isinstance(params.cv, int) and params.cv > 0']
    (165, '            if isinstance(params.cv, int) and params.cv > 0:')
    (166, '                conf["L1"] = f"L1\\\\t0"')
    (167, '                conf["L2"] = f"L2\\\\t0"')
    (168, '                conf["ErrorFunction"] = f"ErrorFunction\\\\tmisclassification"')
    (169, '                conf["CVMode"] = f"CVMode\\\\tfold"')
    (170, '                conf["alpha"] = f"alpha\\\\t0"')
    (171, '            # Add a priori feature selection, if specified in config.yml')
    (172, '            # if input.preselected is not "" and os.path.exists(input.preselected):')
    (173, '            #     conf["preselected_features"] = \\\\')
    (174, '            #         f"preselected_features\\\\t{input.preselected}"')
    (175, '            # Write the configuration files to the procdata directory')
    (176, '            conf_file = "\\')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=sam0per/gatk-variant-calling, file=rules/calling.smk
context_key: ['rule call_variants', 'input', 'else [']
    (23, '            else []')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Albinam1/12, file=rules/calling.smk
context_key: ['rule call_variants', 'input', 'else [']
    (23, '            else []')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=ebi-gene-expression-group/bulk-recalculations, file=Snakefile-sorting-hat
context_key: ['rule produce_reprocess_call', 'run', 'if [[ "{params.allowed_organism}" == "True" ]]; the']
    (284, '        if [[ "{params.allowed_organism}" == "True" ]]; then')
    (285, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=ebi-gene-expression-group/bulk-recalculations, file=Snakefile-sorting-hat
context_key: ['rule produce_recalculations_call', 'run', 'if ! [ -z {params.lsf_config} ]; the']
    (342, '        if ! [ -z {params.lsf_config} ]; then')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=ebi-gene-expression-group/bulk-recalculations, file=Snakefile-sorting-hat
context_key: ['rule produce_recalculations_call', 'run', 'if [ ! -f "lsf.yaml" ]; the']
    (343, '            if [ ! -f "lsf.yaml" ]; then')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=ebi-gene-expression-group/bulk-recalculations, file=Snakefile-sorting-hat
context_key: ['rule produce_recalculations_call', 'run', 'if [[ "{params.allowed_organism}" == "True" ]]; the']
    (348, '        if [[ "{params.allowed_organism}" == "True" ]]; then')
    (349, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=vojtab84/ACGT_snakemake, file=rules/calling.smk
context_key: ['rule call_variants', 'input', 'else [']
    (23, '            else []')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NCI-CGR/Pacbio-Alternative-Splicing, file=modules/Snakefile_gen
context_key: ['rule gmap_index', 'run', "if gref == \\'\\'"]
    (53, "          if gref == \\'\\':")
    (54, '             shell("""gmap_build -d {ref} {genome} -t 16 -D {out}gmap_index 2>log/gmap_index.err;touch {output}""")')
    (55, '             gref = out + "gmap_index/" + ref')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NCI-CGR/Pacbio-Alternative-Splicing, file=modules/Snakefile_gen
context_key: ['rule targeted', 'run', 'if read.reference_name == cn and read.reference_start > st and read.reference_start < ed']
    (84, '              if read.reference_name == cn and read.reference_start > st and read.reference_start < ed:')
    (85, '                 osamfile.write(read)')
    (86, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NCI-CGR/Pacbio-Alternative-Splicing, file=modules/Snakefile_annot
context_key: ['rule targeted2', 'run', 'if read.reference_name == cn and read.reference_start > st and read.reference_start < ed']
    (74, '              if read.reference_name == cn and read.reference_start > st and read.reference_start < ed:')
    (75, '                 osamfile.write(read)')
    (76, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=weizhu365/gatk-variant-calling, file=rules/filtering.smk
context_key: ['rule merge_calls', 'input', 'else "hardfiltered"']
    (58, '                              else "hardfiltered")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=fuzhiliang/dna-seq-gatk-variant-calling, file=rules/filtering.smk
context_key: ['rule merge_calls', 'input', 'else "hardfiltered"']
    (58, '                              else "hardfiltered")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=nextstrain/monkeypox, file=workflow/snakemake_rules/core.smk
context_key: ['rule refine', 'input', 'else rules.tree.output.tree']
    (232, '        else rules.tree.output.tree,')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=nextstrain/monkeypox, file=workflow/snakemake_rules/core.smk
context_key: ['rule refine', 'params', 'if "clock_rate" in confi']
    (244, '        if "clock_rate" in config')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=nextstrain/monkeypox, file=workflow/snakemake_rules/core.smk
context_key: ['rule refine', 'params', 'else ""']
    (245, '        else "",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=nextstrain/monkeypox, file=workflow/snakemake_rules/core.smk
context_key: ['rule refine', 'params', 'if "clock_std_dev" in confi']
    (247, '        if "clock_std_dev" in config')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=nextstrain/monkeypox, file=workflow/snakemake_rules/core.smk
context_key: ['rule refine', 'params', 'else ""']
    (248, '        else "",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=nextstrain/monkeypox, file=workflow/snakemake_rules/core.smk
context_key: ['rule export', 'input', 'else "results/{build_name}/branch_lengths_no_time.json"']
    (436, '        else "results/{build_name}/branch_lengths_no_time.json",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=nextstrain/monkeypox, file=workflow/snakemake_rules/core.smk
context_key: ['rule export', 'input', 'else []']
    (444, '        else [],')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=yoshihikosuzuki/purge_tips_smk, file=workflow/Snakefile
context_key: ['rule ln_input', 'params', 'else f"{int(w.dir) - 1}/{BASE}.filtered.fastq"']
    (31, '                                     else f"{int(w.dir) - 1}/{BASE}.filtered.fastq")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=luntergroup/single-cell, file=workflow/rules/monovar.smk
context_key: ['rule get_monovar_somatic', 'run', 'if is_monovar_somatic(rec, samples)']
    (86, '            if is_monovar_somatic(rec, samples):')
    (87, '                out_vcf.write(rec)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=luntergroup/single-cell, file=workflow/rules/sccaller.smk
context_key: ['rule fix_sccaller', 'run', 'if rec[0].startswith("##")', 'if rec[0].startswith("##FILTER=<ID=No.variants<4")']
    (53, '                    if rec[0].startswith("##"):')
    (54, '                        if rec[0].startswith("##FILTER=<ID=No.variants<4"):')
    (55, '                            rec[0] = rec[0].replace("ID=No.variants<4", "ID=No_variants4")')
    (56, '                        elif rec[0].startswith("##FORMAT=<ID=PL,Number=G"):')
    (57, '                            rec[0] = rec[0].replace("ID=PL,Number=G", "ID=CPL,Number=.") # PL invalid: https://github.com/biosinodx/SCcaller/issues/10')
    (58, '                    elif rec[0].startswith("#"):')
    (59, '                        rec[-1] = wildcards.cell # SCCaller reports incorrect sample name')
    (60, '                    else:')
    (61, '                        if "No.variants<4" in rec[6]: continue')
    (62, '                        ref, alt = rec[3], rec[4]')
    (63, "                        if any(b not in [\\'A\\', \\'C\\', \\'G\\', \\'T\\', \\'N\\'] for b in ref): continue")
    (64, "                        alts = alt.split(\\',\\')")
    (65, "                        if \\'-\\' in alt:")
    (66, '                            longest_del = ""')
    (67, '                            for alt_idx, alt in enumerate(alts):')
    (68, "                                if alt[0] == \\'-\\':")
    (69, '                                    allele = ""')
    (70, '                                    for b in reversed(alt):')
    (71, '                                        if b.isdigit():')
    (72, '                                            break')
    (73, '                                        allele = b + allele')
    (74, '                                    if len(allele) > len(longest_del):')
    (75, '                                        longest_del = allele')
    (76, '                                    alts[alt_idx] = ref + allele')
    (77, '                            ref += longest_del')
    (78, '                            for alt_idx, alt in enumerate(alts):')
    (79, '                                if ref.startswith(alt):')
    (80, '                                    alts[alt_idx] = ref[0] + ref[len(alt):]')
    (81, "                        if \\'+\\' in alt:")
    (82, '                            for alt_idx, alt in enumerate(alts):')
    (83, "                                if alt[0] == \\'+\\':")
    (84, '                                    allele = ""')
    (85, '                                    for b in reversed(alt):')
    (86, '                                        if b.isdigit():')
    (87, '                                            break')
    (88, '                                        allele = b + allele')
    (89, '                                    alts[alt_idx] = ref + allele')
    (90, "                        rec[3], rec[4] = ref, \\',\\'.join(alts)")
    (91, '                        if "No.variants<4" in rec[7]:')
    (92, '                            rec[7] = rec[7].replace("No.variants<4", "No_variants4")')
    (93, "                        format_fields = rec[-2].split(\\':\\')")
    (94, '                        if "PL" in format_fields:')
    (95, '                            format_fields[format_fields.index("PL")] = "CPL"')
    (96, "                            rec[-2] = \\':\\'.join(format_fields)")
    (97, "                    out_vcf.write(\\'\\\\t\\'.join(rec) + \\'\\")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=luntergroup/single-cell, file=workflow/rules/prosolo.smk
context_key: ['rule add_prosolo_gt', 'run', 'try', 'if prob_het >= prob_hom_ref and prob_het >= prob_hom_alt']
    (56, '                if prob_het >= prob_hom_ref and prob_het >= prob_hom_alt:')
    (57, '                    gt = (0,1)')
    (58, '                    gq = encode_phred(prob_het)')
    (59, '                elif prob_hom_alt >= prob_hom_ref:')
    (60, '                    gt = (1,1)')
    (61, '                    gq = encode_phred(prob_hom_alt)')
    (62, '                else:')
    (63, '                    gt = (0,0)')
    (64, '                    gq = encode_phred(prob_hom_ref)')
    (65, '                for sample, fields in rec.samples.items():')
    (66, '                    fields["GT"] = gt')
    (67, '                    fields["GQ"] = gq')
    (68, '                out_vcf.write(rec)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=luntergroup/single-cell, file=workflow/rules/prosolo.smk
context_key: ['rule get_prosolo_somatic', 'run', 'if is_prosolo_somatic(rec, samples)']
    (146, '            if is_prosolo_somatic(rec, samples):')
    (147, '                out_vcf.write(rec)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=RuiyuRayWang/ScRNAseq_smkpipe_at_Luolab, file=workflow/rules/common.smk
context_key: ["if rule == \\'umi_tools_whitelist\\'"]
    (174, "    if rule == \\'umi_tools_whitelist\\':")
    (175, "        return \\'whitelist.txt\\'")
    (176, "    elif rule == \\'wash_whitelist\\':")
    (177, "        return \\'whitelist_washed.txt\\'")
    (178, "    elif rule == \\'umi_tools_extract\\':")
    (179, "        return \\'extracted.fq.gz\\'")
    (180, "    elif rule == \\'STAR\\':")
    (181, "        return \\'Aligned.sortedByCoord.out.bam\\'")
    (182, "    elif rule == \\'featureCounts\\':")
    (183, "        return \\'Aligned.sortedByCoord.out.bam.featureCounts.bam\\'")
    (184, "    elif rule == \\'sambamba_sort\\':")
    (185, "        return \\'assigned_sorted.bam\\'")
    (186, "    elif rule == \\'umi_tools_count\\':")
    (187, "        return \\'counts_raw.tsv.gz\\'")
    (188, '    elif rule == "append_sfx":')
    (189, "        return \\'counts.tsv.gz\\'")
    (190, '    elif rule == "umi_tools_whitelist_report":')
    (191, "        return \\'cell_barcode_counts.png\\'")
    (192, '    elif rule == "featureCounts_report":')
    (193, "        return \\'gene_assigned.summary\\'")
    (194, '    elif rule == "STAR_report":')
    (195, "        return \\'Log.final.out\\'")
    (196, '    elif rule == "log_whitelist":')
    (197, "        return \\'whitelist.log\\'")
    (198, '    elif rule == "log_extract":')
    (199, "        return \\'extract.log\\'")
    (200, '    elif rule == "log_count":')
    (201, "        return \\'count.log\\'")
    (202, '    elif rule == "tagged":')
    (203, "        return \\'tagged.bam\\'")
    (204, '    elif rule == "velocyto":')
    (205, "        return \\'velocyto.loom\\'")
    (206, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Faitero/rna-seq-gatk-variant-calling, file=rules/filtering.smk
context_key: ['rule merge_calls', 'input', 'else "hardfiltered"']
    (58, '                              else "hardfiltered")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=maniakk2000/School_cbai, file=rules/calling.smk
context_key: ['rule call_variants', 'input', 'else [']
    (23, '            else []')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=bnelsj/bwa_mem_mapping, file=Snakefile
context_key: ['rule merge_bams', 'run', 'if len(input) > 1']
    (110, '        if len(input) > 1:')
    (111, '            shell("samtools merge -p -@ 8 {output} {input}")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=amoffitt/MASQ, file=Snakefile
context_key: ['rule bad_loci', 'run', 'if "bad_loci" in config']
    (415, '            if "bad_loci" in config:')
    (416, '                for loc in config["bad_loci"]:')
    (417, '                    f.write(str(loc)+"\\')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Masteryuanli/snakerTest, file=workflow/Snakefile
context_key: ['rule modify_measurement_pipeline', 'run', 'if line.rstrip()']
    (536, '                        if line.rstrip())')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Masteryuanli/snakerTest, file=workflow/Snakefile
context_key: ['rule download_example_data', 'run', 'if ~fn.exists()']
    (614, '            if ~fn.exists():')
    (615, '                shutil.move(fn_cache[0], fn)')
    (616, '')
    (617, '### Varia')
    (618, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=shukwong/dna-seq-varlociraptor-test, file=workflow/rules/filtering.smk
context_key: ['rule control_fdr', 'input', 'if not is_activated("benchmarking") else "results/calls/{group}.bcf"']
    (62, '         if not is_activated("benchmarking") else "results/calls/{group}.bcf")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=snakemake-workflows/chipseq, file=workflow/rules/peak_analysis.smk
context_key: ['rule frip_score', 'input', 'else "orph_rm_pe"']
    (139, '        else "orph_rm_pe")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=kalenkovich/reproducible-MEEG, file=Snakefile
context_key: ['rule extract_bad_channels', 'run', "if line.startswith(\\'Static bad channels\\')"]
    (263, "                if line.startswith(\\'Static bad channels\\'):")
    (264, "                    chs = line.split(\\':\\')[-1].split()")
    (265, "                    bads = [\\'MEG%04d\\' % int(ch) for ch in chs]")
    (266, '                    break')
    (267, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=1709mrd/12345, file=rules/calling.smk
context_key: ['rule call_variants', 'input', 'else [']
    (23, '            else []')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=MetaSUB-CAMP/camp_short-read-quality-control, file=workflow/Snakefile
context_key: ['rule make_config', 'run', 'if s not in dct']
    (266, '            if s not in dct: dct[s] = {}')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=ZunsongHu/pipeline, file=rules/filtering.smk
context_key: ['rule merge_calls', 'input', 'else "hardfiltered"']
    (58, '                              else "hardfiltered")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=aryarm/as_analysis, file=Snakefiles/Snakefile-counts
context_key: ["if not hasattr(rules, \\'all\\')", 'rule all', 'input']
    (59, "if not hasattr(rules, \\'all\\'):")
    (60, '    rule all:')
    (61, "        # if you\\'d like to run the pipeline on only a subset of the samples,")
    (62, "        # you should specify them in the config[\\'SAMP_NAMES\\'] variable above")
    (63, '        input:')
    (64, '            expand(config[\\\'output_dir\\\'] + "/final/{sample}/result.csv.gz",')
    (65, "                   sample=config[\\'SAMP_NAMES\\'])")
    (66, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=aryarm/as_analysis, file=Snakefiles/Snakefile-counts
context_key: ["if not hasattr(rules, \\'vcf2h5\\')"]
    (83, "if not hasattr(rules, \\'vcf2h5\\'):")
    (84, '    include: "snp2h5_rules.smk"')
    (85, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=PerinatalLab/metaGWAS, file=scripts/LOCO_meta/Snakefile
context_key: ['rule independent_GWAS_regions_LOCO', 'run', 'if pos in d_temp.POS.values']
    (107, '                                if pos in d_temp.POS.values:')
    (108, '                                        df_list.append(d_temp.loc[d_temp.POS== pos, :])')
    (109, '                                        d_temp= d_temp.loc[(d_temp.POS < pos - (1.5*10**6)) | (d_temp.POS> pos + (1.5 * 10**6)), :]')
    (110, '                                else:')
    (111, '                                        continue')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=calliope-project/sector-coupled-euro-calliope, file=rules/analyse.smk
context_key: ['rule consolidate_spores_result_metrics', 'input', 'if "spore_0.nc" not in']
    (116, '                if "spore_0.nc" not in i')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=mtandon09/CCBR_GATK4_Exome_Seq_Pipeline, file=workflow/rules/somatic_snps.common.smk
context_key: ['rule split_bam_by_chrom', 'if [ ! -d "$(dirname {output.split_bam})" ]; the']
    (17, '    if [ ! -d "$(dirname {output.split_bam})" ]; then')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=mtandon09/CCBR_GATK4_Exome_Seq_Pipeline, file=workflow/rules/somatic_snps.common.smk
context_key: ['rule somatic_merge_callers', 'if [ ! -d "$(dirname {output.mergedvcf})" ]; the']
    (168, '    if [ ! -d "$(dirname {output.mergedvcf})" ]; then')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=mtandon09/CCBR_GATK4_Exome_Seq_Pipeline, file=workflow/rules/cnv.smk
context_key: ['rule freec_exome_somatic_pass1', 'if [ ! -d "$myoutdir" ]; then mkdir -p "$myoutdir"; f']
    (28, '    if [ ! -d "$myoutdir" ]; then mkdir -p "$myoutdir"; fi')
    (29, ' ')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=mtandon09/CCBR_GATK4_Exome_Seq_Pipeline, file=workflow/rules/cnv.smk
context_key: ['rule sequenza', 'if [ ! -d "$myoutdir" ]; then mkdir -p "$myoutdir"; f']
    (76, '    if [ ! -d "$myoutdir" ]; then mkdir -p "$myoutdir"; fi')
    (77, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=mtandon09/CCBR_GATK4_Exome_Seq_Pipeline, file=workflow/rules/cnv.smk
context_key: ['rule freec_exome_somatic_pass2', 'if [ ! -d "$myoutdir" ]; then mkdir -p "$myoutdir"; f']
    (135, '    if [ ! -d "$myoutdir" ]; then mkdir -p "$myoutdir"; fi')
    (136, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=mtandon09/CCBR_GATK4_Exome_Seq_Pipeline, file=workflow/rules/qc.smk
context_key: ['rule fc_lane', 'if [ ! -d "$(dirname {output.txt})" ]; then']
    (25, '    if [ ! -d "$(dirname {output.txt})" ]; then ')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=mtandon09/CCBR_GATK4_Exome_Seq_Pipeline, file=workflow/rules/ffpe.smk
context_key: ['rule sobdetect_pass1', 'if [ ! -d "$(dirname {output.pass1_vcf})" ]; then']
    (30, '    if [ ! -d "$(dirname {output.pass1_vcf})" ]; then ')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=mtandon09/CCBR_GATK4_Exome_Seq_Pipeline, file=workflow/rules/ffpe.smk
context_key: ['rule sobdetect_pass1', 'if [ $header_length -eq $file_length ]; the']
    (47, '    if [ $header_length -eq $file_length ]; then')
    (48, '        # VCF file only contains header')
    (49, '        # File contains no variants, catch')
    (50, '        # problem so pipeline can continue')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=mtandon09/CCBR_GATK4_Exome_Seq_Pipeline, file=workflow/rules/ffpe.smk
context_key: ['rule sobdetect_cohort_params', 'if [ $all_length -eq 0 ]; then']
    (85, '    if [ $all_length -eq 0 ]; then ')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=mtandon09/CCBR_GATK4_Exome_Seq_Pipeline, file=workflow/rules/ffpe.smk
context_key: ['rule sobdetect_pass2', 'if [ ! -d "$(dirname {output.pass2_vcf})" ]; then']
    (117, '    if [ ! -d "$(dirname {output.pass2_vcf})" ]; then ')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=mtandon09/CCBR_GATK4_Exome_Seq_Pipeline, file=workflow/rules/ffpe.smk
context_key: ['rule sobdetect_pass2', 'if [ $header_length -eq $file_length ]; the']
    (136, '    if [ $header_length -eq $file_length ]; then')
    (137, '        # VCF file only contains header')
    (138, '        # File contains no variants, catch')
    (139, '        # problem so pipeline can continue')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=mtandon09/CCBR_GATK4_Exome_Seq_Pipeline, file=workflow/rules/somatic_snps.paired.smk
context_key: ['rule gatk_mutect2', 'if [ ! -d "$(dirname {output.vcf})" ];']
    (24, '    if [ ! -d "$(dirname {output.vcf})" ]; ')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=mtandon09/CCBR_GATK4_Exome_Seq_Pipeline, file=workflow/rules/somatic_snps.paired.smk
context_key: ['rule strelka', 'if [ -d "$myoutdir" ]; then rm -r "$myoutdir"; f']
    (139, '    if [ -d "$myoutdir" ]; then rm -r "$myoutdir"; fi')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=mtandon09/CCBR_GATK4_Exome_Seq_Pipeline, file=workflow/rules/somatic_snps.paired.smk
context_key: ['rule mutect_paired', 'if [ ! -d "$(dirname {output.vcf})" ]; then mkdir -p "$(dirname {output.vcf})"; f']
    (249, '    if [ ! -d "$(dirname {output.vcf})" ]; then mkdir -p "$(dirname {output.vcf})"; fi')
    (250, '    ')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=mtandon09/CCBR_GATK4_Exome_Seq_Pipeline, file=workflow/rules/somatic_snps.paired.smk
context_key: ['rule vardict_paired', 'if [ ! -d "$(dirname {output.vcf})" ]; then mkdir -p "$(dirname {output.vcf})"; f']
    (329, '    if [ ! -d "$(dirname {output.vcf})" ]; then mkdir -p "$(dirname {output.vcf})"; fi')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=mtandon09/CCBR_GATK4_Exome_Seq_Pipeline, file=workflow/rules/somatic_snps.paired.smk
context_key: ['rule varscan_paired', 'if [ ! -d "$(dirname {output.vcf})" ]; then mkdir -p "$(dirname {output.vcf})"; f']
    (433, '    if [ ! -d "$(dirname {output.vcf})" ]; then mkdir -p "$(dirname {output.vcf})"; fi')
    (434, '    ')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=nanoporetech/pipeline-nanopore-denovo-isoforms, file=Snakefile
context_key: ['rule link_root', 'if nr == 0 or n.Left is None or n.Right is None']
    (114, '            if nr == 0 or n.Left is None or n.Right is None:')
    (115, '                jr = init_template % (n.Id, n.Id, n.Id, config["cls_mode"], "{input.left}", "{output}", purge)')
    (116, '                fh.write(jr)')
    (117, '            else:')
    (118, '                jr = template % (n.Id, n.Left.Id, n.Right.Id, n.Id, config["cls_mode"], "{input.left}", "{input.right}", "{output}", purge)')
    (119, '                fh.write(jr)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=shukwong/dna-seq-gatk-variant-calling-test, file=rules/filtering.smk
context_key: ['rule merge_calls', 'input', 'else "hardfiltered"']
    (58, '                              else "hardfiltered")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=xiangyugits/wgs, file=rules/calling.smk
context_key: ['rule call_variants', 'input', 'else [']
    (23, '            else []')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=xiangyugits/wgs, file=rules/filtering.smk
context_key: ['rule merge_calls', 'input', 'else "hardfiltered"']
    (48, '            else "hardfiltered",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=babramso/vcf_snake, file=rules/filtering.smk
context_key: ['rule merge_calls', 'input', 'else "hardfiltered"']
    (58, '                              else "hardfiltered")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=dredge-bio/dredge-sc-snakemake, file=Snakefile
context_key: ['rule all', 'if "seurat_object" in config', 'elif "count_matrix" in config', 'else', 'rule seurat_extract', 'rule pack_matrix', 'rule compress_matrix', 'rule parse_transcripts', 'rule merge_dges']
    (11, 'if "seurat_object" in config:')
    (12, '\\trule seurat_object:')
    (13, '\\t\\tinput:')
    (14, '\\t\\t\\tconfig["seurat_object"]')
    (15, '\\t\\toutput:')
    (16, '\\t\\t\\t"out/seurat.rds"')
    (17, '\\t\\tshell:')
    (18, '\\t\\t\\t"cp {input} {output}"')
    (19, 'elif "count_matrix" in config:')
    (20, '\\trule seurat_object:')
    (21, '\\t\\tinput:')
    (22, '\\t\\t\\tconfig["count_matrix"]')
    (23, '\\t\\toutput:')
    (24, '\\t\\t\\t"out/seurat.rds"')
    (25, '\\t\\tscript:')
    (26, '\\t\\t\\t"scripts/seurat_create.R"')
    (27, 'else:')
    (28, "\\traise Exception(\\'No configuration method specified. Please set either `seurat_object` or `count_matrix` in config.yaml\\')")
    (29, '\\tsys.exit(1)')
    (30, '')
    (31, 'rule seurat_extract:')
    (32, '\\tinput:')
    (33, '\\t\\t"out/seurat.rds"')
    (34, '\\toutput:')
    (35, '\\t\\tclusters="out/clusters.json",')
    (36, '\\t\\ttranscripts="out/transcripts_raw.csv",')
    (37, '\\t\\tembeddings="out/embeddings.csv",')
    (38, '\\t\\tmetadata="out/metadata.csv",')
    (39, '\\t\\texpressions="out/expressions.mtx",')
    (40, '\\t\\tdifferential_expressions="out/seurat_cluster_dge.json"')
    (41, '\\tscript:')
    (42, '\\t\\t"scripts/seurat.R"')
    (43, '')
    (44, 'rule pack_matrix:')
    (45, '\\tinput:')
    (46, '\\t\\t"out/expressions.mtx"')
    (47, '\\toutput:')
    (48, '\\t\\t"out/expressions.bin"')
    (49, '\\tshell:')
    (50, '\\t\\t"./scripts/compress_matrix.py {input} {output}"')
    (51, '')
    (52, 'rule compress_matrix:')
    (53, '\\tinput:')
    (54, '\\t\\t"out/expressions.bin"')
    (55, '\\toutput:')
    (56, '\\t\\t"out/expressions.bin.gz"')
    (57, '\\tshell:')
    (58, '\\t\\t"gzip -k {input}"')
    (59, '')
    (60, 'rule parse_transcripts:')
    (61, '\\tinput:')
    (62, '\\t\\t"out/transcripts_raw.csv"')
    (63, '\\toutput:')
    (64, '\\t\\t"out/transcripts.csv"')
    (65, '\\trun:')
    (66, '\\t\\tif "transcript_id_prefix" in config:')
    (67, '\\t\\t\\tshell("./scripts/parse_transcripts.py {input} -p=\\\\"{config[transcript_id_prefix]}\\\\" > {output}")')
    (68, '\\t\\telse:')
    (69, '\\t\\t\\tshell("./scripts/parse_transcripts.py {input} > {output}")')
    (70, '')
    (71, '')
    (72, 'rule merge_dges:')
    (73, '\\tinput:')
    (74, '\\t\\t"out/seurat_cluster_dge.json"')
    (75, '\\toutput:')
    (76, '\\t\\t"out/cluster_dge.json"')
    (77, '\\tshell:')
    (78, '\\t\\t"./scripts/merge_dges.py {input} > {output}"')
    (79, "'")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=yplakaka/imc, file=workflow/Snakefile
context_key: ['rule modify_measurement_pipeline', 'run', 'if line.rstrip()']
    (536, '                        if line.rstrip())')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=yplakaka/imc, file=workflow/Snakefile
context_key: ['rule download_example_data', 'run', 'if ~fn.exists()']
    (614, '            if ~fn.exists():')
    (615, '                shutil.move(fn_cache[0], fn)')
    (616, '')
    (617, '### Varia')
    (618, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=ktmeaton/plague-phylogeography, file=workflow/rules/alignment.smk
context_key: ['rule eager', 'input', 'if wildcards.sample in path]']
    (17, '                                  if wildcards.sample in path],')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=ktmeaton/plague-phylogeography, file=workflow/Snakefile
context_key: ['rule help', 'run', 'if rule.docstring']
    (142, '      if rule.docstring:')
    (143, '          print(rule.docstring)')
    (144, '      if rule._input:')
    (145, '          print("\\\\tinput:")')
    (146, '          for in_file in rule.input:')
    (147, '              print("\\\\t\\\\t" + str(in_file))')
    (148, '          for in_file in rule.input.keys():')
    (149, '              print("\\\\t\\\\t" + in_file + ": " + str(rule.input[in_file]))')
    (150, '      if rule._output:')
    (151, '          print("\\\\toutput:")')
    (152, '          for out_file in rule.output:')
    (153, '              print("\\\\t\\\\t" + out_file)')
    (154, '          for out_file in rule.output.keys():')
    (155, '              print("\\\\t\\\\t" + out_file + ": " + str(rule.output[out_file]))')
    (156, '      if rule._params:')
    (157, '          print("\\\\tparams:")')
    (158, '          for param in rule.params.keys():')
    (159, '              print("\\\\t\\\\t" + param + ": " + str(rule.params[param]))')
    (160, '      if rule.resources:')
    (161, '          print("\\\\tresources:")')
    (162, '          for resource in rule.resources.keys():')
    (163, '              print("\\\\t\\\\t" + resource.strip("_") + ": " + str(rule.resources[resource]))')
    (164, '      if rule.conda_env:')
    (165, '          print("\\\\t\\\\tconda: ", rule.conda_env)')
    (166, '      if rule._log:')
    (167, '          print("\\\\t\\\\tlog: ", rule._log)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=mitoNGS/MToolBox_snakemake, file=snakefiles/variant_calling.snakefile
context_key: ['rule map_MT_PE_SE', 'run', 'if seq_type == "pe"']
    (279, '        if seq_type == "pe":')
    (280, '            print("PE mode")')
    (281, '            shell("gsnap -D {params.gmap_db_dir} -d {params.gmap_db} -o {params.uncompressed_output} -A sam --gunzip --nofails --pairmax-dna=500 --query-unk-mismatch=1 {params.RG_tag} -n 1 -Q -O -t {threads} {input[0]} {input[1]} &> {log} && gzip {params.uncompressed_output} &>> {log}")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=mitoNGS/MToolBox_snakemake, file=snakefiles/variant_calling.snakefile
context_key: ['rule map_MT_PE_SE', 'run', 'if seq_type == "se"']
    (282, '        if seq_type == "se":')
    (283, '            print("SE mode")')
    (284, '            shell("gsnap -D {params.gmap_db_dir} -d {params.gmap_db} -o {params.uncompressed_output} -A sam --gunzip --nofails --pairmax-dna=500 --query-unk-mismatch=1 {params.RG_tag} -n 1 -Q -O -t {threads} {input[0]} &> {log} && gzip {params.uncompressed_output} &>> {log}")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=mitoNGS/MToolBox_snakemake, file=snakefiles/variant_calling.snakefile
context_key: ['rule map_MT_PE_SE', 'run', 'elif seq_type == "both"']
    (285, '        elif seq_type == "both":')
    (286, '            print("PE + SE mode")')
    (287, '            shell("gsnap -D {params.gmap_db_dir} -d {params.gmap_db} -o {params.uncompressed_output} -A sam --gunzip --nofails --pairmax-dna=500 --query-unk-mismatch=1 {params.RG_tag} -n 1 -Q -O -t {threads} {input[0]} {input[1]} {input[2]} &> {log} && gzip {params.uncompressed_output} &>> {log}")')
    (288, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=mitoNGS/MToolBox_snakemake, file=snakefiles/variant_calling.snakefile
context_key: ['rule map_nuclear_MT_SE', 'run', 'if os.path.isfile(input.outmt)']
    (396, '        if os.path.isfile(input.outmt):')
    (397, '            shell("gsnap -D {params.gmap_db_dir} -d {params.gmap_db} -o {params.uncompressed_output} --gunzip -A sam --nofails --query-unk-mismatch=1 -O -t {threads} {input[:-1]} &> {log.logS} && gzip {params.uncompressed_output} &>> {log.logS}")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=mitoNGS/MToolBox_snakemake, file=snakefiles/variant_calling.snakefile
context_key: ['rule map_nuclear_MT_PE', 'run', 'if os.path.isfile(input.outmt1)']
    (429, '        if os.path.isfile(input.outmt1):')
    (430, '            shell("gsnap -D {params.gmap_db_dir} -d {params.gmap_db} -o {params.uncompressed_output} --gunzip -A sam --nofails --query-unk-mismatch=1 -O -t {threads} {input.outmt1} {input.outmt2} &> {log.logP} && gzip {params.uncompressed_output} &>> {log.logP}")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=mitoNGS/MToolBox_snakemake, file=snakefiles/variant_calling.snakefile
context_key: ['rule map_nuclear_MT_PE_SE', 'run', 'if len(input_files_SE) > 1']
    (461, '        if len(input_files_SE) > 1:')
    (462, "            with open(input_files_SE_all, \\'wb\\') as input_files_SE_cat:")
    (463, '                for f in input_files_SE:')
    (464, "                    with open(f, \\'rb\\') as rfp:")
    (465, '                        shutil.copyfileobj(rfp, input_files_SE_cat)')
    (466, '            input_files_SE = [input_files_SE_all]')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=mitoNGS/MToolBox_snakemake, file=snakefiles/variant_calling.snakefile
context_key: ['rule map_nuclear_MT_PE_SE', 'run', 'if os.path.isfile(input_files_SE_all)']
    (469, '        if os.path.isfile(input_files_SE_all):')
    (470, '            os.remove(input_files_SE_all)')
    (471, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=mitoNGS/MToolBox_snakemake, file=snakefiles/variant_calling.snakefile
context_key: ['rule mark_duplicates', 'run', 'if params.mark_duplicates == True']
    (528, '        if params.mark_duplicates == True:')
    (529, '            shell("picard MarkDuplicates \\\\')
    (530, '                INPUT={input.sorted_bam} \\\\')
    (531, '                OUTPUT={output.sorted_bam_md} \\\\')
    (532, '                METRICS_FILE={output.metrics_file} \\\\')
    (533, '                ASSUME_SORTED=true \\\\')
    (534, '                REMOVE_DUPLICATES=true \\\\')
    (535, '                TMP_DIR={params.TMP}")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=mitoNGS/MToolBox_snakemake, file=snakefiles/variant_calling.snakefile
context_key: ['rule bam2cov', 'input', 'else "results/{sample}/map/{sample}_{ref_genome_mt}_{ref_genome_n}_OUT-sorted.realign.bam"']
    (677, '                        else "results/{sample}/map/{sample}_{ref_genome_mt}_{ref_genome_n}_OUT-sorted.realign.bam",')
    (678, '        #genome_index = "data/genomes/{ref_genome_mt}_{ref_genome_n}.fasta.fai"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=mitoNGS/MToolBox_snakemake, file=snakefiles/variant_calling.snakefile
context_key: ['rule make_single_VCF', 'input', 'else "results/{sample}/map/{sample}_{ref_genome_mt}_{ref_genome_n}_OUT-sorted.realign.bam"']
    (700, '                        else "results/{sample}/map/{sample}_{ref_genome_mt}_{ref_genome_n}_OUT-sorted.realign.bam",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=mitoNGS/MToolBox_snakemake, file=snakefiles/variant_calling.snakefile
context_key: ['rule merge_VCF', 'run', 'if len(input.single_vcf_list) == 1']
    (772, '        if len(input.single_vcf_list) == 1:')
    (773, '            shutil.copy2(input.single_vcf_list[0], output.merged_vcf+".gz")')
    (774, '            shell("gunzip {output.merged_vcf}.gz")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=christacaggiano/GATK_exome_seq, file=rules/filtering.smk
context_key: ['rule merge_calls', 'input', 'else "hardfiltered"']
    (58, '                              else "hardfiltered")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=crazyhottommy/pyflow-ChIPseq, file=Snakefile
context_key: ['rule down_sample', 'run', 'if total_reads > target_reads']
    (206, '        if total_reads > target_reads:')
    (207, '            down_rate = target_reads/total_reads')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=david-a-parry/vase_family_filtering_workflow, file=workflow/rules/vase.smk
context_key: ['rule vase_annotate', 'output', 'else [])']
    (51, '                else []),')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=JamieCFreeman/DGN_compatible, file=Snakefile
context_key: ['rule indel_target', 'rule indel_realign', 'if ROUND == 1']
    (295, '        if ROUND == 1:')
    (296, '                return ["-ploidy 1"]')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=JamieCFreeman/DGN_compatible, file=Snakefile
context_key: ['rule indel_target', 'elif ROUND == 2']
    (297, '        elif ROUND == 2:')
    (298, '                return "".join(["-ploidy ", config["ploidy"], " -out_mode EMIT_ALL_SITES"])')
    (299, '                ')
    (300, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=biolaboro/PSET, file=workflow/Snakefile
context_key: ['rule simcamp', 'run', 'if params.sim <= sim and sims.get(hsp.hit_id, 0) < sim']
    (168, '            if params.sim <= sim and sims.get(hsp.hit_id, 0) < sim:')
    (169, '                sims[hsp.hit_id] = sim')
    (170, '                hsps[hsp.hit_id] = hsp')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=biolaboro/PSET, file=workflow/Snakefile
context_key: ['rule varcamp', 'run', 'if pair[0] != pair[1']
    (329, '            if pair[0] != pair[1]')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=biolaboro/PSET, file=workflow/Snakefile
context_key: ['rule varcamp', 'run', 'if ele[-1] != AlignType.SIM and ele[-1] != AlignType.UNK']
    (334, '                if ele[-1] != AlignType.SIM and ele[-1] != AlignType.UNK:')
    (335, '                    print(*ele[:-1], ele[-1].name, len(mapped[ele[0]]), sep="\\\\t", file=file)')
    (336, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=biolaboro/PSET, file=workflow/Snakefile
context_key: ['rule simcomp', 'run', 'if hsp.hit_id not in sims']
    (374, '            if hsp.hit_id not in sims:')
    (375, '                sims[hsp.hit_id] = sim')
    (376, '                hsps[hsp.hit_id] = hsp')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=biolaboro/PSET, file=workflow/Snakefile
context_key: ['rule extract', 'run', 'if rec.id in bat']
    (405, '            if rec.id in bat:')
    (406, '                coor = bat[rec.id]')
    (407, '                rec = rec[coor[0]:coor[1]]')
    (408, '                rec = rec if coor[2] >= 0 else rec.reverse_complement()')
    (409, '                key = seguid(rec.seq)')
    (410, '                recs[key] = recs.get(key, rec)')
    (411, '                maps[key].append(rec.id)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=biolaboro/PSET, file=workflow/Snakefile
context_key: ['rule matrix', 'run', 'if is_100']
    (541, '                    if is_100:')
    (542, '                        outcome = "PT" if is_tar else "PF"')
    (543, '                    elif is_hit:')
    (544, '                        outcome = "TP" if is_tar else "FP"')
    (545, '                    else:')
    (546, '                        outcome = "FN" if is_tar else "TN"')
    (547, '                    outcome += "N" * bool(int(row["num_n"]))')
    (548, '                    print(ele, is_hit, is_tar, outcome, sep="\\\\t", file=file2)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=vsoch/dna-seq-varlociraptor, file=workflow/rules/trimming.smk
context_key: ['rule merge_fastqs', 'run', 'if input[0].endswith(".gz")']
    (38, '        if input[0].endswith(".gz"):')
    (39, '            shell("cat {input} > {output}")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=CUMoellerLab/sn-mg-pipeline, file=resources/snakefiles/prototype_selection.smk
context_key: ['rule prototype_selection', 'run', "if params[\\'min_seqs\\'] <= seqs <= params[\\'max_seqs\\']"]
    (258, "            if params[\\'min_seqs\\'] <= seqs <= params[\\'max_seqs\\']:")
    (259, '                pf_seqs.append(fp)')
    (260, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=CarolinaPB/population-mapping, file=Snakefile
context_key: ['rule merge_mapped', 'run', 'if len(input) >1']
    (120, '        if len(input) >1:')
    (121, '            shell("module load samtools && samtools merge -@ 16 {output} {input}")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=TBradley27/FilTar, file=modules/quant_reads/kallisto/Snakefile
context_key: ['rule get_index', "if wildcards.accession in config[\\'paired_end\\']"]
    (38, "        if wildcards.accession in config[\\'paired_end\\']:")
    (39, '                input_files = [')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Konjkov/QMC-snakemake-workflow, file=Snakefile
context_key: ['rule DMC_STATS_INPUT', 'run', 'if pp_basis(wildcards.basis)']
    (322, '        if pp_basis(wildcards.basis):')
    (323, '            max_Z = charge_pseudo_atom(max_Z)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Konjkov/QMC-snakemake-workflow, file=Snakefile
context_key: ['rule DMC_STATS_INPUT', 'run', 'if STD_ERR > stderr']
    (325, '        if STD_ERR > stderr:')
    (326, '            nstep = 10000')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Konjkov/QMC-snakemake-workflow, file=Snakefile
context_key: ['rule DMC_STATS_INPUT', 'run', 'if pp_basis(wildcards.basis)']
    (330, '        if pp_basis(wildcards.basis):')
    (331, "            tmove = \\'T\\'")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Konjkov/QMC-snakemake-workflow, file=Snakefile
context_key: ['rule DMC_STATS_INPUT', 'run', 'if pp_basis(wildcards.basis)']
    (340, '        if pp_basis(wildcards.basis):')
    (341, '            for symbol in get_atomic_symbols(wildcards.molecule):')
    (342, '                symbol = symbol.lower()')
    (343, '                shell(\\\'cd "$(dirname "{output}")" && ln -s ../../../../../../../../ppotential/DiracFock_AREP/{symbol}_pp.data\\\')')
    (344, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Konjkov/QMC-snakemake-workflow, file=Snakefile
context_key: ['rule VMC_DMC_INPUT', 'run', 'if pp_basis(wildcards.basis)']
    (356, '        if pp_basis(wildcards.basis):')
    (357, '            max_Z = charge_pseudo_atom(max_Z)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Konjkov/QMC-snakemake-workflow, file=Snakefile
context_key: ['rule VMC_DMC_INPUT', 'run', 'if pp_basis(wildcards.basis)']
    (360, '        if pp_basis(wildcards.basis):')
    (361, "            tmove = \\'T\\'")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Konjkov/QMC-snakemake-workflow, file=Snakefile
context_key: ['rule VMC_DMC_INPUT', 'run', 'if pp_basis(wildcards.basis)']
    (370, '        if pp_basis(wildcards.basis):')
    (371, '            for symbol in get_atomic_symbols(wildcards.molecule):')
    (372, '                symbol = symbol.lower()')
    (373, '                shell(\\\'cd "$(dirname "{output}")" && ln -s ../../../../../../../../ppotential/DiracFock_AREP/{symbol}_pp.data\\\')')
    (374, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Konjkov/QMC-snakemake-workflow, file=Snakefile
context_key: ['rule VMC_OPT_ENERGY_INPUT', 'run', 'if pp_basis(wildcards.basis)']
    (408, '        if pp_basis(wildcards.basis):')
    (409, '            for symbol in get_atomic_symbols(wildcards.molecule):')
    (410, '                symbol = symbol.lower()')
    (411, '                shell(\\\'cd "$(dirname "{output}")" && ln -s ../../../../../../../../ppotential/DiracFock_AREP/{symbol}_pp.data\\\')')
    (412, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Konjkov/QMC-snakemake-workflow, file=Snakefile
context_key: ['rule VMC_OPT_INPUT', 'run', 'if pp_basis(wildcards.basis)']
    (450, '        if pp_basis(wildcards.basis):')
    (451, '            for symbol in get_atomic_symbols(wildcards.molecule):')
    (452, '                symbol = symbol.lower()')
    (453, '                shell(\\\'cd "$(dirname "{output}")" && ln -s ../../../../../../../ppotential/DiracFock_AREP/{symbol}_pp.data\\\')')
    (454, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Konjkov/QMC-snakemake-workflow, file=Snakefile
context_key: ['rule VMC_INPUT', 'run', 'if pp_basis(wildcards.basis)']
    (489, '        if pp_basis(wildcards.basis):')
    (490, '            for symbol in get_atomic_symbols(wildcards.molecule):')
    (491, '                symbol = symbol.lower()')
    (492, '                shell(\\\'cd "$(dirname "{output}")" && ln -s ../../../../../../ppotential/DiracFock_AREP/{symbol}_pp.data\\\')')
    (493, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Konjkov/QMC-snakemake-workflow, file=Snakefile
context_key: ['rule DMC_STATS_BF_INPUT', 'run', 'if STD_ERR > stderr']
    (523, '        if STD_ERR > stderr:')
    (524, '            nstep = 10000')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Konjkov/QMC-snakemake-workflow, file=Snakefile
context_key: ['rule DMC_STATS_BF_INPUT', 'run', 'if pp_basis(wildcards.basis)']
    (528, '        if pp_basis(wildcards.basis):')
    (529, "            tmove = \\'T\\'")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Konjkov/QMC-snakemake-workflow, file=Snakefile
context_key: ['rule VMC_DMC_BF_INPUT', 'run', 'if pp_basis(wildcards.basis)']
    (550, '        if pp_basis(wildcards.basis):')
    (551, "            tmove = \\'T\\'")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Konjkov/QMC-snakemake-workflow, file=Snakefile
context_key: ['rule VMC_OPT_BF_DATA_JASTROW', 'run', "if backflow[1] != \\'0\\'"]
    (645, "            if backflow[1] != \\'0\\':")
    (646, '                mu_sets.append(mu_set.format(')
    (647, '                    number_of_atoms=len(labels),')
    (648, '                    spin_dep=0 if neu == ned else 1,')
    (649, "                    atom_labels=\\' \\'.join(map(str, labels)),")
    (650, '                    mu_term=backflow[1],')
    (651, '                    nset=nset + 1')
    (652, '                ))')
    (653, "            if backflow[2] != \\'00\\':")
    (654, '                phi_sets.append(phi_set.format(')
    (655, '                    number_of_atoms=len(labels),')
    (656, "                    atom_labels=\\' \\'.join(map(str, labels)),")
    (657, '                    phi_term_eN=backflow[2][0], phi_term_ee=backflow[2][1],')
    (658, '                    nset=nset + 1')
    (659, '                ))')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Konjkov/QMC-snakemake-workflow, file=Snakefile
context_key: ['rule VMC_OPT_BF_DATA_JASTROW', 'run', "if backflow[0] != \\'0\\'"]
    (661, "        if backflow[0] != \\'0\\':")
    (662, '            terms.append(eta_term.format(eta_term=backflow[0]))')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Konjkov/QMC-snakemake-workflow, file=Snakefile
context_key: ['rule VMC_OPT_BF_DATA_JASTROW', 'run', "if backflow[1] != \\'0\\'"]
    (663, "        if backflow[1] != \\'0\\':")
    (664, "            terms.append(mu_term.format(number_of_mu_sets=nset + 1, mu_sets=\\'\\")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=elswob/neo4j-build-pipeline, file=workflow/Snakefile
context_key: ['rule check_configs', 'run', 'if NODEDIR in config']
    (42, '        if NODEDIR in config:')
    (43, '            nodes = config[NODEDIR]')
    (44, '            for i in nodes:')
    (45, '                o.write(f"integration node {i}\\')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=calliope-project/solar-and-wind-potentials, file=rules/data-preprocessing.smk
context_key: ['rule raw_srtm_elevation_data', 'input', 'if not (x is 34 and y in [3, 4, 5, 6])] # these tiles do not exis']
    (168, '         if not (x is 34 and y in [3, 4, 5, 6])] # these tiles do not exist')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=bihealth/varfish-wf-validation, file=workflow/Snakefile
context_key: ['rule generate_spike_in_files', 'run', 'if test_case["affected"].get(test_case["map"][member["name"]]']
    (154, '                    if test_case["affected"].get(test_case["map"][member["name"]])')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=bihealth/varfish-wf-validation, file=workflow/Snakefile
context_key: ['rule generate_spike_in_files', 'run', 'else 1']
    (155, '                    else 1,')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=bihealth/varfish-wf-validation, file=workflow/Snakefile
context_key: ['rule wait_for_query', 'run', 'if grep failed {output.status}.tmp >/dev/null; the']
    (440, '            if grep failed {output.status}.tmp >/dev/null; then')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=bihealth/varfish-wf-validation, file=workflow/Snakefile
context_key: ['rule wait_for_query', 'run', 'elif grep done {output.status}.tmp >/dev/null; the']
    (443, '            elif grep done {output.status}.tmp >/dev/null; then')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=bihealth/varfish-wf-validation, file=workflow/Snakefile
context_key: ['rule check_result_json', 'run', 'if missing']
    (567, '            if missing:')
    (568, '                print(f"MISSING: {missing}", file=outputf)')
    (569, '            else:')
    (570, '                print("OK", file=outputf)')
    (571, '')
    (572, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=robinmeyers/atac-encode-snakemake, file=Snakefile
context_key: ['rule clean_up', 'if [ -d {params.dir}/align']
    (146, '        if [ -d {params.dir}/align ]')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/spatial-frequency-preferences, file=Snakefile
context_key: ['rule move_off_tesla', 'run', 'if params.wrong_task is not None']
    (565, '        if params.wrong_task is not None:')
    (566, '            # we rename all the files that contain the wrong_task')
    (567, "            for f in glob.glob(os.path.join(output[0], \\'*\\', \\'*\\'+params.wrong_task+\\'*\\')):")
    (568, '                shutil.move(f, f.replace(params.wrong_task, params.right_task))')
    (569, '            # we rename all the files that contain the wrong_task')
    (570, "            for f in glob.glob(os.path.join(output[1], \\'*\\', \\'*\\'+params.wrong_task+\\'*\\')):")
    (571, '                shutil.move(f, f.replace(params.wrong_task, params.right_task))')
    (572, "            for f in glob.glob(os.path.join(output[2], \\'*\\'+params.wrong_task+\\'*\\')):")
    (573, '                shutil.move(f, f.replace(params.wrong_task, params.right_task))')
    (574, '            # and go through and edit all the text as well')
    (575, "            wrong_task = params.wrong_task.replace(\\'task-\\', \\'\\')")
    (576, "            right_task = params.right_task.replace(\\'task-\\', \\'\\')")
    (577, '            shell(\\\'grep -rl --exclude \\\\*nii.gz "{wrong_task}" {output[0]} | xargs sed -i "s/{wrong_task}/{right_task}/g"\\\')')
    (578, '            shell(\\\'grep -rl --exclude \\\\*nii.gz "{wrong_task}" {output[2]} | xargs sed -i "s/{wrong_task}/{right_task}/g"\\\')')
    (579, '')
    (580, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/spatial-frequency-preferences, file=Snakefile
context_key: ['rule rearrange_preprocess_extras', 'run', "if os.path.split(input[0])[-1] == \\'session.json\\'"]
    (736, "        if os.path.split(input[0])[-1] == \\'session.json\\':")
    (737, '            # we handle this differently, because we want to merge the jsons instead')
    (738, '            master_json = {}')
    (739, '            for filename in input:')
    (740, '                run_name = os.path.abspath(filename).split(os.sep)[-2]')
    (741, '                with open(filename) as f:')
    (742, '                    master_json[run_name] = json.load(f)')
    (743, '                os.remove(filename)')
    (744, "            with open(output[0], \\'w\\') as f:")
    (745, '                json.dump(master_json, f)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/spatial-frequency-preferences, file=Snakefile
context_key: ['rule rearrange_preprocess_extras', 'run', 'else', "if subprocess.call([\\'cmp\\', \\'-s\\', file1, file2]) == 1"]
    (749, "                if subprocess.call([\\'cmp\\', \\'-s\\', file1, file2]) == 1:")
    (750, '                    raise Exception("%s and %s are different, they should be the same!" % (file1, file2))')
    (751, '                else:')
    (752, '                    os.remove(file2)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/spatial-frequency-preferences, file=Snakefile
context_key: ['rule prf_check_plot', 'run', "if wildcards.prf_prop == \\'varea\\'"]
    (834, "        if wildcards.prf_prop == \\'varea\\':")
    (835, "            mask = (\\'plot_property\\', [1, 2, 3])")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/spatial-frequency-preferences, file=Snakefile
context_key: ['rule compute_groupaverage', 'input', 'if TASKS[(sub, wildcards.session)] == wildcards.task']
    (1070, '                           if TASKS[(sub, wildcards.session)] == wildcards.task]')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/spatial-frequency-preferences, file=Snakefile
context_key: ['rule summarize_gathered_results', 'input', 'if TASKS[(subj, ses)] == wildcards.task']
    (1556, '                           if TASKS[(subj, ses)] == wildcards.task]')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/spatial-frequency-preferences, file=Snakefile
context_key: ['rule noise_ceiling_monte_carlo', 'run', "if \\'simulated\\' in wildcards.subject"]
    (1944, "        if \\'simulated\\' in wildcards.subject:")
    (1945, "            # don\\'t filter the simulated subject, because the filtering is just")
    (1946, "            # to get rid of voxels whose responses we don\\'t trust, and there")
    (1947, '            # are none of those in a simulation')
    (1948, '            df_filter_str = None')
    (1949, '            is_simulated = True')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/spatial-frequency-preferences, file=Snakefile
context_key: ['rule noise_ceiling_monte_carlo_overall', 'input', 'if TASKS[(sub, wildcards.session)] == wildcards.task']
    (1968, '                           if TASKS[(sub, wildcards.session)] == wildcards.task]')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/spatial-frequency-preferences, file=Snakefile
context_key: ['rule voxel_exclusion_df', 'run', "if wildcards.df_filter == \\'filter-any\\'"]
    (2051, "        if wildcards.df_filter == \\'filter-any\\':")
    (2052, "            df_filter_str = [\\'drop_voxels_with_any_negative_amplitudes\\', \\'drop_voxels_near_border\\']")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/spatial-frequency-preferences, file=Snakefile
context_key: ['rule voxel_exclusion_df', 'run', "elif wildcards.df_filter == \\'filter-mean\\'"]
    (2053, "        elif wildcards.df_filter == \\'filter-mean\\':")
    (2054, "            df_filter_str = [\\'drop_voxels_with_mean_negative_amplitudes\\', \\'drop_voxels_near_border\\']")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/spatial-frequency-preferences, file=Snakefile
context_key: ['rule voxel_exclusion_df', 'run', 'if len(vareas) > 1']
    (2058, '        if len(vareas) > 1:')
    (2059, '            raise Exception("Wrote this assuming there was only one varea!")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/spatial-frequency-preferences, file=Snakefile
context_key: ['rule figure_summarize_1d', 'run', "if wildcards.tuning_param.endswith(\\'overall\\')", "if wildcards.groupaverage == \\'sub-groupaverage\\'"]
    (2163, "        if wildcards.tuning_param.endswith(\\'overall\\'):")
    (2164, "            if wildcards.groupaverage == \\'sub-groupaverage\\':")
    (2165, '                raise Exception(f"Can\\\'t use sub-groupaverage with {wildcards.tuning_param}! Drop "')
    (2166, '                                "the \\\'-overall\\\'")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/spatial-frequency-preferences, file=Snakefile
context_key: ['rule figure_summarize_1d', 'run', "if wildcards.tuning_param.endswith(\\'overall\\')", "if \\'degrees\\' in wildcards.tuning_param"]
    (2167, "            if \\'degrees\\' in wildcards.tuning_param:")
    (2168, "                df[\\'tuning_curve_bandwidth_degrees\\'] = df.apply(sfp.utils._octave_to_degrees, 1)")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/spatial-frequency-preferences, file=Snakefile
context_key: ['rule figure_summarize_1d', 'run', "if wildcards.tuning_param.endswith(\\'overall\\')"]
    (2169, "            col = {\\'pref-period-overall\\': \\'preferred_period\\',")
    (2170, "                   \\'bandwidth-overall\\': \\'tuning_curve_bandwidth\\',")
    (2171, "                   \\'bandwidth-degrees-overall\\': \\'tuning_curve_bandwidth_degrees\\'}[wildcards.tuning_param]")
    (2172, '            df = sfp.figures.append_precision_col(df, col)')
    (2173, '            df = sfp.figures.precision_weighted_bootstrap(df, int(wildcards.seed), col=col,')
    (2174, '                                                          precision_col=f"{col}_precision")')
    (2175, '            col_wrap = None')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/spatial-frequency-preferences, file=Snakefile
context_key: ['rule figure_summarize_1d', 'run', "if wildcards.tuning_param.startswith(\\'pref-period\\')"]
    (2179, "        if wildcards.tuning_param.startswith(\\'pref-period\\'):")
    (2180, '            function = sfp.figures.pref_period_1d')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/spatial-frequency-preferences, file=Snakefile
context_key: ['rule figure_summarize_1d', 'run', "elif wildcards.tuning_param.startswith(\\'bandwidth\\')", "if \\'degrees\\' in wildcards.tuning_param"]
    (2181, "        elif wildcards.tuning_param.startswith(\\'bandwidth\\'):")
    (2182, '            function = sfp.figures.bandwidth_1d')
    (2183, "            if \\'degrees\\' in wildcards.tuning_param:")
    (2184, "                kwargs[\\'units\\'] = \\'degrees\\'")
    (2185, "                kwargs[\\'ylim\\'] = (0, 20)")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/spatial-frequency-preferences, file=Snakefile
context_key: ['rule figure_loss_check', 'run', "if wildcards.modeling_goal == \\'initial_cv\\'"]
    (2250, "        if wildcards.modeling_goal == \\'initial_cv\\':")
    (2251, "            hue = \\'test_subset\\'")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/spatial-frequency-preferences, file=Snakefile
context_key: ['rule figure_loss_check', 'run', "elif wildcards.modeling_goal == \\'bootstrap\\'"]
    (2252, "        elif wildcards.modeling_goal == \\'bootstrap\\':")
    (2253, "            hue = \\'bootstrap_num\\'")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/spatial-frequency-preferences, file=Snakefile
context_key: ['rule figure_loss_check', 'run', "elif wildcards.modeling_goal == \\'initial\\'"]
    (2254, "        elif wildcards.modeling_goal == \\'initial\\':")
    (2255, "            hue = \\'groupaverage_seed\\'")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/spatial-frequency-preferences, file=Snakefile
context_key: ['rule figure_crossvalidation', 'run', "if \\'-nc\\' in wildcards.cv_type"]
    (2291, "        if \\'-nc\\' in wildcards.cv_type:")
    (2292, '            noise_ceiling = sfp.figures.prep_df(pd.read_csv(input[1]), wildcards.task)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/spatial-frequency-preferences, file=Snakefile
context_key: ['rule figure_crossvalidation', 'run', "if \\'remeaned\\' in wildcards.cv_type"]
    (2295, "        if \\'remeaned\\' in wildcards.cv_type:")
    (2296, '            remeaned = True')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/spatial-frequency-preferences, file=Snakefile
context_key: ['rule figure_crossvalidation', 'run', 'if df.loss_func.nunique() > 1']
    (2299, '        if df.loss_func.nunique() > 1:')
    (2300, '            warnings.warn("This will only show the cross-validated loss for weighted_normed_loss loss_func")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/spatial-frequency-preferences, file=Snakefile
context_key: ['rule figure_crossvalidation', 'run', "if wildcards.sort == \\'sort_\\'", "if not wildcards.cv_type.startswith(\\'model_point\\')"]
    (2302, "        if wildcards.sort == \\'sort_\\':")
    (2303, '            sort = True')
    (2304, "            if not wildcards.cv_type.startswith(\\'model_point\\'):")
    (2305, '                raise Exception("Can only sort model_point plot!")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/spatial-frequency-preferences, file=Snakefile
context_key: ['rule figure_crossvalidation', 'run', "if wildcards.doubleup == \\'doubleup_\\'", "if not wildcards.cv_type.startswith(\\'model_point\\')"]
    (2308, "        if wildcards.doubleup == \\'doubleup_\\':")
    (2309, '            doubleup = True')
    (2310, "            if not wildcards.cv_type.startswith(\\'model_point\\'):")
    (2311, '                raise Exception("Can only doubleup model_point plot!")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/spatial-frequency-preferences, file=Snakefile
context_key: ['rule figure_crossvalidation', 'run', "if wildcards.doubleup == \\'doubleup_\\'", 'if sort']
    (2312, '            if sort:')
    (2313, '                raise Exception("Can only doubleup cv loss plot if we\\\'re not sorting it!")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/spatial-frequency-preferences, file=Snakefile
context_key: ['rule figure_crossvalidation', 'run', "if wildcards.cv_type.startswith(\\'demeaned\\')"]
    (2316, "        if wildcards.cv_type.startswith(\\'demeaned\\'):")
    (2317, '            g = sfp.figures.cross_validation_demeaned(df, int(wildcards.seed), remeaned,')
    (2318, '                                                      context=wildcards.context,')
    (2319, '                                                      orient=wildcards.orient)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/spatial-frequency-preferences, file=Snakefile
context_key: ['rule figure_crossvalidation', 'run', "elif wildcards.cv_type.startswith(\\'raw\\')"]
    (2320, "        elif wildcards.cv_type.startswith(\\'raw\\'):")
    (2321, '            g = sfp.figures.cross_validation_raw(df, int(wildcards.seed), noise_ceiling,')
    (2322, '                                                 context=wildcards.context,')
    (2323, '                                                 orient=wildcards.orient)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/spatial-frequency-preferences, file=Snakefile
context_key: ['rule figure_crossvalidation', 'run', "elif wildcards.cv_type.startswith(\\'model_point\\')"]
    (2324, "        elif wildcards.cv_type.startswith(\\'model_point\\'):")
    (2325, "            g = sfp.figures.cross_validation_model(df, int(wildcards.seed), \\'point\\', remeaned,")
    (2326, '                                                   noise_ceiling, context=wildcards.context,')
    (2327, '                                                   orient=wildcards.orient, sort=sort,')
    (2328, '                                                   doubleup=doubleup)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/spatial-frequency-preferences, file=Snakefile
context_key: ['rule figure_crossvalidation', 'run', "elif wildcards.cv_type.startswith(\\'model\\')"]
    (2329, "        elif wildcards.cv_type.startswith(\\'model\\'):")
    (2330, '            g = sfp.figures.cross_validation_model(df, int(wildcards.seed), remeaned=remeaned,')
    (2331, '                                                   orient=wildcards.orient,')
    (2332, '                                                   context=wildcards.context)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/spatial-frequency-preferences, file=Snakefile
context_key: ['rule figure_crossvalidation', 'run', "if wildcards.context == \\'paper\\'"]
    (2333, "        if wildcards.context == \\'paper\\':")
    (2334, "            g.axes[0, 0].set_title(\\'\\')")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/spatial-frequency-preferences, file=Snakefile
context_key: ['rule create_precision_df', 'run', "if wildcards.summary_func == \\'mean\\'"]
    (2409, "        if wildcards.summary_func == \\'mean\\':")
    (2410, '            summary_func = np.mean')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/spatial-frequency-preferences, file=Snakefile
context_key: ['rule create_precision_df', 'run', "elif wildcards.summary_func == \\'median\\'"]
    (2411, "        elif wildcards.summary_func == \\'median\\':")
    (2412, '            summary_func = np.median')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/spatial-frequency-preferences, file=Snakefile
context_key: ['rule understand_loss_figure', 'run', 'if df_filter_string is not None']
    (2473, '        if df_filter_string is not None:')
    (2474, '            df_filter = sfp.model.construct_df_filter(df_filter_string)')
    (2475, '            first_level_df = df_filter(first_level_df).reset_index()')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/spatial-frequency-preferences, file=Snakefile
context_key: ['rule figure_params', 'run', "if wildcards.plot_kind.endswith(\\'overall\\')"]
    (2553, "            if wildcards.plot_kind.endswith(\\'overall\\'):")
    (2554, '                # get the median parameter value per subject and model type')
    (2555, "                tmp = tmp.groupby([\\'subject\\', \\'model_parameter\\', \\'fit_model_type\\']).median().reset_index()")
    (2556, '                precision = sfp.figures.prep_df(pd.read_csv(input.precision[0]), wildcards.task)')
    (2557, "                tmp = tmp.merge(precision, on=[\\'subject\\'])")
    (2558, "                tmp = sfp.figures.precision_weighted_bootstrap(tmp, int(wildcards.seed), 100, \\'fit_value\\',")
    (2559, "                                                               [\\'model_parameter\\',")
    (2560, "                                                                \\'fit_model_type\\'], \\'precision\\')")
    (2561, '            df.append(sfp.figures.prep_model_df(tmp))')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/spatial-frequency-preferences, file=Snakefile
context_key: ['rule figure_params', 'run', "if wildcards.plot_kind.startswith(\\'pair\\')", "if wildcards.plot_kind.endswith(\\'drop\\')"]
    (2562, "        if wildcards.plot_kind.startswith(\\'pair\\'):")
    (2563, "            if wildcards.plot_kind.endswith(\\'drop\\'):")
    (2564, '                drop_outlier = True')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/spatial-frequency-preferences, file=Snakefile
context_key: ['rule figure_params', 'run', "if wildcards.plot_kind.startswith(\\'pair\\')", 'else']
    (2565, '            else:')
    (2566, '                drop_outlier = False')
    (2567, '            # this returns the PairPlot, so we need to do .fig to')
    (2568, '            # grab the underlying Figure')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/spatial-frequency-preferences, file=Snakefile
context_key: ['rule figure_params', 'run', "if wildcards.plot_kind.startswith(\\'pair\\')"]
    (2569, '            fig = sfp.figures.model_parameters_pairplot(df[0], drop_outlier).fig')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/spatial-frequency-preferences, file=Snakefile
context_key: ['rule figure_params', 'run', "elif wildcards.plot_kind == \\'compare\\'", "if wildcards.vf == \\'all\\'"]
    (2570, "        elif wildcards.plot_kind == \\'compare\\':")
    (2571, "            if wildcards.vf == \\'all\\':")
    (2572, '                # this returns the FacetGrid, so we need to do .fig to')
    (2573, '                # grab the underlying Figure. bootstrap_df comes before')
    (2574, '                # regular one')
    (2575, '                fig = sfp.figures.model_parameters_compare_plot(df[1], df[0]).fig')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/spatial-frequency-preferences, file=Snakefile
context_key: ['rule figure_params', 'run', "elif wildcards.plot_kind == \\'compare\\'", 'else', "if wildcards.vf == \\'vertical\\'"]
    (2576, '            else:')
    (2577, '                # first draw the distribution of model parameters')
    (2578, '                # for model fit to whole visual field')
    (2579, "                fig = sfp.figures.model_parameters(df[0], \\'dist\\', wildcards.vf, size=7)")
    (2580, "                # this sets the markers and labels we\\'ll use to")
    (2581, '                # distinguish the different parts of the visual')
    (2582, '                # field')
    (2583, "                if wildcards.vf == \\'vertical\\':")
    (2584, "                    kwargs = [{\\'marker\\': \\'^\\', \\'size\\': 7}, {\\'marker\\': \\'v\\', \\'size\\': 7}]")
    (2585, "                    labels = [\\'Upper visual field\\', \\'Lower visual field\\']")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/spatial-frequency-preferences, file=Snakefile
context_key: ['rule figure_params', 'run', "elif wildcards.plot_kind == \\'compare\\'", 'else', "elif wildcards.vf == \\'horizontal\\'"]
    (2586, "                elif wildcards.vf == \\'horizontal\\':")
    (2587, "                    kwargs = [{\\'marker\\': \\'<\\', \\'size\\': 7}, {\\'marker\\': \\'>\\', \\'size\\': 7}]")
    (2588, "                    labels = [\\'Left visual field\\', \\'Right visual field\\']")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/spatial-frequency-preferences, file=Snakefile
context_key: ['rule figure_params', 'run', "elif wildcards.plot_kind == \\'compare\\'", 'else', "elif wildcards.vf == \\'eccen\\'"]
    (2589, "                elif wildcards.vf == \\'eccen\\':")
    (2590, '                    kwargs = [{\\\'size\\\': 5, \\\'marker\\\': \\\'o\\\'}, {\\\'marker\\\': "o", \\\'size\\\': 10}]')
    (2591, "                    labels = [\\'Inner visual field\\', \\'Outer visual field\\']")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/spatial-frequency-preferences, file=Snakefile
context_key: ['rule figure_params', 'run', "elif wildcards.plot_kind == \\'compare\\'", 'else']
    (2592, "                kwargs.append({\\'marker\\': \\'o\\', \\'size\\': 7})")
    (2593, "                labels.append(\\'Full visual field\\')")
    (2594, '                # add the two estimates from parts of the visual')
    (2595, '                # field onto the existing figure, as strip plots')
    (2596, '                # (because we only have a single estimate per model,')
    (2597, "                # not the full distribution). we don\\'t update the")
    (2598, '                # legend within the function...')
    (2599, "                fig = sfp.figures.model_parameters(df[1], \\'strip\\', wildcards.vf, fig, False,")
    (2600, '                                                   **kwargs[0])')
    (2601, "                fig = sfp.figures.model_parameters(df[2], \\'strip\\', wildcards.vf, fig, False,")
    (2602, '                                                   **kwargs[1])')
    (2603, '                # instead doing it manually with some dummy markers')
    (2604, '                dummy_markers = []')
    (2605, '                for m, l in zip(kwargs[::-1], labels[::-1]):')
    (2606, "                    m[\\'markersize\\'] = m.pop(\\'size\\')")
    (2607, "                    dummy_markers.append(mpl.lines.Line2D([], [], linewidth=0, color=\\'gray\\',")
    (2608, '                                                          label=l, **m))')
    (2609, '                fig.axes[-1].legend(handles=dummy_markers, loc=(1.01, .5), frameon=False)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/spatial-frequency-preferences, file=Snakefile
context_key: ['rule figure_params', 'run', 'else', "if wildcards.model_type == \\'full_full_absolute\\'"]
    (2611, "            if wildcards.model_type == \\'full_full_absolute\\':")
    (2612, "                # since this doesn\\'t fit those")
    (2613, '                df[0] = df[0].query("model_parameter not in [\\\'$A_3$\\\', \\\'$A_4$\\\']")')
    (2614, "            # don\\'t add a legend if the plot_kind is point or dist-overall")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/spatial-frequency-preferences, file=Snakefile
context_key: ['rule figure_params', 'run', 'else', "if wildcards.groupaverage == \\'sub-groupaverage\\'"]
    (2617, "            if wildcards.groupaverage == \\'sub-groupaverage\\':")
    (2618, '                add_legend = False')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/spatial-frequency-preferences, file=Snakefile
context_key: ['rule figure_feature_df', 'run', "if wildcards.plot_kind.endswith(\\'overall\\')"]
    (2639, "        if wildcards.plot_kind.endswith(\\'overall\\'):")
    (2640, '            # get the median parameter value per subject and model type')
    (2641, "            df = df.groupby([\\'subject\\', \\'model_parameter\\', \\'fit_model_type\\']).median().reset_index()")
    (2642, '            precision = sfp.figures.prep_df(pd.read_csv(input.precision[0]), wildcards.task)')
    (2643, "            df = df.merge(precision, on=[\\'subject\\'])")
    (2644, "            df = sfp.figures.precision_weighted_bootstrap(df, int(wildcards.seed), 100, \\'fit_value\\',")
    (2645, "                                                          [\\'model_parameter\\', \\'fit_model_type\\'],")
    (2646, "                                                          \\'precision\\')")
    (2647, '            col_wrap = None')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/spatial-frequency-preferences, file=Snakefile
context_key: ['rule figure_feature_df', 'run', "if wildcards.angles == \\'avg\\'"]
    (2650, "        if wildcards.angles == \\'avg\\':")
    (2651, '            angles = True')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/spatial-frequency-preferences, file=Snakefile
context_key: ['rule figure_feature_df', 'run', "elif wildcards.angles == \\'all\\'"]
    (2652, "        elif wildcards.angles == \\'all\\':")
    (2653, '            angles = False')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/spatial-frequency-preferences, file=Snakefile
context_key: ['rule figure_schematic', 'run', "if wildcards.schematic_type == \\'2d\\'"]
    (2668, "        if wildcards.schematic_type == \\'2d\\':")
    (2669, '            fig = sfp.figures.model_schematic(wildcards.context)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/spatial-frequency-preferences, file=Snakefile
context_key: ['rule figure_schematic', 'run', "elif wildcards.schematic_type == \\'2d-inputs\\'"]
    (2670, "        elif wildcards.schematic_type == \\'2d-inputs\\':")
    (2671, '            fig = sfp.figures.input_schematic(wildcards.context)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/spatial-frequency-preferences, file=Snakefile
context_key: ['rule figure_schematic', 'run', "elif wildcards.schematic_type == \\'background\\'"]
    (2672, "        elif wildcards.schematic_type == \\'background\\':")
    (2673, '            fig = sfp.figures.theory_background_figure(wildcards.context)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/spatial-frequency-preferences, file=Snakefile
context_key: ['rule figure_model_schematic', 'run', "if \\'annot\\' in wildcards.extra"]
    (2711, "        if \\'annot\\' in wildcards.extra:")
    (2712, '            annotate = True')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/spatial-frequency-preferences, file=Snakefile
context_key: ['rule figure_model_schematic', 'run', "if \\'sort\\' in wildcards.extra"]
    (2715, "        if \\'sort\\' in wildcards.extra:")
    (2716, '            warnings.warn("Sorting by remeaned cv loss, using weighted_normed_loss, task-sfprescaled runs")')
    (2717, "            df = sfp.figures.prep_df(pd.read_csv(input[0]), \\'task-sfprescaled\\')")
    (2718, '            df = sfp.figures._demean_df(df.query(\\\'loss_func == "weighted_normed_loss"\\\'))')
    (2719, '            gb = df.query("loss_func == \\\'weighted_normed_loss\\\'").groupby(\\\'fit_model_type\\\')')
    (2720, "            order = gb[\\'remeaned_cv_loss\\'].median().sort_values(ascending=False).index")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/spatial-frequency-preferences, file=Snakefile
context_key: ['rule figure_model_schematic', 'run', "if \\'doubleup\\' in wildcards.extra", 'if order is not None']
    (2723, "        if \\'doubleup\\' in wildcards.extra:")
    (2724, '            doubleup = True')
    (2725, '            if order is not None:')
    (2726, '                raise Exception("Can only doubleup the schematic if we\\\'re not sorting it!")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/spatial-frequency-preferences, file=Snakefile
context_key: ['rule figure_peakiness_check', 'run', "if wildcards.col == \\'all\\'"]
    (2804, "        if wildcards.col == \\'all\\':")
    (2805, '            col = None')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/spatial-frequency-preferences, file=Snakefile
context_key: ['rule figure_peakiness_check', 'run', "elif wildcards.col == \\'individual\\'"]
    (2806, "        elif wildcards.col == \\'individual\\':")
    (2807, "            col = \\'subject\\'")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/spatial-frequency-preferences, file=Snakefile
context_key: ['rule figure_compare_surface_area', 'input', "if TASKS.get((subj, \\'ses-04\\'), None) == \\'task-sfprescaled\\']"]
    (2860, "                                    if TASKS.get((subj, \\'ses-04\\'), None) == \\'task-sfprescaled\\'],")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/spatial-frequency-preferences, file=Snakefile
context_key: ['rule figure_compare_surface_area', 'input', "if TASKS.get((subj, \\'ses-04\\'), None) == \\'task-sfprescaled\\']"]
    (2862, "                                    if TASKS.get((subj, \\'ses-04\\'), None) == \\'task-sfprescaled\\'],")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/spatial-frequency-preferences, file=Snakefile
context_key: ['rule figure_compare_visual_field', 'run', "if \\'vertical\\' in p"]
    (2916, "            if \\'vertical\\' in p:")
    (2917, "                tmp[\\'Visual field\\'] = \\'Vertical meridians\\'")
    (2918, "            elif \\'horizontal\\' in p:")
    (2919, "                tmp[\\'Visual field\\'] = \\'Horizontal meridians\\'")
    (2920, '            else:')
    (2921, "                tmp[\\'Visual field\\'] = \\'Full visual field\\'")
    (2922, '            df.append(tmp)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/spatial-frequency-preferences, file=Snakefile
context_key: ['rule compose_figures', 'run', "if \\'crossvalidation\\' in wildcards.figure_name"]
    (3060, "        if \\'crossvalidation\\' in wildcards.figure_name:")
    (3061, '            sfp.compose_figures.crossvalidation(*input, output[0], wildcards.context)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/spatial-frequency-preferences, file=Snakefile
context_key: ['rule compose_figures', 'run', "elif \\'with_legend\\' in wildcards.figure_name", "if \\'1d_pref-period-overall\\' in wildcards.figure_name"]
    (3062, "        elif \\'with_legend\\' in wildcards.figure_name:")
    (3063, "            if \\'1d_pref-period-overall\\' in wildcards.figure_name:")
    (3064, "                sfp.compose_figures.add_legend(input[0], \\'half\\', (143, 136),")
    (3065, "                                               output[0], (0, 0), 1, \\'rel\\',")
    (3066, '                                               wildcards.context)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/spatial-frequency-preferences, file=Snakefile
context_key: ['rule compose_figures', 'run', "elif \\'with_legend\\' in wildcards.figure_name", "if \\'schematic_2d\\' in wildcards.figure_name"]
    (3067, "            if \\'schematic_2d\\' in wildcards.figure_name:")
    (3068, "                sfp.compose_figures.add_legend(input[0], \\'half\\', (70, 0),")
    (3069, "                                               output[0], (0, 70), .8, \\'rel\\',")
    (3070, '                                               wildcards.context)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/spatial-frequency-preferences, file=Snakefile
context_key: ['rule compose_figures', 'run', "elif \\'2d_summary\\' in wildcards.figure_name"]
    (3071, "        elif \\'2d_summary\\' in wildcards.figure_name:")
    (3072, '            sfp.compose_figures.feature_df_summary(input[:3], input[3:],')
    (3073, '                                                   output[0], wildcards.context)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/spatial-frequency-preferences, file=Snakefile
context_key: ['rule compose_figures', 'run', "elif \\'1d_summary\\' in wildcards.figure_name"]
    (3074, "        elif \\'1d_summary\\' in wildcards.figure_name:")
    (3075, '            sfp.compose_figures.summary_1d(input[0], input[1], output[0], wildcards.context)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/spatial-frequency-preferences, file=Snakefile
context_key: ['rule compose_figures', 'run', "elif \\'stimulus\\' in wildcards.figure_name"]
    (3076, "        elif \\'stimulus\\' in wildcards.figure_name:")
    (3077, '            sfp.compose_figures.stimulus_figure(input[0], input[1], input[2],')
    (3078, '                                                output[0], wildcards.context)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/spatial-frequency-preferences, file=Snakefile
context_key: ['rule compose_figures', 'run', "elif \\'background\\' in wildcards.figure_name"]
    (3079, "        elif \\'background\\' in wildcards.figure_name:")
    (3080, '            sfp.compose_figures.background_figure(input[0], output[0],')
    (3081, '                                                  wildcards.context)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/spatial-frequency-preferences, file=Snakefile
context_key: ['rule compose_figures', 'run', "elif \\'example_voxel\\' in wildcards.figure_name"]
    (3082, "        elif \\'example_voxel\\' in wildcards.figure_name:")
    (3083, '            sfp.compose_figures.example_voxels(input[0], input[1], output[0],')
    (3084, '                                               wildcards.context)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/spatial-frequency-preferences, file=Snakefile
context_key: ['rule compose_figures', 'run', "elif \\'parameters\\' in wildcards.figure_name"]
    (3085, "        elif \\'parameters\\' in wildcards.figure_name:")
    (3086, '            sfp.compose_figures.parameters(input[0], input[1], output[0],')
    (3087, '                                           wildcards.context)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/spatial-frequency-preferences, file=Snakefile
context_key: ['rule compose_figures', 'run', "elif \\'visual-field-diff\\' in wildcards.figure_name"]
    (3088, "        elif \\'visual-field-diff\\' in wildcards.figure_name:")
    (3089, '            sfp.compose_figures.visual_field_differences(input[0], input[1],')
    (3090, '                                                         output[0], wildcards.context)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/spatial-frequency-preferences, file=Snakefile
context_key: ['rule compose_figures', 'run', "elif \\'example_ecc_bins\\' in wildcards.figure_name"]
    (3091, "        elif \\'example_ecc_bins\\' in wildcards.figure_name:")
    (3092, '            sfp.compose_figures.example_ecc_bins(input[0], output[0], wildcards.context)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/spatial-frequency-preferences, file=Snakefile
context_key: ['rule compose_figures', 'run', "elif \\'schematic_model_2d\\' in wildcards.figure_name"]
    (3093, "        elif \\'schematic_model_2d\\' in wildcards.figure_name:")
    (3094, '            sfp.compose_figures.schematic_model_2d(*input, output[0], wildcards.context)')
    (3095, '')
    (3096, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/spatial-frequency-preferences, file=Snakefile
context_key: ['rule predicted_bold', 'run', "if wildcards.param_set == \\'paper\\'"]
    (3241, "        if wildcards.param_set == \\'paper\\':")
    (3242, "            model_params = {\\'sigma\\': 2,")
    (3243, "                            \\'sf_ecc_slope\\': .1,")
    (3244, "                            \\'sf_ecc_intercept\\': .35,")
    (3245, "                            \\'abs_mode_cardinals\\': .06,")
    (3246, "                            \\'abs_mode_obliques\\': -.03,")
    (3247, "                            \\'rel_mode_cardinals\\': .06,")
    (3248, "                            \\'rel_mode_obliques\\': 0,")
    (3249, "                            \\'abs_amplitude_cardinals\\': .04,")
    (3250, "                            \\'abs_amplitude_obliques\\': -.01,")
    (3251, "                            \\'rel_amplitude_cardinals\\': 0,")
    (3252, "                            \\'rel_amplitude_obliques\\': 0}")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/spatial-frequency-preferences, file=Snakefile
context_key: ['rule predicted_bold', 'run', "elif wildcards.param_set == \\'simple\\'"]
    (3253, "        elif wildcards.param_set == \\'simple\\':")
    (3254, "            model_params = {\\'sigma\\': 2,")
    (3255, "                            \\'sf_ecc_slope\\': .1,")
    (3256, "                            \\'sf_ecc_intercept\\': .35,")
    (3257, "                            \\'abs_mode_cardinals\\': 0,")
    (3258, "                            \\'abs_mode_obliques\\': 0,")
    (3259, "                            \\'rel_mode_cardinals\\': 0,")
    (3260, "                            \\'rel_mode_obliques\\': 0,")
    (3261, "                            \\'abs_amplitude_cardinals\\': 0,")
    (3262, "                            \\'abs_amplitude_obliques\\': 0,")
    (3263, "                            \\'rel_amplitude_cardinals\\': 0,")
    (3264, "                            \\'rel_amplitude_obliques\\': 0}")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/spatial-frequency-preferences, file=Snakefile
context_key: ['rule predicted_bold', 'run', "elif wildcards.param_set == \\'flat\\'"]
    (3265, "        elif wildcards.param_set == \\'flat\\':")
    (3266, "            model_params = {\\'sigma\\': 2,")
    (3267, "                            \\'sf_ecc_slope\\': 0,")
    (3268, "                            \\'sf_ecc_intercept\\': .5,")
    (3269, "                            \\'abs_mode_cardinals\\': 0,")
    (3270, "                            \\'abs_mode_obliques\\': 0,")
    (3271, "                            \\'rel_mode_cardinals\\': 0,")
    (3272, "                            \\'rel_mode_obliques\\': 0,")
    (3273, "                            \\'abs_amplitude_cardinals\\': 0,")
    (3274, "                            \\'abs_amplitude_obliques\\': 0,")
    (3275, "                            \\'rel_amplitude_cardinals\\': 0,")
    (3276, "                            \\'rel_amplitude_obliques\\': 0}")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/spatial-frequency-preferences, file=Snakefile
context_key: ['rule predicted_bold', 'run', "elif wildcards.param_set == \\'scaling\\'"]
    (3277, "        elif wildcards.param_set == \\'scaling\\':")
    (3278, "            model_params = {\\'sigma\\': 2,")
    (3279, "                            \\'sf_ecc_slope\\': .15,")
    (3280, "                            \\'sf_ecc_intercept\\': 0,")
    (3281, "                            \\'abs_mode_cardinals\\': 0,")
    (3282, "                            \\'abs_mode_obliques\\': 0,")
    (3283, "                            \\'rel_mode_cardinals\\': 0,")
    (3284, "                            \\'rel_mode_obliques\\': 0,")
    (3285, "                            \\'abs_amplitude_cardinals\\': 0,")
    (3286, "                            \\'abs_amplitude_obliques\\': 0,")
    (3287, "                            \\'rel_amplitude_cardinals\\': 0,")
    (3288, "                            \\'rel_amplitude_obliques\\': 0}")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Monia234/LocalAncestry, file=Snakefile
context_key: ['rule merge_rfmix_output', 'input', 'if wildcards.chr not in ACROCENTRIC else \\']
    (287, '            if wildcards.chr not in ACROCENTRIC else \\\\')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Monia234/LocalAncestry, file=Snakefile
context_key: ['rule merge_rfmix_output', 'input', 'if wildcards.chr not in ACROCENTRIC else \\']
    (291, '            if wildcards.chr not in ACROCENTRIC else \\\\')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Monia234/LocalAncestry, file=Snakefile
context_key: ['rule merge_rfmix_output', 'input', 'if wildcards.chr not in ACROCENTRIC else \\']
    (295, '            if wildcards.chr not in ACROCENTRIC else \\\\')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Monia234/LocalAncestry, file=Snakefile
context_key: ['rule merge_phasing', 'input', 'if wildcards.chr not in ACROCENTRIC else \\']
    (457, '            if wildcards.chr not in ACROCENTRIC else \\\\')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=open2c/inspectro, file=Snakefile
context_key: ['rule make_bintable', 'run', 'if centros is None or len(centros) == 0']
    (76, '        if centros is None or len(centros) == 0:')
    (77, '            mids = {chrom: 0 for chrom in CHROMOSOMES}')
    (78, '            arms = pd.DataFrame({')
    (79, '                "chrom": CHROMSIZES.index,')
    (80, '                "start": 0,')
    (81, '                "end": CHROMSIZES.values,')
    (82, '                "name": CHROMSIZES.index,')
    (83, '            })')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=open2c/inspectro, file=Snakefile
context_key: ['rule make_track_db', 'run', 'if not op.exists(output.track_db)']
    (272, '        if not op.exists(output.track_db):')
    (273, "            with h5py.File(output.track_db, \\'w\\') as f:")
    (274, '                for col in [')
    (275, "                    \\'chrom\\',")
    (276, "                    \\'start\\',")
    (277, "                    \\'end\\',")
    (278, "                    \\'GC\\',")
    (279, "                    \\'armlen\\',")
    (280, "                    \\'centel\\',")
    (281, "                    \\'centel_abs\\'")
    (282, '                ]:')
    (283, '                    f.create_dataset(col, data=bins[col].values, **h5opts)')
    (284, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=open2c/inspectro, file=Snakefile
context_key: ['rule make_track_db', 'run', "if row[\\'ID\\'] in f"]
    (289, "                if row[\\'ID\\'] in f:")
    (290, '                    continue')
    (291, '')
    (292, "                if row[\\'FileFormat\\'].lower() == \\'bigwig\\':")
    (293, '                    with get_reusable_executor(26) as pool:')
    (294, "                        acc = row[\\'ID\\']")
    (295, '                        x = fetch_binned(')
    (296, '                            paths[acc],')
    (297, '                            CHROMSIZES,')
    (298, '                            CHROMOSOMES,')
    (299, '                            binsize,')
    (300, '                            pool.map')
    (301, '                        )')
    (302, '                        f.create_dataset(acc, data=x, **h5opts)')
    (303, '')
    (304, "                elif row[\\'FileFormat\\'].lower() == \\'bedgraph\\':")
    (305, "                    acc = row[\\'ID\\']")
    (306, "                    df = bioframe.read_table(paths[acc], schema=\\'bedGraph\\')")
    (307, '                    ov = bioframe.overlap(')
    (308, '                        bins,')
    (309, '                        df,')
    (310, "                        how=\\'left\\',")
    (311, '                        return_overlap=True,')
    (312, '                        keep_order=True,')
    (313, "                        suffixes=(\\'\\', \\'_\\')")
    (314, '                    )')
    (315, "                    ov[\\'overlap\\'] = ov[\\'overlap_end\\'] - ov[\\'overlap_start\\']")
    (316, "                    ov[\\'score\\'] = ov[\\'value_\\'] * ov[\\'overlap\\']")
    (317, "                    out = ov.groupby([\\'chrom\\', \\'start\\', \\'end\\'], sort=False).agg(**{")
    (318, "                        \\'score\\': (\\'score\\', \\'sum\\')")
    (319, '                    }).reset_index()')
    (320, "                    out[\\'score\\'] /= (out[\\'end\\'] - out[\\'start\\'])")
    (321, "                    x = out[\\'score\\'].values")
    (322, '                    f.create_dataset(acc, data=x, **h5opts)')
    (323, '')
    (324, '                else:')
    (325, "                    raise ValueError(row[\\'FileFormat\\'])")
    (326, '')
    (327, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=open2c/inspectro, file=Snakefile
context_key: ['rule heatmap', 'run', "if norm == \\'sqrt\\'"]
    (348, "        if norm == \\'sqrt\\':")
    (349, "            eigvecs.loc[:, \\'E1\\':f\\'E{n_eigs_heatmap}\\'] *= sqrt_lam[np.newaxis, :]")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=open2c/inspectro, file=Snakefile
context_key: ['rule heatmap', 'run', 'if op.exists(track_db_path)', 'if track_name not in bins.columns']
    (356, '        if op.exists(track_db_path):')
    (357, '            meta = pd.read_table(config[\\\'bigwig_metadata_path\\\']).set_index("Name")')
    (358, "            with h5py.File(track_db_path, \\'r\\') as db:")
    (359, '                for group in config["scatter_groups"].values():')
    (360, '                    for track_name in group:')
    (361, '                        if track_name not in bins.columns:')
    (362, '                            uid = meta["ID"].get(track_name, track_name)')
    (363, '                            bins[track_name] = db[uid][:]')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=open2c/inspectro, file=Snakefile
context_key: ['rule heatmap', 'run', "if sort_by == \\'centel\\'"]
    (366, "        if sort_by == \\'centel\\':")
    (367, '            idx = np.lexsort([')
    (368, "                bins[\\'centel_abs\\'].values, bins[\\'cluster\\'].values")
    (369, '            ])')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=open2c/inspectro, file=Snakefile
context_key: ['rule scatters', 'run', 'if op.exists(track_db_path)', 'if track_name not in bins.columns']
    (411, '        if op.exists(track_db_path):')
    (412, '            meta = pd.read_table(config[\\\'bigwig_metadata_path\\\']).set_index("Name")')
    (413, "            with h5py.File(track_db_path, \\'r\\') as db:")
    (414, '                for group in config["scatter_groups"].values():')
    (415, '                    for track_name in group:')
    (416, '                        if track_name not in bins.columns:')
    (417, '                            uid = meta["ID"].get(track_name, track_name)')
    (418, '                            bins[track_name] = db[uid][:]')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/foveated-metamers, file=Snakefile
context_key: ['rule crop_image', 'run', 'if len(target_shape) == 1']
    (283, '                if len(target_shape) == 1:')
    (284, '                    target_shape = 2* target_shape')
    (285, '                target_shape = np.array(target_shape)')
    (286, '                crop_amt = curr_shape - target_shape')
    (287, "                # this is ugly, but I can\\'t come up with an easier way to make")
    (288, '                # sure that we skip a dimension if crop_amt is 0 for it')
    (289, '                cropped_im = im')
    (290, '                for i, c in enumerate(crop_amt):')
    (291, '                    if c == 0:')
    (292, '                        continue')
    (293, '                    else:')
    (294, '                        if i == 0:')
    (295, '                            cropped_im = cropped_im[c//2:-c//2]')
    (296, '                        elif i == 1:')
    (297, '                            cropped_im = cropped_im[:, c//2:-c//2]')
    (298, '                        else:')
    (299, '                            raise Exception("Can only crop up to two dimensions!")')
    (300, '                cropped_im = color.rgb2gray(cropped_im)')
    (301, '                imageio.imwrite(output[0], fov.utils.convert_im_to_int(cropped_im, np.uint16))')
    (302, "                # tiffs can\\'t be read in using the as_gray arg, so we")
    (303, '                # save it as a png, and then read it back in as_gray and')
    (304, '                # save it back out')
    (305, '                cropped_im = imageio.imread(output[0], as_gray=True)')
    (306, '                imageio.imwrite(output[0], cropped_im.astype(np.uint16))')
    (307, '')
    (308, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/foveated-metamers, file=Snakefile
context_key: ['rule preproc_image', 'run', "if \\'full\\' in wildcards.img_preproc"]
    (332, "                if \\'full\\' in wildcards.img_preproc:")
    (333, '                    print("Setting image to use full dynamic range")')
    (334, '                    # set the minimum value to 0')
    (335, '                    im = im - im.min()')
    (336, '                    # set the maximum value to 1')
    (337, '                    im = im / im.max()')
    (338, "                elif \\'range\\' in wildcards.img_preproc:")
    (339, "                    a, b = re.findall(\\'range-([.0-9]+),([.0-9]+)\\', wildcards.img_preproc)[0]")
    (340, '                    a, b = float(a), float(b)')
    (341, '                    print(f"Setting range to {a:02f}, {b:02f}")')
    (342, '                    if a > b:')
    (343, '                        raise Exception("For consistency, with range-a,b preprocessing, b must be"')
    (344, '                                        " greater than a, but got {a} > {b}!")')
    (345, '                    # set the minimum value to 0')
    (346, '                    im = im - im.min()')
    (347, '                    # set the maximum value to 1')
    (348, '                    im = im / im.max()')
    (349, '                    # and then rescale')
    (350, '                    im = im * (b - a) + a')
    (351, '                else:')
    (352, '                    print("Image will *not* use full dynamic range")')
    (353, '                    im = im / np.iinfo(dtype).max')
    (354, "                if \\'downsample\\' in wildcards.img_preproc:")
    (355, "                    downscale = float(re.findall(\\'downsample-([.0-9]+)_\\', wildcards.img_preproc)[0])")
    (356, '                    im = transform.pyramid_reduce(im, downscale)')
    (357, '                # always save it as 16 bit')
    (358, '                print("Saving as 16 bit")')
    (359, '                im = fov.utils.convert_im_to_int(im, np.uint16)')
    (360, '                imageio.imwrite(output[0], im)')
    (361, '')
    (362, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/foveated-metamers, file=Snakefile
context_key: ['rule preproc_textures', 'run', 'if im.ndim == 3']
    (449, '                    if im.ndim == 3:')
    (450, "                        # then it\\'s a color image, and we need to make it grayscale")
    (451, '                        im = color.rgb2gray(im)')
    (452, "                    if \\'degamma\\' in wildcards.preproc:")
    (453, '                        # 1/2.2 is the standard encoding gamma for jpegs, so we')
    (454, '                        # raise this to its reciprocal, 2.2, in order to reverse')
    (455, '                        # it')
    (456, '                        im = im ** 2.2')
    (457, '                    # save as a 16 bit png')
    (458, '                    im = fov.utils.convert_im_to_int(im, np.uint16)')
    (459, "                    imageio.imwrite(op.join(output[0], op.split(i)[-1].replace(\\'jpg\\', \\'png\\')), im)")
    (460, '')
    (461, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/foveated-metamers, file=Snakefile
context_key: ['rule combine_norm_stats', 'run', 'if isinstance(v, dict)']
    (513, '                    if isinstance(v, dict):')
    (514, '                        d = {}')
    (515, '                        for l in v:')
    (516, '                            s = []')
    (517, '                            for i in to_combine:')
    (518, '                                s.append(i[k][l])')
    (519, '                            d[l] = torch.cat(s, 0)')
    (520, '                        combined_stats[k] = d')
    (521, '                    else:')
    (522, '                        s = []')
    (523, '                        for i in to_combine:')
    (524, '                            s.append(i[k])')
    (525, '                        combined_stats[k] = torch.cat(s, 0)')
    (526, '                torch.save(combined_stats, output[0])')
    (527, '')
    (528, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/foveated-metamers, file=Snakefile
context_key: ['rule cache_windows', 'run', "if wildcards.window_type == \\'cosine\\'"]
    (635, "                if wildcards.window_type == \\'cosine\\':")
    (636, '                    t_width = float(wildcards.t_width)')
    (637, '                    std_dev = None')
    (638, '                    min_ecc = float(wildcards.min_ecc)')
    (639, "                elif wildcards.window_type == \\'gaussian\\':")
    (640, '                    std_dev = float(wildcards.t_width)')
    (641, '                    t_width = None')
    (642, '                    min_ecc = float(wildcards.min_ecc)')
    (643, '                pooling.PoolingWindows(float(wildcards.scaling), img_size, min_ecc,')
    (644, '                                       float(wildcards.max_ecc), cache_dir=op.dirname(output[0]),')
    (645, '                                       transition_region_width=t_width, std_dev=std_dev,')
    (646, '                                       window_type=wildcards.window_type, **kwargs)')
    (647, '')
    (648, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/foveated-metamers, file=Snakefile
context_key: ['rule create_metamers', 'run', "if wildcards.clamp_each_iter == \\'True\\'"]
    (821, "                if wildcards.clamp_each_iter == \\'True\\':")
    (822, '                    clamp_each_iter = True')
    (823, "                elif wildcards.clamp_each_iter == \\'False\\':")
    (824, '                    clamp_each_iter = False')
    (825, "                if wildcards.coarse_to_fine == \\'False\\':")
    (826, '                    coarse_to_fine = False')
    (827, '                else:')
    (828, '                    coarse_to_fine = wildcards.coarse_to_fine')
    (829, "                if wildcards.init_type not in [\\'white\\', \\'blue\\', \\'pink\\', \\'gray\\']:")
    (830, '                    init_type = fov.utils.get_ref_image_full_path(wildcards.init_type)')
    (831, '                else:')
    (832, '                    init_type = wildcards.init_type')
    (833, '                if resources.gpu == 1:')
    (834, '                    get_gid = True')
    (835, '                elif resources.gpu == 0:')
    (836, '                    get_gid = False')
    (837, '                else:')
    (838, '                    raise Exception("Multiple gpus are not supported!")')
    (839, '                if wildcards.save_all:')
    (840, '                    save_all = True')
    (841, '                else:')
    (842, '                    save_all = False')
    (843, '                with fov.utils.get_gpu_id(get_gid, on_cluster=ON_CLUSTER) as gpu_id:')
    (844, '                    fov.create_metamers.main(wildcards.model_name, float(wildcards.scaling),')
    (845, '                                             input.ref_image, int(wildcards.seed), float(wildcards.min_ecc),')
    (846, '                                             float(wildcards.max_ecc), float(wildcards.learning_rate),')
    (847, '                                             int(wildcards.max_iter), float(wildcards.loss_thresh),')
    (848, '                                             int(wildcards.loss_change_iter), output[0],')
    (849, '                                             init_type, gpu_id, params.cache_dir, input.norm_dict,')
    (850, '                                             wildcards.optimizer, float(wildcards.fract_removed),')
    (851, '                                             float(wildcards.loss_fract),')
    (852, '                                             float(wildcards.loss_change_thresh), coarse_to_fine,')
    (853, '                                             wildcards.clamp, clamp_each_iter, wildcards.loss,')
    (854, '                                             save_all=save_all, num_threads=resources.num_threads)')
    (855, '')
    (856, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/foveated-metamers, file=Snakefile
context_key: ['rule continue_metamers', 'run', "if wildcards.clamp_each_iter == \\'True\\'"]
    (898, "                if wildcards.clamp_each_iter == \\'True\\':")
    (899, '                    clamp_each_iter = True')
    (900, "                elif wildcards.clamp_each_iter == \\'False\\':")
    (901, '                    clamp_each_iter = False')
    (902, "                if wildcards.coarse_to_fine == \\'False\\':")
    (903, '                    coarse_to_fine = False')
    (904, '                else:')
    (905, '                    coarse_to_fine = wildcards.coarse_to_fine')
    (906, "                if wildcards.init_type not in [\\'white\\', \\'blue\\', \\'pink\\', \\'gray\\']:")
    (907, '                    init_type = fov.utils.get_ref_image_full_path(wildcards.init_type)')
    (908, '                else:')
    (909, '                    init_type = wildcards.init_type')
    (910, '                if resources.gpu == 1:')
    (911, '                    get_gid = True')
    (912, '                elif resources.gpu == 0:')
    (913, '                    get_gid = False')
    (914, '                else:')
    (915, '                    raise Exception("Multiple gpus are not supported!")')
    (916, '                with fov.utils.get_gpu_id(get_gid, on_cluster=ON_CLUSTER) as gpu_id:')
    (917, '                    # this is the same as the original call in the')
    (918, '                    # create_metamers rule, except we replace max_iter with')
    (919, '                    # extra_iter, set learning_rate to None, and add the')
    (920, '                    # input continue_path at the end')
    (921, '                    fov.create_metamers.main(wildcards.model_name, float(wildcards.scaling),')
    (922, '                                             input.ref_image, int(wildcards.seed), float(wildcards.min_ecc),')
    (923, '                                             float(wildcards.max_ecc), None,')
    (924, '                                             int(wildcards.extra_iter), float(wildcards.loss_thresh),')
    (925, '                                             int(wildcards.loss_change_iter), output[0],')
    (926, '                                             init_type, gpu_id, params.cache_dir, input.norm_dict,')
    (927, '                                             wildcards.optimizer, float(wildcards.fract_removed),')
    (928, '                                             float(wildcards.loss_fract),')
    (929, '                                             float(wildcards.loss_change_thresh), coarse_to_fine,')
    (930, '                                             wildcards.clamp, clamp_each_iter, wildcards.loss,')
    (931, '                                             input.continue_path, num_threads=resources.num_threads)')
    (932, '')
    (933, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/foveated-metamers, file=Snakefile
context_key: ['rule gamma_correct_metamer', 'run', "if output[0].endswith(\\'metamer_gamma-corrected.png\\')"]
    (951, "                if output[0].endswith(\\'metamer_gamma-corrected.png\\'):")
    (952, "                    if (\\'degamma\\' in wildcards.image_name or")
    (953, '                        any([i in wildcards.image_name for i in LINEAR_IMAGES])):')
    (954, '                        print(f"Saving gamma-corrected image {output[0]} as np.uint8")')
    (955, '                        im = np.load(input[0])')
    (956, '                        im = im ** (1/2.2)')
    (957, '                        im = fov.utils.convert_im_to_int(im, np.uint8)')
    (958, '                        imageio.imwrite(output[0], im)')
    (959, '                    else:')
    (960, '                        print("Image already gamma-corrected, copying to {output[0]}")')
    (961, "                        shutil.copy(output[0].replace(\\'_gamma-corrected\\', \\'\\'), output[0])")
    (962, '')
    (963, '')
    (964, '# for subject to learn task structure: comparing noise and reference images')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/foveated-metamers, file=Snakefile
context_key: ['rule collect_training_noise', 'run', 'if i < 4']
    (991, '                    if i < 4:')
    (992, "                        image_name = op.basename(input[-2:][i//2]).replace(\\'.pgm\\', \\'\\').replace(\\'.png\\', \\'\\')")
    (993, '                        # dummy scaling value')
    (994, '                        scaling = 1')
    (995, "                        model = \\'training\\'")
    (996, '                        seed = i % 2')
    (997, '                    else:')
    (998, "                        image_name = op.basename(p).replace(\\'.pgm\\', \\'\\').replace(\\'.png\\', \\'\\')")
    (999, '                        scaling = None')
    (1000, '                        model = None')
    (1001, '                        seed = None')
    (1002, "                    df.append(pd.DataFrame({\\'base_signal\\': p, \\'image_name\\': image_name, \\'model\\': model,")
    (1003, "                                            \\'scaling\\': scaling, \\'seed\\': seed}, index=[0]))")
    (1004, '                pd.concat(df).to_csv(output[1], index=False)')
    (1005, '')
    (1006, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/foveated-metamers, file=Snakefile
context_key: ['rule generate_experiment_idx', 'run', 'try', "if \\'training\\' in wildcards.model_name"]
    (1132, "                    if \\'training\\' in wildcards.model_name:")
    (1133, '                        raise Exception("training models only allowed for sub-training!")')
    (1134, '                    # in a session, we show 5 images. each run has 3 of those')
    (1135, '                    # images, and we rotate so that each image shows up in 3')
    (1136, '                    # runs.')
    (1137, "                    idx = list(range(len(config[\\'PSYCHOPHYSICS\\'][\\'RUNS\\'])))")
    (1138, '                    r = int(wildcards.run_num)')
    (1139, "                    # we\\'re 0-indexed, so r==4 is the 5th run")
    (1140, '                    if r > 4 or len(idx) != 5:')
    (1141, '                        raise Exception("This only works for 5 runs per session!")')
    (1142, '                    idx = idx[r:r+3] + idx[:max(0, r-2)]')
    (1143, '                    ref_image_to_include = ref_image_to_include[idx]')
    (1144, '                except ValueError:')
    (1145, '                    # then this is the training subject')
    (1146, '                    if int(wildcards.sess_num) > 0 or int(wildcards.run_num):')
    (1147, '                        raise Exception("only session 0 and run 0 allowed for sub-training!")')
    (1148, "                    if \\'training\\' not in wildcards.model_name:")
    (1149, '                        raise Exception("only training models allowed for sub-training!")')
    (1150, '                    else:')
    (1151, '                        # if it is the traning model, then the stimuli description')
    (1152, '                        # has already been restricted to only the values we want')
    (1153, '                        ref_image_idx = [0, 1]')
    (1154, '                    ref_image_to_include = stim_df.image_name.unique()[ref_image_idx]')
    (1155, '                stim_df = stim_df.query("image_name in @ref_image_to_include")')
    (1156, '                # we might have something after the - (like downsample-2), which')
    (1157, "                # we don\\'t want to include")
    (1158, "                comp = \\'met_v_\\' + wildcards.comp.split(\\'-\\')[0]")
    (1159, '                idx = fov.stimuli.generate_indices_split(stim_df, params.seed, comp, n_repeats=12)')
    (1160, '                np.save(output[0], idx)')
    (1161, '')
    (1162, '')
    (1163, '# for training, we want an array of correct responses so we can give feedback.')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/foveated-metamers, file=Snakefile
context_key: ['rule create_experiment_df', 'run', "if len(wildcards.comp.split(\\'-\\')) > 1"]
    (1246, "                if len(wildcards.comp.split(\\'-\\')) > 1:")
    (1247, "                    df[\\'trial_type\\'] = df.trial_type.apply(lambda x: x+\\'-\\'+wildcards.comp.split(\\'-\\')[1])")
    (1248, '                df = fov.analysis.add_response_info(df, trials, wildcards.subject,')
    (1249, '                                                    wildcards.sess_num, wildcards.run_num)')
    (1250, '                if wildcards.ecc_mask:')
    (1251, "                    mask_idx = int(wildcards.ecc_mask.split(\\'-\\')[1])")
    (1252, "                    ecc_mask_df = pd.read_csv(input[3]).set_index(\\'window_n\\')")
    (1253, '                    ecc_mask_df = ecc_mask_df.loc[mask_idx]')
    (1254, "                    df[\\'min_ecc\\'] = ecc_mask_df.min_eccentricity")
    (1255, '                    # the outer-most mask in ecc_mask_df will have')
    (1256, '                    # max_eccentricity larger than the actual image (which is')
    (1257, '                    # equivalent to saying that the mask hasn\\\'t "turnd off" by')
    (1258, "                    # the edge of the image). for ease, we don\\'t change max_ecc")
    (1259, '                    # in that case.')
    (1260, '                    if ecc_mask_df.max_eccentricity < df.max_ecc.unique()[0]:')
    (1261, "                        df[\\'max_ecc\\'] = ecc_mask_df.max_eccentricity")
    (1262, '                df.to_csv(output[0], index=False)')
    (1263, '')
    (1264, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/foveated-metamers, file=Snakefile
context_key: ['rule simulate_dataset', 'run', "if \\'V1\\' in wildcards.model_name"]
    (1353, "                if \\'V1\\' in wildcards.model_name:")
    (1354, "                    scaling = config[\\'V1\\'][\\'scaling\\']")
    (1355, '                    s0 = .08')
    (1356, "                elif \\'RGC\\' in wildcards.model_name:")
    (1357, "                    scaling = config[\\'RGC\\'][\\'scaling\\']")
    (1358, '                    s0 = .01')
    (1359, '                simul = fov.mcmc.simulate_dataset(s0, 5, num_subjects=4,')
    (1360, '                                                  trial_types=1, num_images=20,')
    (1361, '                                                  num_trials=36)')
    (1362, '                obs = simul.observed_responses.copy().astype(np.float32)')
    (1363, '                # block out simulated data like our actual data is blocked out')
    (1364, '                obs[:, :, :len(simul.subject_name):2, 10:15] = np.nan')
    (1365, '                obs[:, :, 1:len(simul.subject_name):2, 15:] = np.nan')
    (1366, "                simul[\\'observed_responses\\'] = obs")
    (1367, '                simul = simul.to_dataframe().reset_index()')
    (1368, "                simul = simul.rename(columns={\\'observed_responses\\': \\'hit_or_miss_numeric\\'})")
    (1369, "                simul[\\'model\\'] = f\\'simulated_{wildcards.model_name}\\'")
    (1370, '                simul.to_csv(output[0], index=False)')
    (1371, '')
    (1372, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/foveated-metamers, file=Snakefile
context_key: ['rule mcmc', 'run', "if \\'interactions\\' in mcmc_model", 'try']
    (1403, "                if \\'interactions\\' in mcmc_model:")
    (1404, '                    try:')
    (1405, "                        interact_sd = float(re.findall(\\'partially-pooled-interactions-([.0-9]+)\\', mcmc_model)[0])")
    (1406, '                    except IndexError:')
    (1407, '                        interact_sd = .1')
    (1408, "                    mcmc_model = \\'partially-pooled-interactions\\'")
    (1409, '                mcmc = fov.mcmc.run_inference(dataset, mcmc_model,')
    (1410, '                                              float(wildcards.step_size),')
    (1411, '                                              int(wildcards.num_draws),')
    (1412, '                                              int(wildcards.num_chains),')
    (1413, '                                              int(wildcards.num_warmup),')
    (1414, '                                              int(wildcards.seed),')
    (1415, '                                              float(wildcards.accept_prob),')
    (1416, '                                              int(wildcards.tree_depth),')
    (1417, '                                              interact_sd=interact_sd)')
    (1418, '                # want to have a different seed for constructing the inference')
    (1419, '                # data object than we did for inference itself')
    (1420, '                inf_data = fov.mcmc.assemble_inf_data(mcmc, dataset,')
    (1421, '                                                      mcmc_model,')
    (1422, '                                                      int(wildcards.seed)+1,')
    (1423, '                                                      interact_sd=interact_sd)')
    (1424, '                inf_data.to_netcdf(output[0])')
    (1425, '                # want to have a different seed for constructing the inference')
    (1426, '                # data object than we did for inference itself')
    (1427, '                inf_data_extended = fov.mcmc.assemble_inf_data(mcmc, dataset,')
    (1428, '                                                               mcmc_model,')
    (1429, '                                                               int(wildcards.seed)+10,')
    (1430, '                                                               extend_scaling=True,')
    (1431, '                                                               interact_sd=interact_sd)')
    (1432, '                inf_data_extended.to_netcdf(output[1])')
    (1433, '                ')
    (1434, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/foveated-metamers, file=Snakefile
context_key: ['rule mcmc_plots', 'run', "if wildcards.plot_type == \\'post-pred-check\\'"]
    (1462, "                if wildcards.plot_type == \\'post-pred-check\\':")
    (1463, '                    print("Creating posterior predictive check.")')
    (1464, "                    fig = fov.figures.posterior_predictive_check(inf_data, col=\\'subject_name\\', row=\\'image_name\\', height=1.5,")
    (1465, "                                                                 style=\\'trial_type\\', hue=\\'distribution\\')")
    (1466, "                elif wildcards.plot_type == \\'performance\\':")
    (1467, '                    print("Creating performance plot.")')
    (1468, '                    fig = fov.figures.posterior_predictive_check(inf_data,')
    (1469, "                                                                 hue=\\'subject_name\\',")
    (1470, "                                                                 col=\\'image_name\\',")
    (1471, '                                                                 height=2.5,')
    (1472, '                                                                 col_wrap=5,')
    (1473, "                                                                 style=\\'trial_type\\')")
    (1474, "                elif wildcards.plot_type == \\'diagnostics\\':")
    (1475, '                    print("Creating MCMC diagnostics plot.")')
    (1476, '                    fig = fov.figures.mcmc_diagnostics_plot(inf_data)')
    (1477, "                elif \\'param-corr\\' in wildcards.plot_type:")
    (1478, '                    print("Creating MCMC parameter correlations plot.")')
    (1479, '                    fig = fov.figures.mcmc_parameter_correlation(inf_data,')
    (1480, "                                                                 wildcards.plot_type.split(\\'_\\')[1])")
    (1481, '                elif wildcards.plot_type == "param-avg-method":')
    (1482, '                    print("Creating MCMC parameter average comparison plot.")')
    (1483, "                    df = fov.mcmc.inf_data_to_df(inf_data, \\'parameter grouplevel means\\',")
    (1484, '                                                 query_str="distribution==\\\'posterior\\\'", hdi=.95)')
    (1485, "                    df[\\'avg_method\\'] = \\'individual curves + avg\\'")
    (1486, "                    tmp = fov.mcmc.inf_data_to_df(inf_data, \\'parameter grouplevel means Heiko method\\',")
    (1487, '                                                  query_str="distribution==\\\'posterior\\\'", hdi=.95)')
    (1488, "                    tmp[\\'avg_method\\'] = \\'overall effects + combine\\'")
    (1489, '                    df = pd.concat([df, tmp]).reset_index(drop=True)')
    (1490, "                    fig = fov.figures.psychophysical_grouplevel_means(df, style=[\\'avg_method\\', \\'trial_type\\'])")
    (1491, "                elif wildcards.plot_type == \\'psychophysical-params\\':")
    (1492, '                    print("Creating psychophysical parameters plot.")')
    (1493, '                    fig = fov.figures.psychophysical_curve_parameters(inf_data,')
    (1494, '                                                                      rotate_xticklabels=True,')
    (1495, '                                                                      aspect=3,')
    (1496, '                                                                      height=5,')
    (1497, "                                                                      style=\\'trial_type\\')")
    (1498, "                elif wildcards.plot_type == \\'pairplot\\':")
    (1499, '                    print("Creating parameter pairplot.")')
    (1500, "                    fig = fov.figures.parameter_pairplot(inf_data, hue=\\'subject_name\\')")
    (1501, "                elif wildcards.plot_type == \\'params\\':")
    (1502, '                    print("Creating parameter distribution plot.")')
    (1503, '                    fig = fov.figures.partially_pooled_parameters(inf_data, height=4, aspect=2.5,')
    (1504, '                                                                  rotate_xticklabels=True)')
    (1505, "                elif wildcards.plot_type == \\'interaction-params\\':")
    (1506, '                    print("Creating interaction parameter distribution plot.")')
    (1507, '                    fig = fov.figures.interaction_parameters(inf_data)')
    (1508, "                elif wildcards.plot_type == \\'metaparams\\':")
    (1509, '                    print("Creating metaparameter distribution plot.")')
    (1510, '                    fig = fov.figures.partially_pooled_metaparameters(inf_data, height=5)')
    (1511, "                elif wildcards.plot_type == \\'grouplevel\\':")
    (1512, '                    print("Creating parameter grouplevel means distribution plot.")')
    (1513, '                    fig = fov.figures.psychophysical_grouplevel_means(inf_data)')
    (1514, '                else:')
    (1515, '                    raise Exception(f"Don\\\'t know how to handle plot_type {wildcards.plot_type}!")')
    (1516, "                fig.savefig(output[0], bbox_inches=\\'tight\\')")
    (1517, '')
    (1518, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/foveated-metamers, file=Snakefile
context_key: ['rule mcmc_compare_plot', 'run', "if wildcards.plot_type == \\'psychophysical-params\\'"]
    (1580, "                if wildcards.plot_type == \\'psychophysical-params\\':")
    (1581, "                    df_type = \\'psychophysical curve parameters\\'")
    (1582, "                elif wildcards.plot_type == \\'psychophysical-grouplevel\\':")
    (1583, "                    df_type = \\'parameter grouplevel means\\'")
    (1584, '                df = []')
    (1585, '                for i in input:')
    (1586, '                    inf = az.from_netcdf(i)')
    (1587, '                    df.append(fov.mcmc.inf_data_to_df(inf, df_type,')
    (1588, '                                                      query_str="distribution==\\\'posterior\\\'", hdi=.95))')
    (1589, '                df = pd.concat(df)')
    (1590, "                if wildcards.plot_type == \\'psychophysical-params\\':")
    (1591, "                    fig = fov.figures.psychophysical_curve_parameters(df, style=[\\'mcmc_model_type\\',")
    (1592, "                                                                                 \\'trial_type\\'],")
    (1593, "                                                                      row=\\'trial_type\\',")
    (1594, '                                                                      height=5, aspect=3,')
    (1595, '                                                                      rotate_xticklabels=True)')
    (1596, "                elif wildcards.plot_type == \\'psychophysical-grouplevel\\':")
    (1597, "                    fig = fov.figures.psychophysical_grouplevel_means(df, style=[\\'mcmc_model_type\\', \\'trial_type\\'])")
    (1598, "                fig.savefig(output[0], bbox_inches=\\'tight\\')")
    (1599, '')
    (1600, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/foveated-metamers, file=Snakefile
context_key: ['rule calculate_heterogeneity', 'run', "if \\'symmetric\\' in n"]
    (1628, "                    if \\'symmetric\\' in n:")
    (1629, "                        n = \\'_\\'.join(n[:2])")
    (1630, '                    else:')
    (1631, '                        n = n[0]')
    (1632, "                    tmp[\\'image\\'] = n")
    (1633, '                    df.append(tmp)')
    (1634, '                    print(n, out)')
    (1635, '                    # this pads out the arrays so we can plot them all on')
    (1636, '                    # imshow')
    (1637, '                    pads = []')
    (1638, '                    for i, h in enumerate(hg[::-1]):')
    (1639, '                        ideal_shape = 2**i * np.array(hg[-1].shape)')
    (1640, '                        pad = []')
    (1641, '                        for x in ideal_shape - h.shape:')
    (1642, '                            pad.append((np.ceil(x/2).astype(int),')
    (1643, '                                        np.floor(x/2).astype(int)))')
    (1644, '                        pads.append(pad)')
    (1645, '                    # need to reverse the order, since we construct it backwards')
    (1646, '                    pads = pads[::-1]')
    (1647, '                    hg = [np.pad(h, pads[i]) for i, h in enumerate(hg)]')
    (1648, '                    fig = pt.imshow(hg, zoom=.125,')
    (1649, "                                    title=[f\\'heterogeneity {n}\\")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/foveated-metamers, file=Snakefile
context_key: ['rule compute_amplitude_spectra', 'run', "if wildcards.model_name.startswith(\\'RGC\\') and wildcards.comp.startswith(\\'met\\')"]
    (1678, "                if wildcards.model_name.startswith(\\'RGC\\') and wildcards.comp.startswith(\\'met\\'):")
    (1679, "                    met_ref_imgs = [\\'llama\\', \\'highway_symmetric\\', \\'rocks\\', \\'boats\\', \\'gnarled\\']")
    (1680, '                else:')
    (1681, '                    met_ref_imgs = LINEAR_IMAGES')
    (1682, '                # make sure this is in the same order as LINEAR_IMAGES, whatever it is')
    (1683, '                met_ref_imgs = sorted(met_ref_imgs, key=lambda x: LINEAR_IMAGES.index(x))')
    (1684, "                seeds = set([int(re.findall(\\'seed-(\\\\d+)_\\', i)[0][-1]) for i in input if \\'seed\\' in i])")
    (1685, "                scalings = set([float(re.findall(\\'scaling-([\\\\d.]+)\\', i)[0])")
    (1686, "                                for i in input if \\'scaling\\' in i])")
    (1687, '                # grab spectra for reference images')
    (1688, "                ims = [i for i in input if \\'scaling\\' not in i and \\'seed\\' not in i]")
    (1689, "                metadata = OrderedDict(model=wildcards.model_name, trial_type=f\\'met_v_{wildcards.comp}\\')")
    (1690, '                ims = sorted(ims, key=lambda x: LINEAR_IMAGES.index([i for i in LINEAR_IMAGES if i in x][0]))')
    (1691, '                assert len(ims) == len(LINEAR_IMAGES), f"Have too many images! Expected {len(LINEAR_IMAGES)}, but got {ims}"')
    (1692, '                ref_image_spectra = fov.statistics.image_set_amplitude_spectra(ims, LINEAR_IMAGES, metadata)')
    (1693, "                ref_image_spectra = ref_image_spectra.rename({\\'sf_amplitude\\': \\'ref_image_sf_amplitude\\',")
    (1694, "                                                              \\'orientation_amplitude\\': \\'ref_image_orientation_amplitude\\'})")
    (1695, '                spectra = []')
    (1696, '                for scaling in scalings:')
    (1697, "                    tmp_ims = [i for i in input if len(re.findall(f\\'scaling-{scaling}{os.sep}\\', i)) == 1]")
    (1698, '                    tmp_spectra = []')
    (1699, '                    for seed in seeds:')
    (1700, '                        # grab spectra for all images with matching seed_n and scaling.')
    (1701, "                        metadata = OrderedDict(model=wildcards.model_name, trial_type=f\\'met_v_{wildcards.comp}\\',")
    (1702, '                                               scaling=scaling, seed_n=seed)')
    (1703, "                        ims = [i for i in tmp_ims if len(re.findall(f\\'seed-\\\\d*{seed}_\\', i)) == 1]")
    (1704, '                        ims = sorted(ims, key=lambda x: LINEAR_IMAGES.index([i for i in LINEAR_IMAGES if i in x][0]))')
    (1705, '                        assert len(ims) == len(met_ref_imgs), f"Have too many images! Expected {len(met_ref_imgs)}, but got {ims}"')
    (1706, '                        tmp_spectra.append(fov.statistics.image_set_amplitude_spectra(ims, met_ref_imgs, metadata))')
    (1707, "                    spectra.append(xarray.concat(tmp_spectra, \\'seed_n\\'))")
    (1708, "                spectra = xarray.concat(spectra, \\'scaling\\')")
    (1709, "                spectra = xarray.merge([spectra.rename({\\'sf_amplitude\\': \\'metamer_sf_amplitude\\',")
    (1710, "                                                        \\'orientation_amplitude\\': \\'metamer_orientation_amplitude\\'}),")
    (1711, '                                        ref_image_spectra])')
    (1712, '                spectra.to_netcdf(output[0])')
    (1713, '')
    (1714, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/foveated-metamers, file=Snakefile
context_key: ['rule plot_amplitude_spectra', 'run', "if wildcards.amplitude_type == \\'sf\\'"]
    (1735, "                if wildcards.amplitude_type == \\'sf\\':")
    (1736, '                    g = fov.figures.amplitude_spectra(ds)')
    (1737, "                elif wildcards.amplitude_type == \\'orientation\\':")
    (1738, '                    g = fov.figures.amplitude_orientation(ds)')
    (1739, "                elif wildcards.amplitude_type == \\'orientation-demeaned\\':")
    (1740, '                    g = fov.figures.amplitude_orientation(ds, demean=True)')
    (1741, "                g.savefig(output[0], bbox_inches=\\'tight\\')")
    (1742, '')
    (1743, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/foveated-metamers, file=Snakefile
context_key: ['rule window_example_figure', 'run', "if \\'downsample\\' in wildcards.comp"]
    (1958, "                if \\'downsample\\' in wildcards.comp:")
    (1959, "                    downsample_n = float(re.findall(\\'downsample-([0-9]+)\\', wildcards.comp)[0])")
    (1960, "                    style[\\'lines.linewidth\\'] = style[\\'lines.linewidth\\'] / downsample_n")
    (1961, '                plt.style.use(style)')
    (1962, '                image = fov.utils.convert_im_to_float(imageio.imread(input[0]))')
    (1963, '                window = torch.load(input[1])')
    (1964, '                # this is the same computation to get the window_max_amplitude')
    (1965, '                # from the creation of the PoolingWindows attribute (but')
    (1966, '                # asserting that the gaussian width is 1, which we guarantee')
    (1967, "                # elsewhere). this way we don\\'t need to load in the")
    (1968, '                # corresponding PoolingWindows object (which may be huge) to')
    (1969, '                # retrieve this value')
    (1970, "                if \\'gaussian\\' in wildcards.model_name:")
    (1971, '                    window_max_amplitude = (1 / (1 * pooling.pooling.GAUSSIAN_SUM)) ** 2')
    (1972, "                elif \\'cosine\\' in wildcards.model_name:")
    (1973, '                    window_max_amplitude = 1')
    (1974, '                fig = fov.figures.pooling_window_example(window, image, vrange=(0, 1),')
    (1975, "                                                         linewidths=float(wildcards.lw)*style[\\'lines.linewidth\\'],")
    (1976, '                                                         target_amp=window_max_amplitude / 2)')
    (1977, '                fig.savefig(output[0])')
    (1978, '')
    (1979, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/foveated-metamers, file=Snakefile
context_key: ['rule performance_figure', 'run', "if wildcards.plot_focus == \\'_focus-image\\'"]
    (2079, "                if wildcards.plot_focus == \\'_focus-image\\':")
    (2080, "                    hue = \\'model\\'")
    (2081, "                elif wildcards.plot_focus == \\'_focus-subject\\':")
    (2082, '                    col = None')
    (2083, '                    height = fig_width / 3')
    (2084, "                expt_df.model = expt_df.model.map(lambda x: {\\'RGC\\': \\'Retina\\'}.get(x.split(\\'_\\')[0],")
    (2085, "                                                                                  x.split(\\'_\\')[0]))")
    (2086, "                df[\\'model\\'] = df[\\'model\\'].map(fov.plotting.MODEL_PLOT)")
    (2087, "                df[\\'trial_type\\'] = df[\\'trial_type\\'].map(fov.plotting.TRIAL_TYPE_PLOT)")
    (2088, '                g = fov.figures.performance_plot(expt_df, hue=hue,')
    (2089, '                                                 height=height, col=col,')
    (2090, '                                                 curve_fit=True,')
    (2091, "                                                 style=\\'trial_type\\')")
    (2092, "                if wildcards.context == \\'paper\\':")
    (2093, "                    g.fig.suptitle(\\'\\')")
    (2094, "                g.fig.savefig(output[0], bbox_inches=\\'tight\\')")
    (2095, '')
    (2096, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/foveated-metamers, file=Snakefile
context_key: ['rule mcmc_figure', 'run', "if wildcards.plot_type == \\'params-grouplevel\\'"]
    (2121, "                if wildcards.plot_type == \\'params-grouplevel\\':")
    (2122, "                    inf_data = fov.mcmc.inf_data_to_df(inf_data, \\'parameter grouplevel means\\',")
    (2123, '                                                       query_str="distribution==\\\'posterior\\\'", hdi=.95)')
    (2124, "                    inf_data[\\'trial_type\\'] = inf_data[\\'trial_type\\'].map(fov.plotting.TRIAL_TYPE_PLOT)")
    (2125, "                    col = \\'level\\'")
    (2126, '                    fig = fov.figures.psychophysical_grouplevel_means(inf_data,')
    (2127, '                                                                      height=fig_width/4,')
    (2128, '                                                                      col=col)')
    (2129, '                    for ax in fig.axes:')
    (2130, "                        ax.set_title(ax.get_title().replace(\\'a0\\', \\'gain\\').replace(\\'s0\\', \\'critical scaling\\'))")
    (2131, '                    fig.suptitle(fig._suptitle.get_text(), y=1.05)')
    (2132, "                elif \\'performance\\' in wildcards.plot_type:")
    (2133, "                    col = \\'image_name\\'")
    (2134, "                    hue = \\'subject_name\\'")
    (2135, "                    style = \\'trial_type\\'")
    (2136, '                    height = fig_width / 6')
    (2137, '                    kwargs = {}')
    (2138, "                    if \\'focus\\' in wildcards.plot_type:")
    (2139, "                        inf_data = fov.mcmc.inf_data_to_df(inf_data, \\'predictive grouplevel means\\', hdi=.95)")
    (2140, "                        if \\'focus-image\\' in wildcards.plot_type:")
    (2141, "                            if \\'one-ax\\' in wildcards.plot_type:")
    (2142, '                                assert inf_data.model.nunique() == 1, "focus-image_one-ax currently only works with one model!"')
    (2143, "                                pal = {k: fov.plotting.get_palette(\\'model\\', inf_data.model.unique())[inf_data.model.unique()[0]]")
    (2144, "                                       for k in fov.plotting.get_palette(\\'image_name\\')}")
    (2145, "                                hue = \\'image_name\\'")
    (2146, '                                col = None')
    (2147, '                                height = fig_width / 2')
    (2148, "                                kwargs[\\'palette\\'] = pal")
    (2149, '                            else:')
    (2150, "                                hue = \\'model\\'")
    (2151, '                            inf_data = inf_data.query("level==\\\'image_name\\\'").rename(')
    (2152, "                                columns={\\'dependent_var\\': \\'image_name\\'})")
    (2153, "                            inf_data[\\'subject_name\\'] = \\'all subjects\\'")
    (2154, "                        elif \\'focus-outlier\\' in wildcards.plot_type:")
    (2155, '                            # want to highlight nyc and llama by changing their color ...')
    (2156, "                            pal = fov.plotting.get_palette(\\'image_name_focus-outlier\\', inf_data.model.unique())")
    (2157, '                            # and plotting them on top of other lines')
    (2158, "                            kwargs[\\'hue_order\\'] = sorted(fov.plotting.get_palette(\\'image_name\\').keys())")
    (2159, "                            zorder = [2 if k in [\\'nyc\\', \\'llama\\'] else 1 for k in kwargs[\\'hue_order\\']]")
    (2160, "                            hue = \\'image_name\\'")
    (2161, '                            col = None')
    (2162, '                            height = fig_width / 2')
    (2163, '                            inf_data = inf_data.query("level==\\\'image_name\\\'").rename(')
    (2164, "                                columns={\\'dependent_var\\': \\'image_name\\'})")
    (2165, "                            inf_data[\\'subject_name\\'] = \\'all subjects\\'")
    (2166, "                            kwargs[\\'palette\\'] = pal")
    (2167, "                            kwargs[\\'hue_kws\\'] = {\\'zorder\\': zorder}")
    (2168, "                        elif \\'focus-subject\\' in wildcards.plot_type:")
    (2169, '                            col = None')
    (2170, "                            if \\'one-ax\\' in wildcards.plot_type:")
    (2171, '                                height = fig_width / 2')
    (2172, '                                assert inf_data.model.nunique() == 1, "focus-image_one-ax currently only works with one model!"')
    (2173, "                                pal = {k: fov.plotting.get_palette(\\'model\\', inf_data.model.unique())[inf_data.model.unique()[0]]")
    (2174, "                                       for k in fov.plotting.get_palette(\\'subject_name\\')}")
    (2175, "                                kwargs[\\'palette\\'] = pal")
    (2176, '                            else:')
    (2177, '                                height = fig_width / 3')
    (2178, '                            inf_data = inf_data.query("level==\\\'subject_name\\\'").rename(')
    (2179, "                                columns={\\'dependent_var\\': \\'subject_name\\'})")
    (2180, "                            inf_data[\\'image_name\\'] = \\'all images\\'")
    (2181, "                    elif \\'all\\' in wildcards.plot_type:")
    (2182, "                        kwargs[\\'col_wrap\\'] = 5")
    (2183, "                        kwargs[\\'hdi\\'] = 0")
    (2184, "                        kwargs[\\'markersize\\'] = .5 * plt.rcParams[\\'lines.markersize\\']")
    (2185, "                        # get rid of those lines that we don\\'t have observations for")
    (2186, "                        inf_data = fov.mcmc._drop_no_observations(inf_data, fov.mcmc.inf_data_to_df(inf_data, \\'predictive\\', hdi=0))")
    (2187, '')
    (2188, "                    inf_data[\\'model\\'] = inf_data[\\'model\\'].map(fov.plotting.MODEL_PLOT)")
    (2189, "                    inf_data[\\'trial_type\\'] = inf_data[\\'trial_type\\'].map(fov.plotting.TRIAL_TYPE_PLOT)")
    (2190, '                    g = fov.figures.posterior_predictive_check(inf_data,')
    (2191, '                                                               col=col,')
    (2192, '                                                               hue=hue,')
    (2193, '                                                               style=style,')
    (2194, '                                                               height=height,')
    (2195, '                                                               increase_size=False,')
    (2196, '                                                               **kwargs)')
    (2197, '                    fig = g.fig')
    (2198, '                else:')
    (2199, '                    raise Exception(f"Don\\\'t know how to handle plot type {wildcards.plot_type}!")')
    (2200, "                if \\'focus-outlier\\' in wildcards.plot_type or \\'one-ax\\' in wildcards.plot_type:")
    (2201, "                    # don\\'t need the legend here, it\\'s not doing much")
    (2202, '                    warnings.warn("Removing legend, because it\\\'s not doing much.")')
    (2203, '                    fig.legends[0].remove()')
    (2204, "                    if \\'V1\\' in wildcards.model_name:")
    (2205, '                        warnings.warn("Removing ylabel so we don\\\'t have redundant labels when composing figure")')
    (2206, "                        fig.axes[0].set_ylabel(\\'\\')")
    (2207, "                    if wildcards.comp == \\'ref\\':")
    (2208, '                        warnings.warn("Removing xlabel so we don\\\'t have redundant labels when composing figure")')
    (2209, "                        fig.axes[0].set_xlabel(\\'\\')")
    (2210, "                elif wildcards.plot_type == \\'performance-all\\':")
    (2211, '                    fig.subplots_adjust(right=.95)')
    (2212, '                    # this only needs to be done on the first axis, because')
    (2213, '                    # their ticks are yoked together')
    (2214, '                    fig.axes[0].set_xticks(fig.axes[0].get_xticks()[::2])')
    (2215, "                if wildcards.context == \\'paper\\':")
    (2216, "                    fig.suptitle(\\'\\')")
    (2217, '                    for i, ax in enumerate(fig.axes):')
    (2218, '                        # also need to move the titles down a bit')
    (2219, "                        if wildcards.plot_type == \\'performance-all\\':")
    (2220, '                            # titles on this one need to be a bit higher than the rest')
    (2221, '                            ax.set_title(ax.get_title(), y=.91)')
    (2222, '                        else:')
    (2223, '                            ax.set_title(ax.get_title(), y=.85)')
    (2224, '                        # still running into this issue')
    (2225, '                        # https://github.com/mwaskom/seaborn/issues/2293 with')
    (2226, '                        # things about this size, so we manually set the')
    (2227, '                        # xticklabels invisible')
    (2228, "                        if col == \\'image_name\\' and i <= 14:")
    (2229, '                            [xticklab.set_visible(False) for xticklab in ax.get_xticklabels()]')
    (2230, "                fig.savefig(output[0], bbox_inches=\\'tight\\', transparent=True)")
    (2231, '')
    (2232, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/foveated-metamers, file=Snakefile
context_key: ['rule mcmc_compare_figure', 'run', "if \\'linear\\' == wildcards.axis_scale"]
    (2271, "                    if \\'linear\\' == wildcards.axis_scale:")
    (2272, "                        ax.set(yscale=\\'linear\\')")
    (2273, "                    elif \\'log\\' == wildcards.axis_scale:")
    (2274, "                        ax.set(yscale=\\'log\\')")
    (2275, '                    title = ax.get_title().replace(\\\'a0\\\', "Max $d\\\'$").replace(\\\'s0\\\', \\\'Critical Scaling\\\')')
    (2276, "                    title = title.split(\\'|\\')[0]")
    (2277, '                    # remove title')
    (2278, "                    ax.set_title(\\'\\')")
    (2279, "                    ax.set_xlabel(ax.get_xlabel().split(\\'_\\')[0].capitalize())")
    (2280, '                    if i % 2 == 0:')
    (2281, '                        ax.set_ylabel(title)')
    (2282, "                if wildcards.yaxis_dbl == \\'double\\':")
    (2283, '                    # need to draw so that the tick locations are set.')
    (2284, '                    fig.canvas.draw()')
    (2285, '                    # because the ylabels are longer for this one')
    (2286, "                    if wildcards.model_name == \\'RGC_norm_gaussian\\' and wildcards.comp == \\'ref\\':")
    (2287, '                        pos = -.20')
    (2288, '                    else:')
    (2289, '                        pos = -.15')
    (2290, '                    fov.plotting.add_asymptotic_performance_yaxis(fig.axes[2], position=pos)')
    (2291, "                fig.suptitle(\\'\\')")
    (2292, '                # change title of this to be clearer. this is an')
    (2293, '                # exceedingly hacky way of doing this.')
    (2294, '                leg = fig.legends[0]')
    (2295, "                leg.texts = [t.set_text(t.get_text().replace(\\'Trial type\\', \\'Comparison\\').replace(\\'Mcmc\\', \\'MCMC\\'))")
    (2296, '                             for t in leg.texts]')
    (2297, "                fig.savefig(output[0], bbox_inches=\\'tight\\', transparent=True)")
    (2298, '')
    (2299, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/foveated-metamers, file=Snakefile
context_key: ['rule mcmc_compare_psychophysical_params_figure', 'run', "if wildcards.context == \\'paper\\'", 'if j <= 14']
    (2350, "                    if wildcards.context == \\'paper\\':")
    (2351, '                        for j, ax in enumerate(g.fig.axes):')
    (2352, '                            # still running into this issue')
    (2353, '                            # https://github.com/mwaskom/seaborn/issues/2293 with')
    (2354, '                            # things about this size, so we manually set the')
    (2355, '                            # xticklabels invisible')
    (2356, '                            if j <= 14:')
    (2357, '                                [xticklab.set_visible(False) for xticklab in ax.get_xticklabels()]')
    (2358, '                            ax.set_title(ax.get_title(), y=.91)')
    (2359, "                    g.savefig(output[i], bbox_inches=\\'tight\\', transparent=True)")
    (2360, '')
    (2361, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/foveated-metamers, file=Snakefile
context_key: ['rule mcmc_performance_comparison_figure', 'run', "if wildcards.mcmc_plot_type == \\'performance\\'"]
    (2433, "                if wildcards.mcmc_plot_type == \\'performance\\':")
    (2434, "                    df_kind = \\'predictive grouplevel means\\'")
    (2435, '                    query_str = None')
    (2436, "                elif \\'params\\' in wildcards.mcmc_plot_type:")
    (2437, "                    df_kind = \\'parameter grouplevel means\\'")
    (2438, '                    query_str = "distribution==\\\'posterior\\\'"')
    (2439, '                df = []')
    (2440, '                # use this because we may drop some of the x-values, but we')
    (2441, '                # still want the same axes')
    (2442, '                x_order = set()')
    (2443, '                for f in input[:-1]:')
    (2444, '                    tmp = az.from_netcdf(f)')
    (2445, "                    if wildcards.focus.startswith(\\'sub\\'):")
    (2446, "                        subject_name = wildcards.focus.split(\\'_\\')[0]")
    (2447, "                        # each subject only sees 15 images, but we\\'ll have")
    (2448, '                        # parameters for all 20 for the partially pooled model')
    (2449, '                        # because we modeled the image-level and subject-level')
    (2450, '                        # effects separately and thus have predictions for the')
    (2451, '                        # unseen (subject, image) pairs')
    (2452, "                        if \\'RGC_norm_gaussian\\' in f and \\'comp-met\\' in f:")
    (2453, '                            # this comparison only had one session')
    (2454, '                            images = np.concatenate([fov.stimuli.get_images_for_session(subject_name, i,')
    (2455, "                                                                                        \\'downsample\\' in f)")
    (2456, '                                                     for i in range(1)])')
    (2457, '                        else:')
    (2458, '                            images = np.concatenate([fov.stimuli.get_images_for_session(subject_name, i,')
    (2459, "                                                                                        \\'downsample\\' in f)")
    (2460, '                                                     for i in range(3)])')
    (2461, '                        x_order = x_order.union(set(tmp.posterior.subject_name.values))')
    (2462, '                        tmp = tmp.sel(subject_name=subject_name, image_name=images)')
    (2463, '                        # need to have subject_name as a dimension still')
    (2464, "                        tmp.posterior = tmp.posterior.expand_dims(\\'subject_name\\')")
    (2465, "                        tmp.prior = tmp.prior.expand_dims(\\'subject_name\\')")
    (2466, "                        tmp.posterior_predictive = tmp.posterior_predictive.expand_dims(\\'subject_name\\')")
    (2467, "                        tmp.prior_predictive = tmp.prior_predictive.expand_dims(\\'subject_name\\')")
    (2468, "                        tmp.observed_data = tmp.observed_data.expand_dims(\\'subject_name\\')")
    (2469, '                    df.append(fov.mcmc.inf_data_to_df(tmp,')
    (2470, '                                                      df_kind, query_str,')
    (2471, '                                                      hdi=.95))')
    (2472, '                df = pd.concat(df)')
    (2473, '                # if x_order is empty, we want it to be None')
    (2474, '                if not x_order:')
    (2475, '                    x_order = None')
    (2476, '                # else, make it a list and sort it')
    (2477, '                else:')
    (2478, '                    x_order = sorted(list(x_order))')
    (2479, '                query_str = None')
    (2480, '                perf_query_str = None')
    (2481, "                if wildcards.focus.startswith(\\'sub\\'):")
    (2482, "                    focus = re.findall(\\'(sub-[0-9]+)\\', wildcards.focus)[0]")
    (2483, "                    if \\'comp-natural\\' in wildcards.focus:")
    (2484, '                        query_str = "trial_type in [\\\'metamer_vs_metamer\\\', \\\'metamer_vs_reference\\\', \\\'metamer_vs_metamer-natural\\\', \\\'metamer_vs_reference-natural\\\']"')
    (2485, "                    elif \\'comp-downsample\\' in wildcards.focus:")
    (2486, '                        query_str = "trial_type in [\\\'metamer_vs_metamer\\\', \\\'metamer_vs_reference\\\', \\\'metamer_vs_metamer-downsample\\\']"')
    (2487, '                    perf_query_str = f"level==\\\'subject_name\\\' & dependent_var==\\\'{focus}\\\'"')
    (2488, "                elif wildcards.focus == \\'comp-all\\':")
    (2489, '                    perf_query_str = "level==\\\'all\\\'"')
    (2490, "                elif wildcards.focus == \\'comp-base\\':")
    (2491, '                    query_str = \\\'trial_type in ["metamer_vs_metamer", "metamer_vs_reference"]\\\'')
    (2492, '                    perf_query_str = \\\'level == "all"\\\'')
    (2493, "                elif wildcards.focus == \\'comp-ref\\':")
    (2494, '                    query_str = \\\'trial_type in ["metamer_vs_reference"] \\\'')
    (2495, '                    perf_query_str = \\\'level == "all"\\\'')
    (2496, '                else:')
    (2497, '                    raise Exception(f"Don\\\'t know how to handle focus {wildcards.focus}!")')
    (2498, '                if query_str is not None:')
    (2499, '                    df = df.query(query_str)')
    (2500, "                df[\\'model\\'] = df[\\'model\\'].map(fov.plotting.MODEL_PLOT)")
    (2501, "                if wildcards.mcmc_plot_type == \\'performance\\':")
    (2502, "                    df[\\'trial_type\\'] = df[\\'trial_type\\'].map(fov.plotting.TRIAL_TYPE_PLOT)")
    (2503, '                    if perf_query_str is not None:')
    (2504, '                        df = df.query(perf_query_str)')
    (2505, "                    if not wildcards.focus.startswith(\\'sub\\'):")
    (2506, "                        df[\\'subject_name\\'] = \\'all subjects\\'")
    (2507, '                    else:')
    (2508, "                        df = df.rename(columns={\\'dependent_var\\': \\'subject_name\\'})")
    (2509, "                    df[\\'image_name\\'] = \\'all images\\'")
    (2510, '                    g = fov.figures.posterior_predictive_check(df, col=None,')
    (2511, "                                                               hue=\\'model\\',")
    (2512, "                                                               style=\\'trial_type\\',")
    (2513, '                                                               height=fig_width/2.5,')
    (2514, '                                                               aspect=2,')
    (2515, '                                                               logscale_xaxis=True,')
    (2516, '                                                               increase_size=False)')
    (2517, '                    g.fig.canvas.draw()')
    (2518, '                    fov.plotting.add_physiological_scaling_bars(g.ax, az.from_netcdf(input[-1]))')
    (2519, '                    fig = g.fig')
    (2520, "                    if \\'line\\' in wildcards.focus:")
    (2521, "                        sc = re.findall(\\'line-scaling-([.0-9]+)\\', wildcards.focus)[0]")
    (2522, "                        g.ax.axvline(float(sc), color=\\'k\\')")
    (2523, "                elif \\'params\\' in wildcards.mcmc_plot_type:")
    (2524, "                    mean_line = {\\'none\\': False, \\'lines\\': \\'lines-only\\', \\'ci\\': True}[wildcards.mcmc_plot_type.split(\\'-\\')[-1]]")
    (2525, '                    warnings.warn("Removing luminance model, metamer_vs_metamer for params plot (it\\\'s not informative)")')
    (2526, '                    df = df.query("trial_type != \\\'metamer_vs_metamer\\\' or model != \\\'Luminance model\\\'")')
    (2527, "                    df[\\'trial_type\\'] = df[\\'trial_type\\'].map(fov.plotting.TRIAL_TYPE_PLOT)")
    (2528, '                    fig = fov.figures.psychophysical_grouplevel_means(df,')
    (2529, '                                                                      height=fig_width/4,')
    (2530, '                                                                      mean_line=mean_line,')
    (2531, '                                                                      x_order=x_order,')
    (2532, '                                                                      increase_size=False,')
    (2533, "                                                                      row_order=[\\'s0\\', \\'a0\\'])")
    (2534, '                    for i, ax in enumerate(fig.axes):')
    (2535, "                        if \\'linear\\' in wildcards.mcmc_plot_type:")
    (2536, "                            if \\'a0\\' in ax.get_title():")
    (2537, '                                ylim = (0, 10)')
    (2538, "                            elif \\'s0\\' in ax.get_title():")
    (2539, '                                ylim = (0, .5)')
    (2540, "                            ax.set(yscale=\\'linear\\', ylim=ylim)")
    (2541, "                        elif \\'log\\' in wildcards.mcmc_plot_type:")
    (2542, "                            if \\'sub-00\\' in  wildcards.focus:")
    (2543, "                                if \\'a0\\' in ax.get_title():")
    (2544, '                                    ylim = (9e-1, 10)')
    (2545, "                                elif \\'s0\\' in ax.get_title():")
    (2546, '                                    ylim = (1e-2, 1e0)')
    (2547, "                            elif \\'comp-ref\\' in wildcards.focus:")
    (2548, "                                if \\'a0\\' in ax.get_title():")
    (2549, '                                    ylim = (8e-1, 10)')
    (2550, "                                elif \\'s0\\' in ax.get_title():")
    (2551, '                                    ylim = (1e-2, 2e-1)')
    (2552, '                            else:')
    (2553, "                                if \\'a0\\' in ax.get_title():")
    (2554, '                                    ylim = (2e-1, 10)')
    (2555, "                                elif \\'s0\\' in ax.get_title():")
    (2556, '                                    ylim = (1e-2, 1e0)')
    (2557, "                            ax.set(yscale=\\'log\\', ylim=ylim)")
    (2558, '                        title = ax.get_title().replace(\\\'a0\\\', "Max $d\\\'$").replace(\\\'s0\\\', \\\'Critical Scaling\\\')')
    (2559, "                        title = title.split(\\'|\\')[0]")
    (2560, '                        # remove title')
    (2561, "                        ax.set_title(\\'\\')")
    (2562, "                        ax.set_xlabel(ax.get_xlabel().split(\\'_\\')[0].capitalize())")
    (2563, '                        if i % 2 == 0:')
    (2564, '                            ax.set_ylabel(title)')
    (2565, "                    if wildcards.context == \\'paper\\':")
    (2566, '                        warnings.warn("Removing legend, because other panel will have it.")')
    (2567, '                        fig.legends[0].remove()')
    (2568, '                    fig.suptitle(fig._suptitle.get_text(), y=1.05)')
    (2569, "                if wildcards.context == \\'paper\\':")
    (2570, "                    fig.suptitle(\\'\\')")
    (2571, '                    # change title of this to be clearer. this is an')
    (2572, '                    # exceedingly hacky way of doing this.')
    (2573, '                    if len(fig.legends) > 0:')
    (2574, '                        leg = fig.legends[0]')
    (2575, "                        leg.texts = [t.set_text(t.get_text().replace(\\'Trial type\\', \\'Comparison\\'))")
    (2576, '                                     for t in leg.texts]')
    (2577, "                fig.savefig(output[0], bbox_inches=\\'tight\\', transparent=True)")
    (2578, '')
    (2579, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/foveated-metamers, file=Snakefile
context_key: ['rule performance_comparison_figure', 'run', "if wildcards.focus.startswith(\\'sub\\')"]
    (2644, "                if wildcards.focus.startswith(\\'sub\\'):")
    (2645, '                    query_str = f"subject_name==\\\'{wildcards.focus}\\\'"')
    (2646, "                elif wildcards.focus.startswith(\\'comp\\'):")
    (2647, "                    if wildcards.focus == \\'comp-base\\':")
    (2648, '                        query_str = f\\\'trial_type in ["metamer_vs_metamer", "metamer_vs_reference"]\\\'')
    (2649, "                    elif wildcards.focus == \\'comp-ref\\':")
    (2650, '                        query_str = f\\\'trial_type == "metamer_vs_reference"\\\'')
    (2651, "                    elif wildcards.focus == \\'comp-ref-natural\\':")
    (2652, '                        query_str = (f\\\'trial_type in ["metamer_vs_reference-natural", "metamer_vs_reference"] & \\\'')
    (2653, '                                     \\\'subject_name=="sub-00" & model == "V1_norm_s6_gaussian"\\\')')
    (2654, "                        col = \\'image_name\\'")
    (2655, '                        logscale_xaxis = False')
    (2656, "                    elif wildcards.focus == \\'comp-met-natural\\':")
    (2657, '                        query_str = (f\\\'trial_type in ["metamer_vs_metamer-natural", "metamer_vs_metamer"] & \\\'')
    (2658, '                                     \\\'subject_name=="sub-00" & model == "V1_norm_s6_gaussian"\\\')')
    (2659, "                        col = \\'image_name\\'")
    (2660, '                        curve_fit = True')
    (2661, "                    elif wildcards.focus == \\'comp-all\\':")
    (2662, "                        query_str = \\'\\'")
    (2663, '                    else:')
    (2664, '                        raise Exception(f"Don\\\'t know how to handle focus {wildcards.focus}")')
    (2665, '                else:')
    (2666, '                    # then assume this is an image')
    (2667, '                    query_str = f"image_name.str.startswith(\\\'{wildcards.focus}\\\')"')
    (2668, '                if query_str:')
    (2669, '                    df = pd.concat([pd.read_csv(f).query(query_str) for f in input[:-1]])')
    (2670, '                else:')
    (2671, '                    df = pd.concat([pd.read_csv(f) for f in input[:-1]])')
    (2672, "                df.model = df.model.map(lambda x: {\\'RGC\\': \\'Retina\\'}.get(x.split(\\'_\\')[0],")
    (2673, "                                                                        x.split(\\'_\\')[0]))")
    (2674, '                style, fig_width = fov.style.plotting_style(wildcards.context)')
    (2675, '                plt.style.use(style)')
    (2676, '                height = fig_width / 3 if col is None else fig_width / 6')
    (2677, "                df[\\'model\\'] = df[\\'model\\'].map(fov.plotting.MODEL_PLOT)")
    (2678, "                df[\\'trial_type\\'] = df[\\'trial_type\\'].map(fov.plotting.TRIAL_TYPE_PLOT)")
    (2679, '                g = fov.figures.performance_plot(df, col=col,')
    (2680, '                                                 curve_fit=curve_fit,')
    (2681, "                                                 hue=\\'model\\',")
    (2682, '                                                 height=height,')
    (2683, "                                                 style=\\'trial_type\\',")
    (2684, '                                                 aspect=2 if col is None else 1,')
    (2685, '                                                 logscale_xaxis=logscale_xaxis)')
    (2686, '                if col is None:')
    (2687, '                    # need to draw so that the following code can check text size')
    (2688, '                    g.fig.canvas.draw()')
    (2689, '                    fov.plotting.add_physiological_scaling_bars(g.ax, az.from_netcdf(input[-1]))')
    (2690, "                if wildcards.context == \\'paper\\':")
    (2691, "                    g.fig.suptitle(\\'\\')")
    (2692, "                g.fig.savefig(output[0], bbox_inches=\\'tight\\')")
    (2693, '')
    (2694, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/foveated-metamers, file=Snakefile
context_key: ['rule compute_distances', 'run', 'if input.norm_dict']
    (2841, '                if input.norm_dict:')
    (2842, '                    norm_dict = torch.load(input.norm_dict)')
    (2843, '                else:')
    (2844, '                    norm_dict = None')
    (2845, "                if wildcards.model_name.startswith(\\'Obs\\'):")
    (2846, "                    if wildcards.model_name == \\'Obs_sfp\\':")
    (2847, '                        # these values come from my spatial frequency')
    (2848, '                        # preferences experiment, using fMRI to measure')
    (2849, '                        # spatial frequency tuning in human V1')
    (2850, "                        sf_params = {\\'sf_weighting_sigma\\': 2.2,")
    (2851, "                                     \\'sf_weighting_slope\\': .12,")
    (2852, "                                     \\'sf_weighting_intercept\\': 3.5,")
    (2853, "                                     \\'sf_weighting_amplitude\\': 1,")
    (2854, '                                     # this value was unmeasured in our')
    (2855, "                                     # experiment, so I don\\'t know what to do")
    (2856, '                                     # with it')
    (2857, "                                     \\'sf_weighting_mean_lum\\': 1}")
    (2858, "                    elif wildcards.model_name == \\'Obs_null\\':")
    (2859, '                        # these values should be exactly equivalent to the V1')
    (2860, '                        # model, not reweighting the values at all')
    (2861, "                        sf_params = {\\'sf_weighting_sigma\\': 1e10,")
    (2862, "                                     \\'sf_weighting_slope\\': 0,")
    (2863, "                                     \\'sf_weighting_intercept\\': 1,")
    (2864, "                                     \\'sf_weighting_amplitude\\': 1,")
    (2865, "                                     \\'sf_weighting_mean_lum\\': 1}")
    (2866, '                    else:')
    (2867, '                        raise Exception("Don\\\'t know how to handle observer models without using sfp parameters!")')
    (2868, '                    model = fov.ObserverModel(float(wildcards.scaling), ref_image.shape[-2:],')
    (2869, '                                              6, 3, normalize_dict=norm_dict,')
    (2870, '                                              cache_dir=params.cache_dir,')
    (2871, '                                              min_eccentricity=float(wildcards.min_ecc),')
    (2872, '                                              max_eccentricity=float(wildcards.max_ecc),')
    (2873, '                                              **sf_params)')
    (2874, '                else:')
    (2875, '                    model = fov.create_metamers.setup_model(wildcards.model_name, float(wildcards.scaling),')
    (2876, '                                                            ref_image, float(wildcards.min_ecc),')
    (2877, '                                                            float(wildcards.max_ecc), params.cache_dir,')
    (2878, '                                                            norm_dict)[0]')
    (2879, "                synth_scaling = config[wildcards.synth_model_name.split(\\'_\\')[0]][\\'scaling\\']")
    (2880, "                met_imgs = [\\'llama\\', \\'highway_symmetric\\', \\'rocks\\', \\'boats\\', \\'gnarled\\']")
    (2881, "                if not wildcards.synth_model_name.startswith(\\'RGC\\') or any([wildcards.image_name.startswith(im) for im in met_imgs]):")
    (2882, "                    synth_scaling += config[wildcards.synth_model_name.split(\\'_\\')[0]][\\'met_v_met_scaling\\']")
    (2883, '                df = []')
    (2884, '                for sc in synth_scaling:')
    (2885, '                    df.append(fov.distances.model_distance(model, wildcards.synth_model_name,')
    (2886, '                                                           wildcards.image_name, sc))')
    (2887, '                df = pd.concat(df).reset_index(drop=True)')
    (2888, "                df[\\'distance_model\\'] = wildcards.model_name")
    (2889, "                df[\\'distance_scaling\\'] = float(wildcards.scaling)")
    (2890, '                df.to_csv(output[0], index=False)')
    (2891, '')
    (2892, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/foveated-metamers, file=Snakefile
context_key: ['rule calculate_radial_squared_error', 'run', "if wildcards.model_name == \\'RGC_norm_gaussian\\' and wildcards.comp == \\'met\\'"]
    (2981, "                if wildcards.model_name == \\'RGC_norm_gaussian\\' and wildcards.comp == \\'met\\':")
    (2982, '                    # for this model and comparison, we only had 5 images')
    (2983, '                    names = stim_df.image_name.unique()[:5].tolist()')
    (2984, '                    stim_df = stim_df.query("image_name in @names")')
    (2985, "                # create a dummy idx, which is not randomized (that\\'s what setting seed=None does)")
    (2986, '                idx = fov.stimuli.generate_indices_split(stim_df, None,')
    (2987, '                                                         f\\\'met_v_{wildcards.comp.split("-")[0]}\\\',')
    (2988, '                                                         12)')
    (2989, '                # this contains all the relevant metadata we want for this comparison')
    (2990, '                dist_df = fov.analysis.create_experiment_df_split(stim_df, idx)')
    (2991, '                # remove duplicates, so we only have a single row for each')
    (2992, "                # (target image, scaling, seed). this means we\\'re throwing out")
    (2993, '                # 3/4 of our rows')
    (2994, "                if wildcards.comp.startswith(\\'ref\\'):")
    (2995, "                    dist_df = dist_df.drop_duplicates([\\'image_name\\', \\'scaling\\', \\'unique_seed\\'])")
    (2996, "                elif wildcards.comp.startswith(\\'met\\'):")
    (2997, '                    # slightly more complicated to do this for the metamer comparisons')
    (2998, '                    tmp = dist_df.apply(lambda x: sorted(set([x.image_left_1, x.image_left_2, x.image_right_1, x.image_right_2])), 1)')
    (2999, "                    dist_df[\\'seeds\\'] = tmp.apply(lambda x: f\\'{int(x[0])},{int(x[1])}\\')")
    (3000, "                    dist_df = dist_df.drop_duplicates([\\'image_name\\', \\'scaling\\', \\'seeds\\'])")
    (3001, "                    dist_df = dist_df.drop(columns=[\\'seeds\\'])")
    (3002, "                # initialize the images we\\'ll use to compute radial means,")
    (3003, '                # modified from fov.statistics.amplitude_spectra')
    (3004, '                rbin = pt.synthetic_images.polar_radius(stim.shape[-2:]).astype(np.int)')
    (3005, '                # only look at the circle that can fit in the image (i.e.,')
    (3006, '                # throw away the corners, because there are fewer pixels out')
    (3007, "                # there and so the averages won\\'t be comparable)")
    (3008, '                disk = pt.synthetic_images.polar_radius(stim.shape[-2:])')
    (3009, '                thresh = min(stim.shape[-2:])//2')
    (3010, '                disk = disk < thresh')
    (3011, '                rbin[~disk] = rbin.max()+1')
    (3012, '                # now iterate through all trials and compute the mse on each of')
    (3013, '                # them')
    (3014, '                df = []')
    (3015, '                for _, row in dist_df.iterrows():')
    (3016, '                    # unpack this to get the index of the stimulus on left and right, for first')
    (3017, '                    # and second image')
    (3018, '                    i = row.trial_number')
    (3019, '                    [[l1, l2], [r1, r2]] = idx[:, i]')
    (3020, '                    # need to cast these as floats else the MSE will be *way*')
    (3021, "                    # off (like 100 instead of 8600). don\\'t do the whole stim")
    (3022, '                    # array at once because that would *drastically* increase')
    (3023, '                    # memory use.')
    (3024, '                    img1 = stim[l1].astype(float)')
    (3025, '                    if l1 == l2:')
    (3026, '                        img2 = stim[r2].astype(float)')
    (3027, '                    else:')
    (3028, '                        img2 = stim[l2].astype(float)')
    (3029, '                    diff = np.square(img1-img2)')
    (3030, '                    diff = scipy.ndimage.mean(diff, labels=rbin, index=np.arange(thresh-1))')
    (3031, '                    row = row.to_dict()')
    (3032, "                    row.update({\\'mse\\': diff, \\'distance_pixels\\': np.arange(len(diff))})")
    (3033, '                    tmp = pd.DataFrame(row)')
    (3034, "                    tmp[\\'distance_degrees\\'] = tmp.distance_pixels * ((2*tmp.max_ecc) / max(img1.shape[-2:]))")
    (3035, '                    df.append(tmp)')
    (3036, '                df = pd.concat(df)')
    (3037, '                df.to_csv(output[0], index=False)')
    (3038, '')
    (3039, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/foveated-metamers, file=Snakefile
context_key: ['rule radial_squared_error_figure', 'run', "if wildcards.ecc == \\'None\\'"]
    (3062, "                if wildcards.ecc == \\'None\\':")
    (3063, '                    ecc_range = None')
    (3064, '                else:')
    (3065, "                    ecc_range = [float(e) for e in wildcards.ecc.split(\\',\\')]")
    (3066, '                g = fov.figures.radial_mse(df, height=fig_width/6, ecc_range=ecc_range)')
    (3067, '                for i, ax in enumerate(g.axes.flatten()):')
    (3068, '                    # still running into this issue')
    (3069, '                    # https://github.com/mwaskom/seaborn/issues/2293 with')
    (3070, '                    # things about this size, so we manually set the')
    (3071, '                    # xticklabels invisible')
    (3072, '                    if i <= 14:')
    (3073, '                        [xticklab.set_visible(False) for xticklab in ax.get_xticklabels()]')
    (3074, "                g.savefig(output[0], bbox_inches=\\'tight\\', transparent=True)")
    (3075, '')
    (3076, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/foveated-metamers, file=Snakefile
context_key: ['rule calculate_mse', 'run', "if wildcards.model_name == \\'RGC_norm_gaussian\\' and wildcards.comp == \\'met\\'"]
    (3096, "                if wildcards.model_name == \\'RGC_norm_gaussian\\' and wildcards.comp == \\'met\\':")
    (3097, '                    # for this model and comparison, we only had 5 images')
    (3098, '                    names = stim_df.image_name.unique()[:5].tolist()')
    (3099, '                    stim_df = stim_df.query("image_name in @names")')
    (3100, "                # create a dummy idx, which is not randomized (that\\'s what setting seed=None does)")
    (3101, '                idx = fov.stimuli.generate_indices_split(stim_df, None,')
    (3102, '                                                         f\\\'met_v_{wildcards.comp.split("-")[0]}\\\',')
    (3103, '                                                         12)')
    (3104, '                # this contains all the relevant metadata we want for this comparison')
    (3105, '                dist_df = fov.analysis.create_experiment_df_split(stim_df, idx)')
    (3106, '                expt_mse = np.empty(len(dist_df))')
    (3107, '                met_mse = np.empty(len(dist_df))')
    (3108, '                # now iterate through all trials and compute the mse on each of')
    (3109, '                # them')
    (3110, '                for i in range(len(dist_df)):')
    (3111, '                    # unpack this to get the index of the stimulus on left and right, for first')
    (3112, '                    # and second image')
    (3113, '                    [[l1, l2], [r1, r2]] = idx[:, i]')
    (3114, '                    # need to cast these as floats else the MSE will be *way*')
    (3115, "                    # off (like 100 instead of 8600). don\\'t do the whole stim")
    (3116, '                    # array at once because that would *drastically* increase')
    (3117, '                    # memory use. and calculate_experiment_mse function handles')
    (3118, '                    # this internally')
    (3119, '                    img1 = stim[l1].astype(float)')
    (3120, '                    if l1 == l2:')
    (3121, '                        img2 = stim[r2].astype(float)')
    (3122, '                    else:')
    (3123, '                        img2 = stim[l2].astype(float)')
    (3124, '                    met_mse[i] = np.square(img1-img2).mean()')
    (3125, '                    expt_mse[i] = fov.distances.calculate_experiment_mse(stim, idx[:, i])')
    (3126, "                dist_df[\\'experiment_mse\\'] = expt_mse")
    (3127, "                dist_df[\\'full_image_mse\\'] = met_mse")
    (3128, "                dist_df[\\'trial_structure\\'] = dist_df.apply(fov.distances._get_trial_structure, 1)")
    (3129, "                dist_df[\\'changed_side\\'] = dist_df.trial_structure.apply(lambda x: x[-1])")
    (3130, '                dist_df.to_csv(output[0], index=False)')
    (3131, '')
    (3132, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/foveated-metamers, file=Snakefile
context_key: ['rule experiment_mse_example_img', 'run', "if wildcards.comp.startswith(\\'ref\\')"]
    (3236, "                if wildcards.comp.startswith(\\'ref\\'):")
    (3237, '                    orig = ref_image.copy()')
    (3238, "                elif wildcards.comp.startswith(\\'met\\'):")
    (3239, '                    orig = metamer.copy()')
    (3240, '                orig = fov.distances._add_bar(orig, bar)')
    (3241, '                imageio.imwrite(output[0], orig)')
    (3242, '                half_width = ref_image.shape[-1] // 2')
    (3243, "                if wildcards.direction == \\'L\\':")
    (3244, '                    ref_image[..., :half_width] = metamer[..., :half_width]')
    (3245, "                elif wildcards.direction == \\'R\\':")
    (3246, '                    ref_image[..., half_width:] = metamer[..., half_width:]')
    (3247, '                ref_image = fov.distances._add_bar(ref_image, bar)')
    (3248, '                imageio.imwrite(output[1], ref_image)')
    (3249, '')
    (3250, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/foveated-metamers, file=Snakefile
context_key: ['rule mix_images_match_mse', 'run', "if wildcards.direction != \\'None\\'"]
    (3278, "                if wildcards.direction != \\'None\\':")
    (3279, '                    mse = mse.query(f"changed_side==\\\'{wildcards.direction}\\\'")')
    (3280, '                    target_err = mse.experiment_mse.min()')
    (3281, '                    direction = wildcards.direction')
    (3282, '                else:')
    (3283, '                    direction = None')
    (3284, '                    target_err = mse.full_image_mse.min()')
    (3285, '                if mse.empty:')
    (3286, '                    raise Exception(f"No comparisons match image {wildcards.ref_image}, scaling {wildcards.scaling},"')
    (3287, '                                    f" and direction {wildcards.direction}")')
    (3288, '                # if the init_type corresponds to another image, we need its')
    (3289, '                # full path. else, just the string identifying the type of')
    (3290, '                # noise suffices')
    (3291, '                if input.init_image:')
    (3292, '                    other_img = input.init_image')
    (3293, '                else:')
    (3294, '                    other_img = wildcards.init_type')
    (3295, '                fov.create_other_synth.main(input.ref_image, other_img,')
    (3296, '                                            target_err, float(wildcards.lr),')
    (3297, '                                            int(wildcards.max_iter),')
    (3298, '                                            direction,')
    (3299, '                                            int(wildcards.seed),')
    (3300, '                                            output[0])')
    (3301, '')
    (3302, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/foveated-metamers, file=Snakefile
context_key: ['rule gamma_correct_match_mse', 'run', 'if im.max() < 1 or im.max() > 256']
    (3321, '                    if im.max() < 1 or im.max() > 256:')
    (3322, '                        raise Exception(f"Expected image to lie within (0, 255), but found max {im.max()}!")')
    (3323, '                    im = (im / 255) ** (1/2.2)')
    (3324, '                    im = fov.utils.convert_im_to_int(im, np.uint8)')
    (3325, '                    imageio.imwrite(output[0], im)')
    (3326, '')
    (3327, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/foveated-metamers, file=Snakefile
context_key: ['rule create_mad_images', 'run', 'if resources.gpu == 1']
    (3371, '                if resources.gpu == 1:')
    (3372, '                    get_gid = True')
    (3373, '                elif resources.gpu == 0:')
    (3374, '                    get_gid = False')
    (3375, '                else:')
    (3376, '                    raise Exception("Multiple gpus are not supported!")')
    (3377, '                # tradeoff_lambda can be a float or None')
    (3378, '                try:')
    (3379, '                    tradeoff_lambda = float(wildcards.tradeoff_lambda)')
    (3380, '                except ValueError:')
    (3381, '                    tradeoff_lambda = None')
    (3382, '                with fov.utils.get_gpu_id(get_gid, on_cluster=ON_CLUSTER) as gpu_id:')
    (3383, "                    fov.create_mad_images.main(\\'mse\\',")
    (3384, '                                               wildcards.model_name,')
    (3385, '                                               input.ref_image,')
    (3386, '                                               wildcards.synth_target,')
    (3387, '                                               int(wildcards.seed),')
    (3388, '                                               float(wildcards.learning_rate),')
    (3389, '                                               int(wildcards.max_iter),')
    (3390, '                                               float(wildcards.stop_criterion),')
    (3391, '                                               int(wildcards.stop_iters),')
    (3392, '                                               output[0],')
    (3393, '                                               input.init_image,')
    (3394, '                                               gpu_id,')
    (3395, '                                               wildcards.optimizer,')
    (3396, '                                               tradeoff_lambda,')
    (3397, '                                               float(wildcards.range_lambda),')
    (3398, '                                               num_threads=resources.num_threads)')
    (3399, '')
    (3400, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/foveated-metamers, file=Snakefile
context_key: ['rule gamma_correct_mad_images', 'run', 'if im.max() < 1 or im.max() > 256']
    (3419, '                    if im.max() < 1 or im.max() > 256:')
    (3420, '                        raise Exception(f"Expected image to lie within (0, 255), but found max {im.max()}!")')
    (3421, '                    im = (im / 255) ** (1/2.2)')
    (3422, '                    im = fov.utils.convert_im_to_int(im, np.uint8)')
    (3423, '                    imageio.imwrite(output[0], im)')
    (3424, '')
    (3425, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/foveated-metamers, file=Snakefile
context_key: ['rule scaling_gif', 'run', "if wildcards.gif_direction == \\'reverse\\'"]
    (3478, "                if wildcards.gif_direction == \\'reverse\\':")
    (3479, "                    sort_files = list(reversed(sorted(files, key=lambda x: float(re.findall(\\'scaling-([0-9.]+)\\', x)[0]))))")
    (3480, "                elif wildcards.gif_direction == \\'forward\\':")
    (3481, "                    sort_files = sorted(files, key=lambda x: float(re.findall(\\'scaling-([0-9.]+)\\', x)[0]))")
    (3482, "                # assert that there\\'s only one per scaling")
    (3483, "                scaling_vals = [float(re.findall(\\'scaling-([0-9.]+)\\', f)[0]) for f in sort_files]")
    (3484, '                if len(scaling_vals) != len(set(scaling_vals)):')
    (3485, '                    raise Exception("Each scaling value should show up exactly once!")')
    (3486, '                tmpdir = tempfile.mkdtemp()')
    (3487, '                for i, f in enumerate(sort_files):')
    (3488, "                    shutil.copy(f, op.join(tmpdir, f\\'frame-{i:02d}.png\\'))")
    (3489, "                print(\\'\\")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/foveated-metamers, file=Snakefile
context_key: ['rule freeman_compare_windows_figure', 'run', 'if bb.y0 != 0']
    (3569, '                    if bb.y0 != 0:')
    (3570, '                        bb.y0 = bb.y0 - bb.y0/4')
    (3571, '                        ax.set_position(bb)')
    (3572, '                    fov.figures.add_fixation_cross(ax, cross_size=25)')
    (3573, "                fig.savefig(output[0], bbox_inches=\\'tight\\', transparent=True)")
    (3574, '')
    (3575, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/foveated-metamers, file=Snakefile
context_key: ['rule window_contours_figure', 'run', "if wildcards.bg == \\'none\\'"]
    (3799, "                if wildcards.bg == \\'none\\':")
    (3800, '                    # set both axes and figure facecolor to transparent')
    (3801, "                    style[\\'axes.facecolor\\'] = (0, 0, 0, 0)")
    (3802, "                    style[\\'figure.facecolor\\'] = (0, 0, 0, 0)")
    (3803, "                elif wildcards.bg == \\'white\\':")
    (3804, '                    # want to see the border of the axis')
    (3805, "                    style[\\'axes.edgecolor\\'] = (0, 0, 0, 1)")
    (3806, "                    style[\\'axes.linewidth\\'] = .5*float(wildcards.lw)*style[\\'lines.linewidth\\']")
    (3807, '                else:')
    (3808, '                    raise Exception("Can only handle background none or white!")')
    (3809, '                plt.style.use(style)')
    (3810, '                ax = None')
    (3811, "                if \\'random\\' in wildcards.fill:")
    (3812, "                    seed = int(wildcards.fill.split(\\'-\\')[-1])")
    (3813, '                    np.random.seed(seed)')
    (3814, '                    ax = pw.plot_window_values(subset=False)')
    (3815, "                elif wildcards.fill != \\'none\\':")
    (3816, '                    im = po.load_images(input[0])')
    (3817, '                    ax = pw.plot_window_values(im, subset=False)')
    (3818, '                # since this is being shrunk, we need to make the lines thicker')
    (3819, '                ax = pw.plot_windows(ax=ax, subset=False,')
    (3820, "                                     linewidths=float(wildcards.lw)*style[\\'lines.linewidth\\'])")
    (3821, "                if wildcards.bg == \\'none\\':")
    (3822, '                    # this is the background image underneath the contour lines')
    (3823, '                    # -- we want it to be invisible so we can overlay these')
    (3824, '                    # contours on another image.')
    (3825, '                    ax.images[0].set_visible(False)')
    (3826, '                else:')
    (3827, '                    # want to see the border of the axis')
    (3828, '                    ax.set_frame_on(True)')
    (3829, "                    ax.spines[\\'top\\'].set_visible(True)")
    (3830, "                    ax.spines[\\'right\\'].set_visible(True)")
    (3831, "                ax.figure.savefig(output[0], bbox_inches=\\'tight\\')")
    (3832, '')
    (3833, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/foveated-metamers, file=Snakefile
context_key: ['rule compose_figures', 'run', "if \\'model_schematic\\' in wildcards.fig_name"]
    (3909, "                if \\'model_schematic\\' in wildcards.fig_name:")
    (3910, "                    width = \\'full\\' if \\'full\\' in wildcards.fig_name else \\'half\\'")
    (3911, '                    fig = fov.compose_figures.model_schematic(input[0],')
    (3912, '                                                              input[1],')
    (3913, '                                                              input[2:], width,')
    (3914, '                                                              wildcards.context)')
    (3915, "                elif \\'metamer_comparison\\' in wildcards.fig_name:")
    (3916, "                    scaling = re.findall(\\'scaling-([0-9,.]+)\\', wildcards.fig_name)[0]")
    (3917, "                    scaling = [float(sc) for sc in scaling.split(\\',\\')]")
    (3918, "                    if \\'performance\\' in wildcards.fig_name:")
    (3919, "                        # doesn\\'t matter what we put in here, we\\'re only using")
    (3920, '                        # the outlier colors')
    (3921, "                        pal = fov.plotting.get_palette(\\'image_name_focus-outlier\\', [\\'V1\\'])")
    (3922, '                        img_names = re.findall("metamer_comparison_([a-z,]+)_scaling", wildcards.fig_name)[0]')
    (3923, '                        fig = fov.compose_figures.performance_metamer_comparison_small(input[1], input[0], scaling,')
    (3924, "                                                                                       [pal[name] for name in img_names.split(\\',\\')])")
    (3925, "                    elif \\'natural-seed\\' in wildcards.fig_name:")
    (3926, "                        if \\'V1\\' in wildcards.fig_name:")
    (3927, "                            labels = [\\'Target image\\',")
    (3928, "                                      \\'Energy model metamer init with natural image 1\\',")
    (3929, "                                      \\'Energy model metamer init with natural image 2\\',")
    (3930, "                                      \\'Energy model metamer init with natural image 3\\',")
    (3931, "                                      \\'Energy model metamer init with white noise 1\\',")
    (3932, "                                      \\'Energy model metamer init with white noise 2\\']")
    (3933, "                        elif \\'RGC\\' in wildcards.fig_name:")
    (3934, "                            labels = [\\'Target image\\',")
    (3935, "                                      \\'Luminance metamer init with natural image 1\\',")
    (3936, "                                      \\'Luminance metamer init with natural image 2\\',")
    (3937, "                                      \\'Luminance metamer init with natural image 3\\',")
    (3938, "                                      \\'Luminance metamer init with white noise 1\\',")
    (3939, "                                      \\'Luminance metamer init with white noise 2\\']")
    (3940, '                        fig = fov.compose_figures.metamer_comparison(*input, labels,')
    (3941, "                                                                     \\'nocutout\\' not in wildcards.fig_name,")
    (3942, '                                                                     True, wildcards.context)')
    (3943, '                    else:')
    (3944, '                        fig = fov.compose_figures.metamer_comparison(*input, scaling,')
    (3945, "                                                                     \\'nocutout\\' not in wildcards.fig_name,")
    (3946, '                                                                     False, wildcards.context)')
    (3947, '                elif "all_comps_summary" in wildcards.fig_name:')
    (3948, '                    fig = fov.compose_figures.combine_one_ax_figs(input, wildcards.context)')
    (3949, '                elif "performance_comparison" in wildcards.fig_name:')
    (3950, '                    fig = fov.compose_figures.performance_comparison(*input, wildcards.context)')
    (3951, '                elif "radial_se" in wildcards.fig_name:')
    (3952, '                    fig = fov.compose_figures.radial_squared_error(*input, wildcards.context)')
    (3953, '                elif "performance-all" in wildcards.fig_name:')
    (3954, '                    fig = fov.compose_figures.performance_all(*input, context=wildcards.context)')
    (3955, '                fig.save(output[0])')
    (3956, '')
    (3957, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/foveated-metamers, file=Snakefile
context_key: ['rule cutout_figures', 'run', "if \\'downsample\\' in wildcards.image_name"]
    (4126, "                if \\'downsample\\' in wildcards.image_name:")
    (4127, "                    downsample_n = float(re.findall(\\'downsample-([0-9]+)_\\', wildcards.image_name)[0])")
    (4128, '                    # these need to be ints')
    (4129, '                    window_size = int(window_size // downsample_n)')
    (4130, '                    offset = [int(o // downsample_n) for o in offset]')
    (4131, "                    style[\\'lines.linewidth\\'] = int(style[\\'lines.linewidth\\'] // downsample_n)")
    (4132, '                    cross_size = cross_size / downsample_n')
    (4133, '                plt.style.use(style)')
    (4134, "                # if we\\'re loading in the metamer with window, it will have a")
    (4135, '                # red oval on it, which we want to preserve')
    (4136, '                im = po.load_images(input, as_gray=False)')
    (4137, "                # if we\\'re loading in an image that is truly grayscale (i.e.,")
    (4138, '                # the ref_images_preproc ones), then it will only have one')
    (4139, '                # channel, even with as_gray=False, so we need to set as_rgb')
    (4140, '                # correctly.')
    (4141, '                fig = po.imshow(im, title=None, as_rgb=True if im.shape[1] > 1 else False,')
    (4142, '                                # need to make sure vrange is set, so the')
    (4143, '                                # dynamic range is the same as everywhere else')
    (4144, '                                vrange=(0, 1))')
    (4145, '                # we do the periphery and fovea separately, so we can plot them')
    (4146, '                # in separate colors')
    (4147, '                fov.figures.add_cutout_box(fig.axes[0], plot_periphery=False,')
    (4148, '                                           window_size=window_size,')
    (4149, '                                           periphery_offset=offset)')
    (4150, "                fov.figures.add_cutout_box(fig.axes[0], plot_fovea=False, colors=\\'b\\',")
    (4151, '                                           window_size=window_size,')
    (4152, '                                           periphery_offset=offset)')
    (4153, "                if wildcards.fixation_cross == \\'cross\\':")
    (4154, '                    fov.figures.add_fixation_cross(fig.axes[0], cross_size=cross_size)')
    (4155, '                # we add an extra bit to the window size here so that the')
    (4156, "                # addition of the cutout box doesn\\'t cause the axes to resize")
    (4157, '                # (and the full width of the lines are visible)')
    (4158, '                fovea_fig = fov.figures.cutout_figure(im[0, 0], plot_periphery=False, label=False,')
    (4159, "                                                      window_size=window_size+style[\\'lines.linewidth\\'],")
    (4160, '                                                      periphery_offset=offset)')
    (4161, '                periphery_fig = fov.figures.cutout_figure(im[0, 0], plot_fovea=False, label=False,')
    (4162, "                                                          window_size=window_size+style[\\'lines.linewidth\\'],")
    (4163, '                                                          periphery_offset=offset)')
    (4164, '                fov.figures.add_cutout_box(fovea_fig.axes[0], plot_periphery=False, periphery_offset=offset,')
    (4165, '                                           window_size=window_size)')
    (4166, '                # note that plot_periphery=False here because the peripheral')
    (4167, '                # cutout is centered')
    (4168, "                fov.figures.add_cutout_box(periphery_fig.axes[0], plot_periphery=False, colors=\\'b\\',")
    (4169, '                                           periphery_offset=offset, window_size=window_size)')
    (4170, "                if wildcards.fixation_cross == \\'cross\\':")
    (4171, '                    fov.figures.add_fixation_cross(fovea_fig.axes[0], cross_size=cross_size)')
    (4172, '                fig.savefig(output[0])')
    (4173, '                fovea_fig.savefig(output[1])')
    (4174, '                periphery_fig.savefig(output[2])')
    (4175, '')
    (4176, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/foveated-metamers, file=Snakefile
context_key: ['rule critical_scaling_pointplot', 'run', "if wildcards.norm == \\'True\\'"]
    (4387, "                if wildcards.norm == \\'True\\':")
    (4388, "                    tmp[\\'critical_scaling\\'] = 8*tmp.critical_scaling")
    (4389, '                else:')
    (4390, "                    tmp[\\'critical_scaling\\'] = 24*tmp.critical_scaling")
    (4391, '                crit_scaling = pd.concat([crit_scaling, tmp])')
    (4392, "                g = sns.FacetGrid(crit_scaling, hue=\\'model\\', palette=pal, height=fig_width)")
    (4393, "                g.map_dataframe(fov.plotting.vertical_pointplot, x=\\'model\\', y=\\'critical_scaling\\',")
    (4394, "                                norm_y=wildcards.norm==\\'True\\')")
    (4395, "                ylabel = \\'Critical scaling\\'")
    (4396, "                # bool(\\'False\\') == True, so we do this to avoid that")
    (4397, '                # situation')
    (4398, "                if wildcards.norm == \\'True\\':")
    (4399, "                    ylabel += \\'\\")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/foveated-metamers, file=Snakefile
context_key: ['rule upload_to_osf', 'run', "if wildcards.to_share.startswith(\\'metamers_\\')"]
    (4662, "        if wildcards.to_share.startswith(\\'metamers_\\'):")
    (4663, "            upload_path = f\\'metamers/{wildcards.to_share}\\'")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/foveated-metamers, file=Snakefile
context_key: ['rule upload_to_osf', 'run', "elif wildcards.to_share.startswith(\\'stimuli_\\')"]
    (4664, "        elif wildcards.to_share.startswith(\\'stimuli_\\'):")
    (4665, "            upload_path = f\\'stimuli/{wildcards.to_share}\\'")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/foveated-metamers, file=Snakefile
context_key: ['rule upload_to_osf', 'run', "elif wildcards.to_share.startswith(\\'mcmc_\\')"]
    (4666, "        elif wildcards.to_share.startswith(\\'mcmc_\\'):")
    (4667, "            upload_path = f\\'mcmc/{wildcards.to_share}\\'")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=billbrod/foveated-metamers, file=Snakefile
context_key: ['rule create_checksum_dict', 'run', 'if len(tmp) > 1']
    (4743, '            if len(tmp) > 1:')
    (4744, '                raise Exception(f"Expected one file but found {len(tmp)}!")')
    (4745, "            # there\\'s only one key, so this grabs it")
    (4746, '            if list(tmp.keys())[0] in checksums.keys():')
    (4747, '                raise Exception(f"{tmp.keys()[0]} already found in checksums dict!")')
    (4748, '            checksums.update(tmp)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=khalillab/coop-TF-chipseq, file=rules/fastqc.smk
context_key: ['rule fastqc_aggregate', 'run', 'if sample_id in ["unmatched_r1", "unmatched_r2"] and title=="Adapter Content"']
    (88, '                    if sample_id in ["unmatched_r1", "unmatched_r2"] and title=="Adapter Content":')
    (89, '                        shell("""awk \\\'BEGIN{{FS=OFS="\\\\t"}} /{title}/{{flag=1;next}}/>>END_MODULE/{{flag=0}} flag {{m=$2;for(i=2;i<=NF-2;i++)if($i>m)m=$i; print $1, m, "{sample_id}", "{read_status}"}}\\\' {fastqc_data} | tail -n +2 >> {out_path}""")')
    (90, '                    else:')
    (91, '                        shell("""awk \\\'BEGIN{{FS=OFS="\\\\t"}} /{title}/{{flag=1;next}}/>>END_MODULE/{{flag=0}} flag {{print $0, "{sample_id}", "{read_status}"}}\\\' {fastqc_data} | tail -n +2 >> {out_path}""")')
    (92, '            shell("""sed -i "1i {fields}" {out_path}""")')
    (93, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=khalillab/coop-TF-chipseq, file=rules/genome_coverage.smk
context_key: ['rule normalize_genome_coverage', 'run', 'if wildcards.norm=="libsizenorm" or wildcards.sample in INPUTS']
    (66, '        if wildcards.norm=="libsizenorm" or wildcards.sample in INPUTS:')
    (67, '            shell("""')
    (68, '                  (awk -v norm_factor=$(samtools view -c {input.bam_experimental} | \\\\')
    (69, '                                        paste -d "" - <(echo "/1000000") | bc -l) \\\\')
    (70, '                   \\\'BEGIN{{FS=OFS="\\\\t"}}{{$4=$4/norm_factor; print $0}}\\\' {input.counts} > {output.normalized}) &> {log}')
    (71, '                  """)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=khalillab/coop-TF-chipseq, file=rules/differential_binding.smk
context_key: ['rule map_counts_to_annotations', 'input', 'else (f"diff_binding/windows/spikein_windows_{config[\\\'differential_occupancy\\\'][\\\'spikein_window_size\\\']}.bed" if wc.annotation=="windows" else config["differential_occupancy"]["annotations"][wc.annotation])']
    (22, '                else (f"diff_binding/windows/spikein_windows_{config[\\\'differential_occupancy\\\'][\\\'spikein_window_size\\\']}.bed" if wc.annotation=="windows" else config["differential_occupancy"]["annotations"][wc.annotation]),')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=MetaSUB-CAMP/CAMP_binning, file=workflow/Snakefile
context_key: ['rule make_config', 'run', 'if s not in dct']
    (224, '            if s not in dct:')
    (225, '                dct[s] = {}')
    (226, '            dct[s][d] = join(*info[:-1] + [s])')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Monia234/admix-map, file=workflow/Snakefile
context_key: ['if rule in plink_rules']
    (84, '        if rule in plink_rules:')
    (85, '            if config[\\\'run_settings\\\'][\\\'scheduler\\\'] == \\\'slurm\\\': plink_run_specs[rule] = f"--memory {int(int(clusterfile[rule][\\\'mem\\\'].replace(\\\'G\\\',\\\'000\\\'))*0.9)} --threads {clusterfile[rule][\\\'ntasks\\\']}" #0.9 multiplication is because plink can be greedy with memory and use more than requested.')
    (86, '            elif config[\\\'run_settings\\\'][\\\'scheduler\\\'] == \\\'pbs\\\':  plink_run_specs[rule] = f"--memory {clusterfile[rule][\\\'mem\\\'].replace(\\\'b\\\',\\\'\\\').replace(\\\'m\\\',\\\'\\\').replace(\\\'g\\\',\\\'000\\\')} --threads 1" #Deprecated')
    (87, '')
    (88, '')
    (89, '#### DEFINE FUNCTIONS #####')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Monia234/admix-map, file=workflow/Snakefile
context_key: ['rule calc_test_coverage', 'run', 'if os.path.exists(f"sHWE/{BASE}_sHWE-DS{int(x.strip(\\\'.bim\\\').replace(\\\'DS\\\', \\\'\\\').split(\\\'_\\\')[-1])}.rmv.bim")] #Create file list of all successful runs of sHWE (the .rmv.bim file will be present if sHWE completed successfully']
    (315, '                     if os.path.exists(f"sHWE/{BASE}_sHWE-DS{int(x.strip(\\\'.bim\\\').replace(\\\'DS\\\', \\\'\\\').split(\\\'_\\\')[-1])}.rmv.bim")] #Create file list of all successful runs of sHWE (the .rmv.bim file will be present if sHWE completed successfully)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Monia234/admix-map, file=workflow/Snakefile
context_key: ['rule fine_map', 'run', "if not os.path.exists(\\'fine-mapping\\')"]
    (563, "        if not os.path.exists(\\'fine-mapping\\'): os.mkdir(\\'fine-mapping\\')")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=steveped/snakemake_h3k27ac, file=workflow/rules/pairwise_comparisons.smk
context_key: ['rule compile_pairwise_comparisons_html', 'if [[ {params.git} == "True" ]]; the']
    (105, '        if [[ {params.git} == "True" ]]; then')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=steveped/snakemake_h3k27ac, file=workflow/rules/pairwise_comparisons.smk
context_key: ['rule compile_pairwise_comparisons_html', 'if [[ "$TRIES" == 0 ]]; the']
    (109, '                if [[ "$TRIES" == 0 ]]; then')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=zavolanlab/zarp, file=workflow/Snakefile
context_key: ['if not rule_config']
    (95, '    if not rule_config:')
    (96, '        logger.info(f"No rule config specified: using default values for all tools.")')
    (97, "        return \\'\\'")
    (98, '    # Same if current rule not specified in rule config')
    (99, '    if current_rule not in rule_config or not rule_config[current_rule]:')
    (100, '        logger.info(f"No additional parameters for rule {current_rule} specified: using default settings.")')
    (101, "        return \\'\\'")
    (102, '')
    (103, '    # Subset only section for current rule')
    (104, '    rule_config = rule_config[current_rule]')
    (105, '    ')
    (106, '    # Build list of parameters and values')
    (107, '    params_vals = []')
    (108, '    for param, val in rule_config.items():')
    (109, '        # Do not allow the user to change wiring-critical, fixed arguments, or arguments that are passed through samples table')
    (110, '        if param in immutable:')
    (111, '            raise ValueError(')
    (112, '                f"The following parameter in rule {current_rule} is critical for the pipeline to "')
    (113, '                f"function as expected and cannot be modified: {param}"')
    (114, '            )')
    (115, '        # Accept only strings; this prevents unintended results potentially')
    (116, '        # arising from users entering reserved YAML keywords or nested')
    (117, '        # structures (lists, dictionaries)')
    (118, '        if isinstance(val, str):')
    (119, '            params_vals.append(str(param))')
    (120, '            # Do not include a value for flags (signified by empty strings)')
    (121, '            if val:')
    (122, '                params_vals.append(val)')
    (123, '        else:')
    (124, '            raise ValueError(')
    (125, '                "Only string values allowed for tool parameters: Found type "')
    (126, '                f"\\\'{type(val).__name__}\\\' for value of parameter \\\'{param}\\\'"')
    (127, '            )')
    (128, '    # Return quoted string')
    (129, "    add_params = \\' \\'.join(quote(item) for item in params_vals)")
    (130, '    logger.info(f"User specified additional parameters for rule {current_rule}:\\')
    (131, ' {add_params}")')
    (132, '    return add_params')
    (133, '')
    (134, '')
    (135, '# Global config')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=1709mrd/MY, file=rules/calling.smk
context_key: ['rule call_variants', 'input', 'else [']
    (23, '            else []')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=momo54/sage-orderby-experiment, file=Snakefile
context_key: ['rule format_run_topk_query', 'run', 'if "query" not in df']
    (106, '        if "query" not in df:')
    (107, '            df["query"] = wildcards.query')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=momo54/sage-orderby-experiment, file=Snakefile
context_key: ['rule format_run_topk_query', 'run', 'if "run" not in df']
    (108, '        if "run" not in df:')
    (109, '            df["run"] = wildcards.run')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=momo54/sage-orderby-experiment, file=Snakefile
context_key: ['rule format_run_topk_query', 'run', 'if "limit" not in df']
    (110, '        if "limit" not in df:')
    (111, '            df["limit"] = wildcards.limit')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=momo54/sage-orderby-experiment, file=Snakefile
context_key: ['rule format_run_topk_query', 'run', 'if "quota" not in df']
    (112, '        if "quota" not in df:')
    (113, '            df["quota"] = wildcards.quota')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=momo54/sage-orderby-experiment, file=Snakefile
context_key: ['rule format_run_topk_query', 'run', 'if "approach" not in df']
    (114, '        if "approach" not in df:')
    (115, '            df["approach"] = wildcards.approach')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=momo54/sage-orderby-experiment, file=Snakefile
context_key: ['rule format_run_topk_query', 'run', 'if "workload" not in df']
    (116, '        if "workload" not in df:')
    (117, '            df["workload"] = wildcards.workload')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=momo54/sage-orderby-experiment, file=Snakefile
context_key: ['rule format_run_topk_query', 'run', 'if "xp" not in df']
    (118, '        if "xp" not in df:')
    (119, '            df["xp"] = wildcards.xp')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=momo54/sage-orderby-experiment, file=Snakefile
context_key: ['rule format_check_topk_query', 'run', 'if "query" not in df']
    (165, '        if "query" not in df:')
    (166, '            df["query"] = wildcards.query')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=momo54/sage-orderby-experiment, file=Snakefile
context_key: ['rule format_check_topk_query', 'run', 'if "limit" not in df']
    (167, '        if "limit" not in df:')
    (168, '            df["limit"] = wildcards.limit')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=momo54/sage-orderby-experiment, file=Snakefile
context_key: ['rule format_check_topk_query', 'run', 'if "approach" not in df']
    (169, '        if "approach" not in df:')
    (170, '            df["approach"] = wildcards.approach')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=momo54/sage-orderby-experiment, file=Snakefile
context_key: ['rule format_check_topk_query', 'run', 'if "workload" not in df']
    (171, '        if "workload" not in df:')
    (172, '            df["workload"] = wildcards.workload')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=momo54/sage-orderby-experiment, file=Snakefile
context_key: ['rule format_check_topk_query', 'run', 'if "xp" not in df']
    (173, '        if "xp" not in df:')
    (174, '            df["xp"] = wildcards.xp')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=fshepherd13/bulk-rnaseq, file=workflow/Snakefile
context_key: ['if "custom_rules" in config']
    (8, 'if "custom_rules" in config:')
    (9, '    for rule_file in config["custom_rules"]:')
    (10, '        include: rule_file')
    (11, '')
    (12, '    ')
    (13, '    ')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=PNNL-CompBio/perseq, file=Snakefile
context_key: ['rule fix_prodigal_multi', 'run', 'if not name.endswith("_1")']
    (387, '                if not name.endswith("_1"):')
    (388, '                    continue')
    (389, '                print(">%s" % name, seq.replace("*", ""), sep="\\')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=PNNL-CompBio/perseq, file=Snakefile
context_key: ['rule aggregate_all_genes', 'run', 'if not name.endswith("_1")']
    (410, '                        if not name.endswith("_1"):')
    (411, '                            continue')
    (412, '                        print(">%d" % name_index, seq.replace("*", ""), sep="\\')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=PNNL-CompBio/perseq, file=Snakefile
context_key: ['rule split_fasta', 'run', 'if lineno % params.chunk_size == 0', 'if fasta_chunk']
    (506, '                if lineno % params.chunk_size == 0:')
    (507, '                    if fasta_chunk:')
    (508, '                        fasta_chunk.close()')
    (509, '                    fasta_chunk_filename = f"gene_catalog/tmp/clustered_genes_{lineno + params.chunk_size}.faa"')
    (510, '                    fasta_chunk = open(fasta_chunk_filename, "w")')
    (511, '                fasta_chunk.write(f">{name}\\')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=1709mrd/THISschool_dna-seq-gatk-variant-calling, file=rules/calling.smk
context_key: ['rule call_variants', 'input', 'else [']
    (23, '            else []')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=taylorreiter/2022-infant-mge, file=Snakefile
context_key: ['rule download_metagenome_reads', 'run', 'if not os.path.exists(output.r1)']
    (86, '        if not os.path.exists(output.r1):')
    (87, '            shell("wget -O {output.r1} ftp://{fastq_1}")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=taylorreiter/2022-infant-mge, file=Snakefile
context_key: ['rule download_metagenome_reads', 'run', 'if not os.path.exists(output.r2)']
    (88, '        if not os.path.exists(output.r2):')
    (89, '            shell("wget -O {output.r2} ftp://{fastq_2}")')
    (90, '')
    (91, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=clinical-genomics-uppsala/accel_amplicon_trimming, file=rules/accel_amplicon.smk
context_key: ['rule cgu_accel_extract_fastq_files', 'run', 'if input[0].endswith("gz")']
    (27, '      if input[0].endswith("gz"):')
    (28, '         shell("zcat {input} > {output}")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=bhattlab/lathe, file=Snakefile
context_key: ['rule misassemblies_correct', 'if [ -s {input[0]} ] #if the input is nonempty..']
    (206, '        if [ -s {input[0]} ] #if the input is nonempty...')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=bhattlab/lathe, file=Snakefile
context_key: ['rule misassemblies_correct', 'if ($1 == prev_tig){']
    (210, '                if ($1 == prev_tig){{')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=bhattlab/lathe, file=Snakefile
context_key: ['rule misassemblies_correct', 'if (prev_len > 0){']
    (214, '                    if (prev_len > 0){{')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=bhattlab/lathe, file=Snakefile
context_key: ['rule misassemblies_correct', 'if [ $x -gt 1']
    (231, '            if [ $x -gt 1 ]')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=bhattlab/lathe, file=Snakefile
context_key: ['rule pilon_subsetrun', "if [ $(echo $cov\\'>\\'{params.target_coverage}|bc) -eq 1"]
    (483, "           if [ $(echo $cov\\'>\\'{params.target_coverage}|bc) -eq 1 ]")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=bhattlab/lathe, file=Snakefile
context_key: ['rule circularize_span_trim', 'run', "if span_out == [\\'done"]
    (685, "        if span_out == [\\'done\\")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=bhattlab/lathe, file=Snakefile
context_key: ['rule circularize_overcirc_trim', 'run', "if span_out == [\\'done"]
    (741, "        if span_out == [\\'done\\")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=fuzhiliang/dna-seq-gatk-variant-calling_test, file=rules/filtering.smk
context_key: ['rule merge_calls', 'input', 'else "hardfiltered"']
    (58, '                              else "hardfiltered")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=ctmrbio/stag-mwc, file=rules/mappers/bbmap.smk
context_key: ['rule', 'if bbmap_config["counts_table"]["annotations"] and not bbmap_config["counts_table"]["columns"]']
    (101, '    if bbmap_config["counts_table"]["annotations"] and not bbmap_config["counts_table"]["columns"]:')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=mhoangvslev/AutoFJ, file=run_xp.Snakefile
context_key: ['rule autofj_benchmark_summary', 'run', 'if f.endswith("_model.pkl")']
    (43, '            if f.endswith("_model.pkl"):')
    (44, '                dataPath = os.path.join(config["dataDir"], dataset)')
    (45, '                outDir = os.path.join(homeDir, f.replace(".pkl", ""))')
    (46, '                os.makedirs(outDir, exist_ok=True)')
    (47, '                modelPath = os.path.join(homeDir, f)')
    (48, '                subprocess.run(["python", "scripts/autofj_benchmark.py", "predict", modelPath, dataPath, f"--outdir={outDir}"])   ')
    (49, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=vibaotram/baseDmux, file=baseDmux/data/Snakefile
context_key: ['rule guppy_demultiplexing', 'rule multi_to_single_fast5', 'rule deepbinner_classification', 'rule deepbinner_bin', 'rule minionqc_basecall', 'rule multiqc_basecall', 'rule get_sequencing_summary_per_barcode', 'rule minionqc_demultiplex', 'rule multiqc_demultiplex', 'rule get_reads_per_genome', 'if [ "{FAST5_PER_GENOME}" == "True" ]; the']
    (655, '        if [ "{FAST5_PER_GENOME}" == "True" ]; then')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=vibaotram/baseDmux, file=baseDmux/data/Snakefile
context_key: ['rule porechop', 'if "porechop" in READS_FILTERING', 'else', 'if "porechop" in READS_FILTERING', 'else', 'rule filtlong', 'rule report_demultiplex', 'rule clean', 'rule clean_basecall', 'rule clean_demultiplex', 'rule help', 'rule test']
    (685, 'if "porechop" in READS_FILTERING:')
    (686, '\\tFILTLONG_INPUT = rules.porechop.output.fastq')
    (687, 'else:')
    (688, '\\tFILTLONG_INPUT = os.path.join(outdir, "reads_per_genome/fastq/{genome}.fastq.gz")')
    (689, '')
    (690, '# FILTLONG_OUTPUT')
    (691, 'if "porechop" in READS_FILTERING:')
    (692, '\\tFILTLONG_OUTPUT = os.path.join(outdir, "reads_per_genome/fastq_porechop_{filtlongid}/{genome}_porechop_{filtlongid}.fastq.gz")')
    (693, 'else:')
    (694, '\\tFILTLONG_OUTPUT = os.path.join(outdir, "reads_per_genome/fastq_{filtlongid}/{genome}_{filtlongid}.fastq.gz")')
    (695, '')
    (696, '')
    (697, 'def filtlong_params(wildcards):')
    (698, '\\tparams = config[wildcards.filtlongid].values()')
    (699, '\\treturn unpack(params)')
    (700, '')
    (701, '')
    (702, 'rule filtlong:')
    (703, '\\tinput: FILTLONG_INPUT')
    (704, '\\toutput:')
    (705, '\\t\\tfastq = FILTLONG_OUTPUT')
    (706, '\\tparams:')
    (707, '\\t\\tfiltlong = filtlong_params,')
    (708, '\\t\\tlog = "{filtlongid}_{genome}.log"')
    (709, '\\tsingularity: guppy_container')
    (710, "\\tconda: \\'conda/conda_filtlong.yaml\\'")
    (711, '\\tshell:')
    (712, '\\t\\t"""')
    (713, '\\t\\texec > >(tee "{SNAKEMAKE_LOG}/{params.log}") 2>&1')
    (714, '\\t\\tfiltlong {params.filtlong} {input} | gzip > {output}')
    (715, '\\t\\t"""')
    (716, '')
    (717, '')
    (718, '##############################')
    (719, '####################### REPORT')
    (720, '')
    (721, '#REPORT_DEMULTIPLEX_INPUT = by_cond(cond = DEMULTIPLEX_REPORT, yes = expand(rules.multiqc_demultiplex.output, demultiplexer = demultiplexer, run = run), no = ())')
    (722, '')
    (723, 'rule report_demultiplex:')
    (724, '\\tinput:')
    (725, '\\t\\t# fast5 = expand(os.path.join(outdir, "reads_per_genome/fast5/{genome}"), genome = genome),')
    (726, '\\t\\tfastq = by_cond(len(genome) > 0, expand(os.path.join(outdir, "reads_per_genome/fastq{filtered}/{genome}{filtered}.fastq.gz"), genome = genome, filtered = filtered),  expand(os.path.join(outdir, "demultiplex/{demultiplexer}/{run}/demultiplex.done"), demultiplexer = demultiplexer, run = run)),')
    (727, '\\tmessage:')
    (728, '\\t\\t"""')
    (729, '\\t\\t"Reporting demultiplex results"')
    (730, '\\t\\tinput:')
    (731, '\\t\\t\\tfastq : {input.fastq}')
    (732, '\\t\\tparams:')
    (733, '\\t\\t\\tbarcode_by_genome : {params.barcode_by_genome}')
    (734, '\\t\\t\\tfastq : {params.fastq}')
    (735, '\\t\\t\\tdemultiplex : {params.demultiplex}')
    (736, '\\t\\t\\tpostdemux : {params.postdemux}')
    (737, '\\t\\t\\tlog : "XXXX?"')
    (738, '\\t\\t\\toutpath : {params.outpath}')
    (739, '\\t\\t"""')
    (740, '\\toutput: os.path.join(outdir, "report/demultiplex_report.html")')
    (741, '\\tparams:')
    (742, '\\t\\tbarcode_by_genome = BARCODE_BY_GENOME,')
    (743, '\\t\\tfastq = by_cond(len(genome) > 0, os.path.join(outdir, "reads_per_genome/fastq"), os.path.join(outdir, "basecall")),')
    (744, '\\t\\tdemultiplex = os.path.join(outdir, "demultiplex"),')
    (745, '\\t\\tpostdemux = by_cond(len(genome) > 0, expand(os.path.join(outdir, "reads_per_genome/fastq{filtered}"), filtered = filtered), os.path.join(outdir, "basecall")),')
    (746, '\\t\\toutpath = lambda wildcards, output: os.path.dirname(output[0]),')
    (747, '\\t\\tlog = "report_demultiplex.log"')
    (748, "\\tthreads: config[\\'REPORTS\\'][\\'DEMULTIPLEX_REPORT_THREADS\\']")
    (749, '\\tsingularity: guppy_container')
    (750, "\\tconda: \\'conda/conda_rmarkdown.yaml\\'")
    (751, '\\tlog: os.path.join(SNAKEMAKE_LOG, "report_demultiplex.log")')
    (752, '\\tscript:')
    (753, '\\t\\tDEMULTIPLEX_REPORT_RMD')
    (754, '')
    (755, '')
    (756, '')
    (757, '##############################')
    (758, '############### SOMETHING ELSE')
    (759, '')
    (760, 'rule clean:')
    (761, '\\tmessage: "Cleaning output directory {outdir}"')
    (762, '\\tshell:')
    (763, '\\t\\t"""')
    (764, '\\t\\trm -rf {outdir}')
    (765, '\\t\\techo "#################  removed {outdir}  #################"')
    (766, '\\t\\t"""')
    (767, '')
    (768, 'rule clean_basecall:')
    (769, '\\tparams:')
    (770, '\\t\\tbasecall = os.path.join(outdir, "basecall"),')
    (771, '\\tshell:')
    (772, '\\t\\t"""')
    (773, '\\t\\trm -rf {params.basecall}')
    (774, '\\t\\t"""')
    (775, '')
    (776, 'rule clean_demultiplex:')
    (777, '\\tparams:')
    (778, '\\t\\tdemultiplex = os.path.join(outdir, "demultiplex")')
    (779, '\\tshell:')
    (780, '\\t\\t"""')
    (781, '\\t\\trm -rf {params.demultiplex}')
    (782, '\\t\\t"""')
    (783, '')
    (784, 'rule help:')
    (785, '\\tshell:')
    (786, '\\t\\t"""')
    (787, '\\t\\tcat README.md')
    (788, '\\t\\t"""')
    (789, '')
    (790, 'rule test:')
    (791, '\\tshell:')
    (792, '\\t\\t"""')
    (793, '\\t\\techo "{filtered}"')
    (794, '\\t\\t"""')
    (795, '')
    (796, '# rule add_slurm_logs:')
    (797, '# \\tshell:')
    (798, '# \\t\\t"""')
    (799, '# \\t\\tmkdir -p {outdir}/slurm_logs')
    (800, '# \\t\\t"""')
    (801, '##############################')
    (802, '##################### HANDLERS')
    (803, '')
    (804, '# onstart:')
    (805, '# \\tprint("Basecalling will be performed by Guppy on", RESOURCE)')
    (806, '# \\tprint("Demultiplexing will be performed by",)')
    (807, '# \\tfor d in demultiplexer: print("\\\\t-", d)')
    (808, '')
    (809, '')
    (810, '#onsuccess:')
    (811, '#\\tprint("Workflow finished, yay")')
    (812, '#\\tprint("Basecalling by Guppy on", RESOURCE)')
    (813, '#\\tprint("Demultiplexing by")')
    (814, '#\\tfor d in demultiplexer: print("\\\\t-", d)')
    (815, '')
    (816, '#onerror:')
    (817, '#\\tprint("OMG ... error ... error ... again")')
    (818, "'")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=cbg-ethz/V-pipe, file=resources/auxiliary_workflows/benchmark/workflow/Snakefile
context_key: ['rule run_method_local', 'input', 'if wildcards.seq_mode == "amplicon']
    (444, '        if wildcards.seq_mode == "amplicon"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=cbg-ethz/V-pipe, file=resources/auxiliary_workflows/benchmark/workflow/Snakefile
context_key: ['rule run_method_local', 'input', 'else f"results/simulated_reads/{paramspace.wildcard_pattern}/replicates/{{replicate}}/reads.{{seq_mode}}.bam"']
    (445, '        else f"results/simulated_reads/{paramspace.wildcard_pattern}/replicates/{{replicate}}/reads.{{seq_mode}}.bam",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=cbg-ethz/V-pipe, file=resources/auxiliary_workflows/benchmark/workflow/Snakefile
context_key: ['rule run_method_local', 'input', 'if wildcards.seq_mode == "amplicon']
    (449, '        if wildcards.seq_mode == "amplicon"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=cbg-ethz/V-pipe, file=resources/auxiliary_workflows/benchmark/workflow/Snakefile
context_key: ['rule run_method_local', 'input', 'else []']
    (450, '        else [],')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=ibmp-bip/tRNAflow, file=workflow/Snakefile
context_key: ['rule addBox', 'run', "if params.option == \\'organellar\\'"]
    (41, "        if params.option == \\'organellar\\':")
    (42, '            shell("workflow/addBox2plantRNA.py -i {input} -o {output} --nobox")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=ibmp-bip/tRNAflow, file=workflow/Snakefile
context_key: ['rule trnascanSE', 'run', "if params.option == \\'eukaryotic\\'"]
    (112, "        if params.option == \\'eukaryotic\\':")
    (113, '            shell("tRNAscan-SE -E -o {output.trna} -f {output.struct} -m {output.stats} -b {output.bed} -a {output.fa} -l {output.log} {params.fasta}")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=ibmp-bip/tRNAflow, file=workflow/Snakefile
context_key: ['rule trnascanSE', 'run', "if params.option == \\'general\\'"]
    (114, "        if params.option == \\'general\\':")
    (115, '            shell("tRNAscan-SE -G -o {output.trna} -f {output.struct} -m {output.stats} -b {output.bed} -a {output.fa} -l {output.log} {params.fasta}")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=ibmp-bip/tRNAflow, file=workflow/Snakefile
context_key: ['rule trnascanSE', 'run', "if params.option == \\'organellar\\'"]
    (116, "        if params.option == \\'organellar\\':")
    (117, '            shell("tRNAscan-SE -O -C -o {output.trna} -f {output.struct} -m {output.stats} -b {output.bed} -a {output.fa} -l {output.log} {params.fasta}")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=ibmp-bip/tRNAflow, file=workflow/Snakefile
context_key: ['rule trnascanSE', 'run', "if params.option == \\'archae\\'"]
    (118, "        if params.option == \\'archae\\':")
    (119, '            shell("tRNAscan-SE -A -o {output.trna} -f {output.struct} -m {output.stats} -b {output.bed} -a {output.fa} -l {output.log} {params.fasta}")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=ibmp-bip/tRNAflow, file=workflow/Snakefile
context_key: ['rule trnascanSE', 'run', "if params.option == \\'bacteria\\'"]
    (120, "        if params.option == \\'bacteria\\':")
    (121, '            shell("tRNAscan-SE -B -o {output.trna} -f {output.struct} -m {output.stats} -b {output.bed} -a {output.fa} -l {output.log} {params.fasta}")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=ibmp-bip/tRNAflow, file=workflow/Snakefile
context_key: ['rule trnascanSE', 'run', "if params.option == \\'mito_vert\\'"]
    (122, "        if params.option == \\'mito_vert\\':")
    (123, '            shell("tRNAscan-SE -M vert -o {output.trna} -f {output.struct} -m {output.stats} -b {output.bed} -a {output.fa} -l {output.log} {params.fasta}")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=ibmp-bip/tRNAflow, file=workflow/Snakefile
context_key: ['rule trnascanSE', 'run', "if params.option == \\'mito_mamm\\'"]
    (124, "        if params.option == \\'mito_mamm\\':")
    (125, '            shell("tRNAscan-SE -M mammal -o {output.trna} -f {output.struct} -m {output.stats} -b {output.bed} -a {output.fa} -l {output.log} {params.fasta}")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=supermaxiste/ARPEGGIO, file=rules/deduplication.smk
context_key: ['rule deduplication_SE', 'input', 'else f"{OUTPUT_DIR}Bismark/{{sample}}_{{one_or_two}}/{{one_or_two}}.{{sample}}_bismark_bt2.bam"']
    (14, '        else f"{OUTPUT_DIR}Bismark/{{sample}}_{{one_or_two}}/{{one_or_two}}.{{sample}}_bismark_bt2.bam",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=supermaxiste/ARPEGGIO, file=rules/deduplication.smk
context_key: ['rule deduplication_SE', 'output', 'else f"{OUTPUT_DIR}Bismark/deduplication/{{sample}}_{{one_or_two}}/{{one_or_two}}.{{sample}}_bismark_bt2.deduplicated.bam"']
    (18, '        else f"{OUTPUT_DIR}Bismark/deduplication/{{sample}}_{{one_or_two}}/{{one_or_two}}.{{sample}}_bismark_bt2.deduplicated.bam",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=supermaxiste/ARPEGGIO, file=rules/deduplication.smk
context_key: ['rule deduplication_PE', 'input', 'else f"{OUTPUT_DIR}Bismark/{{sample}}_{{one_or_two}}/{{one_or_two}}.{{sample}}_{str(config[\\\'PAIR_1\\\'])}_bismark_bt2_pe.bam"']
    (38, '        else f"{OUTPUT_DIR}Bismark/{{sample}}_{{one_or_two}}/{{one_or_two}}.{{sample}}_{str(config[\\\'PAIR_1\\\'])}_bismark_bt2_pe.bam",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=supermaxiste/ARPEGGIO, file=rules/deduplication.smk
context_key: ['rule deduplication_PE', 'output', 'else f"{OUTPUT_DIR}Bismark/deduplication/{{sample}}_{{one_or_two}}/{{one_or_two}}.{{sample}}_{str(config[\\\'PAIR_1\\\'])}_bismark_bt2_pe.deduplicated.bam"']
    (42, '        else f"{OUTPUT_DIR}Bismark/deduplication/{{sample}}_{{one_or_two}}/{{one_or_two}}.{{sample}}_{str(config[\\\'PAIR_1\\\'])}_bismark_bt2_pe.deduplicated.bam",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=supermaxiste/ARPEGGIO, file=rules/quality_check.smk
context_key: ['rule bismark_alignment_SE_control', 'input', 'else f"{RAW_DATA_DIR}{{sample}}.{str(config[\\\'RAW_DATA_EXTENSION\\\'])}.gz"']
    (98, '        else f"{RAW_DATA_DIR}{{sample}}.{str(config[\\\'RAW_DATA_EXTENSION\\\'])}.gz",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=supermaxiste/ARPEGGIO, file=rules/quality_check.smk
context_key: ['rule bismark_alignment_SE_control', 'output', 'else f"{OUTPUT_DIR}Conversion_efficiency/{{sample}}/cc.{{sample}}_bismark_bt2.bam"']
    (102, '        else f"{OUTPUT_DIR}Conversion_efficiency/{{sample}}/cc.{{sample}}_bismark_bt2.bam",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=supermaxiste/ARPEGGIO, file=rules/quality_check.smk
context_key: ['rule bismark_alignment_SE_control', 'output', 'else f"{OUTPUT_DIR}Conversion_efficiency/{{sample}}/cc.{{sample}}_bismark_bt2_SE_report.txt"']
    (105, '        else f"{OUTPUT_DIR}Conversion_efficiency/{{sample}}/cc.{{sample}}_bismark_bt2_SE_report.txt",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=supermaxiste/ARPEGGIO, file=rules/quality_check.smk
context_key: ['rule bismark_alignment_PE_control', 'input', 'else f"{RAW_DATA_DIR}{{sample}}_{str(config[\\\'PAIR_1\\\'])}.{str(config[\\\'RAW_DATA_EXTENSION\\\'])}.gz"']
    (129, '        else f"{RAW_DATA_DIR}{{sample}}_{str(config[\\\'PAIR_1\\\'])}.{str(config[\\\'RAW_DATA_EXTENSION\\\'])}.gz",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=supermaxiste/ARPEGGIO, file=rules/quality_check.smk
context_key: ['rule bismark_alignment_PE_control', 'input', 'else f"{RAW_DATA_DIR}{{sample}}_{str(config[\\\'PAIR_2\\\'])}.{str(config[\\\'RAW_DATA_EXTENSION\\\'])}.gz"']
    (132, '        else f"{RAW_DATA_DIR}{{sample}}_{str(config[\\\'PAIR_2\\\'])}.{str(config[\\\'RAW_DATA_EXTENSION\\\'])}.gz",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=supermaxiste/ARPEGGIO, file=rules/quality_check.smk
context_key: ['rule bismark_alignment_PE_control', 'output', 'else f"{OUTPUT_DIR}Conversion_efficiency/{{sample}}/cc.{{sample}}_{str(config[\\\'PAIR_1\\\'])}_bismark_bt2_pe.bam"']
    (136, '        else f"{OUTPUT_DIR}Conversion_efficiency/{{sample}}/cc.{{sample}}_{str(config[\\\'PAIR_1\\\'])}_bismark_bt2_pe.bam",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=supermaxiste/ARPEGGIO, file=rules/quality_check.smk
context_key: ['rule bismark_alignment_PE_control', 'output', 'else f"{OUTPUT_DIR}Conversion_efficiency/{{sample}}/cc.{{sample}}_{str(config[\\\'PAIR_1\\\'])}_bismark_bt2_PE_report.txt"']
    (139, '        else f"{OUTPUT_DIR}Conversion_efficiency/{{sample}}/cc.{{sample}}_{str(config[\\\'PAIR_1\\\'])}_bismark_bt2_PE_report.txt",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=supermaxiste/ARPEGGIO, file=rules/quality_check.smk
context_key: ['rule bam_sorting_p1', 'input', 'else f"{OUTPUT_DIR}Bismark/deduplication/{{sample}}_1/1.{{sample}}_{str(config[\\\'PAIR_1\\\'])}_bismark_bt2_pe.deduplicated.bam']
    (165, '        else f"{OUTPUT_DIR}Bismark/deduplication/{{sample}}_1/1.{{sample}}_{str(config[\\\'PAIR_1\\\'])}_bismark_bt2_pe.deduplicated.bam"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=supermaxiste/ARPEGGIO, file=rules/quality_check.smk
context_key: ['rule bam_sorting_p1', 'input', 'else f"{OUTPUT_DIR}Bismark/deduplication/{{sample}}_1/1.{{sample}}_trimmed_bismark_bt2.deduplicated.bam']
    (167, '        else f"{OUTPUT_DIR}Bismark/deduplication/{{sample}}_1/1.{{sample}}_trimmed_bismark_bt2.deduplicated.bam"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=supermaxiste/ARPEGGIO, file=rules/quality_check.smk
context_key: ['rule bam_sorting_p1', 'input', 'else f"{OUTPUT_DIR}Bismark/deduplication/{{sample}}_1/1.{{sample}}_bismark_bt2.deduplicated.bam"']
    (169, '        else f"{OUTPUT_DIR}Bismark/deduplication/{{sample}}_1/1.{{sample}}_bismark_bt2.deduplicated.bam",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=supermaxiste/ARPEGGIO, file=rules/quality_check.smk
context_key: ['rule bam_sorting_p1', 'output', 'else f"{OUTPUT_DIR}Bismark/deduplication/{{sample}}_1/1.{{sample}}_{str(config[\\\'PAIR_1\\\'])}_bismark_bt2_pe.deduplicated_sorted.bam']
    (173, '        else f"{OUTPUT_DIR}Bismark/deduplication/{{sample}}_1/1.{{sample}}_{str(config[\\\'PAIR_1\\\'])}_bismark_bt2_pe.deduplicated_sorted.bam"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=supermaxiste/ARPEGGIO, file=rules/quality_check.smk
context_key: ['rule bam_sorting_p1', 'output', 'else f"{OUTPUT_DIR}Bismark/deduplication/{{sample}}_1/1.{{sample}}_trimmed_bismark_bt2.deduplicated_sorted.bam']
    (175, '        else f"{OUTPUT_DIR}Bismark/deduplication/{{sample}}_1/1.{{sample}}_trimmed_bismark_bt2.deduplicated_sorted.bam"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=supermaxiste/ARPEGGIO, file=rules/quality_check.smk
context_key: ['rule bam_sorting_p1', 'output', 'else f"{OUTPUT_DIR}Bismark/deduplication/{{sample}}_1/1.{{sample}}_bismark_bt2.deduplicated_sorted.bam"']
    (177, '        else f"{OUTPUT_DIR}Bismark/deduplication/{{sample}}_1/1.{{sample}}_bismark_bt2.deduplicated_sorted.bam",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=supermaxiste/ARPEGGIO, file=rules/quality_check.smk
context_key: ['rule bam_sorting_p2', 'input', 'else f"{OUTPUT_DIR}Bismark/deduplication/{{sample}}_2/2.{{sample}}_{str(config[\\\'PAIR_1\\\'])}_bismark_bt2_pe.deduplicated.bam']
    (193, '        else f"{OUTPUT_DIR}Bismark/deduplication/{{sample}}_2/2.{{sample}}_{str(config[\\\'PAIR_1\\\'])}_bismark_bt2_pe.deduplicated.bam"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=supermaxiste/ARPEGGIO, file=rules/quality_check.smk
context_key: ['rule bam_sorting_p2', 'input', 'else f"{OUTPUT_DIR}Bismark/deduplication/{{sample}}_2/2.{{sample}}_trimmed_bismark_bt2.deduplicated.bam']
    (195, '        else f"{OUTPUT_DIR}Bismark/deduplication/{{sample}}_2/2.{{sample}}_trimmed_bismark_bt2.deduplicated.bam"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=supermaxiste/ARPEGGIO, file=rules/quality_check.smk
context_key: ['rule bam_sorting_p2', 'input', 'else f"{OUTPUT_DIR}Bismark/deduplication/{{sample}}_2/2.{{sample}}_bismark_bt2.deduplicated.bam"']
    (197, '        else f"{OUTPUT_DIR}Bismark/deduplication/{{sample}}_2/2.{{sample}}_bismark_bt2.deduplicated.bam",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=supermaxiste/ARPEGGIO, file=rules/quality_check.smk
context_key: ['rule bam_sorting_p2', 'output', 'else f"{OUTPUT_DIR}Bismark/deduplication/{{sample}}_2/2.{{sample}}_{str(config[\\\'PAIR_1\\\'])}_bismark_bt2_pe.deduplicated_sorted.bam']
    (201, '        else f"{OUTPUT_DIR}Bismark/deduplication/{{sample}}_2/2.{{sample}}_{str(config[\\\'PAIR_1\\\'])}_bismark_bt2_pe.deduplicated_sorted.bam"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=supermaxiste/ARPEGGIO, file=rules/quality_check.smk
context_key: ['rule bam_sorting_p2', 'output', 'else f"{OUTPUT_DIR}Bismark/deduplication/{{sample}}_2/2.{{sample}}_trimmed_bismark_bt2.deduplicated_sorted.bam']
    (203, '        else f"{OUTPUT_DIR}Bismark/deduplication/{{sample}}_2/2.{{sample}}_trimmed_bismark_bt2.deduplicated_sorted.bam"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=supermaxiste/ARPEGGIO, file=rules/quality_check.smk
context_key: ['rule bam_sorting_p2', 'output', 'else f"{OUTPUT_DIR}Bismark/deduplication/{{sample}}_2/2.{{sample}}_bismark_bt2.deduplicated_sorted.bam"']
    (205, '        else f"{OUTPUT_DIR}Bismark/deduplication/{{sample}}_2/2.{{sample}}_bismark_bt2.deduplicated_sorted.bam",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=supermaxiste/ARPEGGIO, file=rules/quality_check.smk
context_key: ['rule bam_sorting_allo', 'input', 'else f"{OUTPUT_DIR}Bismark/deduplication/{{sample}}_{{one_or_two}}/{{one_or_two}}.{{sample}}_{str(config[\\\'PAIR_1\\\'])}_val_1_bismark_bt2_pe.deduplicated.bam']
    (221, '        else f"{OUTPUT_DIR}Bismark/deduplication/{{sample}}_{{one_or_two}}/{{one_or_two}}.{{sample}}_{str(config[\\\'PAIR_1\\\'])}_val_1_bismark_bt2_pe.deduplicated.bam"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=supermaxiste/ARPEGGIO, file=rules/quality_check.smk
context_key: ['rule bam_sorting_allo', 'input', 'else f"{OUTPUT_DIR}Bismark/deduplication/{{sample}}_{{one_or_two}}/{{one_or_two}}.{{sample}}_{str(config[\\\'PAIR_1\\\'])}_bismark_bt2_pe.deduplicated.bam']
    (223, '        else f"{OUTPUT_DIR}Bismark/deduplication/{{sample}}_{{one_or_two}}/{{one_or_two}}.{{sample}}_{str(config[\\\'PAIR_1\\\'])}_bismark_bt2_pe.deduplicated.bam"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=supermaxiste/ARPEGGIO, file=rules/quality_check.smk
context_key: ['rule bam_sorting_allo', 'input', 'else f"{OUTPUT_DIR}read_sorting/{{sample}}_se/{{sample}}_classified{{one_or_two}}.ref.bam']
    (225, '        else f"{OUTPUT_DIR}read_sorting/{{sample}}_se/{{sample}}_classified{{one_or_two}}.ref.bam"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=supermaxiste/ARPEGGIO, file=rules/quality_check.smk
context_key: ['rule bam_sorting_allo', 'input', 'else f"{OUTPUT_DIR}Bismark/deduplication/{{sample}}_{{one_or_two}}/{{one_or_two}}.{{sample}}_trimmed_bismark_bt2.deduplicated.bam']
    (227, '        else f"{OUTPUT_DIR}Bismark/deduplication/{{sample}}_{{one_or_two}}/{{one_or_two}}.{{sample}}_trimmed_bismark_bt2.deduplicated.bam"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=supermaxiste/ARPEGGIO, file=rules/quality_check.smk
context_key: ['rule bam_sorting_allo', 'input', 'else f"{OUTPUT_DIR}Bismark/deduplication/{{sample}}_{{one_or_two}}/{{one_or_two}}.{{sample}}_bismark_bt2.deduplicated.bam"']
    (229, '        else f"{OUTPUT_DIR}Bismark/deduplication/{{sample}}_{{one_or_two}}/{{one_or_two}}.{{sample}}_bismark_bt2.deduplicated.bam",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=supermaxiste/ARPEGGIO, file=rules/quality_check.smk
context_key: ['rule bam_sorting_allo', 'output', 'else f"{OUTPUT_DIR}Bismark/deduplication/{{sample}}_{{one_or_two}}/{{one_or_two}}.{{sample}}_{str(config[\\\'PAIR_1\\\'])}_val_1_bismark_bt2_pe.deduplicated_sorted_allo.bam']
    (233, '        else f"{OUTPUT_DIR}Bismark/deduplication/{{sample}}_{{one_or_two}}/{{one_or_two}}.{{sample}}_{str(config[\\\'PAIR_1\\\'])}_val_1_bismark_bt2_pe.deduplicated_sorted_allo.bam"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=supermaxiste/ARPEGGIO, file=rules/quality_check.smk
context_key: ['rule bam_sorting_allo', 'output', 'else f"{OUTPUT_DIR}Bismark/deduplication/{{sample}}_{{one_or_two}}/{{one_or_two}}.{{sample}}_{str(config[\\\'PAIR_1\\\'])}_bismark_bt2_pe.deduplicated_sorted_allo.bam']
    (235, '        else f"{OUTPUT_DIR}Bismark/deduplication/{{sample}}_{{one_or_two}}/{{one_or_two}}.{{sample}}_{str(config[\\\'PAIR_1\\\'])}_bismark_bt2_pe.deduplicated_sorted_allo.bam"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=supermaxiste/ARPEGGIO, file=rules/quality_check.smk
context_key: ['rule bam_sorting_allo', 'output', 'else f"{OUTPUT_DIR}read_sorting/{{sample}}_se/{{sample}}_classified{{one_or_two}}_sorted.ref.bam']
    (237, '        else f"{OUTPUT_DIR}read_sorting/{{sample}}_se/{{sample}}_classified{{one_or_two}}_sorted.ref.bam"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=supermaxiste/ARPEGGIO, file=rules/quality_check.smk
context_key: ['rule bam_sorting_allo', 'output', 'else f"{OUTPUT_DIR}Bismark/deduplication/{{sample}}_{{one_or_two}}/{{one_or_two}}.{{sample}}_trimmed_bismark_bt2.deduplicated_sorted_allo.bam']
    (239, '        else f"{OUTPUT_DIR}Bismark/deduplication/{{sample}}_{{one_or_two}}/{{one_or_two}}.{{sample}}_trimmed_bismark_bt2.deduplicated_sorted_allo.bam"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=supermaxiste/ARPEGGIO, file=rules/quality_check.smk
context_key: ['rule bam_sorting_allo', 'output', 'else f"{OUTPUT_DIR}Bismark/deduplication/{{sample}}_{{one_or_two}}/{{one_or_two}}.{{sample}}_bismark_bt2.deduplicated_sorted_allo.bam"']
    (241, '        else f"{OUTPUT_DIR}Bismark/deduplication/{{sample}}_{{one_or_two}}/{{one_or_two}}.{{sample}}_bismark_bt2.deduplicated_sorted_allo.bam",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=supermaxiste/ARPEGGIO, file=rules/quality_check.smk
context_key: ['rule qualimap_p1', 'input', 'else f"{OUTPUT_DIR}Bismark/deduplication/{{sample}}_1/1.{{sample}}_{str(config[\\\'PAIR_1\\\'])}_bismark_bt2_pe.deduplicated_sorted.bam']
    (257, '        else f"{OUTPUT_DIR}Bismark/deduplication/{{sample}}_1/1.{{sample}}_{str(config[\\\'PAIR_1\\\'])}_bismark_bt2_pe.deduplicated_sorted.bam"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=supermaxiste/ARPEGGIO, file=rules/quality_check.smk
context_key: ['rule qualimap_p1', 'input', 'else f"{OUTPUT_DIR}Bismark/deduplication/{{sample}}_1/1.{{sample}}_bismark_bt2.deduplicated_sorted.bam']
    (262, '            else f"{OUTPUT_DIR}Bismark/deduplication/{{sample}}_1/1.{{sample}}_bismark_bt2.deduplicated_sorted.bam"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=supermaxiste/ARPEGGIO, file=rules/quality_check.smk
context_key: ['rule qualimap_p2', 'input', 'else f"{OUTPUT_DIR}Bismark/deduplication/{{sample}}_2/2.{{sample}}_{str(config[\\\'PAIR_1\\\'])}_bismark_bt2_pe.deduplicated_sorted.bam']
    (286, '        else f"{OUTPUT_DIR}Bismark/deduplication/{{sample}}_2/2.{{sample}}_{str(config[\\\'PAIR_1\\\'])}_bismark_bt2_pe.deduplicated_sorted.bam"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=supermaxiste/ARPEGGIO, file=rules/quality_check.smk
context_key: ['rule qualimap_p2', 'input', 'else f"{OUTPUT_DIR}Bismark/deduplication/{{sample}}_2/2.{{sample}}_bismark_bt2.deduplicated_sorted.bam']
    (291, '            else f"{OUTPUT_DIR}Bismark/deduplication/{{sample}}_2/2.{{sample}}_bismark_bt2.deduplicated_sorted.bam"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=supermaxiste/ARPEGGIO, file=rules/quality_check.smk
context_key: ['rule qualimap_allo_se', 'input', 'else f"{OUTPUT_DIR}Bismark/deduplication/{{sample}}_{{one_or_two}}/{{one_or_two}}.{{sample}}_trimmed_bismark_bt2.deduplicated_sorted_allo.bam']
    (315, '        else f"{OUTPUT_DIR}Bismark/deduplication/{{sample}}_{{one_or_two}}/{{one_or_two}}.{{sample}}_trimmed_bismark_bt2.deduplicated_sorted_allo.bam"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=supermaxiste/ARPEGGIO, file=rules/quality_check.smk
context_key: ['rule qualimap_allo_se', 'input', 'else f"{OUTPUT_DIR}Bismark/deduplication/{{sample}}_{{one_or_two}}/{{one_or_two}}.{{sample}}_bismark_bt2.deduplicated_sorted_allo.bam"']
    (317, '        else f"{OUTPUT_DIR}Bismark/deduplication/{{sample}}_{{one_or_two}}/{{one_or_two}}.{{sample}}_bismark_bt2.deduplicated_sorted_allo.bam",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=supermaxiste/ARPEGGIO, file=rules/quality_check.smk
context_key: ['rule qualimap_allo_pe', 'input', 'else f"{OUTPUT_DIR}Bismark/deduplication/{{sample}}_{{one_or_two}}/{{one_or_two}}.{{sample}}_{str(config[\\\'PAIR_1\\\'])}_val_1_bismark_bt2_pe.deduplicated.bam']
    (340, '        else f"{OUTPUT_DIR}Bismark/deduplication/{{sample}}_{{one_or_two}}/{{one_or_two}}.{{sample}}_{str(config[\\\'PAIR_1\\\'])}_val_1_bismark_bt2_pe.deduplicated.bam"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=supermaxiste/ARPEGGIO, file=rules/quality_check.smk
context_key: ['rule qualimap_allo_pe', 'input', 'else f"{OUTPUT_DIR}Bismark/deduplication/{{sample}}_{{one_or_two}}/{{one_or_two}}.{{sample}}_{str(config[\\\'PAIR_1\\\'])}_bismark_bt2_pe.deduplicated.bam"']
    (342, '        else f"{OUTPUT_DIR}Bismark/deduplication/{{sample}}_{{one_or_two}}/{{one_or_two}}.{{sample}}_{str(config[\\\'PAIR_1\\\'])}_bismark_bt2_pe.deduplicated.bam",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=supermaxiste/ARPEGGIO, file=rules/differential_methylation_analysis.smk
context_key: ['rule dmrseq_CG_special', 'output', 'else f"{OUTPUT_DIR}DMR_analysis/dmrseq/CG_context/A_v_B_polyploid.txt"']
    (237, '        else f"{OUTPUT_DIR}DMR_analysis/dmrseq/CG_context/A_v_B_polyploid.txt",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=supermaxiste/ARPEGGIO, file=rules/differential_methylation_analysis.smk
context_key: ['rule dmrseq_CHG_special', 'output', 'else f"{OUTPUT_DIR}DMR_analysis/dmrseq/CHG_context/A_v_B_polyploid.txt"']
    (259, '        else f"{OUTPUT_DIR}DMR_analysis/dmrseq/CHG_context/A_v_B_polyploid.txt",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=supermaxiste/ARPEGGIO, file=rules/differential_methylation_analysis.smk
context_key: ['rule dmrseq_CHH_special', 'output', 'else f"{OUTPUT_DIR}DMR_analysis/dmrseq/CHH_context/A_v_B_polyploid.txt"']
    (281, '        else f"{OUTPUT_DIR}DMR_analysis/dmrseq/CHH_context/A_v_B_polyploid.txt",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=supermaxiste/ARPEGGIO, file=rules/read_sorting.smk
context_key: ['rule read_sorting_SE', 'input', 'else f"{OUTPUT_DIR}Bismark/deduplication/{{sample}}_1/1.{{sample}}_bismark_bt2.deduplicated.bam"']
    (17, '        else f"{OUTPUT_DIR}Bismark/deduplication/{{sample}}_1/1.{{sample}}_bismark_bt2.deduplicated.bam",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=supermaxiste/ARPEGGIO, file=rules/read_sorting.smk
context_key: ['rule read_sorting_SE', 'input', 'else f"{OUTPUT_DIR}Bismark/deduplication/{{sample}}_2/2.{{sample}}_bismark_bt2.deduplicated.bam"']
    (20, '        else f"{OUTPUT_DIR}Bismark/deduplication/{{sample}}_2/2.{{sample}}_bismark_bt2.deduplicated.bam",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=supermaxiste/ARPEGGIO, file=rules/read_sorting.smk
context_key: ['rule read_sorting_PE', 'input', 'else f"{OUTPUT_DIR}Bismark/deduplication/{{sample}}_1/1.{{sample}}_{str(config[\\\'PAIR_1\\\'])}_bismark_bt2_pe.deduplicated.bam"']
    (48, '        else f"{OUTPUT_DIR}Bismark/deduplication/{{sample}}_1/1.{{sample}}_{str(config[\\\'PAIR_1\\\'])}_bismark_bt2_pe.deduplicated.bam",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=supermaxiste/ARPEGGIO, file=rules/read_sorting.smk
context_key: ['rule read_sorting_PE', 'input', 'else f"{OUTPUT_DIR}Bismark/deduplication/{{sample}}_2/2.{{sample}}_{str(config[\\\'PAIR_1\\\'])}_bismark_bt2_pe.deduplicated.bam"']
    (51, '        else f"{OUTPUT_DIR}Bismark/deduplication/{{sample}}_2/2.{{sample}}_{str(config[\\\'PAIR_1\\\'])}_bismark_bt2_pe.deduplicated.bam",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=supermaxiste/ARPEGGIO, file=rules/downstream.smk
context_key: ['rule dm_regions_bed_special', 'input', 'else (f"{OUTPUT_DIR}DMR_analysis/dmrseq/{{context}}/A_v_B_polyploid.txt")']
    (33, '        else (f"{OUTPUT_DIR}DMR_analysis/dmrseq/{{context}}/A_v_B_polyploid.txt"),')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=supermaxiste/ARPEGGIO, file=rules/downstream.smk
context_key: ['rule dm_regions_bed_special', 'params', 'else (f"{OUTPUT_DIR}DMR_analysis/dmrseq/{{context}}/A_v_B_polyploid_sig")']
    (45, '        else (f"{OUTPUT_DIR}DMR_analysis/dmrseq/{{context}}/A_v_B_polyploid_sig"),')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=supermaxiste/ARPEGGIO, file=rules/alignment.smk
context_key: ['rule bismark_alignment_SE_1', 'input', 'else f"{RAW_DATA_DIR}{{sample}}.{str(config[\\\'RAW_DATA_EXTENSION\\\'])}.gz"']
    (55, '        else f"{RAW_DATA_DIR}{{sample}}.{str(config[\\\'RAW_DATA_EXTENSION\\\'])}.gz",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=supermaxiste/ARPEGGIO, file=rules/alignment.smk
context_key: ['rule bismark_alignment_SE_1', 'output', 'else f"{OUTPUT_DIR}Bismark/{{sample}}_1/1.{{sample}}_bismark_bt2.bam"']
    (59, '        else f"{OUTPUT_DIR}Bismark/{{sample}}_1/1.{{sample}}_bismark_bt2.bam",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=supermaxiste/ARPEGGIO, file=rules/alignment.smk
context_key: ['rule bismark_alignment_SE_1', 'output', 'else f"{OUTPUT_DIR}Bismark/{{sample}}_1/1.{{sample}}_bismark_bt2_SE_report.txt"']
    (62, '        else f"{OUTPUT_DIR}Bismark/{{sample}}_1/1.{{sample}}_bismark_bt2_SE_report.txt",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=supermaxiste/ARPEGGIO, file=rules/alignment.smk
context_key: ['rule bismark_alignment_SE_2', 'input', 'else f"{RAW_DATA_DIR}{{sample}}.{str(config[\\\'RAW_DATA_EXTENSION\\\'])}.gz"']
    (89, '        else f"{RAW_DATA_DIR}{{sample}}.{str(config[\\\'RAW_DATA_EXTENSION\\\'])}.gz",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=supermaxiste/ARPEGGIO, file=rules/alignment.smk
context_key: ['rule bismark_alignment_SE_2', 'output', 'else f"{OUTPUT_DIR}Bismark/{{sample}}_2/2.{{sample}}_bismark_bt2.bam"']
    (93, '        else f"{OUTPUT_DIR}Bismark/{{sample}}_2/2.{{sample}}_bismark_bt2.bam",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=supermaxiste/ARPEGGIO, file=rules/alignment.smk
context_key: ['rule bismark_alignment_SE_2', 'output', 'else f"{OUTPUT_DIR}Bismark/{{sample}}_2/2.{{sample}}_bismark_bt2_SE_report.txt"']
    (96, '        else f"{OUTPUT_DIR}Bismark/{{sample}}_2/2.{{sample}}_bismark_bt2_SE_report.txt",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=supermaxiste/ARPEGGIO, file=rules/alignment.smk
context_key: ['rule bismark_alignment_PE_1', 'input', 'else f"{RAW_DATA_DIR}{{sample}}_{str(config[\\\'PAIR_1\\\'])}.{str(config[\\\'RAW_DATA_EXTENSION\\\'])}.gz"']
    (123, '        else f"{RAW_DATA_DIR}{{sample}}_{str(config[\\\'PAIR_1\\\'])}.{str(config[\\\'RAW_DATA_EXTENSION\\\'])}.gz",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=supermaxiste/ARPEGGIO, file=rules/alignment.smk
context_key: ['rule bismark_alignment_PE_1', 'input', 'else f"{RAW_DATA_DIR}{{sample}}_{str(config[\\\'PAIR_2\\\'])}.{str(config[\\\'RAW_DATA_EXTENSION\\\'])}.gz"']
    (126, '        else f"{RAW_DATA_DIR}{{sample}}_{str(config[\\\'PAIR_2\\\'])}.{str(config[\\\'RAW_DATA_EXTENSION\\\'])}.gz",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=supermaxiste/ARPEGGIO, file=rules/alignment.smk
context_key: ['rule bismark_alignment_PE_1', 'output', 'else f"{OUTPUT_DIR}Bismark/{{sample}}_1/1.{{sample}}_{str(config[\\\'PAIR_1\\\'])}_bismark_bt2_pe.bam"']
    (130, '        else f"{OUTPUT_DIR}Bismark/{{sample}}_1/1.{{sample}}_{str(config[\\\'PAIR_1\\\'])}_bismark_bt2_pe.bam",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=supermaxiste/ARPEGGIO, file=rules/alignment.smk
context_key: ['rule bismark_alignment_PE_1', 'output', 'else f"{OUTPUT_DIR}Bismark/{{sample}}_1/1.{{sample}}_{str(config[\\\'PAIR_1\\\'])}_bismark_bt2_PE_report.txt"']
    (133, '        else f"{OUTPUT_DIR}Bismark/{{sample}}_1/1.{{sample}}_{str(config[\\\'PAIR_1\\\'])}_bismark_bt2_PE_report.txt",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=supermaxiste/ARPEGGIO, file=rules/alignment.smk
context_key: ['rule bismark_alignment_PE_2', 'input', 'else f"{RAW_DATA_DIR}{{sample}}_{str(config[\\\'PAIR_1\\\'])}.{str(config[\\\'RAW_DATA_EXTENSION\\\'])}.gz"']
    (160, '        else f"{RAW_DATA_DIR}{{sample}}_{str(config[\\\'PAIR_1\\\'])}.{str(config[\\\'RAW_DATA_EXTENSION\\\'])}.gz",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=supermaxiste/ARPEGGIO, file=rules/alignment.smk
context_key: ['rule bismark_alignment_PE_2', 'input', 'else f"{RAW_DATA_DIR}{{sample}}_{str(config[\\\'PAIR_2\\\'])}.{str(config[\\\'RAW_DATA_EXTENSION\\\'])}.gz"']
    (163, '        else f"{RAW_DATA_DIR}{{sample}}_{str(config[\\\'PAIR_2\\\'])}.{str(config[\\\'RAW_DATA_EXTENSION\\\'])}.gz",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=supermaxiste/ARPEGGIO, file=rules/alignment.smk
context_key: ['rule bismark_alignment_PE_2', 'output', 'else f"{OUTPUT_DIR}Bismark/{{sample}}_2/2.{{sample}}_{str(config[\\\'PAIR_1\\\'])}_bismark_bt2_pe.bam"']
    (167, '        else f"{OUTPUT_DIR}Bismark/{{sample}}_2/2.{{sample}}_{str(config[\\\'PAIR_1\\\'])}_bismark_bt2_pe.bam",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=supermaxiste/ARPEGGIO, file=rules/alignment.smk
context_key: ['rule bismark_alignment_PE_2', 'output', 'else f"{OUTPUT_DIR}Bismark/{{sample}}_2/2.{{sample}}_{str(config[\\\'PAIR_1\\\'])}_bismark_bt2_PE_report.txt"']
    (170, '        else f"{OUTPUT_DIR}Bismark/{{sample}}_2/2.{{sample}}_{str(config[\\\'PAIR_1\\\'])}_bismark_bt2_PE_report.txt",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Albinam1/bio_inf, file=rules/calling.smk
context_key: ['rule call_variants', 'input', 'else [']
    (23, '            else []')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=iwohlers/lied_egypt_genome, file=Snakefile_metaassembly
context_key: ['rule check_which_egyptrefv2_covers_wtdbg', 'run', 'if line[0] == "#"']
    (71, '                if line[0] == "#":')
    (72, '                    continue')
    (73, '                s = line.split("\\\\t")')
    (74, '                chrom,start,end = s[1:4]')
    (75, '                # Remember to remove "chr" from chromosome')
    (76, '                centromeres.append([chrom[3:],int(start),int(end)])')
    (77, '        # Read in aligned EGYPTREF coordinates')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=iwohlers/lied_egypt_genome, file=Snakefile_metaassembly
context_key: ['rule make_fasta_with_egyptrefv2_added_seq', 'run', 'if line[']
    (141, '                if line[:9] == "gap_chrom":')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=iwohlers/lied_egypt_genome, file=Snakefile_metaassembly
context_key: ['rule make_fasta_with_egyptrefv2_added_seq', 'run', 'if contig in egyptrefv2_seq_coords']
    (144, '                if contig in egyptrefv2_seq_coords:')
    (145, '                    egyptrefv2_seq_coords[contig].append([int(start),int(end)])')
    (146, '                else:')
    (147, '                    egyptrefv2_seq_coords[contig] = [[int(start),int(end)]]')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=iwohlers/lied_egypt_genome, file=Snakefile_metaassembly
context_key: ['rule make_fasta_with_egyptrefv2_added_seq', 'run', 'if record.id in egyptrefv2_seq_coords', 'if seq_name in added_seqs']
    (152, '                if record.id in egyptrefv2_seq_coords:')
    (153, '                    get_seqs = egyptrefv2_seq_coords[record.id]')
    (154, '                    for seq_pos in get_seqs:')
    (155, '                        start = seq_pos[0]')
    (156, '                        end = seq_pos[1]')
    (157, '                        seq_name = record.id+"_"+str(start)+"_"+str(end)')
    (158, '                        # Some seqs would be added multiple times because they')
    (159, "                        # cover more than one gap, thus check for this and don\\'t")
    (160, '                        # add if this is the case')
    (161, '                        if seq_name in added_seqs:')
    (162, '                            continue')
    (163, '                        added_seqs[seq_name] = True')
    (164, '                        # If the sequence is less than ')
    (165, "                        new_record = SeqRecord(record.seq[min(start,end):max(start,end)],seq_name, \\'\\', \\'\\')")
    (166, '                        SeqIO.write(new_record, f_out, "fasta")')
    (167, '')
    (168, '')
    (169, '# Here, we extract a list of partially covered genes in the base wtdbg2 assembly')
    (170, '# For this: get the genes covered in EGYPTREFV2 if they are complete there')
    (171, '# and add a gene to the list only if it is in the base assembly split in minimum ')
    (172, '# three parts and thus likely missing something in between (still we')
    (173, "# don\\'t know this and may make a mistake)")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=iwohlers/lied_egypt_genome, file=Snakefile_metaassembly
context_key: ['rule get_partial_genes_wtdbg2_in_egyptrefv2', 'run', 'if line[']
    (184, '                if line[:2] in ["ID","=="]:')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=iwohlers/lied_egypt_genome, file=Snakefile_metaassembly
context_key: ['rule replace_partial_genes', 'run', 'if line[']
    (254, '                if line[:5] == "gene\\\\t":')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=iwohlers/lied_egypt_genome, file=Snakefile_gwas
context_key: ['rule list_diseases', 'run', 'if line[']
    (49, '                if line[:4] == "DATE":')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=iwohlers/lied_egypt_genome, file=Snakefile_gwas
context_key: ['rule make_disease_specific_gwas_lists', 'run', 'if line[']
    (88, '                    if line[:4] == "DATE":')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=iwohlers/lied_egypt_genome, file=Snakefile_gwas
context_key: ['rule make_disease_specific_gwas_lists', 'run', 'if disease_id == GWAS_CATALOG_DISEASES[i]']
    (93, '                    if disease_id == GWAS_CATALOG_DISEASES[i]:')
    (94, '                        f_out.write(line)                        ')
    (95, '                i += 1 ')
    (96, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=iwohlers/lied_egypt_genome, file=Snakefile_gwas
context_key: ['rule filter_disease_specific_gwas_lists_for_european', 'run', 'if line[']
    (119, '                if line[:5] == "STUDY":')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=iwohlers/lied_egypt_genome, file=Snakefile_gwas
context_key: ['rule filter_disease_specific_gwas_lists_for_european', 'run', 'if ancestry == "European"']
    (126, '                if ancestry == "European":')
    (127, '                    study_accessions[s[0]] = True')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=iwohlers/lied_egypt_genome, file=Snakefile_gwas
context_key: ['rule filter_disease_specific_gwas_lists_for_european', 'run', 'if line[']
    (130, '                if line[:4] == "DATE":')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=iwohlers/lied_egypt_genome, file=Snakefile_gwas
context_key: ['rule filter_disease_specific_gwas_lists_for_european', 'run', 'if study_accession in study_accessions']
    (135, '                if study_accession in study_accessions:')
    (136, '                    f_out.write(line)')
    (137, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=iwohlers/lied_egypt_genome, file=Snakefile_gwas
context_key: ['rule filter_disease_specific_gwas_lists_for_recurrent_loci', 'run', 'if line[']
    (162, '                if line[:4] == "DATE":')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=iwohlers/lied_egypt_genome, file=Snakefile_gwas
context_key: ['rule filter_disease_specific_gwas_lists_for_recurrent_loci', 'run', 'if s[12] == "" or "x" in s[12] or ";" in s[12]']
    (167, '                if s[12] == "" or "x" in s[12] or ";" in s[12]:')
    (168, '                    continue')
    (169, '                pos = int(s[12])')
    (170, '                positions.append([chrom,pos,line])')
    (171, '        # Go again over the associations')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=iwohlers/lied_egypt_genome, file=Snakefile_gwas
context_key: ['rule filter_disease_specific_gwas_lists_for_recurrent_loci', 'run', 'if line[']
    (174, '                if line[:4] == "DATE":')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=iwohlers/lied_egypt_genome, file=Snakefile_gwas
context_key: ['rule filter_disease_specific_gwas_lists_for_recurrent_loci', 'run', 'if s[12] == "" or "x" in s[12] or ";" in s[12]']
    (180, '                if s[12] == "" or "x" in s[12] or ";" in s[12]:')
    (181, '                    continue')
    (182, '                pos = int(s[12])')
    (183, '                for prev_chrom,prev_pos,prev_line in positions:')
    (184, '                    if prev_line == line or not chrom == prev_chrom:')
    (185, '                        continue')
    (186, '                    if abs(pos-prev_pos)<1000000:')
    (187, '                        f_out.write(line)')
    (188, '                        break')
    (189, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=iwohlers/lied_egypt_genome, file=Snakefile_gwas
context_key: ['rule extract_european_1000g', 'run', 'if s[6] in POPULATIONS_EUR and s[13] == "1"']
    (212, '                if s[6] in POPULATIONS_EUR and s[13] == "1":')
    (213, '                    f_out.write(s[1]+"\\')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=iwohlers/lied_egypt_genome, file=Snakefile_gwas
context_key: ['rule get_snp_ids', 'run', 'if line[']
    (263, '                if line[:4] == "DATE":')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=iwohlers/lied_egypt_genome, file=Snakefile_gwas
context_key: ['rule num_recurrentloci_in_vcf_per_disease', 'run', 'if line.decode()[0] == "#"']
    (299, '                    if line.decode()[0] == "#":')
    (300, '                        continue')
    (301, '                    num_ass += 1')
    (302, '                f_out.write(GWAS_CATALOG_DISEASES_LOCI[i]+"\\\\t"+str(num_ass)+"\\')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=iwohlers/lied_egypt_genome, file=Snakefile_gwas
context_key: ['rule num_recurrentloci_in_ld_per_disease', 'run', 'if line[0] == "CHR"']
    (338, '                    if line[0] == "CHR":')
    (339, '                        continue')
    (340, '                    num_ass += 1')
    (341, '                f_out.write(GWAS_CATALOG_DISEASES_LOCI_VCF[i]+"\\\\t"+str(num_ass)+"\\')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=iwohlers/lied_egypt_genome, file=Snakefile_gwas
context_key: ['rule keep_one_variant_per_locus', 'run', 'if line[']
    (372, '                if line[:3] == "CHR":')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=iwohlers/lied_egypt_genome, file=Snakefile_gwas
context_key: ['rule keep_one_variant_per_locus', 'run', 'if line[']
    (382, '                if line[:4] == "DATE":')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=iwohlers/lied_egypt_genome, file=Snakefile_gwas
context_key: ['rule keep_one_variant_per_locus', 'run', 'if "\\\\t".join([chrom,pos]) in position_count']
    (388, '                if "\\\\t".join([chrom,pos]) in position_count:')
    (389, '                    position_count["\\\\t".join([chrom,pos])] += 1')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=iwohlers/lied_egypt_genome, file=Snakefile_gwas
context_key: ['rule keep_one_variant_per_locus', 'run', 'if not chrom == loc_chrom']
    (398, '                if not chrom == loc_chrom:')
    (399, '                    continue')
    (400, '                if (int(pos)-int(loc_pos)) <= 1000000:')
    (401, '                    locus_new = False')
    (402, '            if locus_new:')
    (403, '                loci.append([chrom,pos])')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=iwohlers/lied_egypt_genome, file=Snakefile_gwas
context_key: ['rule keep_one_variant_per_locus', 'run', 'if line[']
    (409, '                if line[:4] == "DATE":')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=iwohlers/lied_egypt_genome, file=Snakefile_gwas
context_key: ['rule keep_one_variant_per_locus', 'run', 'if [chrom,pos] in loci']
    (415, '                if [chrom,pos] in loci:')
    (416, '                    f_out.write(line)')
    (417, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=iwohlers/lied_egypt_genome, file=Snakefile_gwas
context_key: ['rule compare_tag_af', 'run', 'if line[']
    (498, '                if line[:5] == "CHROM":')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=iwohlers/lied_egypt_genome, file=Snakefile_gwas
context_key: ['rule num_proxy_snps', 'run', 'if line[']
    (740, '                if line[:5] == "CHROM":')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=iwohlers/lied_egypt_genome, file=Snakefile_gwas
context_key: ['rule compare_proxy_snps', 'run', 'if line[']
    (794, '                if line[:3] == "CHR":')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=iwohlers/lied_egypt_genome, file=Snakefile_gwas
context_key: ['rule compare_proxy_snps', 'run', 'if line[']
    (805, '                if line[:3] == "CHR":')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=iwohlers/lied_egypt_genome, file=Snakefile_gwas
context_key: ['rule compare_proxy_snps', 'run', 'if chrom_pos in proxy_eur']
    (808, '                if chrom_pos in proxy_eur:')
    (809, '                    same_proxy += 1')
    (810, '                else:')
    (811, '                    egp_only += 1')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=iwohlers/lied_egypt_genome, file=Snakefile_gwas
context_key: ['rule annotated_loci_files', 'run', 'if line[']
    (843, '                if line[:5] == "CHROM":')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=iwohlers/lied_egypt_genome, file=Snakefile_gwas
context_key: ['rule annotated_loci_files', 'run', 'if line[']
    (852, '                if line[:4] == "DATE":')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=iwohlers/lied_egypt_genome, file=Snakefile_gwas
context_key: ['rule combine_annotated_loci_files_all', 'run', 'if line[']
    (871, '                        if line[:4] == "DATE":                ')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=iwohlers/lied_egypt_genome, file=Snakefile_gwas
context_key: ['rule combine_annotated_loci_files_all', 'run', 'if not header_written']
    (872, '                            if not header_written:')
    (873, '                                f_out.write(line)')
    (874, '                                header_written = True')
    (875, '                            continue')
    (876, '                        f_out.write(line)')
    (877, '                        ')
    (878, '')
    (879, '')
    (880, '')
    (881, '########### Matching Egyptian population-specific variants and GWAS data #######')
    (882, '')
    (883, '# Extract those Egyptian population-specific SNPs that are within 100kb of a SNP ')
    (884, '# listed in the GWAS catalog')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=iwohlers/lied_egypt_genome, file=Snakefile_gwas
context_key: ['rule egyptian_popspecific_in_proximity', 'run', 'if line[']
    (897, "                if line[:3] == \\'chr\\':")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=iwohlers/lied_egypt_genome, file=Snakefile_gwas
context_key: ['rule egyptian_popspecific_in_proximity', 'run', 'if chrom in pop_spec']
    (903, '                if chrom in pop_spec:')
    (904, '                    pop_spec[chrom].append([chrom,int(pos),line])')
    (905, '                else:')
    (906, '                    pop_spec[chrom] = [[chrom,int(pos),line]]')
    (907, '        # Go over the GWAS catalog lines associations for this disease')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=iwohlers/lied_egypt_genome, file=Snakefile_gwas
context_key: ['rule egyptian_popspecific_in_proximity', 'run', 'if line[']
    (911, '                if line[:4] == "DATE":')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=iwohlers/lied_egypt_genome, file=Snakefile_gwas
context_key: ['rule egyptian_sv_in_proximity', 'run', "if line[0] == \\'##\\'"]
    (951, "                if line[0] == \\'##\\':")
    (952, '                    continue')
    (953, "                if line[0] == \\'#\\':")
    (954, '                    header_pop = line[1:]')
    (955, '                    continue')
    (956, '                s = line.split("\\\\t")')
    (957, '                # Only consider passing SV calls')
    (958, '                if not s[6] == "PASS":')
    (959, '                    continue')
    (960, '                chrom = s[0]')
    (961, '                if chrom[:3] == "chr":')
    (962, '                    chrom = chrom[3:]')
    (963, '                pos = s[1]')
    (964, '                if chrom in svs:')
    (965, '                    svs[chrom].append([chrom,int(pos),line])')
    (966, '                else:')
    (967, '                    svs[chrom] = [[chrom,int(pos),line]]')
    (968, '                # Get the end position')
    (969, '                chr2 = ""')
    (970, '                pos2 = ""')
    (971, '                for entry in s[7].split(";"):')
    (972, '                    if not len(entry.split("=")) == 2:')
    (973, '                        continue')
    (974, '                    first,second = entry.split("=")')
    (975, '                    if first == "CHR2":')
    (976, '                        chrom2 = second')
    (977, '                        if chrom2[:3] == "chr":')
    (978, '                            chrom2 = chrom2[3:]')
    (979, '                    if first == "END":')
    (980, '                        assert(chrom == chrom2)')
    (981, '                        if chrom2 in svs:')
    (982, '                            svs[chrom2].append([chrom2,int(pos),line])')
    (983, '                        else:')
    (984, '                            svs[chrom2] = [[chrom2,int(pos),line]]')
    (985, '        # Go over the GWAS catalog lines associations for this disease')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=iwohlers/lied_egypt_genome, file=Snakefile_gwas
context_key: ['rule egyptian_sv_in_proximity', 'run', 'if line[']
    (989, '                if line[:4] == "DATE":')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=sinanugur/RNAseq-variant-calling, file=workflow/Snakefile
context_key: ['rule all', 'elif route == "bowtie1"', 'elif route == "stats" or route == "statistics"', 'else']
    (30, 'elif route == "bowtie1":')
    (31, '\\tprint("Bowtie1 route has been selected")')
    (32, '\\trule all_bowtie1:')
    (33, '\\t\\tinput:')
    (34, '\\t\\t\\texpand("analyses/bowtie1_mappings/{sample}.sorted.bam",sample=files)')
    (35, '')
    (36, '')
    (37, 'elif route == "stats" or route == "statistics":')
    (38, '\\tprint("Statistics route has been selected. This workflow requires Bowtie1 outputs")')
    (39, '\\trule statistics:')
    (40, '\\t\\tinput:')
    (41, '\\t\\t\\texpand("analyses/bowtie1_mappings/{sample}.sorted.bam",sample=files)')
    (42, '\\t')
    (43, '')
    (44, 'else:')
    (45, '\\tprint("Please select a correct route...")')
    (46, '\\tprint("bowtie1/bowtie2")')
    (47, ' """')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=singleron-RD/Dna-seq_Analysis, file=workflow/rules/calling.smk
context_key: ['rule call_variants', 'input', 'else [']
    (23, '            else []')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=singleron-RD/Dna-seq_Analysis, file=workflow/rules/filtering.smk
context_key: ['rule merge_calls', 'input', 'else "hardfiltered"']
    (54, '            else "hardfiltered",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AAFC-BICoE/snakemake-partial-genome-pipeline, file=Snakefile
context_key: ['rule gather_assemblies', 'run', 'if os.path.exists(input.assembly)', 'if os.path.exists("phyluce-spades/assemblies")']
    (215, '        if os.path.exists(input.assembly):')
    (216, '            if os.path.exists("phyluce-spades/assemblies"):')
    (217, '                pass')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AAFC-BICoE/snakemake-partial-genome-pipeline, file=Snakefile
context_key: ['rule gather_assemblies', 'run', 'if os.path.exists(input.assembly)', 'else']
    (218, '            else:')
    (219, '                os.path.mkdir("phyluce-spades/assemblies")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AAFC-BICoE/snakemake-partial-genome-pipeline, file=Snakefile
context_key: ['rule gather_assemblies', 'run', 'if os.path.exists(input.assembly)']
    (220, '            copyfile(input.assembly,output.renamed_assembly)')
    (221, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AAFC-BICoE/snakemake-partial-genome-pipeline, file=Snakefile
context_key: ['rule gather_rna_assemblies', 'run', 'if os.path.exists(input.assembly)', 'if os.path.exists("phyluce-rnaspades/assemblies")']
    (316, '        if os.path.exists(input.assembly):')
    (317, '            if os.path.exists("phyluce-rnaspades/assemblies"):')
    (318, '                pass')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AAFC-BICoE/snakemake-partial-genome-pipeline, file=Snakefile
context_key: ['rule gather_rna_assemblies', 'run', 'if os.path.exists(input.assembly)', 'else']
    (319, '            else:')
    (320, '                os.path.mkdir("phyluce-rnaspades/assemblies")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AAFC-BICoE/snakemake-partial-genome-pipeline, file=Snakefile
context_key: ['rule gather_rna_assemblies', 'run', 'if os.path.exists(input.assembly)']
    (321, '            copyfile(input.assembly,output.renamed_assembly)')
    (322, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=yplakaka/imcsegmentation, file=workflow/Snakefile
context_key: ['rule modify_measurement_pipeline', 'run', 'if line.rstrip()']
    (536, '                        if line.rstrip())')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=yplakaka/imcsegmentation, file=workflow/Snakefile
context_key: ['rule download_example_data', 'run', 'if ~fn.exists()']
    (614, '            if ~fn.exists():')
    (615, '                shutil.move(fn_cache[0], fn)')
    (616, '')
    (617, '### Varia')
    (618, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=mptrsen/gatk-variant-calling, file=rules/filtering.smk
context_key: ['rule merge_calls', 'input', 'else "hardfiltered"']
    (58, '                              else "hardfiltered")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=kcivkulis/stag-mwc, file=rules/mappers/bbmap.smk
context_key: ['rule', 'if bbmap_config["counts_table"]["annotations"] and not bbmap_config["counts_table"]["columns"]']
    (101, '    if bbmap_config["counts_table"]["annotations"] and not bbmap_config["counts_table"]["columns"]:')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Albinam1/day_7, file=rules/calling.smk
context_key: ['rule call_variants', 'input', 'else [']
    (23, '            else []')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=osvaldoreisss/polya-seq_workflow_analysis, file=workflow/rules/filter.smk
context_key: ['rule feauture_distribution_peak', 'run', 'if feature in res']
    (86, '                    if feature in res:')
    (87, '                        out.append(res[feature])')
    (88, '                    else:')
    (89, '                        out.append(0)')
    (90, "                # res = [res[\\'five_prime_utr\\'], res[\\'three_prime_utr\\'],res[\\'CDS\\'], res[\\'ncRNA\\'], res[\\'tRNA\\'], res[\\'snoRNA\\'], res[\\'snRNA\\'], res[\\'pseudogene\\'], res[\\'transposable_element\\']]")
    (91, '                df_tmp = pd.DataFrame(out).T')
    (92, '                df_tmp.index = [file.split("/")[2].split(".")[0]]')
    (93, '                df = df.append(df_tmp)')
    (94, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=osvaldoreisss/polya-seq_workflow_analysis, file=workflow/rules/filter.smk
context_key: ['rule feauture_distribution', 'run', 'if feature in res']
    (145, '                    if feature in res:')
    (146, '                        out.append(res[feature])')
    (147, '                    else:')
    (148, '                        out.append(0)')
    (149, "                # res = [res[\\'five_prime_utr\\'], res[\\'three_prime_utr\\'],res[\\'CDS\\'], res[\\'ncRNA\\'], res[\\'tRNA\\'], res[\\'snoRNA\\'], res[\\'snRNA\\'], res[\\'pseudogene\\'], res[\\'transposable_element\\']]")
    (150, '                df_tmp = pd.DataFrame(out).T')
    (151, '                df_tmp.index = [file.split("/")[2].split(".")[0]]')
    (152, '                df = df.append(df_tmp)')
    (153, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=osvaldoreisss/polya-seq_workflow_analysis, file=workflow/rules/filter.smk
context_key: ['rule select_peak_reads_by_name', 'run', 'if line.read.name in read_set']
    (223, '            if line.read.name in read_set:')
    (224, '                bam_writer.write(line)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=osvaldoreisss/polya-seq_workflow_analysis, file=workflow/rules/filter.smk
context_key: ['rule plot_premature_polyadenylation_x_expression', 'run', 'if "cds_out" in file']
    (327, '            if "cds_out" in file:')
    (328, '                df_tmp = pd.read_csv(')
    (329, '                    file, sep="\\\\t", header=None, index_col=0')
    (330, '                ).sort_index()')
    (331, '                if not df_cds.empty:')
    (332, '                    df_cds = df_cds + df_tmp')
    (333, '                else:')
    (334, '                    df_cds = df_tmp')
    (335, '                cds_file_count += 1')
    (336, '            elif "three_out" in file:')
    (337, '                df_tmp = pd.read_csv(')
    (338, '                    file, sep="\\\\t", header=None, index_col=0')
    (339, '                ).sort_index()')
    (340, '                if not df_three.empty:')
    (341, '                    df_three = df_three + df_tmp')
    (342, '                else:')
    (343, '                    df_three = df_tmp.copy()')
    (344, '                three_file_count += 1')
    (345, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=osvaldoreisss/polya-seq_workflow_analysis, file=workflow/rules/filter.smk
context_key: ['rule plot_polyadenylation_in_cds_with_stop_in_frame', 'run', 'if cond in cond_dict_out_frame.keys()']
    (460, '                if cond in cond_dict_out_frame.keys():')
    (461, '                    cond_dict_out_frame[cond].append(res["out_frame"])')
    (462, '                else:')
    (463, '                    cond_dict_out_frame[cond] = []')
    (464, '                    cond_dict_out_frame[cond].append(res["out_frame"])')
    (465, '                if cond in cond_dict_in_frame.keys():')
    (466, '                    cond_dict_in_frame[cond].append(res["in_frame"])')
    (467, '                else:')
    (468, '                    cond_dict_in_frame[cond] = []')
    (469, '                    cond_dict_in_frame[cond].append(res["in_frame"])')
    (470, '')
    (471, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=osvaldoreisss/polya-seq_workflow_analysis, file=workflow/rules/filter.smk
context_key: ['rule plot_polyadenylation_in_cds_by_condition', 'run', 'if cond in cond_dict_cds.keys()']
    (575, '                if cond in cond_dict_cds.keys():')
    (576, '                    cond_dict_cds[cond].append(res["CDS"])')
    (577, '                else:')
    (578, '                    cond_dict_cds[cond] = []')
    (579, '                    cond_dict_cds[cond].append(res["CDS"])')
    (580, '                if cond in cond_dict_five.keys():')
    (581, '                    cond_dict_five[cond].append(res["five_prime_utr"])')
    (582, '                else:')
    (583, '                    cond_dict_five[cond] = []')
    (584, '                    cond_dict_five[cond].append(res["five_prime_utr"])')
    (585, '                if cond in cond_dict_three.keys():')
    (586, '                    cond_dict_three[cond].append(res["three_prime_utr"])')
    (587, '                else:')
    (588, '                    cond_dict_three[cond] = []')
    (589, '                    cond_dict_three[cond].append(res["three_prime_utr"])')
    (590, '')
    (591, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=osvaldoreisss/polya-seq_workflow_analysis, file=workflow/rules/filter.smk
context_key: ['rule plot_polyadenylation_in_cds_by_condition', 'run', 'if i == 0']
    (623, '            if i == 0:')
    (624, '                pvalue_list.append(1)')
    (625, '                significance_list.append(False)')
    (626, '            else:')
    (627, '                statistic, pvalue = stats.ttest_ind(')
    (628, '                    data[conditions_labels[0]], data[conditions_labels[i]]')
    (629, '                )')
    (630, '                print(')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=hydra-genetics/qc, file=workflow/rules/multiqc.smk
context_key: ['rule multiqc', 'input', 'if u.type in config["multiqc"]["reports"][wildcards.report]["included_unit_types"']
    (14, '                if u.type in config["multiqc"]["reports"][wildcards.report]["included_unit_types"]')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=hydra-genetics/qc, file=workflow/rules/multiqc.smk
context_key: ['rule multiqc', 'params', 'if "config" in config.get("multiqc", {}).get("reports", {}).get(wildcards.report, {}']
    (26, '            if "config" in config.get("multiqc", {}).get("reports", {}).get(wildcards.report, {})')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=hydra-genetics/qc, file=workflow/rules/multiqc.smk
context_key: ['rule multiqc', 'params', 'else ""']
    (27, '            else "",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=BodenmillerGroup/ImcSegmentationSnakemake, file=workflow/Snakefile
context_key: ['rule modify_measurement_pipeline', 'run', 'if line.rstrip()']
    (536, '                        if line.rstrip())')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=BodenmillerGroup/ImcSegmentationSnakemake, file=workflow/Snakefile
context_key: ['rule download_example_data', 'run', 'if ~fn.exists()']
    (614, '            if ~fn.exists():')
    (615, '                shutil.move(fn_cache[0], fn)')
    (616, '')
    (617, '### Varia')
    (618, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=tanaes/snake_strainer, file=snakefiles/drep.smk
context_key: ['rule import_genome_list', 'run', 'if isfile(genome_path)']
    (48, '            if isfile(genome_path):')
    (49, '                shutil.copy(genome_path, fname)')
    (50, '            elif is_url(genome_path):')
    (51, '                urlretrieve(genome_path, fname)')
    (52, '')
    (53, '            if is_gzip(fname):')
    (54, "                rename(fname, \\'%s.gz\\' % fname)")
    (55, "                with gzip.open(\\'%s.gz\\' % fname, \\'rb\\') as f_in:")
    (56, "                    with open(fname, \\'wb\\') as f_out:")
    (57, '                        shutil.copyfileobj(f_in, f_out)')
    (58, "                remove(\\'%s.gz\\' % fname)")
    (59, '')
    (60, "            path_list += \\'%s\\")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlthafSinghawansaUHN/cfmedipseq_pipeline, file=Snakefile
context_key: ['rule extract_barcodes', 'run', 'if params.bpattern is None', 'if params.blist is None']
    (265, '        if params.bpattern is None:')
    (266, '            if params.blist is None:')
    (267, '                shell("cp {input.R1} > {output.R1}")')
    (268, '                shell("cp {input.R2} > {output.R2}")')
    (269, '                shell("touch {output.stats}")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlthafSinghawansaUHN/cfmedipseq_pipeline, file=Snakefile
context_key: ['rule extract_barcodes', 'run', 'if params.bpattern is None', 'else']
    (270, '            else:')
    (271, '                shell("python {params.extract_barcodes} --read1 {input.R1} --read2 {input.R2} --outfile {params.outprefix} --blist {params.blist}")')
    (272, '                shell("cp {params.barcode_stats_tmp_path} {params.barcode_stats_out_path}")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlthafSinghawansaUHN/cfmedipseq_pipeline, file=Snakefile
context_key: ['rule merge_QSEA_count', 'run', 'if i == 0']
    (719, '            if i == 0:')
    (720, "                input_data.to_csv(output[0], header=True, sep=\\'\\\\t\\', index=False)")
    (721, '            else:')
    (722, "                input_data.to_csv(output[0], header=False, sep=\\'\\\\t\\', index=False, mode=\\'a\\')")
    (723, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlthafSinghawansaUHN/cfmedipseq_pipeline, file=Snakefile
context_key: ['rule merge_QSEA_beta', 'run', 'if i == 0']
    (733, '            if i == 0:')
    (734, "                input_data.to_csv(output[0], header=True, sep=\\'\\\\t\\', index=False)")
    (735, '            else:')
    (736, "                input_data.to_csv(output[0], header=False, sep=\\'\\\\t\\', index=False, mode=\\'a\\')")
    (737, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=AlthafSinghawansaUHN/cfmedipseq_pipeline, file=Snakefile
context_key: ['rule merge_QSEA_QCStats', 'run', 'if i == 0']
    (747, '            if i == 0:')
    (748, "                input_data.to_csv(output[0], header=True, sep=\\'\\\\t\\', index=False)")
    (749, '            else:')
    (750, "                input_data.to_csv(output[0], header=False, sep=\\'\\\\t\\', index=False, mode=\\'a\\')")
    (751, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=cmdoret/Acastellanii_hybrid_assembly, file=rules/01_reads_processing.smk
context_key: ['rule combine_units', 'run', 'if len(input[']
    (32, '    if len(input[:]) > 1:')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=cmdoret/Acastellanii_hybrid_assembly, file=rules/01_reads_processing.smk
context_key: ['rule combine_units', 'run', "if len(params[\\'r2\\'])"]
    (34, "      if len(params[\\'r2\\']):")
    (35, '        shell(f"cat {\\\' \\\'.join(params[\\\'r2\\\'])} > {output[\\\'r2\\\']}")')
    (36, '      else:')
    (37, '        shell(f"touch {output[\\\'r2\\\']}")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=cmdoret/Acastellanii_hybrid_assembly, file=rules/01_reads_processing.smk
context_key: ['rule combine_units', 'run', 'else', "if len(params[\\'r2\\'])"]
    (40, "      if len(params[\\'r2\\']):")
    (41, '        shell(f"ln -s $PWD/{params[\\\'r2\\\'][0]} {output[\\\'r2\\\']}")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Monia234/LocalAncestry_RFmix_admixture, file=Snakefile
context_key: ['rule merge_rfmix_output', 'input', 'if wildcards.chr not in ACROCENTRIC else \\']
    (287, '            if wildcards.chr not in ACROCENTRIC else \\\\')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Monia234/LocalAncestry_RFmix_admixture, file=Snakefile
context_key: ['rule merge_rfmix_output', 'input', 'if wildcards.chr not in ACROCENTRIC else \\']
    (291, '            if wildcards.chr not in ACROCENTRIC else \\\\')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Monia234/LocalAncestry_RFmix_admixture, file=Snakefile
context_key: ['rule merge_rfmix_output', 'input', 'if wildcards.chr not in ACROCENTRIC else \\']
    (295, '            if wildcards.chr not in ACROCENTRIC else \\\\')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Monia234/LocalAncestry_RFmix_admixture, file=Snakefile
context_key: ['rule merge_phasing', 'input', 'if wildcards.chr not in ACROCENTRIC else \\']
    (457, '            if wildcards.chr not in ACROCENTRIC else \\\\')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=cnio-bu/varca, file=rules/filtering.smk
context_key: ['rule recalibrate_calls', 'params', 'if wc.vartype == "snvs']
    (61, '                if wc.vartype == "snvs"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=cnio-bu/varca, file=rules/filtering.smk
context_key: ['rule recalibrate_calls', 'params', 'else "INDEL"']
    (62, '                else "INDEL",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=cnio-bu/varca, file=rules/filtering.smk
context_key: ['rule merge_calls', 'input', 'else "hardfiltered"']
    (81, '                              else "hardfiltered")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=nkimoto/GATK_pipeline, file=rules/filtering.smk
context_key: ['rule merge_calls', 'input', 'else "hardfiltered"']
    (58, '                              else "hardfiltered")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=LUMC/HAMLET, file=includes/snv-indels/Snakefile
context_key: ['rule annotate_vars', 'params', 'else ""']
    (311, '        else "",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=BleekerLab/freebayes_snp_calling, file=Snakefile
context_key: ['rule bwa_align', 'run', 'if is_single_end(wildcards.sample, wildcards.unit)']
    (310, '        if is_single_end(wildcards.sample, wildcards.unit):')
    (311, '            shell("bwa mem -v 1 -t {threads} -R \\\'@RG\\\\\\\\tID:{READ_GROUP}\\\\\\\\tPL:ILLUMINA\\\\\\\\tLB:{wildcards.unit}\\\\\\\\tSM:{wildcards.sample}\\\' {params.db_prefix} {input.forward} >{output}")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=BleekerLab/freebayes_snp_calling, file=Snakefile
context_key: ['rule uncompress', 'run', 'if is_single_end(wildcards.sample, wildcards.unit)']
    (325, '        if is_single_end(wildcards.sample, wildcards.unit):')
    (326, '            shell("gzip -cd {input.forward} > {output.forward};touch {output.reverse}")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=BleekerLab/freebayes_snp_calling, file=Snakefile
context_key: ['rule fastp', 'run', 'if is_single_end(wildcards.sample, wildcards.unit)']
    (384, '        if is_single_end(wildcards.sample, wildcards.unit):')
    (385, '            shell("fastp --thread {threads}  --html {output.html} --json {output.json} \\\\')
    (386, '            --qualified_quality_phred {params.qualified_quality_phred} \\\\')
    (387, '            --max_len1 {params.maximum_read_length} \\\\')
    (388, '            --in1 {input} --out1 {output} \\\\')
    (389, '            2> {log}; \\\\')
    (390, '            touch {output.fq2}")')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Finn-Lab/skin_microbiome, file=modules/coas.Snakefile
context_key: ['rule readcounts_coas', 'run', 'if os.path.exists(outfile)']
    (90, '        if os.path.exists(outfile):')
    (91, '            os.remove(outfile)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=Finn-Lab/skin_microbiome, file=euk.Snakefile
context_key: ['rule make_csv', 'run', 'if float(completeness)>50 and float(contamination)<5']
    (85, '             if float(completeness)>50 and float(contamination)<5:')
    (86, "                  g.write(run+\\',\\'+completeness+\\',\\'+contamination+\\'\\")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NCI-CGR/GEMSCAN, file=workflow/rules/Snakefile_DeepVariant
context_key: ['rule DV_create_cohort_manifest', 'params', 'if by_chro']
    (104, '            if by_chrom')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NCI-CGR/GEMSCAN, file=workflow/rules/Snakefile_DeepVariant
context_key: ['rule DV_create_cohort_manifest', 'params', 'else outputDir + "deepVariant/called/gvcfs/']
    (105, '            else outputDir + "deepVariant/called/gvcfs/"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NCI-CGR/GEMSCAN, file=workflow/rules/Snakefile_DeepVariant
context_key: ['rule DV_GLmerge_gvcfs', 'input', 'if by_chro']
    (136, '            if by_chrom')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NCI-CGR/GEMSCAN, file=workflow/rules/Snakefile_DeepVariant
context_key: ['rule DV_GLmerge_gvcfs', 'input', 'else expand("deepVariant/called_by_sample/{sample}.g.vcf.gz", sample=sampleList']
    (137, '            else expand("deepVariant/called_by_sample/{sample}.g.vcf.gz", sample=sampleList)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NCI-CGR/GEMSCAN, file=workflow/rules/Snakefile_DeepVariant
context_key: ['rule DV_GLmerge_gvcfs', 'input', 'if by_chro']
    (141, '            if by_chrom')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NCI-CGR/GEMSCAN, file=workflow/rules/Snakefile_DeepVariant
context_key: ['rule DV_GLmerge_gvcfs', 'input', 'else "deepVariant/called/gvcfs/manifest.txt']
    (142, '            else "deepVariant/called/gvcfs/manifest.txt"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NCI-CGR/GEMSCAN, file=workflow/rules/Snakefile_DeepVariant
context_key: ['rule DV_run_deepvariant', 'output', 'if by_chro']
    (200, '            if by_chrom')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NCI-CGR/GEMSCAN, file=workflow/rules/Snakefile_DeepVariant
context_key: ['rule DV_run_deepvariant', 'output', 'else "deepVariant/called_by_sample/{sample}.vcf.gz']
    (201, '            else "deepVariant/called_by_sample/{sample}.vcf.gz"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NCI-CGR/GEMSCAN, file=workflow/rules/Snakefile_DeepVariant
context_key: ['rule DV_run_deepvariant', 'output', 'if by_chro']
    (205, '            if by_chrom')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NCI-CGR/GEMSCAN, file=workflow/rules/Snakefile_DeepVariant
context_key: ['rule DV_run_deepvariant', 'output', 'else "deepVariant/called_by_sample/{sample}.vcf.gz.tbi']
    (206, '            else "deepVariant/called_by_sample/{sample}.vcf.gz.tbi"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NCI-CGR/GEMSCAN, file=workflow/rules/Snakefile_DeepVariant
context_key: ['rule DV_run_deepvariant', 'output', 'if by_chro']
    (210, '            if by_chrom')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NCI-CGR/GEMSCAN, file=workflow/rules/Snakefile_DeepVariant
context_key: ['rule DV_run_deepvariant', 'output', 'else "deepVariant/called_by_sample/{sample}.g.vcf.gz']
    (211, '            else "deepVariant/called_by_sample/{sample}.g.vcf.gz"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NCI-CGR/GEMSCAN, file=workflow/rules/Snakefile_DeepVariant
context_key: ['rule DV_run_deepvariant', 'output', 'if by_chro']
    (215, '            if by_chrom')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NCI-CGR/GEMSCAN, file=workflow/rules/Snakefile_DeepVariant
context_key: ['rule DV_run_deepvariant', 'output', 'else "deepVariant/called_by_sample/{sample}.g.vcf.gz.tbi']
    (216, '            else "deepVariant/called_by_sample/{sample}.g.vcf.gz.tbi"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NCI-CGR/GEMSCAN, file=workflow/rules/Snakefile_Strelka2
context_key: ['rule strelka2_AddSampleName', 'input', 'if by_chro']
    (20, '            if by_chrom')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NCI-CGR/GEMSCAN, file=workflow/rules/Snakefile_Strelka2
context_key: ['rule strelka2_AddSampleName', 'input', 'else "strelka2/calledBySample/{sample}/results/variants/genome.S1.vcf.gz']
    (21, '            else "strelka2/calledBySample/{sample}/results/variants/genome.S1.vcf.gz"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NCI-CGR/GEMSCAN, file=workflow/rules/Snakefile_Strelka2
context_key: ['rule strelka2_AddSampleName', 'input', 'if by_chro']
    (25, '            if by_chrom')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NCI-CGR/GEMSCAN, file=workflow/rules/Snakefile_Strelka2
context_key: ['rule strelka2_AddSampleName', 'input', 'else "strelka2/calledBySample/{sample}/results/variants/genome.S1.vcf.gz.tbi']
    (26, '            else "strelka2/calledBySample/{sample}/results/variants/genome.S1.vcf.gz.tbi"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NCI-CGR/GEMSCAN, file=workflow/rules/Snakefile_Strelka2
context_key: ['rule strelka2_AddSampleName', 'output', 'if by_chro']
    (31, '            if by_chrom')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NCI-CGR/GEMSCAN, file=workflow/rules/Snakefile_Strelka2
context_key: ['rule strelka2_AddSampleName', 'output', 'else "strelka2/called/genome.{sample}.vcf.gz']
    (32, '            else "strelka2/called/genome.{sample}.vcf.gz"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NCI-CGR/GEMSCAN, file=workflow/rules/Snakefile_Strelka2
context_key: ['rule strelka2_AddSampleName', 'output', 'if by_chro']
    (36, '            if by_chrom')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NCI-CGR/GEMSCAN, file=workflow/rules/Snakefile_Strelka2
context_key: ['rule strelka2_AddSampleName', 'output', 'else "strelka2/called/genome.{sample}.vcf.gz.tbi']
    (37, '            else "strelka2/called/genome.{sample}.vcf.gz.tbi"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NCI-CGR/GEMSCAN, file=workflow/rules/Snakefile_Strelka2
context_key: ['rule strelka2_callVariant', 'output', 'if by_chro']
    (73, '            if by_chrom')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NCI-CGR/GEMSCAN, file=workflow/rules/Snakefile_Strelka2
context_key: ['rule strelka2_callVariant', 'output', 'else "strelka2/calledBySample/{sample}/results/variants/genome.S1.vcf.gz']
    (74, '            else "strelka2/calledBySample/{sample}/results/variants/genome.S1.vcf.gz"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NCI-CGR/GEMSCAN, file=workflow/rules/Snakefile_Strelka2
context_key: ['rule strelka2_callVariant', 'output', 'if by_chro']
    (78, '            if by_chrom')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NCI-CGR/GEMSCAN, file=workflow/rules/Snakefile_Strelka2
context_key: ['rule strelka2_callVariant', 'output', 'else "strelka2/calledBySample/{sample}/results/variants/genome.S1.vcf.gz.tbi']
    (79, '            else "strelka2/calledBySample/{sample}/results/variants/genome.S1.vcf.gz.tbi"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NCI-CGR/GEMSCAN, file=workflow/rules/Snakefile_Strelka2
context_key: ['rule strelka2_callVariant', 'output', 'if by_chro']
    (83, '            if by_chrom')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NCI-CGR/GEMSCAN, file=workflow/rules/Snakefile_Strelka2
context_key: ['rule strelka2_callVariant', 'output', 'else "strelka2/calledBySample/{sample}/results/variants/variants.vcf.gz']
    (84, '            else "strelka2/calledBySample/{sample}/results/variants/variants.vcf.gz"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NCI-CGR/GEMSCAN, file=workflow/rules/Snakefile_Strelka2
context_key: ['rule strelka2_callVariant', 'output', 'if by_chro']
    (88, '            if by_chrom')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NCI-CGR/GEMSCAN, file=workflow/rules/Snakefile_Strelka2
context_key: ['rule strelka2_callVariant', 'output', 'else "strelka2/calledBySample/{sample}/results/variants/variants.vcf.gz.tbi']
    (89, '            else "strelka2/calledBySample/{sample}/results/variants/variants.vcf.gz.tbi"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NCI-CGR/GEMSCAN, file=workflow/rules/Snakefile_Strelka2
context_key: ['rule strelka2_callVariant', 'params', 'if by_chro']
    (94, '            if by_chrom')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NCI-CGR/GEMSCAN, file=workflow/rules/Snakefile_Strelka2
context_key: ['rule strelka2_callVariant', 'params', 'else outputDir + "strelka2/calledBySample/{sample}']
    (95, '            else outputDir + "strelka2/calledBySample/{sample}"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NCI-CGR/GEMSCAN, file=workflow/rules/Snakefile_Strelka2
context_key: ['rule Strelka2_GLmerge_gvcfs', 'input', 'if by_chro']
    (180, '            if by_chrom')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NCI-CGR/GEMSCAN, file=workflow/rules/Snakefile_Strelka2
context_key: ['rule Strelka2_GLmerge_gvcfs', 'input', 'else expand("strelka2/called/genome.{sample}.vcf.gz", sample=sampleList']
    (181, '            else expand("strelka2/called/genome.{sample}.vcf.gz", sample=sampleList)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NCI-CGR/GEMSCAN, file=workflow/rules/Snakefile_Strelka2
context_key: ['rule Strelka2_GLmerge_gvcfs', 'input', 'if by_chro']
    (185, '            if by_chrom')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NCI-CGR/GEMSCAN, file=workflow/rules/Snakefile_Strelka2
context_key: ['rule Strelka2_GLmerge_gvcfs', 'input', 'else "strelka2/called/gvcfs/manifest.txt']
    (186, '            else "strelka2/called/gvcfs/manifest.txt"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NCI-CGR/GEMSCAN, file=workflow/rules/Snakefile_Strelka2
context_key: ['rule Strelka2_GLmerge_gvcfs', 'params', 'else "Strelka2_GLmerge_gvcfs/']
    (197, '            else "Strelka2_GLmerge_gvcfs/"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NCI-CGR/GEMSCAN, file=workflow/rules/Snakefile_Strelka2
context_key: ['rule strelka2_create_cohort_manifest', 'params', 'if by_chro']
    (249, '            if by_chrom')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NCI-CGR/GEMSCAN, file=workflow/rules/Snakefile_Strelka2
context_key: ['rule strelka2_create_cohort_manifest', 'params', 'else outputDir + "strelka2/called/manifests/']
    (250, '            else outputDir + "strelka2/called/manifests/"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NCI-CGR/GEMSCAN, file=workflow/rules/Snakefile_HaplotypeCaller
context_key: ['rule HC_call_variants', 'output', 'if by_chro']
    (32, '            if by_chrom')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NCI-CGR/GEMSCAN, file=workflow/rules/Snakefile_HaplotypeCaller
context_key: ['rule HC_call_variants', 'output', 'else "HaplotypeCaller/called/{sample}.g.vcf']
    (33, '            else "HaplotypeCaller/called/{sample}.g.vcf"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NCI-CGR/GEMSCAN, file=workflow/rules/Snakefile_HaplotypeCaller
context_key: ['rule HC_call_variants', 'output', 'if by_chro']
    (37, '            if by_chrom')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NCI-CGR/GEMSCAN, file=workflow/rules/Snakefile_HaplotypeCaller
context_key: ['rule HC_call_variants', 'output', 'else "HaplotypeCaller/called/{sample}.g.vcf.idx']
    (38, '            else "HaplotypeCaller/called/{sample}.g.vcf.idx"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NCI-CGR/GEMSCAN, file=workflow/rules/Snakefile_HaplotypeCaller
context_key: ['rule HC_compress_gvcfs', 'input', 'if by_chro']
    (68, '            if by_chrom')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NCI-CGR/GEMSCAN, file=workflow/rules/Snakefile_HaplotypeCaller
context_key: ['rule HC_compress_gvcfs', 'input', 'else "HaplotypeCaller/called/{sample}.g.vcf']
    (69, '            else "HaplotypeCaller/called/{sample}.g.vcf"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NCI-CGR/GEMSCAN, file=workflow/rules/Snakefile_HaplotypeCaller
context_key: ['rule HC_compress_gvcfs', 'input', 'if by_chro']
    (73, '            if by_chrom')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NCI-CGR/GEMSCAN, file=workflow/rules/Snakefile_HaplotypeCaller
context_key: ['rule HC_compress_gvcfs', 'input', 'else "HaplotypeCaller/called/{sample}.g.vcf.idx']
    (74, '            else "HaplotypeCaller/called/{sample}.g.vcf.idx"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NCI-CGR/GEMSCAN, file=workflow/rules/Snakefile_HaplotypeCaller
context_key: ['rule HC_create_cohort_manifest', 'params', 'if by_chro']
    (126, '            if by_chrom')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NCI-CGR/GEMSCAN, file=workflow/rules/Snakefile_HaplotypeCaller
context_key: ['rule HC_create_cohort_manifest', 'params', 'else outputDir + "HaplotypeCaller/called/gvcfs/']
    (127, '            else outputDir + "HaplotypeCaller/called/gvcfs/"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NCI-CGR/GEMSCAN, file=workflow/rules/Snakefile_HaplotypeCaller
context_key: ['rule HC_GLmerge_gvcfs', 'input', 'if by_chro']
    (138, '            if by_chrom')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NCI-CGR/GEMSCAN, file=workflow/rules/Snakefile_HaplotypeCaller
context_key: ['rule HC_GLmerge_gvcfs', 'input', 'else expand("HaplotypeCaller/called/{sample}.g.vcf.gz", sample=sampleList']
    (139, '            else expand("HaplotypeCaller/called/{sample}.g.vcf.gz", sample=sampleList)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NCI-CGR/GEMSCAN, file=workflow/rules/Snakefile_HaplotypeCaller
context_key: ['rule HC_GLmerge_gvcfs', 'input', 'if by_chro']
    (143, '            if by_chrom')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NCI-CGR/GEMSCAN, file=workflow/rules/Snakefile_HaplotypeCaller
context_key: ['rule HC_GLmerge_gvcfs', 'input', 'else "HaplotypeCaller/called/gvcfs/manifest.txt']
    (144, '            else "HaplotypeCaller/called/gvcfs/manifest.txt"')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NCI-CGR/GEMSCAN, file=workflow/rules/Snakefile_HaplotypeCaller
context_key: ['rule HC_indexBCF', 'input', 'else "HaplotypeCaller/genotyped/HC_variants.bcf")']
    (194, '             else "HaplotypeCaller/genotyped/HC_variants.bcf"),')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NCI-CGR/GEMSCAN, file=workflow/rules/Snakefile_HaplotypeCaller
context_key: ['rule HC_indexBCF', 'output', 'else "HaplotypeCaller/genotyped/HC_variants.bcf.csi")']
    (197, '             else "HaplotypeCaller/genotyped/HC_variants.bcf.csi"),')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=mozilla/firefox-translations-training, file=Snakefile
context_key: ['rule evaluate', 'input', "if wildcards.model != \\'teacher-ensemble\\"]
    (769, "                                    if wildcards.model != \\'teacher-ensemble\\'")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=mozilla/firefox-translations-training, file=Snakefile
context_key: ['rule evaluate', 'input', "else [f\\'{final_teacher_dir}{ens}/{best_model}\\' for ens in ensemble"]
    (770, "                                    else [f\\'{final_teacher_dir}{ens}/{best_model}\\' for ens in ensemble]")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=mozilla/firefox-translations-training, file=Snakefile
context_key: ['rule evaluate', 'params', "if wildcards.model != \\'teacher-ensemble\\"]
    (780, "                            if wildcards.model != \\'teacher-ensemble\\'")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=mozilla/firefox-translations-training, file=Snakefile
context_key: ['rule evaluate', 'params', "else f\\'{final_teacher_dir}0/{best_model}.decoder.yml\\"]
    (781, "                            else f\\'{final_teacher_dir}0/{best_model}.decoder.yml\\'")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=VUEG/bdes_to, file=Snakefile
context_key: ['rule preprocess_nuts_level2_data', 'run', 'if country_code in PROJECT_COUNTRIES']
    (224, '                        if country_code in PROJECT_COUNTRIES:')
    (225, "                            f[\\'properties\\'][\\'ID\\'] = ID")
    (226, '                            ID += 1')
    (227, "                            f[\\'properties\\'][\\'country\\'] = country_code")
    (228, '                            # Write the record out.')
    (229, '                            sink.write(f)')
    (230, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=VUEG/bdes_to, file=Snakefile
context_key: ['rule harmonize_data', 'run', 'if s_raster.endswith(".zip")', 'if not os.path.exists(target_dir)']
    (407, '            if s_raster.endswith(".zip"):')
    (408, '                target_dir = s_raster.replace("external", "processed/features_flow_zones")')
    (409, '                target_dir = os.path.dirname(target_dir)')
    (410, '                # Get rid of the last path component to avoid repetition')
    (411, '                target_dir = os.path.sep.join(target_dir.split(os.path.sep)[:-1])')
    (412, '                if not os.path.exists(target_dir):')
    (413, '                    os.mkdir(target_dir)')
    (414, '                prefix = utils.get_iteration_prefix(i+1, nsteps)')
    (415, '                llogger.info("{0} Unzipping dataset {1}".format(prefix, s_raster))')
    (416, '                shell("unzip -o {} -d {} >& {}".format(s_raster, target_dir, log[0]))')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=VUEG/bdes_to, file=Snakefile
context_key: ['rule harmonize_data', 'run', 'if s_raster.endswith(".zip")', 'else', 'if s_raster == input.like_raster']
    (417, '            else:')
    (418, '                ## WARP')
    (419, '                # Target raster')
    (420, '                warped_raster = s_raster.replace("external", "interim/warped")')
    (421, '                # No need to process the snap raster, just copy it')
    (422, '                prefix = utils.get_iteration_prefix(i+1, nsteps)')
    (423, '                if s_raster == input.like_raster:')
    (424, '                    llogger.info("{0} Copying dataset {1}".format(prefix, s_raster))')
    (425, '                    llogger.debug("{0} Target dataset {1}".format(prefix, warped_raster))')
    (426, '                    ret = shell("cp {s_raster} {warped_raster}", read=True)')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=VUEG/bdes_to, file=Snakefile
context_key: ['rule harmonize_data', 'run', 'if s_raster.endswith(".zip")', 'else', 'else']
    (427, '                else:')
    (428, '                    llogger.info("{0} Warping dataset {1}".format(prefix, s_raster))')
    (429, '                    llogger.debug("{0} Target dataset {1}".format(prefix, warped_raster))')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=kircherlab/MPRAsnakeflow, file=workflow/rules/assignment.smk
context_key: ['rule assignment_filter', 'params', 'else ""']
    (294, '        else "",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=kircherlab/MPRAsnakeflow, file=workflow/rules/assignment.smk
context_key: ['rule assignment_filter', 'params', 'else ""']
    (299, '        else "",')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NCI-CGR/QIIME_pipeline, file=workflow/Snakefile
context_key: ['rule merge_feature_tables', 'run', 'if len(RUN_IDS) == 1']
    (530, '        if len(RUN_IDS) == 1:')
    (531, "            shell(\\'cp {input.feature_tables} {output}\\')")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NCI-CGR/QIIME_pipeline, file=workflow/Snakefile
context_key: ['rule merge_feature_tables', 'run', 'elif Q2_2017']
    (532, '        elif Q2_2017:')
    (533, "            shell(\\'bash {params.e}workflow/scripts/q2_2017_table_merge.sh {params.tp} {output} {input.feature_tables}\\')")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NCI-CGR/QIIME_pipeline, file=workflow/Snakefile
context_key: ['rule merge_sequence_tables', 'run', 'if len(RUN_IDS) == 1']
    (557, '        if len(RUN_IDS) == 1:')
    (558, "            shell(\\'cp {input.seqs} {output}\\')")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=NCI-CGR/QIIME_pipeline, file=workflow/Snakefile
context_key: ['rule merge_sequence_tables', 'run', 'elif Q2_2017']
    (559, '        elif Q2_2017:')
    (560, "            shell(\\'bash {params.e}workflow/scripts/q2_2017_table_merge.sh {params.tp} {output} {input.seqs}\\')")
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

repo=sravel/RattleSNP, file=rattleSNP/snakefiles/Snakefile
context_key: ['if fail return default value define on each rule']
    (52, '    if fail return default value define on each rules')
    (53, '')
-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  

