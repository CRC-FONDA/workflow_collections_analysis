{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e1eb0c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing DOT file: airrflow_dag.dot\n",
      "Processing DOT file: ampliseq_dag.dot\n",
      "Processing DOT file: atacseq_dag.dot\n",
      "Processing DOT file: bacass_dag.dot\n",
      "Processing DOT file: bamtofastq_dag.dot\n",
      "Processing DOT file: cageseq_dag.dot\n",
      "Processing DOT file: callingcards_dag.dot\n",
      "Processing DOT file: chipseq_dag.dot\n",
      "Processing DOT file: circdna_dag.dot\n",
      "Processing DOT file: circrna_dag.dot\n",
      "Processing DOT file: clipseq_dag.dot\n",
      "Processing DOT file: coproid_dag.dot\n",
      "Processing DOT file: createpanelrefs_dag.dot\n",
      "Processing DOT file: createtaxdb_dag.dot\n",
      "Processing DOT file: crisprseq_dag.dot\n",
      "Processing DOT file: cutandrun_dag.dot\n",
      "Processing DOT file: ddamsproteomics_dag.dot\n",
      "Processing DOT file: demultiplex_dag.dot\n",
      "Processing DOT file: denovohybrid_dag.dot\n",
      "Processing DOT file: detaxizer_dag.dot\n",
      "Processing DOT file: diaproteomics_dag.dot\n",
      "Processing DOT file: differentialabundance_dag.dot\n",
      "Processing DOT file: dualrnaseq_dag.dot\n",
      "Processing DOT file: eager_dag.dot\n",
      "Processing DOT file: epitopeprediction_dag.dot\n",
      "Processing DOT file: funcscan_dag.dot\n",
      "Processing DOT file: genomeannotator_dag.dot\n",
      "Processing DOT file: genomeassembler_dag.dot\n",
      "Processing DOT file: genomeskim_dag.dot\n",
      "Processing DOT file: gwas_dag.dot\n",
      "Processing DOT file: hgtseq_dag.dot\n",
      "Processing DOT file: hicar_dag.dot\n",
      "Processing DOT file: hic_dag.dot\n",
      "Processing DOT file: hlatyping_dag.dot\n",
      "Processing DOT file: imcyto_dag.dot\n",
      "Processing DOT file: isoseq_dag.dot\n",
      "Processing DOT file: kmermaid_dag.dot\n",
      "Processing DOT file: liverctanalysis_dag.dot\n",
      "Processing DOT file: mag_dag.dot\n",
      "Processing DOT file: metaboigniter_dag.dot\n",
      "Processing DOT file: metapep_dag.dot\n",
      "Processing DOT file: metatdenovo_dag.dot\n",
      "Processing DOT file: methylseq_dag.dot\n",
      "Processing DOT file: mnaseseq_dag.dot\n",
      "Processing DOT file: nanoseq_dag.dot\n",
      "Processing DOT file: nanostring_dag.dot\n",
      "Processing DOT file: nascent_dag.dot\n",
      "Processing DOT file: pangenome_dag.dot\n",
      "Processing DOT file: pgdb_dag.dot\n",
      "Processing DOT file: phageannotator_dag.dot\n",
      "Processing DOT file: phyloplace_dag.dot\n",
      "Processing DOT file: pixelator_dag.dot\n",
      "Processing DOT file: proteinfold_dag.dot\n",
      "Processing DOT file: proteomicslfq_dag.dot\n",
      "Processing DOT file: quantms_dag.dot\n",
      "Processing DOT file: rangeland_dag.dot\n",
      "Skipping processing for: raredisease_dag.dot\n",
      "Processing DOT file: readsimulator_dag.dot\n",
      "Processing DOT file: rnadnavar_dag.dot\n",
      "Processing DOT file: rnaseq_dag.dot\n",
      "Processing DOT file: rnasplice_dag.dot\n",
      "Processing DOT file: rnavar_dag.dot\n",
      "Processing DOT file: sammyseq_dag.dot\n",
      "Processing DOT file: sarek_dag.dot\n",
      "Processing DOT file: scflow_dag.dot\n",
      "Processing DOT file: scrnaseq_dag.dot\n",
      "Processing DOT file: slamseq_dag.dot\n",
      "Processing DOT file: smartseq2_dag.dot\n",
      "Processing DOT file: smrnaseq_dag.dot\n",
      "Processing DOT file: spinningjenny_dag.dot\n",
      "Processing DOT file: ssds_dag.dot\n",
      "Processing DOT file: taxprofiler_dag.dot\n",
      "Processing DOT file: viralintegration_dag.dot\n",
      "Processing DOT file: viralrecon_dag.dot\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import networkx as nx\n",
    "\n",
    "def get_graph(dot_file):\n",
    "    G = nx.nx_agraph.read_dot(dot_file)\n",
    "    \n",
    "    nodes_to_delete = [node for node, attr in G.nodes(data=True) if 'shape' in attr]\n",
    "\n",
    "    node_labels = {}\n",
    "\n",
    "    for node, attr in G.nodes(data=True):\n",
    "        label = attr.get('label', '') \n",
    "        if label.startswith('\"') and label.endswith('\"'):\n",
    "            label = label[1:-1]\n",
    "        node_labels[node] = label\n",
    "\n",
    "    for node in nodes_to_delete:\n",
    "        # connect in and out nodes with parent and child, delete channel nodes\n",
    "        for in_src, _ in G.in_edges(node):\n",
    "            for _, out_dst in G.out_edges(node):\n",
    "                G.add_edge(in_src, out_dst)\n",
    "\n",
    "        G.remove_node(node)\n",
    "    \n",
    "    if len(G.nodes()) == 0:\n",
    "        return [], None, None, None\n",
    "    \n",
    "    longest_path = nx.dag_longest_path(G)\n",
    "    \n",
    "    # if longest path empty, return empty list\n",
    "    if len(longest_path) == 0:\n",
    "        return [], None, None, None\n",
    "    \n",
    "    # source node is first node\n",
    "    source_node = longest_path[0]\n",
    "    \n",
    "    # target node is last node of longest path\n",
    "    target_node = longest_path[-1]\n",
    "    \n",
    "    return G, source_node, target_node, node_labels\n",
    "\n",
    "def find_all_paths_between_nodes(G, source, target):\n",
    "    all_paths = list(nx.all_simple_paths(G, source, target))\n",
    "    return all_paths\n",
    "\n",
    "def find_repeated_patterns(lst):\n",
    "    patterns = set()\n",
    "    repeated_patterns = set()\n",
    "    \n",
    "    for pattern_length in range(2, len(lst)+1):\n",
    "        for i in range(len(lst) - pattern_length + 1):\n",
    "            pattern = tuple(lst[i:i+pattern_length])\n",
    "            if len(set(pattern)) == pattern_length:\n",
    "                if pattern in patterns:\n",
    "                    repeated_patterns.add(pattern)\n",
    "                else:\n",
    "                    patterns.add(pattern)\n",
    "    \n",
    "    return repeated_patterns\n",
    "\n",
    "def process_dot_file(dot_file):\n",
    "    # skipping this file, hardcoded\n",
    "    if os.path.basename(dot_file) == 'raredisease_dag.dot':\n",
    "        print(\"Skipping processing for:\", os.path.basename(dot_file))\n",
    "        return\n",
    "    \n",
    "    G, source_node, target_node, node_labels = get_graph(dot_file)\n",
    "    print(\"Processing DOT file:\", os.path.basename(dot_file))\n",
    "    if G:\n",
    "        paths = find_all_paths_between_nodes(G, source_node, target_node)\n",
    "        repeated_patterns = set()\n",
    "        pattern_found = False\n",
    "        for path in paths:\n",
    "            labels = [node_labels[node] for node in path]\n",
    "            path_repeated_patterns = find_repeated_patterns(labels)\n",
    "            repeated_patterns.update(path_repeated_patterns)\n",
    "            if repeated_patterns and not pattern_found:\n",
    "                pattern_found = True\n",
    "                with open(\"./results/repetition_pattern.txt\", \"w\") as output_file:\n",
    "                    output_file.write(\"File: {}\\n\".format(os.path.basename(dot_file)))\n",
    "                    for pattern in repeated_patterns:\n",
    "                        output_file.write(\"Repeated Pattern: {}\\n\".format(pattern))\n",
    "                        output_file.write(\"Path: {}\\n\".format(labels))\n",
    "                print(pattern)\n",
    "                print(labels)\n",
    "                print(\"Repeated patterns written to repetition.txt\")\n",
    "                break\n",
    "\n",
    "\n",
    "\n",
    "directory = \"./dags/\"\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".dot\"):\n",
    "        dot_file = os.path.join(directory, filename)\n",
    "        process_dot_file(dot_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df026018",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
