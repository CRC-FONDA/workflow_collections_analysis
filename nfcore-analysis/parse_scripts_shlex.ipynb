{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c5aaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "import shlex\n",
    "import pandas as pd\n",
    "\n",
    "def preprocess_token(token):\n",
    "    token = token.strip(\"-:\")\n",
    "    return token\n",
    "\n",
    "def find_operators_in_script(directory, pattern_list, output_file_name):\n",
    "    result_list = []\n",
    "\n",
    "    for pipeline in os.listdir(directory):\n",
    "        subdirectory_path = os.path.join(directory, pipeline)\n",
    "        folder_name = os.path.basename(subdirectory_path)\n",
    "        #print(pipeline)\n",
    "\n",
    "        for root, dirs, files in os.walk(subdirectory_path):\n",
    "            for filename in files:\n",
    "                file_path = os.path.join(root, filename)\n",
    "                \n",
    "                if filename.endswith('.nf'):\n",
    "                    try:\n",
    "                        with open(file_path, 'r', encoding='utf-8', errors='ignore') as file:\n",
    "                            lines = file.readlines()\n",
    "                        \n",
    "                        inside_block = False\n",
    "                        process_name = None\n",
    "                        continuation_line = \"\"\n",
    "\n",
    "                        process_pattern = r'process\\s+(\\w+)\\s*{'\n",
    "                        \n",
    "                        for line_num, line in enumerate(lines):\n",
    "                            line = continuation_line + line\n",
    "                            continuation_line = \"\"\n",
    "\n",
    "                            stripped_line = line.strip()\n",
    "                            \n",
    "                            if line.strip().startswith(('#', '//', '*')):\n",
    "                                continue\n",
    "\n",
    "                            if re.search(process_pattern, stripped_line):\n",
    "                                process_flag = True\n",
    "                                process_match = re.search(process_pattern, stripped_line)\n",
    "                                if process_match:\n",
    "                                    process_name = process_match.group(1)\n",
    "\n",
    "                            if '\"\"\"' in stripped_line:\n",
    "                                inside_block = not inside_block\n",
    "                                continue\n",
    "\n",
    "                            if inside_block:\n",
    "                                if stripped_line.endswith(\"\\\\\"):\n",
    "                                    continuation_line = stripped_line[:-2]\n",
    "                                    continue\n",
    "\n",
    "                                lexer = shlex.shlex(stripped_line, posix=True)\n",
    "                                lexer.whitespace_split = True\n",
    "                                tokens = list(lexer)\n",
    "                                #print(tokens)\n",
    "                                \n",
    "                                for token in tokens:\n",
    "                                    processed_token = preprocess_token(token)\n",
    "                                    if processed_token in pattern_list:\n",
    "                                        result_list.append([folder_name, process_name, processed_token, file_path, line_num+1, stripped_line])\n",
    "                    except Exception as e:\n",
    "                        #print(f\"Error processing file '{file_path}' in line {line_num}: {e}\")\n",
    "                        continue \n",
    "\n",
    "    write_to_csv(result_list, output_file_name)\n",
    "\n",
    "def write_to_csv(result_list, output_file_name):\n",
    "    with open(f'./results/{output_file_name}.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(['pipeline', 'process_name', 'operator', 'file_path', 'line_number', 'line_content'])\n",
    "        writer.writerows(result_list)\n",
    "        \n",
    "directory_path = './git_repos/'\n",
    "\n",
    "df_operators = pd.read_excel('./data/all_operator_dataset.xlsx')\n",
    "operator_list = [str(operator) for operator in df_operators['operator']]\n",
    "\n",
    "output_file_name = 'all_operators_in_scripts_shlex'\n",
    "\n",
    "find_operators_in_script(directory_path, operator_list, output_file_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46633739",
   "metadata": {},
   "source": [
    "Change Assigned Group of Bioinformatic Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bca17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import pandas as pd\n",
    "\n",
    "bio_tools = pd.read_excel(\"./data/bioinformatics_tools.xlsx\")\n",
    "all_operators = pd.read_csv(\"./data/operator_dataset_clustered.csv\")\n",
    "\n",
    "operators_set = set(bio_tools['operator'])\n",
    "all_operators.loc[all_operators['Operator'].isin(operators_set), 'Assigned Group'] = 0\n",
    "\n",
    "\n",
    "#print(all_operators[all_operators['Assigned Group'] == 0])\n",
    "\n",
    "all_operators.to_csv(\"./data/operator_dataset_clustered_edited.csv\", index=False)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd56508d",
   "metadata": {},
   "source": [
    "# Analysis of the processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e4d14565",
   "metadata": {},
   "outputs": [],
   "source": [
    "#operator_script = pd.read_csv('./results/all_operators_in_processes_shlex.csv')\n",
    "\n",
    "operator_script = pd.read_csv('./results/all_operators_in_scripts_shlex.csv')\n",
    "df_operator_clustered = pd.read_csv('./data/operator_dataset_clustered_edited.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4331487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pipeline</th>\n",
       "      <th>process_name</th>\n",
       "      <th>operator</th>\n",
       "      <th>file_path</th>\n",
       "      <th>line_number</th>\n",
       "      <th>line_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>airrflow</td>\n",
       "      <td>FASTQC_POSTASSEMBLY</td>\n",
       "      <td>[</td>\n",
       "      <td>./git_repos/airrflow\\modules\\local\\fastqc_post...</td>\n",
       "      <td>23</td>\n",
       "      <td>[ ! -f  ${prefix}.fastq ] &amp;&amp; ln -s $reads ${pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>airrflow</td>\n",
       "      <td>FASTQC_POSTASSEMBLY</td>\n",
       "      <td>!</td>\n",
       "      <td>./git_repos/airrflow\\modules\\local\\fastqc_post...</td>\n",
       "      <td>23</td>\n",
       "      <td>[ ! -f  ${prefix}.fastq ] &amp;&amp; ln -s $reads ${pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>airrflow</td>\n",
       "      <td>FASTQC_POSTASSEMBLY</td>\n",
       "      <td>f</td>\n",
       "      <td>./git_repos/airrflow\\modules\\local\\fastqc_post...</td>\n",
       "      <td>23</td>\n",
       "      <td>[ ! -f  ${prefix}.fastq ] &amp;&amp; ln -s $reads ${pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>airrflow</td>\n",
       "      <td>FASTQC_POSTASSEMBLY</td>\n",
       "      <td>]</td>\n",
       "      <td>./git_repos/airrflow\\modules\\local\\fastqc_post...</td>\n",
       "      <td>23</td>\n",
       "      <td>[ ! -f  ${prefix}.fastq ] &amp;&amp; ln -s $reads ${pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>airrflow</td>\n",
       "      <td>FASTQC_POSTASSEMBLY</td>\n",
       "      <td>&amp;&amp;</td>\n",
       "      <td>./git_repos/airrflow\\modules\\local\\fastqc_post...</td>\n",
       "      <td>23</td>\n",
       "      <td>[ ! -f  ${prefix}.fastq ] &amp;&amp; ln -s $reads ${pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26717</th>\n",
       "      <td>viralrecon</td>\n",
       "      <td>UNTAR</td>\n",
       "      <td>touch</td>\n",
       "      <td>./git_repos/viralrecon\\modules\\nf-core\\untar\\m...</td>\n",
       "      <td>56</td>\n",
       "      <td>touch ${prefix}/file.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26718</th>\n",
       "      <td>viralrecon</td>\n",
       "      <td>UNTAR</td>\n",
       "      <td>cat</td>\n",
       "      <td>./git_repos/viralrecon\\modules\\nf-core\\untar\\m...</td>\n",
       "      <td>58</td>\n",
       "      <td>cat &lt;&lt;-END_VERSIONS &gt; versions.yml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26719</th>\n",
       "      <td>viralrecon</td>\n",
       "      <td>UNTAR</td>\n",
       "      <td>sed</td>\n",
       "      <td>./git_repos/viralrecon\\modules\\nf-core\\untar\\m...</td>\n",
       "      <td>60</td>\n",
       "      <td>untar: \\$(echo \\$(tar --version 2&gt;&amp;1) | sed 's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26720</th>\n",
       "      <td>viralrecon</td>\n",
       "      <td>VCFLIB_VCFUNIQ</td>\n",
       "      <td>bgzip</td>\n",
       "      <td>./git_repos/viralrecon\\modules\\nf-core\\vcflib\\...</td>\n",
       "      <td>28</td>\n",
       "      <td>vcfuniq         $vcf         | bgzip -c $args ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26721</th>\n",
       "      <td>viralrecon</td>\n",
       "      <td>VCFLIB_VCFUNIQ</td>\n",
       "      <td>cat</td>\n",
       "      <td>./git_repos/viralrecon\\modules\\nf-core\\vcflib\\...</td>\n",
       "      <td>30</td>\n",
       "      <td>cat &lt;&lt;-END_VERSIONS &gt; versions.yml</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26722 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         pipeline         process_name operator  \\\n",
       "0        airrflow  FASTQC_POSTASSEMBLY        [   \n",
       "1        airrflow  FASTQC_POSTASSEMBLY        !   \n",
       "2        airrflow  FASTQC_POSTASSEMBLY        f   \n",
       "3        airrflow  FASTQC_POSTASSEMBLY        ]   \n",
       "4        airrflow  FASTQC_POSTASSEMBLY       &&   \n",
       "...           ...                  ...      ...   \n",
       "26717  viralrecon                UNTAR    touch   \n",
       "26718  viralrecon                UNTAR      cat   \n",
       "26719  viralrecon                UNTAR      sed   \n",
       "26720  viralrecon       VCFLIB_VCFUNIQ    bgzip   \n",
       "26721  viralrecon       VCFLIB_VCFUNIQ      cat   \n",
       "\n",
       "                                               file_path  line_number  \\\n",
       "0      ./git_repos/airrflow\\modules\\local\\fastqc_post...           23   \n",
       "1      ./git_repos/airrflow\\modules\\local\\fastqc_post...           23   \n",
       "2      ./git_repos/airrflow\\modules\\local\\fastqc_post...           23   \n",
       "3      ./git_repos/airrflow\\modules\\local\\fastqc_post...           23   \n",
       "4      ./git_repos/airrflow\\modules\\local\\fastqc_post...           23   \n",
       "...                                                  ...          ...   \n",
       "26717  ./git_repos/viralrecon\\modules\\nf-core\\untar\\m...           56   \n",
       "26718  ./git_repos/viralrecon\\modules\\nf-core\\untar\\m...           58   \n",
       "26719  ./git_repos/viralrecon\\modules\\nf-core\\untar\\m...           60   \n",
       "26720  ./git_repos/viralrecon\\modules\\nf-core\\vcflib\\...           28   \n",
       "26721  ./git_repos/viralrecon\\modules\\nf-core\\vcflib\\...           30   \n",
       "\n",
       "                                            line_content  \n",
       "0      [ ! -f  ${prefix}.fastq ] && ln -s $reads ${pr...  \n",
       "1      [ ! -f  ${prefix}.fastq ] && ln -s $reads ${pr...  \n",
       "2      [ ! -f  ${prefix}.fastq ] && ln -s $reads ${pr...  \n",
       "3      [ ! -f  ${prefix}.fastq ] && ln -s $reads ${pr...  \n",
       "4      [ ! -f  ${prefix}.fastq ] && ln -s $reads ${pr...  \n",
       "...                                                  ...  \n",
       "26717                           touch ${prefix}/file.txt  \n",
       "26718                 cat <<-END_VERSIONS > versions.yml  \n",
       "26719  untar: \\$(echo \\$(tar --version 2>&1) | sed 's...  \n",
       "26720  vcfuniq         $vcf         | bgzip -c $args ...  \n",
       "26721                 cat <<-END_VERSIONS > versions.yml  \n",
       "\n",
       "[26722 rows x 6 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "operator_script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "13381f65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "335"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_counts = operator_script[operator_script['operator'] == 'if'].value_counts()\n",
    "\n",
    "len(value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f268063b",
   "metadata": {},
   "outputs": [],
   "source": [
    "operator_script = operator_script[operator_script['operator'].str.len() >= 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d11d40fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_process = operator_script.groupby(['pipeline', 'process_name']).size().reset_index(name='operator_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0a921d31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pipeline</th>\n",
       "      <th>process_name</th>\n",
       "      <th>operator_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>airrflow</td>\n",
       "      <td>ADD_META_TO_TAB</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>airrflow</td>\n",
       "      <td>AIRRFLOW_REPORT</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>airrflow</td>\n",
       "      <td>CHANGEO_ASSIGNGENES</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>airrflow</td>\n",
       "      <td>CHANGEO_CONVERTDB_FASTA</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>airrflow</td>\n",
       "      <td>CHANGEO_CREATEGERMLINES</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2579</th>\n",
       "      <td>viralrecon</td>\n",
       "      <td>TABIX_BGZIP</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2580</th>\n",
       "      <td>viralrecon</td>\n",
       "      <td>TABIX_TABIX</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2581</th>\n",
       "      <td>viralrecon</td>\n",
       "      <td>UNICYCLER</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2582</th>\n",
       "      <td>viralrecon</td>\n",
       "      <td>UNTAR</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2583</th>\n",
       "      <td>viralrecon</td>\n",
       "      <td>VCFLIB_VCFUNIQ</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2584 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        pipeline             process_name  operator_count\n",
       "0       airrflow          ADD_META_TO_TAB               2\n",
       "1       airrflow          AIRRFLOW_REPORT               4\n",
       "2       airrflow      CHANGEO_ASSIGNGENES               4\n",
       "3       airrflow  CHANGEO_CONVERTDB_FASTA               5\n",
       "4       airrflow  CHANGEO_CREATEGERMLINES               5\n",
       "...          ...                      ...             ...\n",
       "2579  viralrecon              TABIX_BGZIP               8\n",
       "2580  viralrecon              TABIX_TABIX               8\n",
       "2581  viralrecon                UNICYCLER               8\n",
       "2582  viralrecon                    UNTAR              17\n",
       "2583  viralrecon           VCFLIB_VCFUNIQ               2\n",
       "\n",
       "[2584 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "operators_in_all_process = operator_script.groupby(['pipeline', 'process_name']).size().reset_index(name='operator_count')\n",
    "operators_in_all_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "edb8f7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_operator_clustered = df_operator_clustered.rename(columns={'Operator': 'operator'})\n",
    "\n",
    "merged_df = pd.merge(operator_script, df_operator_clustered, on='operator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3365ca6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pipeline</th>\n",
       "      <th>process_name</th>\n",
       "      <th>operator</th>\n",
       "      <th>file_path</th>\n",
       "      <th>line_number</th>\n",
       "      <th>line_content</th>\n",
       "      <th>Assigned Group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>airrflow</td>\n",
       "      <td>FASTQC_POSTASSEMBLY</td>\n",
       "      <td>&amp;&amp;</td>\n",
       "      <td>./git_repos/airrflow\\modules\\local\\fastqc_post...</td>\n",
       "      <td>23</td>\n",
       "      <td>[ ! -f  ${prefix}.fastq ] &amp;&amp; ln -s $reads ${pr...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>airrflow</td>\n",
       "      <td>COLLAPSE_DUPLICATES</td>\n",
       "      <td>&amp;&amp;</td>\n",
       "      <td>./git_repos/airrflow\\modules\\local\\enchantr\\co...</td>\n",
       "      <td>34</td>\n",
       "      <td>cp -r enchantr ${meta.id}_collapse_report &amp;&amp; r...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>airrflow</td>\n",
       "      <td>DETECT_CONTAMINATION</td>\n",
       "      <td>&amp;&amp;</td>\n",
       "      <td>./git_repos/airrflow\\modules\\local\\enchantr\\de...</td>\n",
       "      <td>33</td>\n",
       "      <td>cp -r enchantr all_reps_cont_report &amp;&amp; rm -rf ...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>airrflow</td>\n",
       "      <td>DOWSER_LINEAGES</td>\n",
       "      <td>&amp;&amp;</td>\n",
       "      <td>./git_repos/airrflow\\modules\\local\\enchantr\\do...</td>\n",
       "      <td>51</td>\n",
       "      <td>cp -r enchantr ${id_name}_dowser_report &amp;&amp; rm ...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>airrflow</td>\n",
       "      <td>FIND_THRESHOLD</td>\n",
       "      <td>&amp;&amp;</td>\n",
       "      <td>./git_repos/airrflow\\modules\\local\\enchantr\\fi...</td>\n",
       "      <td>59</td>\n",
       "      <td>cp -r enchantr all_reps_dist_report &amp;&amp; rm -rf ...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21640</th>\n",
       "      <td>viralrecon</td>\n",
       "      <td>NEXTCLADE_DATASETGET</td>\n",
       "      <td>nextclade</td>\n",
       "      <td>./git_repos/viralrecon\\modules\\nf-core\\nextcla...</td>\n",
       "      <td>39</td>\n",
       "      <td>nextclade: \\$(echo \\$(nextclade --version 2&gt;&amp;1...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21641</th>\n",
       "      <td>viralrecon</td>\n",
       "      <td>NEXTCLADE_RUN</td>\n",
       "      <td>nextclade</td>\n",
       "      <td>./git_repos/viralrecon\\modules\\nf-core\\nextcla...</td>\n",
       "      <td>40</td>\n",
       "      <td>nextclade         run         $args         --...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21642</th>\n",
       "      <td>viralrecon</td>\n",
       "      <td>NEXTCLADE_RUN</td>\n",
       "      <td>nextclade</td>\n",
       "      <td>./git_repos/viralrecon\\modules\\nf-core\\nextcla...</td>\n",
       "      <td>44</td>\n",
       "      <td>nextclade: \\$(echo \\$(nextclade --version 2&gt;&amp;1...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21643</th>\n",
       "      <td>viralrecon</td>\n",
       "      <td>PANGOLIN</td>\n",
       "      <td>pangolin</td>\n",
       "      <td>./git_repos/viralrecon\\modules\\nf-core\\pangoli...</td>\n",
       "      <td>28</td>\n",
       "      <td>pangolin         $fasta        --outfile ${pre...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21644</th>\n",
       "      <td>viralrecon</td>\n",
       "      <td>PANGOLIN</td>\n",
       "      <td>pangolin</td>\n",
       "      <td>./git_repos/viralrecon\\modules\\nf-core\\pangoli...</td>\n",
       "      <td>32</td>\n",
       "      <td>pangolin: \\$(pangolin --version | sed \"s/pango...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21645 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         pipeline          process_name   operator  \\\n",
       "0        airrflow   FASTQC_POSTASSEMBLY         &&   \n",
       "1        airrflow   COLLAPSE_DUPLICATES         &&   \n",
       "2        airrflow  DETECT_CONTAMINATION         &&   \n",
       "3        airrflow       DOWSER_LINEAGES         &&   \n",
       "4        airrflow        FIND_THRESHOLD         &&   \n",
       "...           ...                   ...        ...   \n",
       "21640  viralrecon  NEXTCLADE_DATASETGET  nextclade   \n",
       "21641  viralrecon         NEXTCLADE_RUN  nextclade   \n",
       "21642  viralrecon         NEXTCLADE_RUN  nextclade   \n",
       "21643  viralrecon              PANGOLIN   pangolin   \n",
       "21644  viralrecon              PANGOLIN   pangolin   \n",
       "\n",
       "                                               file_path  line_number  \\\n",
       "0      ./git_repos/airrflow\\modules\\local\\fastqc_post...           23   \n",
       "1      ./git_repos/airrflow\\modules\\local\\enchantr\\co...           34   \n",
       "2      ./git_repos/airrflow\\modules\\local\\enchantr\\de...           33   \n",
       "3      ./git_repos/airrflow\\modules\\local\\enchantr\\do...           51   \n",
       "4      ./git_repos/airrflow\\modules\\local\\enchantr\\fi...           59   \n",
       "...                                                  ...          ...   \n",
       "21640  ./git_repos/viralrecon\\modules\\nf-core\\nextcla...           39   \n",
       "21641  ./git_repos/viralrecon\\modules\\nf-core\\nextcla...           40   \n",
       "21642  ./git_repos/viralrecon\\modules\\nf-core\\nextcla...           44   \n",
       "21643  ./git_repos/viralrecon\\modules\\nf-core\\pangoli...           28   \n",
       "21644  ./git_repos/viralrecon\\modules\\nf-core\\pangoli...           32   \n",
       "\n",
       "                                            line_content  Assigned Group  \n",
       "0      [ ! -f  ${prefix}.fastq ] && ln -s $reads ${pr...               6  \n",
       "1      cp -r enchantr ${meta.id}_collapse_report && r...               6  \n",
       "2      cp -r enchantr all_reps_cont_report && rm -rf ...               6  \n",
       "3      cp -r enchantr ${id_name}_dowser_report && rm ...               6  \n",
       "4      cp -r enchantr all_reps_dist_report && rm -rf ...               6  \n",
       "...                                                  ...             ...  \n",
       "21640  nextclade: \\$(echo \\$(nextclade --version 2>&1...               6  \n",
       "21641  nextclade         run         $args         --...               6  \n",
       "21642  nextclade: \\$(echo \\$(nextclade --version 2>&1...               6  \n",
       "21643  pangolin         $fasta        --outfile ${pre...               6  \n",
       "21644  pangolin: \\$(pangolin --version | sed \"s/pango...               6  \n",
       "\n",
       "[21645 rows x 7 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "267bc0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_operators = merged_df[merged_df['Assigned Group'] == 0].groupby('operator')['operator'].count()\n",
    "nunique_pipeline = merged_df[merged_df['Assigned Group'] == 0].groupby('operator')['pipeline'].nunique()\n",
    "nunique_file_path = merged_df[merged_df['Assigned Group'] == 0].groupby('operator')['file_path'].nunique()\n",
    "\n",
    "bio_tools = pd.DataFrame({\n",
    "    'pipeline': nunique_pipeline,\n",
    "    'file_path': nunique_file_path,\n",
    "    'sum_operators': count_operators\n",
    "})\n",
    "\n",
    "bio_tools = bio_tools.sort_values(by='pipeline', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e54f0aba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pipeline</th>\n",
       "      <th>file_path</th>\n",
       "      <th>sum_operators</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>operator</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>multiqc</th>\n",
       "      <td>75</td>\n",
       "      <td>84</td>\n",
       "      <td>354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fastqc</th>\n",
       "      <td>60</td>\n",
       "      <td>61</td>\n",
       "      <td>304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samtools</th>\n",
       "      <td>53</td>\n",
       "      <td>342</td>\n",
       "      <td>988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fasta</th>\n",
       "      <td>23</td>\n",
       "      <td>31</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bwa</th>\n",
       "      <td>22</td>\n",
       "      <td>48</td>\n",
       "      <td>176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fastp</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cutadapt</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bedtools</th>\n",
       "      <td>19</td>\n",
       "      <td>56</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bowtie2-build</th>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bowtie2</th>\n",
       "      <td>17</td>\n",
       "      <td>34</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>picard</th>\n",
       "      <td>17</td>\n",
       "      <td>39</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tabix</th>\n",
       "      <td>14</td>\n",
       "      <td>26</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fastq</th>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bcftools</th>\n",
       "      <td>12</td>\n",
       "      <td>38</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trim_galore</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gffread</th>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>featureCounts</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gatk</th>\n",
       "      <td>10</td>\n",
       "      <td>115</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gtf2bed</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minimap2</th>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seqtk</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bedGraphToBigWig</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kraken2</th>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bwa-mem2</th>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NanoPlot</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vcftools</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macs2</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trimmomatic</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stringtie</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bamtools</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hisat2</th>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seqkit</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bedClip</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bamCoverage</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transcripts.fasta</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sortBed</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>salmon</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>complementBed</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mmseqs</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mergeBed</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>biom</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fgbio</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bam_stat.py</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sourmash</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>megahit</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bismark_genome_preparation</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>findMotifsGenome.pl</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abricate</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bismark_methylation_extractor</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gtdbtk</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bismark</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isoseq3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kallisto</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qiime</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bedToBigBed</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bedops</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multiBamSummary</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>checkm</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jgi_summarize_bam_contig_depths</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 pipeline  file_path  sum_operators\n",
       "operator                                                           \n",
       "multiqc                                75         84            354\n",
       "fastqc                                 60         61            304\n",
       "samtools                               53        342            988\n",
       "fasta                                  23         31             42\n",
       "bwa                                    22         48            176\n",
       "fastp                                  20         20            118\n",
       "cutadapt                               20         20             43\n",
       "bedtools                               19         56            149\n",
       "bowtie2-build                          18         19             19\n",
       "bowtie2                                17         34             94\n",
       "picard                                 17         39            112\n",
       "tabix                                  14         26             61\n",
       "fastq                                  14         16             24\n",
       "bcftools                               12         38            119\n",
       "trim_galore                            12         12             27\n",
       "gffread                                11         14             27\n",
       "featureCounts                          10         10             13\n",
       "gatk                                   10        115            126\n",
       "gtf2bed                                 9          9              9\n",
       "minimap2                                9         14             30\n",
       "seqtk                                   9         10             21\n",
       "bedGraphToBigWig                        8          8              8\n",
       "kraken2                                 8         10             19\n",
       "bwa-mem2                                7         14             15\n",
       "NanoPlot                                6          6              7\n",
       "vcftools                                4          5              8\n",
       "macs2                                   4          4              8\n",
       "trimmomatic                             4          4              8\n",
       "stringtie                               4          8             18\n",
       "bamtools                                4          4             12\n",
       "hisat2                                  4         13             29\n",
       "seqkit                                  4          5             21\n",
       "bedClip                                 4          4              4\n",
       "bamCoverage                             3          3              5\n",
       "transcripts.fasta                       3          3              6\n",
       "sortBed                                 3          3              3\n",
       "salmon                                  3          7             14\n",
       "complementBed                           3          3              3\n",
       "mmseqs                                  2          3              9\n",
       "mergeBed                                2          2              2\n",
       "biom                                    2          7              8\n",
       "fgbio                                   2         10             20\n",
       "bam_stat.py                             2          2              2\n",
       "sourmash                                2          3             14\n",
       "megahit                                 2          2              3\n",
       "bismark_genome_preparation              1          1              1\n",
       "findMotifsGenome.pl                     1          1              1\n",
       "abricate                                1          2              3\n",
       "bismark_methylation_extractor           1          1              1\n",
       "gtdbtk                                  1          1              3\n",
       "bismark                                 1          7              8\n",
       "isoseq3                                 1          1              3\n",
       "kallisto                                1          2              8\n",
       "qiime                                   1         24             76\n",
       "bedToBigBed                             1          1              1\n",
       "bedops                                  1          1              2\n",
       "multiBamSummary                         1          1              1\n",
       "checkm                                  1          2              6\n",
       "jgi_summarize_bam_contig_depths         1          1              1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bio_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f32d0ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['pipeline_process_name'] = merged_df['pipeline'] + \".\" + merged_df['process_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b9196750",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = merged_df.groupby('Assigned Group').agg({'pipeline': 'nunique', 'pipeline_process_name': 'nunique', 'operator': 'count'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e6869ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_processes = 3081"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "049e4994",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df['Ratio to total processes'] = grouped_df['pipeline_process_name']/sum_processes\n",
    "\n",
    "# insert to position 2\n",
    "position_to_insert = 1\n",
    "grouped_df.insert(position_to_insert, 'Ratio to total processes', grouped_df.pop('Ratio to total processes'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "81f27297",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = grouped_df.rename(columns={'file_path': 'Files', 'operator' : 'Total operator occurrences'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d42e177c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Assigned Group</th>\n",
       "      <th>Ratio to total processes</th>\n",
       "      <th>pipeline</th>\n",
       "      <th>pipeline_process_name</th>\n",
       "      <th>Total operator occurrences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.355080</td>\n",
       "      <td>85</td>\n",
       "      <td>1094</td>\n",
       "      <td>3217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.101266</td>\n",
       "      <td>84</td>\n",
       "      <td>312</td>\n",
       "      <td>1288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.283999</td>\n",
       "      <td>84</td>\n",
       "      <td>875</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.741318</td>\n",
       "      <td>81</td>\n",
       "      <td>2284</td>\n",
       "      <td>4052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.316780</td>\n",
       "      <td>91</td>\n",
       "      <td>976</td>\n",
       "      <td>1897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.078870</td>\n",
       "      <td>64</td>\n",
       "      <td>243</td>\n",
       "      <td>469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.714054</td>\n",
       "      <td>94</td>\n",
       "      <td>2200</td>\n",
       "      <td>8721</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Assigned Group  Ratio to total processes  pipeline  pipeline_process_name  \\\n",
       "0               0                  0.355080        85                   1094   \n",
       "1               1                  0.101266        84                    312   \n",
       "2               2                  0.283999        84                    875   \n",
       "3               3                  0.741318        81                   2284   \n",
       "4               4                  0.316780        91                    976   \n",
       "5               5                  0.078870        64                    243   \n",
       "6               6                  0.714054        94                   2200   \n",
       "\n",
       "   Total operator occurrences  \n",
       "0                        3217  \n",
       "1                        1288  \n",
       "2                        2001  \n",
       "3                        4052  \n",
       "4                        1897  \n",
       "5                         469  \n",
       "6                        8721  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5207c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_operators = merged_df[merged_df['Assigned Group'] == 0].groupby('operator')['operator'].count()\n",
    "nunique_pipeline = merged_df[merged_df['Assigned Group'] == 0].groupby('operator')['pipeline'].nunique()\n",
    "nunique_file_path = merged_df[merged_df['Assigned Group'] == 0].groupby('operator')['file_path'].nunique()\n",
    "\n",
    "bio_tools = pd.DataFrame({\n",
    "    'pipeline': nunique_pipeline,\n",
    "    'file_path': nunique_file_path,\n",
    "    'sum_operators': count_operators\n",
    "})\n",
    "\n",
    "bio_tools = bio_tools.sort_values(by='pipeline', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0c5c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "bio_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74044e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import re\n",
    "\n",
    "def find_operators_in_config(directory, operator_list, output_file_name):\n",
    "    result_list = []\n",
    "\n",
    "    for pipeline in os.listdir(directory):\n",
    "        subdirectory_path = os.path.join(directory, pipeline)\n",
    "        folder_name = os.path.basename(subdirectory_path)\n",
    "        print(pipeline)\n",
    "\n",
    "        for root, _, files in os.walk(subdirectory_path):\n",
    "            for file in files:\n",
    "                file_path = os.path.join(root, file)\n",
    "                if file.endswith('.config'):\n",
    "                    with open(file_path, 'r') as config_file:\n",
    "                        for line_number, line in enumerate(config_file, start=1):\n",
    "                            if line.strip().startswith(('#', '//', '*')):\n",
    "                                continue\n",
    "                            stripped_line = line.strip()\n",
    "                            for pattern in operator_list:\n",
    "                                pattern = r'\\s' + re.escape(pattern) + r'\\s'\n",
    "                                \n",
    "                                pattern = re.escape(pattern)\n",
    "                                if re.search(pattern, stripped_line):\n",
    "                                    result_list.append([folder_name, pattern, file_path, line_number, stripped_line])\n",
    "    \n",
    "    write_to_csv(result_list, output_file_name)\n",
    "\n",
    "def write_to_csv(result_list, output_file_name):\n",
    "    with open(f'./results/{output_file_name}.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(['pipeline', 'operator', 'file_path', 'line_number', 'line_content'])\n",
    "        writer.writerows(result_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4201ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = './git_repos/'\n",
    "\n",
    "df_operators = pd.read_csv('./data/operator_dataset_clustered_edited.csv')\n",
    "operator_list = [str(operator) for operator in df_operators[df_operators['Assigned Group'] == 0]['Operator']]\n",
    "\n",
    "output_file_name = 'all_operators_in_configs'\n",
    "\n",
    "find_operators_in_config(directory_path, operator_list, output_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b872ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "bio_in_config = pd.read_csv('./results/all_operators_in_configs.csv')\n",
    "\n",
    "bio_in_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094d959c",
   "metadata": {},
   "outputs": [],
   "source": [
    "exact_entry = 'BATCH_PROC'\n",
    "column_name = 'process_name'\n",
    "\n",
    "if df[df['process_name'] == exact_entry].empty:\n",
    "    print(f\"No exact entry '{exact_entry}' found in column '{column_name}'.\")\n",
    "else:\n",
    "    print(f\"Exact entry '{exact_entry}' found in column '{column_name}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c39ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "import shlex\n",
    "import pandas as pd\n",
    "\n",
    "def preprocess_token(token):\n",
    "    token = token.strip(\"-:\")\n",
    "    return token\n",
    "\n",
    "def find_operators_in_script(directory, pattern_list, output_file_name):\n",
    "    result_list = []\n",
    "\n",
    "    for pipeline in os.listdir(directory):\n",
    "        subdirectory_path = os.path.join(directory, pipeline)\n",
    "        folder_name = os.path.basename(subdirectory_path)\n",
    "        #print(pipeline)\n",
    "\n",
    "        for root, dirs, files in os.walk(subdirectory_path):\n",
    "            for filename in files:\n",
    "                file_path = os.path.join(root, filename)\n",
    "                \n",
    "                if filename.endswith('.nf'):\n",
    "                    try:\n",
    "                        with open(file_path, 'r', encoding='utf-8', errors='ignore') as file:\n",
    "                            lines = file.readlines()\n",
    "                        \n",
    "                        inside_block = False\n",
    "                        process_name = None\n",
    "                        continuation_line = \"\"\n",
    "\n",
    "                        process_pattern = r'process\\s+(\\w+)\\s*{'\n",
    "                        \n",
    "                        for line_num, line in enumerate(lines):\n",
    "                            line = continuation_line + line\n",
    "                            continuation_line = \"\"\n",
    "\n",
    "                            stripped_line = line.strip()\n",
    "                            \n",
    "                            if line.strip().startswith(('#', '//', '*')):\n",
    "                                continue\n",
    "\n",
    "                            if re.search(process_pattern, stripped_line):\n",
    "                                process_flag = True\n",
    "                                process_match = re.search(process_pattern, stripped_line)\n",
    "                                if process_match:\n",
    "                                    process_name = process_match.group(1)\n",
    "\n",
    "                            if '\"\"\"' in stripped_line:\n",
    "                                inside_block = not inside_block\n",
    "                                continue\n",
    "\n",
    "                            if inside_block:\n",
    "                                if stripped_line.endswith(\"\\\\\"):\n",
    "                                    continuation_line = stripped_line[:-2]\n",
    "                                    continue\n",
    "\n",
    "                                lexer = shlex.shlex(stripped_line, posix=True)\n",
    "                                lexer.whitespace_split = True\n",
    "                                tokens = list(lexer)\n",
    "                                #print(tokens)\n",
    "                                \n",
    "                                for token in tokens:\n",
    "                                    processed_token = preprocess_token(token)\n",
    "                                    if processed_token in pattern_list:\n",
    "                                        result_list.append([folder_name, process_name, processed_token, file_path, line_num+1, stripped_line])\n",
    "                    except Exception as e:\n",
    "                        #print(f\"Error processing file '{file_path}' in line {line_num}: {e}\")\n",
    "                        continue \n",
    "\n",
    "    write_to_csv(result_list, output_file_name)\n",
    "\n",
    "def write_to_csv(result_list, output_file_name):\n",
    "    with open(f'./results/{output_file_name}.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(['pipeline', 'process_name', 'operator', 'file_path', 'line_number', 'line_content'])\n",
    "        writer.writerows(result_list)\n",
    "        \n",
    "directory_path = './git_repos/'\n",
    "\n",
    "df_operators = pd.read_excel('./data/all_operator_dataset.xlsx')\n",
    "operator_list = [str(operator) for operator in df_operators['operator']]\n",
    "\n",
    "output_file_name = 'all_operators_in_scripts_shlex'\n",
    "\n",
    "find_operators_in_script(directory_path, operator_list, output_file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a85bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_operators_in_script(directory, operator_list, result_dir):\n",
    "    result_list = []\n",
    "\n",
    "    for pipeline in os.listdir(directory):\n",
    "        subdirectory_path = os.path.join(directory, pipeline)\n",
    "        folder_name = os.path.basename(subdirectory_path)\n",
    "        print(pipeline)\n",
    "\n",
    "        for root, dirs, files in os.walk(subdirectory_path):\n",
    "            for filename in files:\n",
    "                file_path = os.path.join(root, filename)\n",
    "                \n",
    "                if filename.endswith('.nf'):\n",
    "                    with open(file_path, 'r', encoding='utf-8', errors='ignore') as file:\n",
    "                        content = file.readlines()\n",
    "\n",
    "                        brace_stack = []\n",
    "                        process_flag = False  \n",
    "                        process_name = None\n",
    "\n",
    "                        for line_num, line in enumerate(content):  # Enumerate lines to get line number\n",
    "                            stripped_line = line.strip()\n",
    "                            \n",
    "                            if line.strip().startswith(('#', '//', '*')):\n",
    "                                continue\n",
    "                                \n",
    "                            process_pattern = r'process\\s+(\\w+)\\s*{'\n",
    "\n",
    "                            if re.search(process_pattern, stripped_line):\n",
    "                                process_flag = True\n",
    "                                process_match = re.search(process_pattern, stripped_line)\n",
    "                                if process_match:\n",
    "                                    process_name = process_match.group(1)\n",
    "                                    print(f'Process {process_name} in filepath {file_path}')\n",
    "                                    brace_stack.clear()\n",
    "\n",
    "                            if '{' in stripped_line:\n",
    "                                brace_stack.append('{')\n",
    "\n",
    "                            if '}' in stripped_line:\n",
    "                                if brace_stack:\n",
    "                                    brace_stack.pop()\n",
    "                                    if not brace_stack and process_flag:\n",
    "                                        process_flag = False\n",
    "                                        \n",
    "\n",
    "                            if process_flag and len(brace_stack) > 0:\n",
    "                                if stripped_line.endswith(\"\\\\\"):\n",
    "                                    continuation_line = stripped_line[:-2]\n",
    "                                    continue\n",
    "\n",
    "                                try:\n",
    "                                    lexer = shlex.shlex(stripped_line, posix=True)\n",
    "                                    lexer.whitespace_split = True\n",
    "                                    tokens = list(lexer)\n",
    "                                except ValueError:\n",
    "                                    continue\n",
    "                                \n",
    "                                for token in tokens:\n",
    "                                    processed_token = preprocess_token(token)\n",
    "                                    if processed_token in operator_list:\n",
    "                                        result_list.append([folder_name, process_name, processed_token, file_path, line_num+1, stripped_line])\n",
    "                                \n",
    "    write_to_csv(result_list, result_dir)\n",
    "\n",
    "\n",
    "def write_to_csv(result_list, output_file_name):\n",
    "    with open(output_file_name, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(['pipeline', 'process_name', 'operator', 'file_path', 'line_number', 'line_content'])\n",
    "        writer.writerows(result_list)\n",
    "        \n",
    "directory_path = './git_repos/'\n",
    "output_file_name = './results/all_operators_in_scripts_shlex.csv'\n",
    "\n",
    "# Read the Excel file to get the list of operators\n",
    "df_operators = pd.read_excel('./data/all_operator_dataset.xlsx')\n",
    "operator_list = [str(operator) for operator in df_operators['operator']]\n",
    "\n",
    "find_operators_in_script(directory_path, operator_list, output_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f9c05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "import shlex\n",
    "import pandas as pd\n",
    "\n",
    "def preprocess_token(token):\n",
    "    token = token.strip(\"-:\")\n",
    "    return token\n",
    "\n",
    "def find_operators_in_script(directory, pattern_list, output_file_name):\n",
    "    result_list = []\n",
    "\n",
    "    for pipeline in os.listdir(directory):\n",
    "        subdirectory_path = os.path.join(directory, pipeline)\n",
    "        folder_name = os.path.basename(subdirectory_path)\n",
    "        #print(pipeline)\n",
    "\n",
    "        for root, dirs, files in os.walk(subdirectory_path):\n",
    "            for filename in files:\n",
    "                file_path = os.path.join(root, filename)\n",
    "                \n",
    "                if filename.endswith('.nf'):\n",
    "                    try:\n",
    "                        with open(file_path, 'r', encoding='utf-8', errors='ignore') as file:\n",
    "                            lines = file.readlines()\n",
    "                        \n",
    "                        process_name = None\n",
    "                        process_flag = False\n",
    "                        brace_stack = [] \n",
    "\n",
    "                        process_pattern = r'process\\s+(\\w+)\\s*{'\n",
    "                        \n",
    "                        try:\n",
    "                            for line_num, line in enumerate(lines):\n",
    "\n",
    "                                # so there wont be issues with double quotation\n",
    "                                line = line.replace('\"', '')\n",
    "\n",
    "                                stripped_line = line.strip()\n",
    "                                if line.strip().startswith(('#', '//', '*', \"'\")):\n",
    "                                    continue\n",
    "\n",
    "                                if re.search(process_pattern, stripped_line):\n",
    "                                    process_flag = True\n",
    "                                    process_match = re.search(process_pattern, stripped_line)\n",
    "                                    if process_match:\n",
    "                                        process_name = process_match.group(1)\n",
    "                                    brace_stack.clear()\n",
    "\n",
    "                                if '{' in stripped_line:\n",
    "                                    brace_stack.append('{')\n",
    "\n",
    "                                if '}' in stripped_line:\n",
    "                                    if brace_stack:\n",
    "                                        brace_stack.pop()\n",
    "                                        if not brace_stack and process_flag:\n",
    "                                            process_flag = False\n",
    "\n",
    "                                if process_flag and len(brace_stack) > 0:\n",
    "                                    if stripped_line.endswith(\"\\\\\"):\n",
    "                                        continuation_line = stripped_line[:-2]\n",
    "                                        continue\n",
    "\n",
    "                                    lexer = shlex.shlex(stripped_line, posix=True)\n",
    "                                    lexer.whitespace_split = True\n",
    "                                    tokens = list(lexer)\n",
    "\n",
    "                                    for token in tokens:\n",
    "                                        processed_token = preprocess_token(token)\n",
    "                                        if processed_token in pattern_list:\n",
    "                                            result_list.append([folder_name, process_name, processed_token, file_path, line_num+1, stripped_line])\n",
    "                        except Exception as e:\n",
    "                            print(f\"Error, processing file '{file_path}' in line {line_num}: {e}\")\n",
    "                            continue \n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        print(f\"File not readable\")\n",
    "                        continue \n",
    "\n",
    "    write_to_csv(result_list, output_file_name)\n",
    "\n",
    "def write_to_csv(result_list, output_file_name):\n",
    "    with open(f'./results/{output_file_name}.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(['pipeline', 'process_name', 'operator', 'file_path', 'line_number', 'line_content'])\n",
    "        writer.writerows(result_list)\n",
    "        \n",
    "directory_path = './git_repos/'\n",
    "\n",
    "df_operators = pd.read_excel('./data/all_operator_dataset.xlsx')\n",
    "operator_list = [str(operator) for operator in df_operators['operator']]\n",
    "\n",
    "output_file_name = 'all_operators_in_processes_shlex'\n",
    "\n",
    "find_operators_in_script(directory_path, operator_list, output_file_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
